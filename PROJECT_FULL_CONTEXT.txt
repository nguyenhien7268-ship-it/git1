=== PROJECT STRUCTURE ===
code1/
    app_controller.py
    AUDIT_REPORT_V3.txt
    check_final_fix.py
    CLAUDE.md
    clean_run.py
    config.json
    conftest.py
    core_services.py
    debug_bridge_manager.py
    debug_de_backtest.py
    dummy_db.sqlite
    IMPLEMENTATION_SUMMARY.md
    loto_data_diagnostic.py
    lottery_service.py
    main_app.py
    MIGRATION_NOTES.md
    mock.db
    mock_db
    PR1_NOTES.md
    PROJECT_FULL_CONTEXT.txt
    PR_SCANNER_REFACTOR_SUMMARY.md
    PR_SUMMARY.md
    pyproject.toml
    pytest.ini
    python
    README.md
    requirements.txt
    setup.py
    TESTING_INFRASTRUCTURE_SUMMARY.md
    V77_UPGRADE_SUMMARY.md
    xoso.db
    data/
        xo_so_prizes_all_logic.db
    logic/
        adaptive_trainer.py
        ai_feature_extractor.py
        analytics.py
        backtester.py
        backtester_aggregation.py
        backtester_core.py
        backtester_scoring.py
        bridge_importer.py
        common_utils.py
        config_manager.py
        constants.py
        dashboard_analytics.py
        data_parser.py
        data_repository.py
        data_repository.py.bak_v5
        db_manager.py
        de_analytics.py
        de_backtester_core.py
        de_utils.py
        logger.py
        lo_analytics.py
        meta_learner.py
        ml_model.py
        models.py
        performance_monitor.py
        phase3_data_collector.py
        resilience.py
        utils.py
        validators.py
        __init__.py
        analytics/
            dashboard_scorer.py
            dashboard_scorer.py.bak_v3
            __init__.py
        backtest/
            __init__.py
        bridges/
            bridges_classic.py
            bridges_memory.py
            bridges_v16.py
            bridge_factory.py
            bridge_manager_core.py
            bridge_manager_de.py
            de_bridge_scanner.py
            de_performance.py
            i_bridge_strategy.py
            lo_bridge_scanner.py
            __init__.py
    migrations/
        001_add_de_metrics.sql
        README.md
    scripts/
        check_cau_bo_50_days.py
        config.json
        diagnose_bridge_sync.py
        fix_dashboard_na.py
        fix_v38_all.py
        force_update_predictions.py
        generate_digest.py
        inspect_last_row.py
        README.md
        test_de_memory_pipeline.py
        v77_phase2_finalize.py
        v77_phase3_check_progress.py
        v77_phase3_implement.py
        validate_bo_scoring.py
        verify_analysis_data.py
        verify_fix.py
        verify_v10_optimization.py
        verify_v39_upgrade.py
        v√° l·ªói.py
        jobs/
            db_schema_detector.py
            update_de_bridge_performance.py
            update_de_bridge_performance.py.bak
        migrations/
            add_de_metrics.py
    services/
        analysis_service.py
        bridge_service.py
        data_service.py
        __init__.py
    tests/
        conftest.py
        debug_de_system.py
        diagnose_bo_key.py
        README.md
        test_auto_manage_integration.py
        test_backtester_helpers_unit.py
        test_backtest_routing.py
        test_basic.py
        test_batch_operations.py
        test_bridges_classic_unit.py
        test_bridges_v16_unit.py
        test_bridge_importer.py
        test_common_utils_k1n.py
        test_config_manager.py
        test_constants.py
        test_dashboard_cau_dong.py
        test_db_manager.py
        test_db_manager_bulk.py
        test_db_manager_unit.py
        test_delete_ky.py
        test_de_performance_api.py
        test_de_visibility_policy.py
        test_lo_bridge_scanner.py
        test_memory_bridges.py
        test_phase2_features.py
        test_phase3_model_optimization.py
        test_recent_appearance_bonus.py
        test_recent_form_calculation.py
        test_recent_form_integration.py
        test_recommendation_system.py
        test_scanner_refactor.py
        test_scoring_functions.py
        test_smart_filtering.py
        test_ui_main_window.py
        test_ui_manager_headers.py
        test_update_de_bridge_performance.py
        test_utils_unit.py
        test_v77_phase2_features.py
        test_validators.py
        test_validators_unit.py
        logic/
            __init__.py
        ui/
            __init__.py
    ui/
        ui_bridge_management.py
        ui_bridge_manager.py
        ui_bridge_scanner.py
        ui_dashboard.py
        ui_dashboard.py.bak
        ui_dashboard.py.bak_v5
        ui_de_dashboard.py
        ui_lookup.py
        ui_main_window.py
        ui_mini_dashboard.py
        ui_optimizer.py
        ui_results_viewer.py
        ui_settings.py
        ui_tuner.py
        ui_vote_statistics.py
        __init__.py
        popups/
            ui_backtest_popup.py
            __init__.py
    xoso_das.egg-info/
        dependency_links.txt
        PKG-INFO
        SOURCES.txt
        top_level.txt

==================================================

=== FILE: app_controller.py ===
# T√™n file: git3/app_controller.py
#
# (N·ªòI DUNG THAY TH·∫æ TO√ÄN B·ªò - ƒê√É KH·∫ÆC PH·ª§C L·ªñI W503, E226)
#
import time
import tkinter as tk
import traceback
import threading

# Import ch·ªâ c√°c h√†m c·∫ßn thi·∫øt cho fallback (n·∫øu services kh√¥ng kh·∫£ d·ª•ng)
try:
    from lottery_service import load_data_ai_from_db
except ImportError as e:
    print(f"L·ªñI NGHI√äM TR·ªåNG: Controller kh√¥ng t√¨m th·∫•y 'lottery_service.py': {e}")
    exit()

# Import SETTINGS
try:
    from logic.config_manager import SETTINGS
except ImportError as e:
    print(f"L·ªñI: Controller kh√¥ng th·ªÉ import logic.config_manager: {e}")
    # Use centralized constants
    from logic.constants import DEFAULT_SETTINGS
    
    settings_dict = DEFAULT_SETTINGS.copy()
    settings_dict.update({
        "get_all_settings": lambda: {},
        "get": lambda k, d: d,
    })
    SETTINGS = type("obj", (object,), settings_dict)

# Import ch·ªâ c√°c h√†m c·∫ßn thi·∫øt cho services

# Import Services Layer (MVC Refactoring Phase 1 & 2)
try:
    from services import DataService, BridgeService, AnalysisService
except ImportError:
    print("C·∫£nh b√°o: Kh√¥ng th·ªÉ import services. S·ª≠ d·ª•ng fallback mode.")
    DataService = None
    BridgeService = None
    AnalysisService = None

class AppController:
    """
    L·ªõp n√†y ch·ª©a TO√ÄN B·ªò logic nghi·ªáp v·ª• (c√°c h√†m _task)
    ƒë∆∞·ª£c t√°ch ra t·ª´ ui_main_window.py.
    ƒê√£ ƒë∆∞·ª£c refactor ƒë·ªÉ s·ª≠ d·ª•ng Service Layer (MVC).
    """

    def __init__(self, app_instance):
        self.app = app_instance  # Tham chi·∫øu ƒë·∫øn DataAnalysisApp
        self.root = app_instance.root
        self.db_name = app_instance.db_name
        self.logger = None  # S·∫Ω ƒë∆∞·ª£c g√°n t·ª´ app_instance

        self.all_data_ai = None  # Cache d·ªØ li·ªáu
        self.dashboard_data_cache = {} # [V10.0 NEW] Cache l∆∞u tr·ªØ k·∫øt qu·∫£ ph√¢n t√≠ch ƒë·ªÉ Safe Merge
        
        # Kh·ªüi t·∫°o Services (MVC Refactoring)
        # L∆∞u √Ω: logger s·∫Ω ƒë∆∞·ª£c c·∫≠p nh·∫≠t sau b·∫±ng set_logger()
        if DataService:
            self.data_service = DataService(self.db_name, logger=None)
        else:
            self.data_service = None
        
        if BridgeService:
            self.bridge_service = BridgeService(self.db_name, logger=None)
        else:
            self.bridge_service = None
        
        if AnalysisService:
            self.analysis_service = AnalysisService(self.db_name, logger=None)
        else:
            self.analysis_service = None
    
    def set_logger(self, logger):
        """C·∫≠p nh·∫≠t logger cho controller v√† c√°c services"""
        self.logger = logger
        if self.data_service:
            self.data_service.logger = logger
        if self.bridge_service:
            self.bridge_service.logger = logger
        if self.analysis_service:
            self.analysis_service.logger = logger

    def root_after(self, ms, func, *args):
        """H√†m g·ªçi root.after an to√†n (ch·∫°y tr√™n lu·ªìng ch√≠nh)."""
        self.root.after(ms, func, *args)
    
    def _refresh_bridge_manager_if_needed(self):
        """Helper: Refresh bridge manager window n·∫øu ƒëang m·ªü"""
        if (self.app.bridge_manager_window and self.app.bridge_manager_window.winfo_exists()):
            self.logger.log("ƒêang t·ª± ƒë·ªông l√†m m·ªõi c·ª≠a s·ªï Qu·∫£n l√Ω C·∫ßu...")
            try:
                self.root_after(0, self.app.bridge_manager_window_instance.refresh_bridge_list)
            except Exception as e:
                self.logger.log(f"L·ªói khi t·ª± ƒë·ªông l√†m m·ªõi QL C·∫ßu: {e}")

    # ===================================================================
    # LOGIC T·∫¢I D·ªÆ LI·ªÜU (ƒê√£ di chuy·ªÉn)
    # ===================================================================

    def load_data_ai_from_db_controller(self):
        """T·∫£i (ho·∫∑c t·∫£i l·∫°i) d·ªØ li·ªáu A:I t·ª´ DB."""
        # S·ª≠ d·ª•ng DataService n·∫øu c√≥, fallback v·ªÅ h√†m c≈©
        if self.data_service:
            rows_of_lists = self.data_service.load_data()
            if rows_of_lists is None:
                self.all_data_ai = None
                return None
            else:
                self.all_data_ai = rows_of_lists
                return rows_of_lists
        else:
            # Fallback: G·ªçi h√†m t·ª´ lottery_service
            rows_of_lists, message = load_data_ai_from_db(self.db_name)
            if rows_of_lists is None:
                self.logger.log(message)
                self.all_data_ai = None
                return None
            else:
                self.logger.log(message)
                self.all_data_ai = rows_of_lists
                return rows_of_lists

    # ===================================================================
    # C√ÅC H√ÄM T√ÅC V·ª§ (ƒê√£ di chuy·ªÉn t·ª´ ui_main_window.py)
    # ===================================================================

    def task_run_parsing(self, input_file):
        if self.data_service:
            def callback():
                self.root_after(0, self.app.run_decision_dashboard)
            success, message = self.data_service.import_data_from_file(input_file, callback_on_success=callback)
            if not success:
                self.logger.log(f"L·ªñI: {message}")

    def task_run_parsing_append(self, input_file):
        if self.data_service:
            def callback():
                self.root_after(0, self.app.run_decision_dashboard)
            success, message = self.data_service.append_data_from_file(input_file, callback_on_success=callback)
            if not success:
                self.logger.log(f"L·ªñI: {message}")

    def task_run_update_from_text(self, raw_data):
        if self.data_service:
            def callback():
                self.root_after(0, self.app.clear_update_text_area)
                time.sleep(0.5)
                self.root_after(0, self.logger.log, "ƒê√£ th√™m d·ªØ li·ªáu. T·ª± ƒë·ªông ch·∫°y l·∫°i B·∫£ng T·ªïng H·ª£p...")
                self.root_after(0, self.app.run_decision_dashboard)
            success, message = self.data_service.update_from_text(raw_data, callback_on_success=callback)
            if not success:
                self.logger.log("(Kh√¥ng c√≥ k·ª≥ n√†o ƒë∆∞·ª£c th√™m ho·∫∑c c√≥ l·ªói nghi√™m tr·ªçng.)")

    def task_run_backtest(self, mode, title):
        all_data = self.load_data_ai_from_db_controller()
        if not all_data:
            return
        if self.analysis_service:
            results = self.analysis_service.run_backtest(all_data, mode, title)
            if results:
                self.logger.log("Backtest ho√†n t·∫•t. ƒêang m·ªü c·ª≠a s·ªï k·∫øt qu·∫£...")
                self.root_after(0, self.app.show_backtest_results, title, results)

    def task_run_custom_backtest(self, mode, title, custom_bridge_name):
        all_data = self.load_data_ai_from_db_controller()
        if not all_data:
            return
        if self.analysis_service:
            results, adjusted_mode, adjusted_title = self.analysis_service.run_custom_backtest(all_data, mode, custom_bridge_name)
            if results:
                self.root_after(0, self.app.show_backtest_results, adjusted_title or title, results)

    def task_run_backtest_managed_n1(self, title):
        all_data = self.load_data_ai_from_db_controller()
        if not all_data:
            return
        if self.analysis_service:
            results = self.analysis_service.run_backtest_managed_n1(all_data)
            if results:
                self.logger.log("Backtest C·∫ßu ƒê√£ L∆∞u N1 ho√†n t·∫•t. ƒêang m·ªü c·ª≠a s·ªï k·∫øt qu·∫£...")
                self.root_after(0, self.app.show_backtest_results, title, results)

    def task_run_backtest_managed_k2n(self, title):
        all_data = self.load_data_ai_from_db_controller()
        if not all_data:
            return
        if self.analysis_service:
            results = self.analysis_service.run_backtest_managed_k2n(all_data)
            if results:
                self.logger.log("Backtest C·∫ßu ƒê√£ L∆∞u K2N ho√†n t·∫•t. ƒêang m·ªü c·ª≠a s·ªï k·∫øt qu·∫£...")
                self.root_after(0, self.app.show_backtest_results, title, results)

    def task_run_decision_dashboard(self, title, lo_mode=True, de_mode=True):
        """
        Ch·∫°y ph√¢n t√≠ch Dashboard v·ªõi ch·∫ø ƒë·ªô t√πy ch·ªçn (On-Demand).
        """
        all_data = self.load_data_ai_from_db_controller()
        if not all_data or len(all_data) < 2:
            self.logger.log("L·ªñI: C·∫ßn √≠t nh·∫•t 2 k·ª≥ d·ªØ li·ªáu ƒë·ªÉ ch·∫°y B·∫£ng T·ªïng H·ª£p.")
            self.root_after(0, self.app._on_dashboard_close)
            return
        try:
            limit = getattr(SETTINGS, "DATA_LIMIT_DASHBOARD", 2000)
        except:
            limit = 2000
        
        if self.analysis_service:
            # [V10.0] G·ªçi Service v·ªõi tham s·ªë mode
            # H√†m n√†y s·∫Ω ch·ªâ tr·∫£ v·ªÅ nh·ªØng ph·∫ßn d·ªØ li·ªáu ƒë∆∞·ª£c y√™u c·∫ßu t√≠nh to√°n
            new_partial_data = self.analysis_service.prepare_dashboard_data(
                all_data, 
                data_limit=limit if limit > 0 else None,
                lo_mode=lo_mode,
                de_mode=de_mode
            )
            
            if not new_partial_data:
                self.logger.log("L·ªñI: Kh√¥ng th·ªÉ chu·∫©n b·ªã d·ªØ li·ªáu dashboard.")
                self.root_after(0, self.app._on_dashboard_close)
                return
            
            # [V10.0] SAFE MERGE LOGIC
            # G·ªôp k·∫øt qu·∫£ m·ªõi v√†o cache, gi·ªØ l·∫°i k·∫øt qu·∫£ c≈© c·ªßa ch·∫ø ƒë·ªô kh√¥ng ch·∫°y
            if not self.dashboard_data_cache:
                self.dashboard_data_cache = {}
            
            # C·∫≠p nh·∫≠t cache v·ªõi d·ªØ li·ªáu m·ªõi
            self.dashboard_data_cache.update(new_partial_data)
            
            # S·ª≠ d·ª•ng d·ªØ li·ªáu t·ªïng h·ª£p t·ª´ Cache ƒë·ªÉ hi·ªÉn th·ªã
            final_data = self.dashboard_data_cache

            try:
                # C·∫≠p nh·∫≠t Tab ƒê·ªÅ (Ch·ªâ khi c√≥ d·ªØ li·ªáu ƒê·ªÅ m·ªõi ho·∫∑c ƒê·ªÅ mode b·∫≠t)
                if hasattr(self.app, 'de_dashboard_tab') and self.app.de_dashboard_tab:
                    if final_data.get('df_de') is not None:
                        # Ch·ªâ log th√¥ng b√°o n·∫øu ƒëang ch·∫°y ch·∫ø ƒë·ªô ƒê·ªÅ
                        if de_mode:
                            self.logger.log("... (Soi C·∫ßu ƒê·ªÅ) ƒêang chu·∫©n b·ªã d·ªØ li·ªáu...")
                        self.root_after(0, self.app.de_dashboard_tab.update_data, final_data['df_de'])
                        
                        if de_mode:
                            self.logger.log(f"... (Soi C·∫ßu ƒê·ªÅ) ƒê√£ n·∫°p {len(final_data['df_de'])} k·ª≥ v√†o h·ªá th·ªëng.")
            except Exception as e_de:
                self.logger.log(f"C·∫£nh b√°o: L·ªói c·∫≠p nh·∫≠t Tab Soi C·∫ßu ƒê·ªÅ: {e_de}")
            
            try:
                self.logger.log("Ph√¢n t√≠ch ho√†n t·∫•t. ƒêang hi·ªÉn th·ªã B·∫£ng Quy·∫øt ƒê·ªãnh T·ªëi ∆Øu...")
                self.root_after(0, self.app._show_dashboard_window,
                    final_data.get('next_ky', "N/A"), 
                    final_data.get('stats_n_day', []), 
                    final_data.get('n_days_stats', 7),
                    final_data.get('consensus', []), 
                    final_data.get('high_win', []), 
                    final_data.get('pending_k2n_data', {}),
                    final_data.get('gan_stats', []), 
                    final_data.get('top_scores', []), 
                    final_data.get('top_memory_bridges', []),
                    final_data.get('ai_predictions', [])
                )
            except Exception as e_final:
                self.logger.log(f"L·ªñI NGHI√äM TR·ªåNG khi hi·ªÉn th·ªã Dashboard: {e_final}")
                self.logger.log(traceback.format_exc())
                self.root_after(0, self.app._on_dashboard_close)

    def task_run_update_all_bridge_K2N_cache(self, title):
        all_data = self.load_data_ai_from_db_controller()
        if not all_data:
            return
        if self.bridge_service:
            _, _, message = self.bridge_service.update_k2n_cache(all_data)
            self.logger.log(message)
            self._refresh_bridge_manager_if_needed()

    def task_run_auto_find_bridges(self, title):
        all_data = self.load_data_ai_from_db_controller()
        if not all_data:
            return
        if self.bridge_service:
            try:
                SCAN_LIMIT = getattr(SETTINGS, "DATA_LIMIT_SCANNER", 500)
            except:
                SCAN_LIMIT = 500
            self.bridge_service.find_and_scan_bridges(all_data, scan_limit=SCAN_LIMIT)
            self.logger.log(">>> T√°c v·ª• ho√†n t·∫•t.")
            self._refresh_bridge_manager_if_needed()

    def task_run_auto_prune_bridges(self, title):
        all_data = self.load_data_ai_from_db_controller()
        if not all_data:
            return
        if self.bridge_service:
            result = self.bridge_service.prune_bad_bridges(all_data)
            self.logger.log(f">>> {title} HO√ÄN T·∫§T:")
            self.logger.log(result)
            self._refresh_bridge_manager_if_needed()

    def task_run_auto_manage_bridges(self, title):
        all_data = self.load_data_ai_from_db_controller()
        if not all_data:
            return
        if self.bridge_service:
            result = self.bridge_service.auto_manage_bridges(all_data)
            self.logger.log(f">>> {title} HO√ÄN T·∫§T:")
            self.logger.log(result)
            self._refresh_bridge_manager_if_needed()
    
    def task_run_prune_bad_de_bridges(self, title):
        """
        T·ª± ƒë·ªông lo·∫°i b·ªè c·∫ßu ƒê·ªÅ y·∫øu (Phase 4 - Pruning).
        Ch·∫°y trong lu·ªìng n·ªÅn ƒë·ªÉ kh√¥ng ch·∫∑n UI.
        
        Args:
            title: Ti√™u ƒë·ªÅ t√°c v·ª• (ƒë·ªÉ log)
        """
        try:
            self.logger.log(f">>> B·∫Øt ƒë·∫ßu {title}...")
            
            # T·∫£i d·ªØ li·ªáu
            all_data = self.load_data_ai_from_db_controller()
            if not all_data:
                self.logger.log("L·ªñI: Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ki·ªÉm tra.")
                return
            
            # G·ªçi service ƒë·ªÉ lo·∫°i b·ªè c·∫ßu ƒê·ªÅ y·∫øu
            if not self.bridge_service:
                self.logger.log("L·ªñI: BridgeService ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o.")
                return
            
            result_msg = self.bridge_service.prune_bad_de_bridges(all_data)
            self.logger.log(f">>> {title} HO√ÄN T·∫§T:")
            self.logger.log(result_msg)
            
            # Refresh bridge manager n·∫øu c·∫ßn
            self._refresh_bridge_manager_if_needed()
            
        except Exception as e:
            error_msg = f"L·ªñI khi lo·∫°i b·ªè c·∫ßu ƒê·ªÅ y·∫øu: {e}"
            self.logger.log(error_msg)
            self.logger.log(traceback.format_exc())
    
    def task_run_toggle_pin(self, bridge_name):
        """
        ƒê·∫£o ng∆∞·ª£c tr·∫°ng th√°i ghim c·ªßa c·∫ßu (Phase 4 - Pinning).
        Ch·∫°y trong lu·ªìng n·ªÅn ƒë·ªÉ kh√¥ng ch·∫∑n UI.
        
        Args:
            bridge_name: T√™n c·∫ßu c·∫ßn ghim/b·ªè ghim
        """
        try:
            if not bridge_name:
                self.logger.log("L·ªñI: T√™n c·∫ßu kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng.")
                return
            
            # G·ªçi service ƒë·ªÉ toggle pin
            if not self.bridge_service:
                self.logger.log("L·ªñI: BridgeService ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o.")
                return
            
            success, message, new_pin_state = self.bridge_service.toggle_pin_bridge(bridge_name)
            
            if success:
                pin_status = "ƒë√£ ghim" if new_pin_state else "ƒë√£ b·ªè ghim"
                self.logger.log(f">>> [PIN] C·∫ßu '{bridge_name}' {pin_status}.")
            else:
                self.logger.log(f">>> [PIN] L·ªói: {message}")
            
            # Refresh bridge manager n·∫øu c·∫ßn
            self._refresh_bridge_manager_if_needed()
            
        except Exception as e:
            error_msg = f"L·ªñI khi ghim/b·ªè ghim c·∫ßu '{bridge_name}': {e}"
            self.logger.log(error_msg)
            self.logger.log(traceback.format_exc())

    def task_run_smart_optimization(self, title):
        all_data = self.load_data_ai_from_db_controller()
        if not all_data:
            return
        if self.bridge_service:
            self.logger.log(f"\n--- ‚ö° B·∫ÆT ƒê·∫¶U: {title} ---")
            msg_prune, msg_manage = self.bridge_service.smart_optimization(all_data)
            self.logger.log(f"‚úÖ T·ªêI ∆ØU H√ìA HO√ÄN T·∫§T!")
            self._refresh_bridge_manager_if_needed()

    def task_run_train_ai(self, title):
        def train_callback(success, message):
            self.logger.log(f">>> {title} HO√ÄN T·∫§T:")
            self.logger.log(message)
        if self.analysis_service:
            success, message = self.analysis_service.train_ai(callback=train_callback)
            if not success:
                self.logger.log(f"L·ªñI KH·ªûI CH·∫†Y LU·ªíNG: {message}")

    def task_run_backtest_memory(self, title):
        all_data = self.load_data_ai_from_db_controller()
        if not all_data:
            return
        if self.analysis_service:
            results = self.analysis_service.run_backtest_memory(all_data)
            if results:
                self.logger.log("Backtest C·∫ßu B·∫°c Nh·ªõ ho√†n t·∫•t. ƒêang m·ªü c·ª≠a s·ªï k·∫øt qu·∫£...")
                self.root_after(0, self.app.show_backtest_results, title, results)

    def task_run_parameter_tuning(self, param_key, val_from, val_to, val_step, tuner_window):
        """Wrapper: Chuy·ªÉn sang AnalysisService"""
        def log_to_tuner(message):
            self.root_after(0, tuner_window.log, message)
        
        try:
            log_to_tuner("ƒêang t·∫£i d·ªØ li·ªáu A:I...")
            all_data_ai = self.load_data_ai_from_db_controller()
            if not all_data_ai or len(all_data_ai) < 2:
                log_to_tuner("L·ªñI: Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu A:I.")
                return
            
            # S·ª≠ d·ª•ng AnalysisService
            if self.analysis_service:
                self.analysis_service.run_parameter_tuning(all_data_ai, param_key, val_from, val_to, val_step, log_to_tuner)
            else:
                # Fallback: Gi·ªØ nguy√™n logic c≈© (r√∫t g·ªçn)
                log_to_tuner("C·∫£nh b√°o: AnalysisService kh√¥ng kh·∫£ d·ª•ng. S·ª≠ d·ª•ng fallback.")
        except Exception as e:
            log_to_tuner(f"L·ªñI: {e}")
            log_to_tuner(traceback.format_exc())
        finally:
            self.root_after(0, tuner_window.run_button.config, {"state": tk.NORMAL})

    def task_run_strategy_optimization(self, strategy, days_to_test, param_ranges, optimizer_tab):
        """Wrapper: Chuy·ªÉn sang AnalysisService"""
        def log_to_optimizer(message):
            self.root_after(0, optimizer_tab.log, message)
        
        def update_tree_results_threadsafe(results_list):
            optimizer_tab.clear_results_tree()
            for i, (rate, hits, params_str, config_dict_str) in enumerate(results_list):
                rate_str = f"{rate * 100:.1f}%"
                tags = ("best",) if i == 0 else ()
                tags_with_data = (config_dict_str,) + tags
                optimizer_tab.tree.insert("", tk.END, values=(rate_str, hits, params_str), tags=tags_with_data)
            optimizer_tab.apply_button.config(state=tk.NORMAL)
        
        try:
            log_to_optimizer("ƒêang t·∫£i to√†n b·ªô d·ªØ li·ªáu A:I...")
            all_data_ai = self.load_data_ai_from_db_controller()
            if not all_data_ai or len(all_data_ai) < days_to_test + 50:
                log_to_optimizer(f"L·ªñI: C·∫ßn √≠t nh·∫•t {days_to_test + 50} k·ª≥ d·ªØ li·ªáu ƒë·ªÉ ki·ªÉm th·ª≠.")
                return
            
            # S·ª≠ d·ª•ng AnalysisService
            if self.analysis_service:
                self.analysis_service.run_strategy_optimization(
                    all_data_ai, days_to_test, param_ranges, log_to_optimizer, update_tree_results_threadsafe
                )
            else:
                # Fallback: Gi·ªØ nguy√™n logic c≈© (r√∫t g·ªçn)
                log_to_optimizer("C·∫£nh b√°o: AnalysisService kh√¥ng kh·∫£ d·ª•ng. S·ª≠ d·ª•ng fallback.")
        except Exception as e:
            log_to_optimizer(f"L·ªñI: {e}")
            log_to_optimizer(traceback.format_exc())
        finally:
            self.root_after(0, optimizer_tab.run_button.config, {"state": tk.NORMAL})
    
    def trigger_bridge_backtest(self, bridge_name, is_de=False):
        """
        K√≠ch ho·∫°t backtest 30 ng√†y cho m·ªôt c·∫ßu c·ª• th·ªÉ (Task Launcher).
        Ch·∫°y logic backtest trong lu·ªìng n·ªÅn ƒë·ªÉ kh√¥ng ch·∫∑n UI.
        
        Args:
            bridge_name: T√™n c·∫ßu c·∫ßn backtest
            is_de: True n·∫øu l√† c·∫ßu ƒê·ªÅ, False n·∫øu l√† c·∫ßu L√¥ (m·∫∑c ƒë·ªãnh)
        """
        print(f"[DEBUG] trigger_bridge_backtest ƒë∆∞·ª£c g·ªçi: bridge_name='{bridge_name}', is_de={is_de}")
        
        if not bridge_name:
            print("[DEBUG] Bridge name r·ªóng, b·ªè qua.")
            return
        
        # Log ƒë·ªÉ debug
        if self.logger:
            self.logger.log(f"ƒêang kh·ªüi ƒë·ªông backtest cho c·∫ßu '{bridge_name}' ({'ƒê·ªÅ' if is_de else 'L√¥'})...")
        
        # Kh·ªüi t·∫°o Thread ƒë·ªÉ ch·∫°y backtest trong lu·ªìng n·ªÅn
        try:
            thread = threading.Thread(
                target=self.task_run_bridge_backtest,
                args=(bridge_name, is_de),
                daemon=True
            )
            thread.start()
            print(f"[DEBUG] Thread ƒë√£ ƒë∆∞·ª£c kh·ªüi ƒë·ªông.")
        except Exception as e:
            print(f"[ERROR] L·ªói khi kh·ªüi ƒë·ªông thread: {e}")
            import traceback
            traceback.print_exc()
            if self.logger:
                self.logger.log(f"L·ªñI khi kh·ªüi ƒë·ªông thread backtest: {e}")
    
    def task_run_bridge_backtest(self, bridge_name, is_de=False):
        """
        Ch·∫°y backtest 30 ng√†y cho m·ªôt c·∫ßu c·ª• th·ªÉ trong lu·ªìng n·ªÅn.
        
        Args:
            bridge_name: T√™n c·∫ßu c·∫ßn backtest
            is_de: True n·∫øu l√† c·∫ßu ƒê·ªÅ, False n·∫øu l√† c·∫ßu L√¥ (m·∫∑c ƒë·ªãnh)
        """
        print(f"[DEBUG] task_run_bridge_backtest B·∫ÆT ƒê·∫¶U: bridge_name='{bridge_name}', is_de={is_de}")
        try:
            # T·∫£i d·ªØ li·ªáu
            print(f"[DEBUG] ƒêang t·∫£i d·ªØ li·ªáu...")
            all_data = self.load_data_ai_from_db_controller()
            if not all_data:
                error_msg = "L·ªñI: Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ch·∫°y backtest."
                print(f"[ERROR] {error_msg}")
                if self.logger:
                    self.logger.log(error_msg)
                return
            
            print(f"[DEBUG] ƒê√£ t·∫£i {len(all_data)} d√≤ng d·ªØ li·ªáu.")
            
            # G·ªçi service ƒë·ªÉ ch·∫°y backtest
            if not self.analysis_service:
                error_msg = "L·ªñI: AnalysisService ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o."
                print(f"[ERROR] {error_msg}")
                if self.logger:
                    self.logger.log(error_msg)
                return
            
            print(f"[DEBUG] ƒêang g·ªçi service ƒë·ªÉ ch·∫°y backtest...")
            if is_de:
                backtest_data = self.analysis_service.run_de_backtest_30_days(bridge_name, all_data)
            else:
                backtest_data = self.analysis_service.run_lo_backtest_30_days(bridge_name, all_data)
            
            print(f"[DEBUG] Backtest ho√†n t·∫•t. K·∫øt qu·∫£: {len(backtest_data) if backtest_data else 0} d√≤ng.")
            
            # Hi·ªÉn th·ªã popup tr√™n UI thread (s·ª≠ d·ª•ng root_after)
            if backtest_data is not None:
                print(f"[DEBUG] ƒêang g·ªçi _show_backtest_popup v·ªõi {len(backtest_data)} d√≤ng d·ªØ li·ªáu.")
                self.root_after(0, self._show_backtest_popup, bridge_name, backtest_data)
            else:
                error_msg = f"Kh√¥ng th·ªÉ ch·∫°y backtest cho c·∫ßu '{bridge_name}'."
                print(f"[ERROR] {error_msg}")
                if self.logger:
                    self.logger.log(error_msg)
        
        except Exception as e:
            error_msg = f"L·ªñI khi ch·∫°y backtest: {e}"
            print(f"[ERROR] {error_msg}")
            import traceback
            traceback.print_exc()
            if self.logger:
                self.logger.log(error_msg)
                self.logger.log(traceback.format_exc())
    
    def _show_backtest_popup(self, bridge_name, backtest_data):
        """
        Hi·ªÉn th·ªã popup backtest (ƒë∆∞·ª£c g·ªçi tr√™n UI thread).
        
        Args:
            bridge_name: T√™n c·∫ßu
            backtest_data: D·ªØ li·ªáu backtest
        """
        print(f"[DEBUG] _show_backtest_popup ƒë∆∞·ª£c g·ªçi: bridge_name='{bridge_name}', data_length={len(backtest_data) if backtest_data else 0}")
        try:
            from ui.popups.ui_backtest_popup import BacktestPopup
            print(f"[DEBUG] ƒêang t·∫°o BacktestPopup...")
            popup = BacktestPopup(self.root, bridge_name, backtest_data)
            print(f"[DEBUG] BacktestPopup ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng.")
        except ImportError as e:
            error_msg = f"L·ªñI: Kh√¥ng th·ªÉ import BacktestPopup: {e}"
            print(f"[ERROR] {error_msg}")
            if self.logger:
                self.logger.log(error_msg)
        except Exception as e:
            error_msg = f"L·ªñI khi hi·ªÉn th·ªã popup: {e}"
            print(f"[ERROR] {error_msg}")
            import traceback
            traceback.print_exc()
            if self.logger:
                self.logger.log(error_msg)
                self.logger.log(traceback.format_exc())


--------------------------------------------------

=== FILE: check_final_fix.py ===
# T√™n file: generate_audit_report.py
import sys
import os
import json
from collections import Counter

# Setup ƒë∆∞·ªùng d·∫´n
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from lottery_service import load_data_ai_from_db, DB_NAME
    from logic.bridges.de_bridge_scanner import run_de_scanner
    from logic.de_analytics import calculate_number_scores, analyze_market_trends
    from logic.de_utils import get_gdb_last_2, BO_SO_DE
    
    # H√†m h·ªó tr·ª£ ph√¢n t√≠ch chi ti·∫øt ƒëi·ªÉm s·ªë
    def analyze_score_contribution(target_num, bridges):
        """Ph√¢n t√≠ch xem s·ªë n√†y ƒë∆∞·ª£c ƒëi·ªÉm t·ª´ nh·ªØng ƒë√¢u"""
        details = {
            "total_bridges": 0,
            "bridge_types": Counter(),
            "score_breakdown": []
        }
        
        # M√¥ ph·ªèng l·∫°i logic t√≠nh ƒëi·ªÉm ƒë·ªÉ l·∫•y chi ti·∫øt
        STANDARD_CONST = 20.0 
        
        for bridge in bridges:
            try:
                # Logic x√°c ƒë·ªãnh s·ªë trong c·∫ßu (copy t·ª´ de_analytics)
                target_numbers = set()
                if 'numbers' in bridge and isinstance(bridge['numbers'], list):
                    target_numbers.update(bridge['numbers'])
                else:
                    val = str(bridge.get('predicted_value', ''))
                    # (Logic parse gi·∫£n l∆∞·ª£c ƒë·ªÉ audit)
                    if "B·ªô" in val:
                        for k, v in BO_SO_DE.items():
                            if k in val: target_numbers.update(v)
                    elif "," in val:
                        parts = [int(v) for v in val.replace("Ch·∫°m","").split(',') if v.strip().isdigit()]
                        for p in parts:
                            for i in range(10): target_numbers.add(f"{p}{i}"); target_numbers.add(f"{i}{p}")
                
                # N·∫øu c·∫ßu n√†y c√≥ ch·ª©a s·ªë m·ª•c ti√™u -> Ghi nh·∫≠n
                if target_num in target_numbers:
                    details["total_bridges"] += 1
                    b_type = bridge.get('type', 'UNKNOWN')
                    details["bridge_types"][b_type] += 1
                    
                    count = len(target_numbers)
                    if count > 0:
                        streak = float(bridge.get('streak', 0))
                        density_weight = STANDARD_CONST / float(count)
                        streak_bonus = 1.0 + (streak * 0.1)
                        final_score = density_weight * streak_bonus
                        
                        details["score_breakdown"].append({
                            "name": bridge.get('name'),
                            "type": b_type,
                            "streak": streak,
                            "count": count,
                            "points": round(final_score, 2)
                        })
            except: continue
            
        # S·∫Øp x·∫øp c√°c c·∫ßu ƒë√≥ng g√≥p ƒëi·ªÉm cao nh·∫•t
        details["score_breakdown"].sort(key=lambda x: x["points"], reverse=True)
        return details

    print(f"\n>>> ƒêANG T·∫†O B√ÅO C√ÅO KI·ªÇM TO√ÅN H·ªÜ TH·ªêNG (AUDIT REPORT)...")
    
    # 1. T·∫£i d·ªØ li·ªáu
    all_data, msg = load_data_ai_from_db(DB_NAME)
    if not all_data or len(all_data) < 100:
        print(f"‚ùå L·ªói t·∫£i d·ªØ li·ªáu: {msg}")
        sys.exit()

    # C·∫•u h√¨nh: Ki·ªÉm tra 15 k·ª≥ g·∫ßn nh·∫•t (ƒë·ªÉ file b√°o c√°o kh√¥ng qu√° d√†i)
    TEST_DAYS = 15
    start_index = len(all_data) - TEST_DAYS
    
    report_lines = []
    report_lines.append(f"B√ÅO C√ÅO KI·ªÇM TO√ÅN HI·ªÜU QU·∫¢ SCORING V3 (FAIRNESS)")
    report_lines.append(f"Th·ªùi gian test: 15 k·ª≥ g·∫ßn nh·∫•t")
    report_lines.append("="*80)

    for i in range(start_index, len(all_data)):
        past_data = all_data[:i]
        current_row = all_data[i]
        
        ky = str(current_row[0])
        kq_thuc_te = get_gdb_last_2(current_row)
        if not kq_thuc_te: continue
        
        # A. Qu√©t & T√≠nh ƒëi·ªÉm
        # L∆∞u √Ω: Kh√¥ng truy·ªÅn scan_limit v√†o run_de_scanner ƒë·ªÉ tr√°nh l·ªói, t·ª± c·∫Øt list sau
        try:
            _, bridges = run_de_scanner(past_data)
            bridges = bridges[:200] # L·∫•y 200 c·∫ßu t·ªët nh·∫•t ƒë·ªÉ ph√¢n t√≠ch
        except Exception as e:
            print(f"L·ªói Scanner k·ª≥ {ky}: {e}")
            continue

        market_stats = analyze_market_trends(past_data)
        ranked_scores = calculate_number_scores(bridges, market_stats)
        
        # B. T√¨m th√¥ng tin KQ th·ª±c t·∫ø
        kq_rank = -1
        kq_score = 0
        kq_info = ""
        
        for rank, (num, score, info) in enumerate(ranked_scores):
            if num == kq_thuc_te:
                kq_rank = rank + 1
                kq_score = score
                kq_info = info
                break
        
        # C. T√¨m th√¥ng tin Top 1 (S·ªë sai nh∆∞ng ƒëi·ªÉm cao nh·∫•t)
        top1_num, top1_score, top1_info = ranked_scores[0]
        
        # D. Ph√¢n t√≠ch s√¢u (Deep Dive)
        report_lines.append(f"\n>>> K·ª≤ {ky} | KQ: {kq_thuc_te} | H·∫°ng: #{kq_rank} | ƒêi·ªÉm: {kq_score:.1f}")
        
        # 1. T·∫°i sao KQ l·∫°i ƒë∆∞·ª£c ƒëi·ªÉm n√†y?
        kq_audit = analyze_score_contribution(kq_thuc_te, bridges)
        report_lines.append(f"    [PH√ÇN T√çCH KQ {kq_thuc_te}]: ƒê∆∞·ª£c {kq_audit['total_bridges']} c·∫ßu ·ªßng h·ªô.")
        report_lines.append(f"    - C∆° c·∫•u c·∫ßu: {dict(kq_audit['bridge_types'])}")
        if kq_audit['score_breakdown']:
            top_b = kq_audit['score_breakdown'][0]
            report_lines.append(f"    - C·∫ßu to nh·∫•t: {top_b['name']} ({top_b['type']}) -> +{top_b['points']}ƒë (Streak {top_b['streak']})")
        
        # 2. T·∫°i sao Top 1 l·∫°i cao ƒëi·ªÉm h∆°n? (N·∫øu KQ kh√¥ng ph·∫£i Top 1)
        if kq_rank > 1:
            top1_audit = analyze_score_contribution(top1_num, bridges)
            diff = top1_score - kq_score
            report_lines.append(f"    [SO S√ÅNH TOP 1 {top1_num}]: Cao h∆°n KQ {diff:.1f} ƒëi·ªÉm.")
            report_lines.append(f"    - Top 1 ƒë∆∞·ª£c {top1_audit['total_bridges']} c·∫ßu ·ªßng h·ªô. C∆° c·∫•u: {dict(top1_audit['bridge_types'])}")
            if top1_audit['score_breakdown']:
                top_b1 = top1_audit['score_breakdown'][0]
                report_lines.append(f"    - C·∫ßu to nh·∫•t c·ªßa Top 1: {top_b1['name']} -> +{top_b1['points']}ƒë")
                
            # ƒê√°nh gi√° nguy√™n nh√¢n
            if top1_audit['total_bridges'] > kq_audit['total_bridges'] * 2:
                report_lines.append(f"    => NH·∫¨N X√âT: Top 1 th·∫Øng nh·ªù S·ªê L∆Ø·ª¢NG c·∫ßu √°p ƒë·∫£o (Spam c·∫ßu).")
            elif top1_audit['score_breakdown'] and kq_audit['score_breakdown'] and \
                 top1_audit['score_breakdown'][0]['points'] > kq_audit['score_breakdown'][0]['points']:
                report_lines.append(f"    => NH·∫¨N X√âT: Top 1 th·∫Øng nh·ªù CH·∫§T L∆Ø·ª¢NG c·∫ßu (C·∫ßu B·ªô/K√©p ƒëi·ªÉm cao).")
        
        print(f"   -> ƒê√£ ph√¢n t√≠ch k·ª≥ {ky}...")

    # Ghi file
    with open("AUDIT_REPORT_V3.txt", "w", encoding="utf-8") as f:
        f.write("\n".join(report_lines))
        
    print("\n‚úÖ ƒê√É T·∫†O B√ÅO C√ÅO TH√ÄNH C√îNG: 'AUDIT_REPORT_V3.txt'")
    print(">>> H√£y g·ª≠i file n√†y cho Gemini ƒë·ªÉ tinh ch·ªânh thu·∫≠t to√°n.")

except Exception as e:
    print(f"L·ªói: {e}")
    import traceback
    traceback.print_exc()

--------------------------------------------------

=== FILE: clean_run.py ===
import os
import shutil
import sys
import time

print(">>> ƒêANG D·ªåN D·∫∏P FILE R√ÅC (CACHE)...")

# 1. Qu√©t v√† x√≥a t·∫•t c·∫£ th∆∞ m·ª•c __pycache__
root_dir = os.path.dirname(os.path.abspath(__file__))
count = 0
for root, dirs, files in os.walk(root_dir):
    for d in dirs:
        if d == "__pycache__":
            path = os.path.join(root, d)
            try:
                shutil.rmtree(path)
                count += 1
                print(f"    ƒê√£ x√≥a: {path}")
            except Exception as e:
                print(f"    L·ªói x√≥a {path}: {e}")

print(f">>> ƒê√£ x√≥a {count} th∆∞ m·ª•c cache. Code m·ªõi s·∫Ω ƒë∆∞·ª£c n·∫°p l·∫°i 100%.")
print(">>> ƒêang kh·ªüi ƒë·ªông ph·∫ßn m·ªÅm sau 2 gi√¢y...")
time.sleep(2)


--------------------------------------------------

=== FILE: config.json ===
{
    "STATS_DAYS": 7,
    "GAN_DAYS": 7,
    "HIGH_WIN_THRESHOLD": 47.0,
    "AUTO_ADD_MIN_RATE": 46.0,
    "AUTO_PRUNE_MIN_RATE": 45.5,
    "K2N_RISK_START_THRESHOLD": 3,
    "K2N_RISK_PENALTY_PER_FRAME": 0.55,
    "AI_PROB_THRESHOLD": 55.0,
    "AI_MAX_DEPTH": 6,
    "AI_N_ESTIMATORS": 200,
    "AI_LEARNING_RATE": 0.05,
    "AI_OBJECTIVE": "binary:logistic",
    "AI_SCORE_WEIGHT": 0.2,
    "RECENT_FORM_PERIODS": 10,
    "RECENT_FORM_BONUS_HIGH": 3.0,
    "RECENT_FORM_BONUS_MED": 2.0,
    "RECENT_FORM_BONUS_LOW": 1.0,
    "RECENT_FORM_MIN_HIGH": 9,
    "RECENT_FORM_MIN_MED": 8,
    "RECENT_FORM_MIN_LOW": 7,
    "DATA_LIMIT_DASHBOARD": 500,
    "DATA_LIMIT_RESEARCH": 0,
    "DATA_LIMIT_SCANNER": 700,
    "DE_MAX_LOSE_THRESHOLD": 20,
    "RECENT_FORM_BONUS_VERY_HIGH": 4.0,
    "RECENT_FORM_MIN_VERY_HIGH": 9,
    "VOTE_SCORE_WEIGHT": 0.5,
    "HIGH_WIN_SCORE_BONUS": 2.5,
    "K2N_RISK_PROGRESSIVE": true,
    "FILTER_MIN_CONFIDENCE": 0,
    "FILTER_MIN_AI_PROB": 0,
    "FILTER_ENABLED": false,
    "MANAGER_RATE_MODE": "K1N"
}

--------------------------------------------------

=== FILE: conftest.py ===
# conftest.py (project root)
# This file ensures pytest can import project modules

import os
import sys

# Add project root to Python path
project_root = os.path.dirname(os.path.abspath(__file__))
if project_root not in sys.path:
    sys.path.insert(0, project_root)


--------------------------------------------------

=== FILE: core_services.py ===
# T√™n file: du-an-backup/core_services.py
#
# (N·ªòI DUNG T·ªÜP M·ªöI)
#
import threading
import tkinter as tk
import traceback


class Logger:
    """Qu·∫£n l√Ω vi·ªác log ra UI an to√†n t·ª´ nhi·ªÅu lu·ªìng."""

    def __init__(self, text_widget, root):
        self.widget = text_widget
        self.root = root

    def _safe_log(self, message):
        """H√†m c·∫≠p nh·∫≠t output an to√†n (ch·ªâ ch·∫°y tr√™n lu·ªìng ch√≠nh)."""
        try:
            self.widget.config(state=tk.NORMAL)
            self.widget.insert(tk.END, message + "\n")
            self.widget.see(tk.END)
            self.widget.config(state=tk.DISABLED)
            self.root.update_idletasks()
        except Exception:
            # B·ªè qua n·∫øu UI ƒë√£ b·ªã h·ªßy
            pass

    def log(self, message):
        """Ghi log. T·ª± ƒë·ªông ki·ªÉm tra lu·ªìng."""
        if threading.current_thread() is threading.main_thread():
            self._safe_log(message)
        else:
            # N·∫øu t·ª´ lu·ªìng kh√°c, g·ªçi an to√†n qua root.after()
            self.root.after(0, self._safe_log, message)


class TaskManager:
    """Qu·∫£n l√Ω vi·ªác ch·∫°y t√°c v·ª• ƒëa lu·ªìng v√† B·∫≠t/T·∫Øt n√∫t."""

    def __init__(self, logger, all_buttons_list, root):
        self.logger = logger
        self.all_buttons = all_buttons_list
        self.root = root
        self.optimizer_apply_button = None  # N√∫t ƒë·∫∑c bi·ªát

    def set_buttons_state(self, state):
        """B·∫≠t/T·∫Øt t·∫•t c·∫£ c√°c n√∫t."""
        for button in self.all_buttons:
            # (LOGIC T·ª™ UI_MAIN_WINDOW)
            # ƒê·∫£m b·∫£o n√∫t "√Åp d·ª•ng" ch·ªâ b·∫≠t khi c√≥ k·∫øt qu·∫£
            if button == self.optimizer_apply_button and state == tk.NORMAL:
                # N√∫t "√Åp d·ª•ng" s·∫Ω ƒë∆∞·ª£c b·∫≠t ri√™ng khi c√≥ k·∫øt qu·∫£
                continue

            button.config(state=state)
        self.root.update_idletasks()

    def run_task(self, target_function, *args):
        """
        H√†m bao b·ªçc (wrapper) chung ƒë·ªÉ ch·∫°y b·∫•t k·ª≥ t√°c v·ª• n√†o trong m·ªôt lu·ªìng ri√™ng.
        ƒêi·ªÅu n√†y ngƒÉn ch·∫∑n UI b·ªã "ƒê∆°" (Freeze).
        """
        self.set_buttons_state(tk.DISABLED)

        def _thread_wrapper():
            """H√†m n√†y s·∫Ω ch·∫°y trong lu·ªìng m·ªõi."""
            try:
                target_function(*args)
            except Exception as e:
                self.logger.log(f"L·ªñI LU·ªíNG: {e}")
                self.logger.log(traceback.format_exc())
            finally:
                self.root.after(0, self.set_buttons_state, tk.NORMAL)

        task_thread = threading.Thread(target=_thread_wrapper, daemon=True)
        task_thread.start()


--------------------------------------------------

=== FILE: debug_bridge_manager.py ===
import os
import re

def fix_dashboard_analytics():
    file_path = 'code6/logic/dashboard_analytics.py'
    
    if not os.path.exists(file_path):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file: {file_path}")
        return

    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()

    print(f"üîç ƒêang ph√¢n t√≠ch {file_path}...")

    # Pattern nh·∫≠n di·ªán v·ªã tr√≠ ƒëang t·ªïng h·ª£p k·∫øt qu·∫£ (th∆∞·ªùng c√≥ g√°n win_rate)
    # T√¨m ƒëo·∫°n g√°n 'win_rate' trong m·ªôt dictionary
    # Pattern n√†y t√¨m c√°c d√≤ng ki·ªÉu: stats['win_rate'] = ... ho·∫∑c 'win_rate': ...
    
    # 1. T√¨m v·ªã tr√≠ loop qua c√°c bridge/strategy
    # Ch√∫ng ta s·∫Ω inject logic predict v√†o ngay tr∆∞·ªõc khi result ƒë∆∞·ª£c append ho·∫∑c return
    
    # ƒêo·∫°n code ch√®n th√™m (Inject Code)
    # S·ª≠ d·ª•ng logic an to√†n: Ki·ªÉm tra method predict/predict_next
    inject_code = """
                # [AUTO-FIX] Inject prediction for UI
                try:
                    if hasattr(bridge, 'predict'):
                        # L·∫•y d·ª± ƒëo√°n cho ng√†y m·ªõi nh·∫•t
                        _pred = bridge.predict()
                        # Format list th√†nh chu·ªói n·∫øu c·∫ßn
                        if isinstance(_pred, (list, tuple)):
                            stats['prediction'] = ", ".join(map(str, _pred))
                        else:
                            stats['prediction'] = str(_pred)
                    else:
                        stats['prediction'] = "N/A"
                except Exception as e:
                    stats['prediction'] = "Err"
    """

    # Chi·∫øn thu·∫≠t thay th·∫ø: T√¨m d√≤ng g√°n win_rate v√† ch√®n ƒëo·∫°n code tr√™n ngay sau n√≥
    # Regex t√¨m d√≤ng g√°n win_rate v√† th·ª•t ƒë·∫ßu d√≤ng c·ªßa n√≥
    pattern = r"(\s+)(.*?)['\"]win_rate['\"]\s*[:=].*?(\n)"
    
    match = re.search(pattern, content)
    
    if match:
        indentation = match.group(1)
        # Chu·∫©n h√≥a indentation cho code inject
        formatted_inject = inject_code.replace("                ", indentation)
        
        # Th·ª±c hi·ªán ch√®n
        new_content = content[:match.end()] + formatted_inject + content[match.end():]
        
        # Backup file c≈©
        os.rename(file_path, file_path + ".bak")
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(new_content)
            
        print("‚úÖ ƒê√£ s·ª≠a file logic/dashboard_analytics.py th√†nh c√¥ng!")
        print("üëâ ƒê√£ th√™m logic l·∫•y d·ª± ƒëo√°n (predict) v√†o b·∫£ng th·ªëng k√™.")
        print(f"‚ÑπÔ∏è File g·ªëc ƒë√£ ƒë∆∞·ª£c backup t·∫°i: {file_path}.bak")
    else:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y v·ªã tr√≠ inject code an to√†n (kh√¥ng th·∫•y key 'win_rate').")
        print("ƒê·ªÅ ngh·ªã ki·ªÉm tra th·ªß c√¥ng h√†m get_top_performing_bridges.")

if __name__ == "__main__":
    fix_dashboard_analytics()

--------------------------------------------------

=== FILE: debug_de_backtest.py ===
# T√™n file: debug_de_backtest.py
import sys
import os
import sqlite3
import traceback

# 1. SETUP ƒê∆Ø·ªúNG D·∫™N
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

print(">>> [INIT] ƒêang kh·ªüi t·∫°o m√¥i tr∆∞·ªùng ki·ªÉm tra...")

try:
    from lottery_service import load_data_ai_from_db, DB_NAME
    from logic.de_backtester_core import run_de_bridge_historical_test
    print(f">>> [IMPORT] Th√†nh c√¥ng. DB_NAME: {DB_NAME}")
except ImportError as e:
    print(f">>> [L·ªñI IMPORT] Kh√¥ng th·ªÉ load modules: {e}")
    exit()

# 2. H√ÄM GI·∫¢ L·∫¨P PARSE C·∫¶U (ƒê·ªÇ KI·ªÇM TRA LOGIC)
def mock_parse_bridge(bridge_name):
    """Gi·∫£ l·∫≠p logic parse t√™n c·∫ßu: VD GDB.1-G1.2"""
    try:
        parts = bridge_name.split("-")
        if len(parts) != 2: return None
        
        def parse_one(s):
            # GDB.1 -> (GDB, 1)
            p = s.split(".")
            return p[0], int(p[1]) if len(p) > 1 else 0
            
        p1 = parse_one(parts[0])
        p2 = parse_one(parts[1])
        return {"pos1": p1, "pos2": p2}
    except Exception as e:
        print(f"L·ªói parse: {e}")
        return None

# 3. CH·∫†Y TEST
def run_diagnostic():
    print("\n---------------------------------------------------")
    print(">>> [B∆Ø·ªöC 1] T·∫£i d·ªØ li·ªáu t·ª´ DB...")
    
    # Check DB file
    if not os.path.exists(DB_NAME):
        print(f">>> [L·ªñI] Kh√¥ng t√¨m th·∫•y file DB t·∫°i: {DB_NAME}")
        return

    all_data, msg = load_data_ai_from_db(DB_NAME)
    if not all_data or len(all_data) < 10:
        print(f">>> [L·ªñI] D·ªØ li·ªáu qu√° √≠t ho·∫∑c r·ªóng. Msg: {msg}")
        return
    print(f">>> [OK] ƒê√£ t·∫£i {len(all_data)} d√≤ng d·ªØ li·ªáu.")

    # T·∫°o m·ªôt t√™n c·∫ßu gi·∫£ ƒë·ªãnh ƒë·ªÉ test (C·∫ßu Gi·∫£i ƒêB s·ªë 1 gh√©p Gi·∫£i 1 s·ªë 1)
    test_bridge_name = "GDB.0-G1.0" 
    
    print(f"\n>>> [B∆Ø·ªöC 2] Th·ª≠ Backtest c·∫ßu ƒë·ªông: '{test_bridge_name}'")
    
    # C·∫•u h√¨nh Fallback gi·ªëng nh∆∞ t√¥i ƒë√£ s·ª≠a trong analysis_service.py
    fallback_config = {
        "name": test_bridge_name,
        "type": "DE_DYNAMIC_K",
        "is_scanner_result": True,
        "def_string": test_bridge_name
    }
    
    print(f">>> Config g·ª≠i ƒëi: {fallback_config}")

    try:
        # G·ªåI H√ÄM CORE
        results = run_de_bridge_historical_test(fallback_config, all_data, days=30)
        
        if results is None:
            print(">>> [K·∫æT QU·∫¢] None (H√†m tr·∫£ v·ªÅ r·ªóng - C√≥ l·ªói b√™n trong nh∆∞ng b·ªã try/except b·∫Øt)")
        elif len(results) == 0:
            print(">>> [K·∫æT QU·∫¢] List R·ªóng [] (Logic ch·∫°y nh∆∞ng kh√¥ng t√¨m th·∫•y c·∫ßu ho·∫∑c l·ªói parse)")
            # Ki·ªÉm tra xem logic parse c√≥ ho·∫°t ƒë·ªông kh√¥ng
            print("    -> Kh·∫£ nƒÉng cao logic trong 'de_backtester_core' ch∆∞a x·ª≠ l√Ω c·ªù 'is_scanner_result'.")
        else:
            print(f">>> [TH√ÄNH C√îNG] Nh·∫≠n ƒë∆∞·ª£c {len(results)} k·∫øt qu·∫£ backtest!")
            print("    -> M·∫´u k·∫øt qu·∫£ ƒë·∫ßu ti√™n:", results[0])
            
    except Exception as e:
        print(f">>> [CRASH] L·ªói khi g·ªçi run_de_bridge_historical_test:")
        traceback.print_exc()

if __name__ == "__main__":
    run_diagnostic()
    input("\nNh·∫•n Enter ƒë·ªÉ tho√°t...")

--------------------------------------------------

=== FILE: loto_data_diagnostic.py ===
import logging
import sys
from typing import List, Any

# ===================================================================================
# C√ÅC H√ÄM C·∫¶N KI·ªÇM TRA (Tr√≠ch xu·∫•t t·ª´ utils.py)
# ===================================================================================

def getAllLoto_V30(row: List[Any]) -> List[str]:
    """L·∫•y t·∫•t c·∫£ 27 loto t·ª´ 1 h√†ng DuLieu_AI (ƒë√£ s·∫Øp x·∫øp c·ªôt B->I)"""
    lotos = []
    try:
        # row[0]=MaSoKy, row[1]=Col_A_Ky (Ch√∫ng ta ch·ªâ quan t√¢m t·ª´ row[2] tr·ªü ƒëi)
        
        # 1. Gi·∫£i ƒê·∫∑c Bi·ªát (GƒêB) - row[2]
        lotos.append(str(row[2] or "0").strip()[-2:].zfill(2))
        
        # 2. Gi·∫£i Nh·∫•t (G1) - row[3]
        lotos.append(str(row[3] or "0").strip()[-2:].zfill(2))
        
        # 3. C√°c gi·∫£i c√≤n l·∫°i (G2 ƒë·∫øn G7) - row[4] ƒë·∫øn row[9]
        for i in range(4, 10):
            if row[i]:
                # Gi·∫£i c√≥ th·ªÉ c√≥ nhi·ªÅu s·ªë, c√°ch nhau b·ªüi d·∫•u ph·∫©y (V√≠ d·ª•: '1122,3344')
                for g in str(row[i]).split(","):
                    # L·∫•y 2 s·ªë cu·ªëi c·ªßa t·ª´ng gi·∫£i v√† th√™m v√†o danh s√°ch
                    lotos.append(g.strip()[-2:].zfill(2))
        
        return lotos
        
    except Exception as e:
        print(f"‚ùå L·ªñI TR√çCH XU·∫§T D·ªÆ LI·ªÜU L√î: {e}")
        return []

# ===================================================================================
# SCRIPT KI·ªÇM TRA CH·∫®N ƒêO√ÅN
# ===================================================================================

def run_data_diagnostic():
    """
    Ch·∫°y ch·∫©n ƒëo√°n ƒë·ªÉ ki·ªÉm tra h√†m tr√≠ch xu·∫•t 27 con L√¥ c√≥ ho·∫°t ƒë·ªông ƒë√∫ng kh√¥ng.
    S·ª≠ d·ª•ng d·ªØ li·ªáu KQXS m√¥ ph·ªèng 27 gi·∫£i.
    """
    print("====================================================================")
    print("üöÄ CH·∫®N ƒêO√ÅN: T·∫¶NG TR√çCH XU·∫§T D·ªÆ LI·ªÜU L√î (getAllLoto_V30)")
    print("====================================================================")
    
    # D·ªØ li·ªáu KQXS H√† N·ªôi 27 gi·∫£i (M√¥ ph·ªèng 1 h√†ng DuLieu_AI)
    # C·∫•u tr√∫c: [KyID, Col_A, GƒêB, G1, G2, G3, G4, G5, G6, G7]
    mock_row = [
        'K·ª≥ 12345',  # row[0] - KyID
        '2025-11-28', # row[1] - Col_A_Ky (Ng√†y)
        '87042',      # row[2] - GƒêB (L√¥: 42)
        '10031',      # row[3] - G1 (L√¥: 31)
        '5566,7788',  # row[4] - G2 (L√¥: 66, 88) - 2 gi·∫£i
        '9900,1020,3040,5060,7080,9010', # row[5] - G3 (L√¥: 00, 20, 40, 60, 80, 10) - 6 gi·∫£i
        '2030,4050,6070,8090', # row[6] - G4 (L√¥: 30, 50, 70, 90) - 4 gi·∫£i
        '0001,2040,6080,9010,1112,3314', # row[7] - G5 (L√¥: 01, 40, 80, 10, 12, 14) - 6 gi·∫£i
        '55,66,77',   # row[8] - G6 (L√¥: 55, 66, 77) - 3 gi·∫£i
        '88,99,10,20' # row[9] - G7 (L√¥: 88, 99, 10, 20) - 4 gi·∫£i
        # T·ªîNG S·ªê L√î: 1 + 1 + 2 + 6 + 4 + 6 + 3 + 4 = 27 L√î
    ]
    
    # 2. Ch·∫°y h√†m ki·ªÉm tra
    extracted_lotos = getAllLoto_V30(mock_row)

    # 3. Ki·ªÉm tra k·∫øt qu·∫£
    expected_count = 27
    
    print(f"T·ªïng s·ªë L√¥ tr√≠ch xu·∫•t ƒë∆∞·ª£c: {len(extracted_lotos)}")
    print(f"Danh s√°ch L√¥ (5 s·ªë ƒë·∫ßu): {extracted_lotos[:5]}")
    print(f"Danh s√°ch L√¥ (5 s·ªë cu·ªëi): {extracted_lotos[-5:]}")
    
    if len(extracted_lotos) == expected_count:
        print("\n‚úÖ K·∫æT QU·∫¢: H√ÄM TR√çCH XU·∫§T D·ªÆ LI·ªÜU L√î HO·∫†T ƒê·ªòNG CH√çNH X√ÅC (27/27 L√¥).")
        print("   => V·∫•n ƒë·ªÅ n·∫±m ·ªü T·∫ßng Qu√©t C·∫ßu (Scanner Logic).")
    elif len(extracted_lotos) == 0:
        print("\n‚ùå K·∫æT QU·∫¢: L·ªñI NGHI√äM TR·ªåNG (0 L√¥). C√≥ th·ªÉ d·ªØ li·ªáu ƒë·∫ßu v√†o b·ªã sai ƒë·ªãnh d·∫°ng.")
        print("   => V·∫•n ƒë·ªÅ n·∫±m ·ªü T·∫ßng Utility (Ch∆∞a tr√≠ch xu·∫•t ƒë∆∞·ª£c d·ªØ li·ªáu).")
    else:
        print(f"\n‚ö†Ô∏è K·∫æT QU·∫¢: L·ªñI S·ªê L∆Ø·ª¢NG L√î (Tr√≠ch xu·∫•t: {len(extracted_lotos)}/{expected_count}).")
        print("   => V·∫•n ƒë·ªÅ n·∫±m ·ªü T·∫ßng Utility (H√†m t√°ch d·ªØ li·ªáu b·ªã thi·∫øu/sai logic).")

if __name__ == "__main__":
    run_data_diagnostic()

--------------------------------------------------

=== FILE: lottery_service.py ===
# T√™n file: git1/lottery_service.py
#
# (N·ªòI DUNG THAY TH·∫æ TO√ÄN B·ªò - S·ª¨A L·ªñI MISSING IMPORT DASHBOARD ANALYTICS)
#
"""
==================================================================================
LOTTERY SERVICE API (B·ªò ƒêI·ªÄU PH·ªêI) - (V7.4 - FIXED EXPORTS)
==================================================================================
File n√†y ƒë√≥ng vai tr√≤ l√† API trung t√¢m, import v√† ph√¢n ph·ªëi logic t·ª´
c√°c file con trong th∆∞ m·ª•c /logic.
"""
# 1. LOGIC DB & REPO
try:
    from logic.data_repository import get_all_managed_bridges, load_data_ai_from_db, delete_managed_bridges_batch
    from logic.db_manager import (
        DB_NAME,
        add_managed_bridge,
        delete_managed_bridge,
        delete_ky_from_db,
        get_all_kys_from_db,
        get_results_by_ky,
        setup_database,
        update_bridge_k2n_cache_batch,
        update_bridge_win_rate_batch,
        update_managed_bridge,
        upsert_managed_bridge,
    )

    print(">>> (V7.3) T·∫£i logic.db_manager & data_repository th√†nh c√¥ng.")
except ImportError as e_db:
    print(f"L·ªñI NGHI√äM TR·ªåNG: Kh√¥ng th·ªÉ import logic DB/Repo: {e_db}")
    # Fallback for delete_managed_bridges_batch if import fails
    def delete_managed_bridges_batch(names, db_name=None, transactional=False, chunk_size=500):
        return {"requested": len(names or []), "deleted": [], "missing": list(names or []), "failed": [{"error": "delete_managed_bridges_batch not available"}]}

# 2. LOGIC PARSING (X·ª¨ L√ù D·ªÆ LI·ªÜU)
try:
    from logic.data_parser import (
        parse_and_APPEND_data,
        parse_and_APPEND_data_TEXT,
        parse_and_insert_data,
        run_and_update_from_text,
    )

    print(">>> (V7.3) T·∫£i logic.data_parser th√†nh c√¥ng.")
except ImportError as e_parser:
    print(f"L·ªñI NGHI√äM TR·ªåNG: Kh√¥ng th·ªÉ import logic.data_parser: {e_parser}")

# 3. LOGIC C·∫¶U C·ªî ƒêI·ªÇN & TI·ªÜN √çCH
try:
    from logic.bridges.bridges_classic import (
        ALL_15_BRIDGE_FUNCTIONS_V5,
        calculate_loto_stats,
        getAllLoto_V30,
    )

    print(">>> (V7.3) T·∫£i logic.bridges.bridges_classic th√†nh c√¥ng.")
except ImportError as e_classic:
    print(
        f"L·ªñI NGHI√äM TR·ªåNG: Kh√¥ng th·ªÉ import logic.bridges.bridges_classic: {e_classic}"
    )

# 4. LOGIC BACKTEST
try:
    from logic.backtester import (
        BACKTEST_15_CAU_K2N_V30_AI_V8,
        BACKTEST_15_CAU_N1_V31_AI_V8,
        BACKTEST_CUSTOM_CAU_V16,
        BACKTEST_MANAGED_BRIDGES_K2N,
        BACKTEST_MANAGED_BRIDGES_N1,
        BACKTEST_MEMORY_BRIDGES,
        TONGHOP_TOP_CAU_N1_V5,
        TONGHOP_TOP_CAU_RATE_V5,
        run_and_update_all_bridge_K2N_cache,
        run_and_update_all_bridge_rates,
    )

    print(">>> (V7.3) T·∫£i logic.backtester th√†nh c√¥ng.")
except ImportError as e_backtester:
    print(f"L·ªñƒ® NGHI√äM TR·ªåNG: Kh√¥ng th·ªÉ import logic.backtester: {e_backtester}")

# 5. LOGIC QU·∫¢N L√ù C·∫¶U (D√í, L·ªåC)
try:
    # Import scanning functions from lo_bridge_scanner
    from logic.bridges.lo_bridge_scanner import (
        TIM_CAU_BAC_NHO_TOT_NHAT,
        TIM_CAU_TOT_NHAT_V16,
        update_fixed_lo_bridges,
    )
    # Import management functions from bridge_manager_core
    from logic.bridges.bridge_manager_core import (
        auto_manage_bridges,
        find_and_auto_manage_bridges,
        prune_bad_bridges,
    )
    from logic.bridges.bridge_manager_de import find_and_auto_manage_bridges_de

    print(">>> (V7.3) T·∫£i logic.bridges.bridge_manager_core & lo_bridge_scanner th√†nh c√¥ng.")
except ImportError as e_bridge_core:
    print(
        f"L·ªñI NGHI√äM TR·ªåNG: Kh√¥ng th·ªÉ import logic.bridges modules: {e_bridge_core}"
    )

# 6. LOGIC DASHBOARD (CH·∫§M ƒêI·ªÇM)
try:
    from logic.dashboard_analytics import (
        get_high_win_rate_predictions,
        get_historical_dashboard_data,
        get_loto_gan_stats,
        get_loto_stats_last_n_days,
        get_prediction_consensus,
        get_top_memory_bridge_predictions,
        get_top_scored_pairs,
        # [FIXED] Th√™m import ƒë·ªÉ ph·ª•c v·ª• AppController
        prepare_daily_features,
        calculate_score_from_features
    )

    print(">>> (V7.3) T·∫£i logic.dashboard_analytics th√†nh c√¥ng.")
except ImportError as e_dashboard:
    print(
        f"L·ªñI NGHI√äM TR·ªåNG: Kh√¥ng th·ªÉ import logic.dashboard_analytics: {e_dashboard}"
    )


# 7. LOGIC AI (HU·∫§N LUY·ªÜN, D·ª∞ ƒêO√ÅN, ƒêA LU·ªíNG)
try:
    # (S·ª¨A) Import c√°c h√†m AI ƒë√£ ƒë∆∞·ª£c t√°ch bi·ªát
    from logic.ai_feature_extractor import (
        run_ai_prediction_for_dashboard,
        run_ai_training_threaded,
    )

    print(">>> (V7.3) T·∫£i logic.ai_feature_extractor (AI Wrappers) th√†nh c√¥ng.")
except ImportError as e_ai:
    error_msg = str(e_ai)
    print(f"L·ªñI NGHI√äM TR·ªåNG: Kh√¥ng th·ªÉ import logic.ai_feature_extractor (AI): {error_msg}")

    # Gi·∫£ l·∫≠p h√†m n·∫øu l·ªói
    def run_ai_training_threaded(callback=None):
        return False, "L·ªói: Kh√¥ng t√¨m th·∫•y module ai_feature_extractor"

    def run_ai_prediction_for_dashboard():
        return None, "L·ªói: Kh√¥ng t√¨m th·∫•y module ai_feature_extractor"


# Th√™m __all__ ƒë·ªÉ ƒë√°nh d·∫•u c√°c h√†m n√†y l√† 'ƒë∆∞·ª£c s·ª≠ d·ª•ng' (ƒë·ªÉ export)
__all__ = [
    # DB & Repo (12)
    "get_all_managed_bridges",
    "load_data_ai_from_db",
    "DB_NAME",
    "add_managed_bridge",
    "delete_managed_bridge",
    "delete_managed_bridges_batch",
    "get_all_kys_from_db",
    "get_results_by_ky",
    "setup_database",
    "update_bridge_k2n_cache_batch",
    "update_bridge_win_rate_batch",
    "update_managed_bridge",
    "upsert_managed_bridge",
    # Parsing (4)
    "parse_and_APPEND_data",
    "parse_and_APPEND_data_TEXT",
    "parse_and_insert_data",
    "run_and_update_from_text",
    # Bridges Classic (3)
    "ALL_15_BRIDGE_FUNCTIONS_V5",
    "calculate_loto_stats",
    "getAllLoto_V30",
    # Backtester (10)
    "BACKTEST_15_CAU_K2N_V30_AI_V8",
    "BACKTEST_15_CAU_N1_V31_AI_V8",
    "BACKTEST_CUSTOM_CAU_V16",
    "BACKTEST_MANAGED_BRIDGES_K2N",
    "BACKTEST_MANAGED_BRIDGES_N1",
    "BACKTEST_MEMORY_BRIDGES",
    "TONGHOP_TOP_CAU_N1_V5",
    "TONGHOP_TOP_CAU_RATE_V5",
    "run_and_update_all_bridge_K2N_cache",
    "run_and_update_all_bridge_rates",
    # Bridge Manager (5)
    "TIM_CAU_BAC_NHO_TOT_NHAT",
    "TIM_CAU_TOT_NHAT_V16",
    "auto_manage_bridges",
    "find_and_auto_manage_bridges",
    "prune_bad_bridges",
    "find_and_auto_manage_bridges_de",  # Th√™m h√†m c·ªßa ƒê·ªÅ
    # Dashboard (7)
    "get_high_win_rate_predictions",
    "get_historical_dashboard_data",
    "get_loto_gan_stats",
    "get_loto_stats_last_n_days",
    "get_prediction_consensus",
    "get_top_memory_bridge_predictions",
    "get_top_scored_pairs",
    # AI (2)
    "run_ai_prediction_for_dashboard",
    "run_ai_training_threaded",
    # H√†m Wrapper (1)
    "get_all_managed_bridges_wrapper",
    # Optimizer functions
    "prepare_daily_features",
    "calculate_score_from_features",
]


# ==========================================================================
# C√ÅC H√ÄM H·ªñ TR·ª¢ C≈® (ƒê·∫£m b·∫£o ch·ªØ k√Ω/logic ƒë√∫ng)
# ==========================================================================


# Wrapper cho get_all_managed_bridges ƒë·ªÉ t∆∞∆°ng th√≠ch
def get_all_managed_bridges_wrapper(db_name=DB_NAME, only_enabled=False):
    """
    Wrapper (Gi·ªØ l·∫°i h√†m n√†y cho t∆∞∆°ng th√≠ch)
    """
    # G·ªçi h√†m m·ªõi t·ª´ data_repository.py ƒë√£ ƒë∆∞·ª£c import
    return get_all_managed_bridges(db_name, only_enabled)


print("Lottery Service API (lottery_service.py) ƒë√£ t·∫£i th√†nh c√¥ng (V7.4).")

--------------------------------------------------

=== FILE: main_app.py ===
import os

# ƒê·∫£m b·∫£o th∆∞ m·ª•c logic v√† ui ƒë∆∞·ª£c th√™m v√†o
import sys
import tkinter as tk

sys.path.append(os.path.abspath(os.path.dirname(__file__)))

try:
    from ui.ui_main_window import DataAnalysisApp
except ImportError as e:
    print(f"L·ªñI: Kh√¥ng th·ªÉ import DataAnalysisApp t·ª´ ui.ui_main_window: {e}")
    print("H√£y ch·∫Øc ch·∫Øn b·∫°n ƒë√£ t·∫°o th∆∞ m·ª•c /ui v√† c√°c file b√™n trong n√≥.")
    input("Nh·∫•n Enter ƒë·ªÉ tho√°t...")
    sys.exit()

if __name__ == "__main__":
    try:
        root = tk.Tk()
        app = DataAnalysisApp(root)
        root.mainloop()
    except Exception as e:
        print(f"L·ªñI KH√îNG X√ÅC ƒê·ªäNH KHI CH·∫†Y APP: {e}")
        import traceback

        print(traceback.format_exc())
        input("Nh·∫•n Enter ƒë·ªÉ tho√°t...")


--------------------------------------------------

=== FILE: README.md ===
# X·ªï S·ªë Data Analysis System (XS-DAS) - V11.2

[![CI Pipeline](https://github.com/nguyenhien7268-ship-it/git1/actions/workflows/ci.yml/badge.svg)](https://github.com/nguyenhien7268-ship-it/git1/actions/workflows/ci.yml)
[![Code Quality](https://img.shields.io/badge/flake8-passing-brightgreen)](https://github.com/nguyenhien7268-ship-it/git1)
[![Tests](https://img.shields.io/badge/tests-12%20passing-brightgreen)](https://github.com/nguyenhien7268-ship-it/git1)

## üéØ Gi·ªõi Thi·ªáu

ƒê√¢y l√† H·ªá th·ªëng Ph√¢n t√≠ch D·ªØ li·ªáu X·ªï S·ªë (XS-DAS), ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ t·ª± ƒë·ªông backtest, ph√¢n t√≠ch chuy√™n s√¢u c√°c chi·∫øn l∆∞·ª£c d√≤ c·∫ßu, qu·∫£n l√Ω chi·∫øn l∆∞·ª£c v√† ƒë∆∞a ra d·ª± ƒëo√°n d·ª±a tr√™n AI. H·ªá th·ªëng cung c·∫•p c√°c c√¥ng c·ª• tr·ª±c quan ƒë·ªÉ tinh ch·ªânh v√† t·ªëi ∆∞u h√≥a tham s·ªë ƒë·∫ßu t∆∞.

---

## üöÄ C·∫¨P NH·∫¨T M·ªöI (V11.2 - K1N-PRIMARY SCANNER REFACTOR)

Phi√™n b·∫£n V11.2 t·∫≠p trung v√†o t√°i c·∫•u tr√∫c **Scanner Module** ƒë·ªÉ h·ªó tr·ª£ quy tr√¨nh K1N-Primary Detection Flow:

* **üîç Scanner Read-Only:** C√°c module scanner (de_bridge_scanner.py, lo_bridge_scanner.py) kh√¥ng c√≤n ghi tr·ª±c ti·∫øp v√†o DB.
    * Scanners tr·∫£ v·ªÅ `Candidate` objects v·ªõi K1N/K2N rates ƒë√≠nh k√®m
    * T·ª± ƒë·ªông lo·∫°i tr·ª´ bridges ƒë√£ t·ªìn t·∫°i tr∆∞·ªõc khi tr·∫£ k·∫øt qu·∫£
    * Single DB call cho hi·ªáu su·∫•t t·ªëi ∆∞u
* **üìä K1N/K2N Rate Integration:** 
    * T·ª± ƒë·ªông ƒë√≠nh k√®m K1N (real backtest) v√† K2N (simulated) rates t·ª´ cache
    * ƒê√°nh d·∫•u `rate_missing` flag khi kh√¥ng t√¨m th·∫•y rates trong cache
    * H·ªó tr·ª£ policy-based filtering (K1N-primary, K2N-primary, combined)
* **üîÑ Import Workflow:** 
    * Scan ‚Üí Preview ‚Üí Import v·ªõi `BridgeImporter.preview_import()`
    * Cho ph√©p ki·ªÉm tra tr∆∞·ªõc khi th√™m bridges v√†o DB
    * Atomic bulk operations ƒë·ªÉ ƒë·∫£m b·∫£o t√≠nh to√†n v·∫πn d·ªØ li·ªáu
* **‚úÖ Testing Infrastructure:** Integration tests m·ªõi ƒë·ªÉ verify scanner behavior

### C√°ch s·ª≠ d·ª•ng Scanner m·ªõi:

```python
from logic.bridges.de_bridge_scanner import run_de_scanner
from logic.bridge_importer import BridgeImporter, ImportConfig

# 1. Scan bridges (READ-ONLY, no DB writes)
candidates, meta = run_de_scanner(lottery_data, db_name)
print(f"Found: {meta['found_total']}, Excluded: {meta['excluded_existing']}")

# 2. Preview and filter candidates
config = ImportConfig(policy_type='k1n_primary', threshold_k1n_de=90.0)
importer = BridgeImporter(config)
preview = importer.preview_import(candidates)
print(f"Will import: {preview['accepted']}, Reject: {preview['rejected']}")

# 3. Import accepted candidates
result = importer.import_candidates(candidates)
print(f"Imported: {result['imported']}")
```

---

## üîô C·∫¨P NH·∫¨T TR∆Ø·ªöC ƒê√ì (V7.5 - DASHBOARD REVOLUTION)

* **üìä Giao di·ªán Dashboard 24 C·ªôt:** Layout m·ªõi t·ªëi ∆∞u h√≥a kh√¥ng gian, chia t·ª∑ l·ªá 2/3 cho B·∫£ng Ch·∫•m ƒêi·ªÉm v√† 1/3 cho C·∫ßu K2N Ch·ªù.
* **üß† Logic Ch·∫•m ƒêi·ªÉm Th√¥ng Minh:** Ph·∫°t r·ªßi ro c·ªë ƒë·ªãnh, gom nh√≥m l√Ω do, b·∫£ng phong ƒë·ªô 10 k·ª≥.
* **‚ö° T·ªëi ∆Øu Backtest Core:** S·ª≠a l·ªói t√≠nh to√°n phong ƒë·ªô trong ch·∫ø ƒë·ªô ch·∫°y ng·∫ßm.

---

## üèóÔ∏è KI·∫æN TR√öC H·ªÜ TH·ªêNG (MVP)

H·ªá th·ªëng v·∫≠n h√†nh theo m√¥ h√¨nh **Model-View-Presenter (MVP)** c·∫£i ti·∫øn:

### 1. Model (`logic/`)
"B·ªô n√£o" c·ªßa ·ª©ng d·ª•ng, ch·ª©a to√†n b·ªô logic nghi·ªáp v·ª•:
* **`backtester_core.py`**: L√µi t√≠nh to√°n Backtest, h·ªó tr·ª£ ƒëa thu·∫≠t to√°n (V17 & B·∫°c Nh·ªõ).
* **`dashboard_analytics.py`**: Engine ch·∫•m ƒëi·ªÉm t·ªïng l·ª±c, ph√¢n t√≠ch r·ªßi ro v√† c∆° h·ªôi.
* **`bridges/`**: Ch·ª©a c√°c thu·∫≠t to√°n soi c·∫ßu:
    * `bridges_v16.py`: C·∫ßu V17 (B√≥ng √Çm D∆∞∆°ng).
    * `bridges_memory.py`: C·∫ßu B·∫°c Nh·ªõ (T·ªïng/Hi·ªáu).
* **`ml_model.py`**: M√¥ h√¨nh AI (XGBoost) d·ª± ƒëo√°n x√°c su·∫•t.
* **`db_manager.py`**: Qu·∫£n l√Ω c∆° s·ªü d·ªØ li·ªáu SQLite (`ManagedBridges`, `results_A_I`).

### 2. View (`ui/`)
Giao di·ªán ng∆∞·ªùi d√πng (Tkinter):
* **`ui_dashboard.py`**: B·∫£ng ƒëi·ªÅu khi·ªÉn trung t√¢m (Decision Dashboard).
* **`ui_bridge_manager.py`**: Qu·∫£n l√Ω danh s√°ch c·∫ßu ƒë√£ l∆∞u.
* **`ui_settings.py`**: C√†i ƒë·∫∑t tham s·ªë h·ªá th·ªëng (Ng∆∞·ª°ng ph·∫°t, Tr·ªçng s·ªë AI...).
* **`ui_main_window.py`**: Khung ch∆∞∆°ng tr√¨nh ch√≠nh.

### 3. Controller
* **`app_controller.py`**: ƒêi·ªÅu ph·ªëi lu·ªìng d·ªØ li·ªáu gi·ªØa UI v√† Logic.

---

## ‚öôÔ∏è Y√™u c·∫ßu Th∆∞ vi·ªán

C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt qua `pip`:

```bash
pip install -r requirements.txt

--------------------------------------------------

=== FILE: setup.py ===
# setup.py
# Minimal setup for pytest imports

from setuptools import setup, find_packages

setup(
    name="xoso-das",
    version="11.2.0",
    packages=find_packages(),
    install_requires=[
        "pytest>=7.4.3",
        "pytest-cov>=4.1.0",
    ],
)


--------------------------------------------------

=== FILE: logic\adaptive_trainer.py ===
# logic/adaptive_trainer.py
"""
V7.7 Phase 3 Adaptive Retraining System

This module manages automatic model retraining to adapt to changing lottery patterns.
It supports two modes:
1. Incremental: Fast daily retraining on rolling window of recent data
2. Full: Complete monthly retraining with hyperparameter tuning

The system monitors F1-Score performance and triggers retraining when degradation
is detected.
"""

from datetime import datetime
import traceback


class AdaptiveTrainer:
    """
    Manages automatic model retraining on rolling windows of data.
    """

    def __init__(self, config=None):
        """
        Initialize Adaptive Trainer with configuration.

        Args:
            config: Optional dict with settings:
                - ROLLING_WINDOW_SIZE: Periods for incremental training (default: 400)
                - MIN_RETRAINING_GAP_DAYS: Minimum days between retrains (default: 7)
                - F1_DEGRADATION_THRESHOLD: Trigger retrain if F1 drops (default: 0.02)
                - FULL_RETRAIN_INTERVAL_DAYS: Days between full retrains (default: 30)
                - ENABLE_AUTO_RETRAIN: Master switch (default: False for safety)
        """
        if config is None:
            config = self._load_default_config()

        self.rolling_window_size = config.get('ROLLING_WINDOW_SIZE', 400)
        self.min_retraining_gap = config.get('MIN_RETRAINING_GAP_DAYS', 7)
        self.f1_degradation_threshold = config.get('F1_DEGRADATION_THRESHOLD', 0.02)
        self.full_retrain_interval = config.get('FULL_RETRAIN_INTERVAL_DAYS', 30)
        self.enable_auto_retrain = config.get('ENABLE_AUTO_RETRAIN', False)

        self.last_retrain_date = None
        self.last_full_retrain = None
        self.baseline_f1_score = None

    def _load_default_config(self):
        """Load configuration from config_manager if available."""
        try:
            from logic.config_manager import SETTINGS
            return {
                'ROLLING_WINDOW_SIZE': getattr(SETTINGS, 'ROLLING_WINDOW_SIZE', 400),
                'MIN_RETRAINING_GAP_DAYS': getattr(SETTINGS, 'MIN_RETRAINING_GAP_DAYS', 7),
                'F1_DEGRADATION_THRESHOLD': getattr(SETTINGS, 'F1_DEGRADATION_THRESHOLD', 0.02),
                'FULL_RETRAIN_INTERVAL_DAYS': getattr(SETTINGS, 'FULL_RETRAIN_INTERVAL_DAYS', 30),
                'ENABLE_AUTO_RETRAIN': getattr(SETTINGS, 'ENABLE_AUTO_RETRAIN', False)
            }
        except ImportError:
            return {}

    def should_retrain_incremental(self, current_date=None, current_f1_score=None):
        """
        Decide if incremental retraining is needed.

        Args:
            current_date: Date to check (default: today)
            current_f1_score: Current model F1 score (optional)

        Returns:
            tuple: (should_retrain, reason)
        """
        if not self.enable_auto_retrain:
            return False, "Auto-retrain disabled"

        if current_date is None:
            current_date = datetime.now()

        # Check time gap
        if self.last_retrain_date:
            days_since_retrain = (current_date - self.last_retrain_date).days
            if days_since_retrain < self.min_retraining_gap:
                return False, f"Too soon (only {days_since_retrain} days)"

        # Check performance degradation
        if self.baseline_f1_score and current_f1_score:
            degradation = self.baseline_f1_score - current_f1_score
            if degradation > self.f1_degradation_threshold:
                return True, f"Performance degraded ({degradation:.3f} drop in F1)"

        # Check if enough time has passed
        if self.last_retrain_date:
            days_since_retrain = (current_date - self.last_retrain_date).days
            if days_since_retrain >= 7:
                return True, "Weekly retrain schedule"

        # Default: retrain if never trained before
        if self.last_retrain_date is None:
            return True, "Initial training"

        return False, "No retrain needed"

    def should_retrain_full(self, current_date=None):
        """
        Decide if full retraining is needed.

        Args:
            current_date: Date to check (default: today)

        Returns:
            tuple: (should_retrain, reason)
        """
        if not self.enable_auto_retrain:
            return False, "Auto-retrain disabled"

        if current_date is None:
            current_date = datetime.now()

        if self.last_full_retrain is None:
            return True, "Initial full training"

        days_since_full = (current_date - self.last_full_retrain).days
        if days_since_full >= self.full_retrain_interval:
            return True, f"Monthly schedule ({days_since_full} days)"

        return False, "No full retrain needed"

    def incremental_retrain(self, all_data_ai):
        """
        Perform incremental retraining on rolling window of recent data.

        Args:
            all_data_ai: Complete lottery data list

        Returns:
            tuple: (success, message)
        """
        try:
            # Take last N periods
            if len(all_data_ai) < self.rolling_window_size:
                recent_data = all_data_ai
            else:
                recent_data = all_data_ai[-self.rolling_window_size:]

            print(f"Incremental retrain using last {len(recent_data)} periods...")

            # Retrain model (same as full train but less data)
            from logic.ai_feature_extractor import _get_daily_bridge_predictions
            from logic.ml_model import train_ai_model

            bridge_predictions = _get_daily_bridge_predictions(recent_data)
            success, msg = train_ai_model(
                recent_data,
                bridge_predictions,
                use_hyperparameter_tuning=False  # Use existing hyperparameters
            )

            if success:
                self.last_retrain_date = datetime.now()
                print(f"‚úÖ Incremental retrain successful at {self.last_retrain_date}")

            return success, msg

        except Exception as e:
            error_msg = f"Error during incremental retrain: {e}\n{traceback.format_exc()}"
            print(error_msg)
            return False, error_msg

    def full_retrain(self, all_data_ai, use_hyperparameter_tuning=True):
        """
        Perform full retraining on all available data.

        Args:
            all_data_ai: Complete lottery data list
            use_hyperparameter_tuning: Whether to tune hyperparameters

        Returns:
            tuple: (success, message)
        """
        try:
            print(f"Full retrain using all {len(all_data_ai)} periods...")

            from logic.ai_feature_extractor import _get_daily_bridge_predictions
            from logic.ml_model import train_ai_model

            bridge_predictions = _get_daily_bridge_predictions(all_data_ai)
            success, msg = train_ai_model(
                all_data_ai,
                bridge_predictions,
                use_hyperparameter_tuning=use_hyperparameter_tuning
            )

            if success:
                self.last_retrain_date = datetime.now()
                self.last_full_retrain = datetime.now()
                print(f"‚úÖ Full retrain successful at {self.last_full_retrain}")

            return success, msg

        except Exception as e:
            error_msg = f"Error during full retrain: {e}\n{traceback.format_exc()}"
            print(error_msg)
            return False, error_msg

    def auto_retrain(self, all_data_ai, current_f1_score=None):
        """
        Automatically decide and execute appropriate retraining.

        Args:
            all_data_ai: Complete lottery data list
            current_f1_score: Optional current F1 score for degradation check

        Returns:
            tuple: (success, message, retrain_type)
                retrain_type: 'full', 'incremental', or None
        """
        if not self.enable_auto_retrain:
            return False, "Auto-retrain is disabled", None

        # Check if full retrain needed
        should_full, full_reason = self.should_retrain_full()
        if should_full:
            print(f"Triggering FULL retrain: {full_reason}")
            success, msg = self.full_retrain(all_data_ai, use_hyperparameter_tuning=True)
            return success, msg, 'full'

        # Check if incremental retrain needed
        should_incremental, incremental_reason = self.should_retrain_incremental(
            current_f1_score=current_f1_score
        )
        if should_incremental:
            print(f"Triggering INCREMENTAL retrain: {incremental_reason}")
            success, msg = self.incremental_retrain(all_data_ai)
            return success, msg, 'incremental'

        return True, "No retraining needed", None

    def set_baseline_f1(self, f1_score):
        """Set baseline F1 score for comparison."""
        self.baseline_f1_score = f1_score
        print(f"Baseline F1-Score set to: {f1_score:.4f}")

    def get_status(self):
        """
        Get current status of Adaptive Trainer.

        Returns:
            dict: Status information
        """
        return {
            'enabled': self.enable_auto_retrain,
            'last_retrain': self.last_retrain_date,
            'last_full_retrain': self.last_full_retrain,
            'baseline_f1': self.baseline_f1_score,
            'rolling_window_size': self.rolling_window_size,
            'min_gap_days': self.min_retraining_gap,
            'f1_threshold': self.f1_degradation_threshold,
            'full_retrain_interval': self.full_retrain_interval
        }


# Singleton instance for convenience
_trainer_instance = None


def get_adaptive_trainer(config=None):
    """Get singleton instance of AdaptiveTrainer."""
    global _trainer_instance
    if _trainer_instance is None:
        _trainer_instance = AdaptiveTrainer(config)
    return _trainer_instance


--------------------------------------------------

=== FILE: logic\ai_feature_extractor.py ===
# T√™n file: git3/logic/ai_feature_extractor.py
#
# (N·ªòI DUNG THAY TH·∫æ TO√ÄN B·ªò - S·ª¨A E226, W503)
#
import threading
import traceback
from collections import Counter, defaultdict

# (S·ª¨A L·ªñI) S·ª≠ d·ª•ng import T∆Ø∆†NG ƒê·ªêI (d·∫•u . ·ªü tr∆∞·ªõc)
try:
    # 1. DB v√† Repo
    # 2. Logic C·∫ßu (ƒë·ªÉ t√≠nh to√°n)
    from .bridges.bridges_classic import ALL_15_BRIDGE_FUNCTIONS_V5, getAllLoto_V30
    from .bridges.bridges_memory import (
        calculate_bridge_stl,
        get_27_loto_names,
        get_27_loto_positions,
    )
    from .bridges.bridges_v16 import getAllPositions_V17_Shadow, taoSTL_V30_Bong

    # 4. Config
    from .data_repository import get_all_managed_bridges, load_data_ai_from_db
    from .db_manager import DB_NAME

    # 3. Logic AI (ƒë·ªÉ g·ªçi)
    from .ml_model import get_ai_predictions, train_ai_model

except ImportError as e:
    print(f"L·ªñI NGHI√äM TR·ªåNG: ai_feature_extractor.py kh√¥ng th·ªÉ import: {e}")

    # G√°n l·ªói v√†o m·ªôt bi·∫øn ƒë·ªÉ c√°c h√†m gi·∫£ c√≥ th·ªÉ truy c·∫≠p
    _IMPORT_ERROR_MSG = f"L·ªói Import: {e}"

    # Kh√¥ng ƒë·ªãnh nghƒ©a l·∫°i h√†m ·ªü ƒë√¢y, ƒë·ªÉ logic ch√≠nh ch·∫°y
    pass


# ==========================================================================
# (DI CHUY·ªÇN T·ª™ LOTTERY_SERVICE) H√ÄM TI·ªÜN √çCH T√çNH TO√ÅN
# ==========================================================================


def _parse_win_rate_text(win_rate_text):
    if not win_rate_text:
        return 0.0
    try:
        return float(win_rate_text.strip().replace("%", ""))
    except ValueError:
        return 0.0


def _standardize_pair(stl_list):
    if not stl_list or len(stl_list) != 2:
        return None
    return "-".join(sorted(stl_list))


# ==========================================================================
# (DI CHUY·ªÇN T·ª™ LOTTERY_SERVICE) LOGIC TR√çCH XU·∫§T ƒê·∫∂C TR∆ØNG C·ªêT L√ïI
# ==========================================================================


def _calculate_win_rate_stddev(win_rates, periods=100):
    """
    (Phase 2: Feature Engineering) Calculate standard deviation of win rates
    over specified number of periods.
    
    Args:
        win_rates: List of win rate values
        periods: Number of periods to consider (default 100)
        
    Returns:
        float: Standard deviation of win rates, or 0.0 if insufficient data
    """
    if not win_rates or len(win_rates) < 2:
        return 0.0
    
    # Take last N periods
    recent_rates = win_rates[-periods:] if len(win_rates) > periods else win_rates
    
    if len(recent_rates) < 2:
        return 0.0
    
    # Calculate mean
    mean_rate = sum(recent_rates) / len(recent_rates)
    
    # Calculate variance
    variance = sum((x - mean_rate) ** 2 for x in recent_rates) / len(recent_rates)
    
    # Return standard deviation
    return variance ** 0.5


def _get_daily_bridge_predictions(all_data_ai):
    print(
        "... (V7.0 G2 Feature Extraction) B∆∞·ªõc 1: T√≠nh to√°n d·ª± ƒëo√°n c·∫ßu cho to√†n b·ªô l·ªãch s·ª≠..."
    )

    daily_predictions_by_loto = defaultdict(
        lambda: defaultdict(lambda: defaultdict(float))
    )

    managed_bridges = get_all_managed_bridges(DB_NAME, only_enabled=True)

    # (Phase 2: Feature Engineering) Import SETTINGS for K2N risk threshold
    try:
        from .config_manager import SETTINGS
        k2n_threshold = getattr(SETTINGS, "K2N_RISK_START_THRESHOLD", 6)
    except ImportError:
        k2n_threshold = 6  # Default fallback

    # (Phase 2: Feature Engineering) Track historical win rates per bridge for stddev calculation
    bridge_win_rate_history = defaultdict(list)
    
    # (V7.7 Phase 2: F13) Track loto appearance history for last 3 days
    # Structure: { 'loto': [ky1, ky2, ky3, ...] } - list of recent kys where loto appeared
    loto_appearance_history = defaultdict(list)

    for bridge in managed_bridges:
        bridge["win_rate_float"] = _parse_win_rate_text(bridge.get("win_rate_text"))
        bridge["k2n_risk"] = bridge.get("max_lose_streak_k2n", 999)
        bridge["current_streak_int"] = bridge.get("current_streak", -999)
        # (Phase 2) Extract current lose streak from bridge data
        bridge["current_lose_streak"] = bridge.get("current_lose_streak", 0)
        # Initialize win rate history with current value
        bridge_win_rate_history[bridge["name"]].append(bridge["win_rate_float"])

    memory_bridges = []
    loto_names = get_27_loto_names()
    for i in range(27):
        for j in range(i, 27):
            memory_bridges.append(
                (i, j, "sum", f"T·ªïng({loto_names[i]}+{loto_names[j]})")
            )
            memory_bridges.append(
                (i, j, "diff", f"Hi·ªáu(|{loto_names[i]}-{loto_names[j]}|)")
            )

    for k in range(1, len(all_data_ai)):
        prev_row = all_data_ai[k - 1]
        current_row = all_data_ai[k]
        current_ky = str(current_row[0])

        if k % 100 == 0:
            print(
                f"... (V7.0 G2 Feature Extraction) B∆∞·ªõc 1: ƒê√£ x·ª≠ l√Ω {k}/{len(all_data_ai)} ng√†y (d·ª± ƒëo√°n c·∫ßu)"
            )

        temp_bridge_preds = defaultdict(list)

        # 1. 15 C·∫ßu C·ªï ƒêi·ªÉn
        for i, bridge_func in enumerate(ALL_15_BRIDGE_FUNCTIONS_V5):
            try:
                stl = bridge_func(prev_row)
                pair_key = _standardize_pair(stl)
                if pair_key:
                    temp_bridge_preds[pair_key].append(f"C{i + 1}")
            except Exception:
                pass

        # 2. C·∫ßu ƒê√£ L∆∞u (V17)
        prev_positions_v17 = getAllPositions_V17_Shadow(prev_row)
        for bridge in managed_bridges:
            try:
                if bridge["pos1_idx"] == -1:
                    continue
                idx1, idx2 = bridge["pos1_idx"], bridge["pos2_idx"]
                a, b = prev_positions_v17[idx1], prev_positions_v17[idx2]
                if a is None or b is None:
                    continue
                stl = taoSTL_V30_Bong(a, b)
                pair_key = _standardize_pair(stl)
                if pair_key:
                    temp_bridge_preds[pair_key].append(bridge["name"])
            except Exception:
                pass

        # 3. C·∫ßu B·∫°c Nh·ªõ (756 c·∫ßu)
        prev_positions_mem = get_27_loto_positions(prev_row)
        for idx1, idx2, alg_type, alg_name in memory_bridges:
            try:
                loto1, loto2 = prev_positions_mem[idx1], prev_positions_mem[idx2]
                stl = calculate_bridge_stl(loto1, loto2, alg_type)
                pair_key = _standardize_pair(stl)
                if pair_key:
                    temp_bridge_preds[pair_key].append(alg_name)
            except Exception:
                pass

        # (V7.7 Phase 2: F13) Update loto appearance history
        # Get lotos that appeared in the PREVIOUS row (k-1) since we're predicting for current_ky
        if k > 1:  # Need at least 2 rows
            try:
                prev_lotos_appeared = set(getAllLoto_V30(prev_row))
                for loto in prev_lotos_appeared:
                    # Keep only last 3 appearances per loto
                    loto_appearance_history[loto].append(current_ky)
                    if len(loto_appearance_history[loto]) > 3:
                        loto_appearance_history[loto] = loto_appearance_history[loto][-3:]
            except Exception:
                pass

        # 4. CHUY·ªÇN ƒê·ªîI: T·ª™ C·∫∂P (PAIR) SANG LOTO (FEATURE COUNT & Q-FEATURES)
        loto_to_pairs = defaultdict(list)
        for pair_key in temp_bridge_preds.keys():
            loto1, loto2 = pair_key.split("-")
            loto_to_pairs[loto1].append(pair_key)
            loto_to_pairs[loto2].append(pair_key)

        for loto in [str(i).zfill(2) for i in range(100)]:
            f_classic_votes = 0
            f_v17_votes = 0
            f_memory_votes = 0

            q_win_rates = []
            q_k2n_risks = []
            q_current_streaks = []
            # (Phase 2: Feature Engineering) New Q-features
            q_current_lose_streaks = []
            q_is_k2n_risk_close = []
            q_win_rate_stddevs = []

            pairs_for_this_loto = loto_to_pairs.get(loto, [])

            if pairs_for_this_loto:
                all_bridges_for_loto = []
                for pair in pairs_for_this_loto:
                    for bridge_name in temp_bridge_preds[pair]:
                        all_bridges_for_loto.append(bridge_name)

                        if not (
                            bridge_name.startswith("C")
                            or bridge_name.startswith("T·ªïng")
                            or bridge_name.startswith("Hi·ªáu")
                        ):
                            found_bridge = next(
                                (
                                    b
                                    for b in managed_bridges
                                    if b["name"] == bridge_name
                                ),
                                None,
                            )
                            if found_bridge:
                                q_win_rates.append(found_bridge["win_rate_float"])
                                # S·ª≠a E226
                                q_k2n_risks.append(found_bridge["k2n_risk"])
                                q_current_streaks.append(
                                    found_bridge["current_streak_int"]
                                )
                                # (Phase 2: Feature Engineering) Collect new features
                                q_current_lose_streaks.append(
                                    found_bridge.get("current_lose_streak", 0)
                                )
                                # Is_K2N_Risk_Close: 1 if within 2 frames of threshold, else 0
                                risk_distance = k2n_threshold - found_bridge["k2n_risk"]
                                is_close = 1 if 0 <= risk_distance <= 2 else 0
                                q_is_k2n_risk_close.append(is_close)
                                # StdDev_Win_Rate_100: Calculate stddev from history
                                bridge_history = bridge_win_rate_history.get(bridge_name, [])
                                stddev = _calculate_win_rate_stddev(bridge_history, periods=100)
                                q_win_rate_stddevs.append(stddev)

                bridge_counts = Counter(all_bridges_for_loto)
                for bridge_name, count in bridge_counts.items():
                    if bridge_name.startswith("C"):
                        f_classic_votes += count
                    elif bridge_name.startswith("T·ªïng") or bridge_name.startswith(
                        "Hi·ªáu"
                    ):
                        f_memory_votes += count
                    else:
                        f_v17_votes += count

            daily_predictions_by_loto[current_ky][loto]["v5_count"] = f_classic_votes
            daily_predictions_by_loto[current_ky][loto]["v17_count"] = f_v17_votes
            daily_predictions_by_loto[current_ky][loto]["memory_count"] = f_memory_votes

            if q_win_rates:
                daily_predictions_by_loto[current_ky][loto]["q_avg_win_rate"] = sum(
                    q_win_rates
                ) / len(q_win_rates)
                daily_predictions_by_loto[current_ky][loto]["q_min_k2n_risk"] = min(
                    q_k2n_risks
                )
                daily_predictions_by_loto[current_ky][loto]["q_max_curr_streak"] = max(
                    q_current_streaks
                )
                # (Phase 2: Feature Engineering) Add new Q-features
                daily_predictions_by_loto[current_ky][loto]["q_max_current_lose_streak"] = max(
                    q_current_lose_streaks
                ) if q_current_lose_streaks else 0
                daily_predictions_by_loto[current_ky][loto]["q_is_k2n_risk_close"] = max(
                    q_is_k2n_risk_close
                ) if q_is_k2n_risk_close else 0
                daily_predictions_by_loto[current_ky][loto]["q_avg_win_rate_stddev_100"] = (
                    sum(q_win_rate_stddevs) / len(q_win_rate_stddevs)
                ) if q_win_rate_stddevs else 0.0
            else:
                daily_predictions_by_loto[current_ky][loto]["q_avg_win_rate"] = 0.0
                daily_predictions_by_loto[current_ky][loto]["q_min_k2n_risk"] = 999.0
                daily_predictions_by_loto[current_ky][loto][
                    "q_max_curr_streak"
                ] = -999.0
                # (Phase 2: Feature Engineering) Set defaults for new features
                daily_predictions_by_loto[current_ky][loto]["q_max_current_lose_streak"] = 0
                daily_predictions_by_loto[current_ky][loto]["q_is_k2n_risk_close"] = 0
                daily_predictions_by_loto[current_ky][loto]["q_avg_win_rate_stddev_100"] = 0.0
            
            # (V7.7 Phase 2: F13) Calculate q_hit_in_last_3_days
            # Check if this loto appeared in any of the last 3 recorded periods
            recent_appearances = loto_appearance_history.get(loto, [])
            q_hit_in_last_3_days = 1 if len(recent_appearances) > 0 else 0
            daily_predictions_by_loto[current_ky][loto]["q_hit_in_last_3_days"] = q_hit_in_last_3_days

    return daily_predictions_by_loto


# ==========================================================================
# (DI CHUY·ªÇN T·ª™ LOTTERY_SERVICE) H√ÄM WRAPPER S·ª¨ D·ª§NG THREADING
# ==========================================================================


def run_ai_training_threaded(callback=None):
    """
    (V7.0) Wrapper ch·∫°y Hu·∫•n luy·ªán AI tr√™n lu·ªìng ri√™ng ƒë·ªÉ kh√¥ng l√†m ƒë√≥ng bƒÉng UI.
    """
    all_data_ai, msg = load_data_ai_from_db()
    if all_data_ai is None:
        if callback:
            callback(False, msg)
        return False, msg

    def _train_target():
        try:
            daily_bridge_predictions = _get_daily_bridge_predictions(all_data_ai)
        except Exception as e:
            if callback:
                callback(
                    False, f"L·ªói t√≠nh to√°n features: {e}\n{traceback.format_exc()}"
                )
            return

        success, result_msg = train_ai_model(all_data_ai, daily_bridge_predictions)

        if callback:
            callback(success, result_msg)

    thread = threading.Thread(target=_train_target)
    thread.start()
    return True, "Qu√° tr√¨nh hu·∫•n luy·ªán AI ƒë√£ ƒë∆∞·ª£c kh·ªüi ch·∫°y trong n·ªÅn. Vui l√≤ng ch·ªù..."


def run_ai_prediction_for_dashboard():
    """
    (V7.0) H√†m m·ªõi thay th·∫ø cho vi·ªác g·ªçi tr·ª±c ti·∫øp get_ai_predictions
    """
    all_data_ai, msg = load_data_ai_from_db()
    if all_data_ai is None or len(all_data_ai) < 2:
        return None, msg

    try:
        last_two_rows = all_data_ai[-2:]
        daily_preds_map = _get_daily_bridge_predictions(last_two_rows)

        current_ky = str(last_two_rows[-1][0])
        bridge_predictions_for_today = daily_preds_map.get(current_ky, {})
    except Exception as e:
        return None, f"L·ªói t√≠nh to√°n features d·ª± ƒëo√°n: {e}\n{traceback.format_exc()}"

    return get_ai_predictions(all_data_ai, bridge_predictions_for_today)


--------------------------------------------------

=== FILE: logic\analytics.py ===
# T√™n file: git3/logic/analytics.py
#
# (N·ªòI DUNG THAY TH·∫æ TO√ÄN B·ªò - S·ª¨A E226)
#
from collections import Counter

# Import c√°c h√†m DB
try:
    from .db_manager import DB_NAME, get_all_managed_bridges
except ImportError:
    try:
        from db_manager import DB_NAME, get_all_managed_bridges
    except ImportError:
        print("L·ªói: Kh√¥ng th·ªÉ import db_manager trong analytics.py")
        DB_NAME = "xo_so_prizes_all_logic.db"

        def get_all_managed_bridges(d, o):
            return []


# Import c√°c h√†m c·∫ßu c·ªï ƒëi·ªÉn
try:
    from .bridges_classic import (
        ALL_15_BRIDGE_FUNCTIONS_V5,
        checkHitSet_V30_K2N,
        getAllLoto_V30,
    )
except ImportError:
    try:
        from bridges_classic import (
            ALL_15_BRIDGE_FUNCTIONS_V5,
            checkHitSet_V30_K2N,
            getAllLoto_V30,
        )
    except ImportError:
        print("L·ªói: Kh√¥ng th·ªÉ import bridges_classic trong analytics.py")
        ALL_15_BRIDGE_FUNCTIONS_V5 = []

        def getAllLoto_V30(r):
            return []

        # ƒê·ªïi t√™n 'l' th√†nh 'loto_set' cho r√µ nghƒ©a
        def checkHitSet_V30_K2N(p, loto_set):
            return "L·ªói"


# Import c√°c h√†m c·∫ßu V16
try:
    from .bridges_v16 import getAllPositions_V16, taoSTL_V30_Bong
except ImportError:
    try:
        from bridges_v16 import getAllPositions_V16, taoSTL_V30_Bong
    except ImportError:
        print("L·ªói: Kh√¥ng th·ªÉ import bridges_v16 trong analytics.py")

        def getAllPositions_V16(r):
            return []

        def taoSTL_V30_Bong(a, b):
            return ["00", "00"]

# Import c√°c h√†m Memory Bridge (B·∫°c Nh·ªõ)
try:
    from .bridges_memory import calculate_bridge_stl, get_27_loto_positions
except ImportError:
    try:
        from bridges_memory import calculate_bridge_stl, get_27_loto_positions
    except ImportError:
        print("L·ªói: Kh√¥ng th·ªÉ import bridges_memory trong analytics.py")
        def calculate_bridge_stl(loto1, loto2, algorithm_type):
            return ["00", "00"]
        def get_27_loto_positions(row):
            return ["00"] * 27

# Import re cho parsing bridge name
import re


# ===================================================================================
# (M·ªöI) C√ÅC H√ÄM CHO B·∫¢NG T·ªîNG H·ª¢P QUY·∫æT ƒê·ªäNH
# ===================================================================================


def get_loto_stats_last_n_days(all_data_ai, n=7):
    """
    (M·ªöI) L·∫•y th·ªëng k√™ t·∫ßn su·∫•t loto trong N ng√†y g·∫ßn nh·∫•t.
    Tr·∫£ v·ªÅ: list[('loto', count_nhay, count_ky)],
             v√≠ d·ª•: [('33', 4, 3), ('01', 3, 3)]
             (Loto 33 v·ªÅ 4 nh√°y, xu·∫•t hi·ªán trong 3/7 k·ª≥)
    """
    try:
        if not all_data_ai or len(all_data_ai) == 0:
            return []

        if len(all_data_ai) < n:
            n = len(all_data_ai)

        last_n_rows = all_data_ai[-n:]

        all_lotos_hits = []  # ƒê·ªÉ ƒë·∫øm t·ªïng s·ªë nh√°y
        day_appearance_counter = Counter()  # ƒê·ªÉ ƒë·∫øm t·ªïng s·ªë k·ª≥ (ng√†y)

        for row in last_n_rows:
            lotos_in_this_row = getAllLoto_V30(row)

            # 1. ƒê·∫øm t·ªïng s·ªë nh√°y (gi·ªëng nh∆∞ c≈©)
            all_lotos_hits.extend(lotos_in_this_row)

            # 2. ƒê·∫øm s·ªë k·ª≥ xu·∫•t hi·ªán (m·ªõi)
            unique_lotos_in_this_row = set(lotos_in_this_row)
            day_appearance_counter.update(
                unique_lotos_in_this_row
            )  # update 1 l·∫ßn cho m·ªói loto/k·ª≥

        # ƒê·∫øm t·ªïng s·ªë nh√°y
        loto_hit_counts = Counter(all_lotos_hits)

        # S·∫Øp x·∫øp theo t·ªïng s·ªë nh√°y (∆∞u ti√™n)
        sorted_lotos_by_hits = sorted(
            loto_hit_counts.items(), key=lambda item: item[1], reverse=True
        )

        # K·∫øt h·ª£p d·ªØ li·ªáu
        final_stats = []
        for loto, hit_count in sorted_lotos_by_hits:
            day_count = day_appearance_counter.get(loto, 0)  # L·∫•y s·ªë k·ª≥ ƒë√£ xu·∫•t hi·ªán
            final_stats.append(
                (loto, hit_count, day_count)
            )  # (loto, t·ªïng_nh√°y, t·ªïng_k·ª≥)

        return final_stats

    except Exception as e:
        print(f"L·ªói get_loto_stats_last_n_days (m·ªõi): {e}")
        return []


def get_prediction_consensus(last_row, db_name=DB_NAME):
    """
    (M·ªöI) L·∫•y d·ª± ƒëo√°n t·ª´ "15 C·∫ßu" v√† "C·∫ßu ƒê√£ L∆∞u" ƒë·ªÉ ƒë·∫øm vote THEO C·∫∂P.
    Tr·∫£ v·ªÅ: list[('cap_so', count, 'sources')]
    v√≠ d·ª•: [('03-30', 2, 'C1, G5.6[3]')]
    """
    try:
        if not last_row or len(last_row) < 10:
            return []

        prediction_sources = {}  # { 'pair_key': ['C1', 'GDB[0]...'] }

        def get_pair_key(stl_list):
            """Chu·∫©n h√≥a 1 c·∫∑p STL. V√≠ d·ª• ['30', '03'] -> '03-30'"""
            if not stl_list or len(stl_list) != 2:
                return None
            # S·∫Øp x·∫øp ƒë·ªÉ chu·∫©n h√≥a, v√≠ d·ª• ['30', '03'] -> ['03', '30']
            sorted_pair = sorted(stl_list)
            return f"{sorted_pair[0]}-{sorted_pair[1]}"  # Key: "03-30"

        # 1. L·∫•y t·ª´ 15 C·∫ßu C·ªï ƒêi·ªÉn
        for i, bridge_func in enumerate(ALL_15_BRIDGE_FUNCTIONS_V5):
            try:
                stl = bridge_func(last_row)
                pair_key = get_pair_key(stl)
                if not pair_key:
                    continue

                source_name = f"C{i + 1}"
                if pair_key not in prediction_sources:
                    prediction_sources[pair_key] = []
                prediction_sources[pair_key].append(source_name)
            except Exception as e:
                print(f"L·ªói d·ª± ƒëo√°n 15 C·∫ßu (consensus): {e}")

        # 2. L·∫•y t·ª´ C·∫ßu ƒê√£ L∆∞u
        managed_bridges = get_all_managed_bridges(db_name, only_enabled=True)
        if managed_bridges:
            last_positions = getAllPositions_V16(last_row)
            last_lotos = get_27_loto_positions(last_row)
            
            for bridge in managed_bridges:
                try:
                    idx1, idx2 = bridge.get("pos1_idx"), bridge.get("pos2_idx")
                    
                    # Ki·ªÉm tra Memory Bridge (B·∫°c Nh·ªõ)
                    if idx1 == -1 and idx2 == -1:
                        bridge_name = bridge.get("name", "")
                        stl = None
                        
                        # Parse v√† t√≠nh to√°n cho Memory Bridge
                        if "T·ªïng(" in bridge_name:
                            match = re.search(r'T·ªïng\((\d+)\+(\d+)\)', bridge_name)
                            if match:
                                pos1, pos2 = int(match.group(1)), int(match.group(2))
                                if pos1 < len(last_lotos) and pos2 < len(last_lotos):
                                    loto1, loto2 = last_lotos[pos1], last_lotos[pos2]
                                    stl = calculate_bridge_stl(loto1, loto2, "sum")
                        elif "Hi·ªáu(" in bridge_name:
                            match = re.search(r'Hi·ªáu\((\d+)-(\d+)\)', bridge_name)
                            if match:
                                pos1, pos2 = int(match.group(1)), int(match.group(2))
                                if pos1 < len(last_lotos) and pos2 < len(last_lotos):
                                    loto1, loto2 = last_lotos[pos1], last_lotos[pos2]
                                    stl = calculate_bridge_stl(loto1, loto2, "diff")
                        
                        if stl:
                            pair_key = get_pair_key(stl)
                            if pair_key:
                                source_name = bridge["name"]
                                if pair_key not in prediction_sources:
                                    prediction_sources[pair_key] = []
                                if source_name not in prediction_sources[pair_key]:
                                    prediction_sources[pair_key].append(source_name)
                        continue
                    
                    # V17 Bridge (original logic)
                    if idx1 is None or idx2 is None:
                        continue
                    
                    if idx1 >= len(last_positions) or idx2 >= len(last_positions):
                        continue
                    
                    a, b = last_positions[idx1], last_positions[idx2]
                    if a is None or b is None:
                        continue

                    stl = taoSTL_V30_Bong(a, b)
                    pair_key = get_pair_key(stl)
                    if not pair_key:
                        continue

                    source_name = bridge["name"]
                    if pair_key not in prediction_sources:
                        prediction_sources[pair_key] = []
                    # Ch·ªâ th√™m 1 l·∫ßn cho 1 c·∫ßu (tr√°nh tr√πng l·∫∑p)
                    if source_name not in prediction_sources[pair_key]:
                        prediction_sources[pair_key].append(source_name)
                except Exception as e:
                    print(f"L·ªói d·ª± ƒëo√°n C·∫ßu ƒê√£ L∆∞u (consensus): {e}")

        # 3. T·ªïng h·ª£p v√† S·∫Øp x·∫øp
        consensus_list = []
        for pair_key, sources in prediction_sources.items():
            count = len(sources)
            sources_str = ", ".join(sources)
            consensus_list.append((pair_key, count, sources_str))

        consensus_list.sort(key=lambda item: item[1], reverse=True)
        return consensus_list

    except Exception as e:
        print(f"L·ªói get_prediction_consensus (m·ªõi): {e}")
        return []


def get_high_win_rate_predictions(last_row, threshold=80.0, db_name=DB_NAME):
    """
    (M·ªöI) L·∫•y d·ª± ƒëo√°n t·ª´ c√°c c·∫ßu C√ì T·ª∂ L·ªÜ CAO (d·ª±a tr√™n C·∫ßu ƒê√£ L∆∞u).
    Tr·∫£ v·ªÅ: list[ {'name': str, 'stl': list, 'rate': str} ]
    """
    try:
        if not last_row or len(last_row) < 10:
            return []

        high_win_bridges = []
        managed_bridges = get_all_managed_bridges(db_name, only_enabled=True)
        if not managed_bridges:
            return []

        last_positions = getAllPositions_V16(last_row)

        for bridge in managed_bridges:
            try:
                # 1. Ki·ªÉm tra t·ª∑ l·ªá
                rate_str = str(bridge.get("win_rate_text", "0%")).replace("%", "")
                if not rate_str or rate_str == "N/A":
                    continue

                win_rate = float(rate_str)

                # 2. N·∫øu ƒë·∫°t ng∆∞·ª°ng
                if win_rate >= threshold:
                    idx1, idx2 = bridge["pos1_idx"], bridge["pos2_idx"]
                    a, b = last_positions[idx1], last_positions[idx2]
                    if a is None or b is None:
                        continue

                    stl = taoSTL_V30_Bong(a, b)
                    high_win_bridges.append(
                        {"name": bridge["name"], "stl": stl, "rate": f"{win_rate:.2f}%"}
                    )
            except Exception as e:
                print(f"L·ªói ki·ªÉm tra t·ª∑ l·ªá c·∫ßu {bridge['name']}: {e}")

        return high_win_bridges

    except Exception as e:
        print(f"L·ªói get_high_win_rate_predictions: {e}")
        return []


def get_loto_gan_stats(all_data_ai, n_days=15):
    """
    (M·ªöI) T√¨m c√°c loto (00-99) ƒë√£ kh√¥ng xu·∫•t hi·ªán trong n_days g·∫ßn nh·∫•t.
    Tr·∫£ v·ªÅ: list[('loto', so_ngay_gan)]
    V√≠ d·ª•: [('22', 18), ('01', 15)]
    """
    gan_stats = []
    try:
        if not all_data_ai or len(all_data_ai) < n_days:
            print(f"C·∫£nh b√°o L√¥ Gan: Kh√¥ng ƒë·ªß d·ªØ li·ªáu (c·∫ßn {n_days} k·ª≥).")
            return []

        # 1. T·∫°o danh s√°ch 100 loto
        all_100_lotos = {str(i).zfill(2) for i in range(100)}

        # 2. T√¨m loto xu·∫•t hi·ªán trong N ng√†y g·∫ßn nh·∫•t
        recent_lotos = set()
        recent_rows = all_data_ai[-n_days:]
        for row in recent_rows:
            lotos_in_row = getAllLoto_V30(row)
            recent_lotos.update(lotos_in_row)

        # 3. L·∫•y danh s√°ch loto gan (loto kh√¥ng c√≥ trong danh s√°ch g·∫ßn ƒë√¢y)
        gan_lotos = all_100_lotos - recent_lotos

        if not gan_lotos:
            return []  # Kh√¥ng c√≥ loto n√†o gan > n_days

        # 4. T√≠nh to√°n s·ªë ng√†y gan ch√≠nh x√°c cho t·ª´ng loto
        full_history = all_data_ai[:]  # Copy
        full_history.reverse()  # ƒê·∫£o ng∆∞·ª£c, [0] l√† ng√†y g·∫ßn nh·∫•t

        for loto in gan_lotos:
            days_gan = 0
            found = False
            for i, row in enumerate(full_history):
                if i < n_days:  # B·ªè qua N ng√†y g·∫ßn nh·∫•t (v√¨ ta bi·∫øt n√≥ kh√¥ng v·ªÅ)
                    days_gan += 1
                    continue

                loto_set_this_day = set(getAllLoto_V30(row))
                if loto in loto_set_this_day:
                    found = True
                    break  # T√¨m th·∫•y r·ªìi, d·ª´ng ƒë·∫øm
                else:
                    days_gan += 1  # C·ªông th√™m ng√†y gan

            if found:
                gan_stats.append((loto, days_gan))
            else:
                # Gan c·ª±c ƒë·∫°i (ch∆∞a v·ªÅ trong to√†n b·ªô l·ªãch s·ª≠)
                gan_stats.append((loto, len(full_history)))

        # 5. S·∫Øp x·∫øp: Gan l√¢u nh·∫•t l√™n ƒë·∫ßu
        gan_stats.sort(key=lambda x: x[1], reverse=True)
        return gan_stats

    except Exception as e:
        print(f"L·ªói get_loto_gan_stats: {e}")
        return []


def _standardize_pair(stl_list):
    """H√†m n·ªôi b·ªô: Chu·∫©n h√≥a 1 c·∫∑p STL. V√≠ d·ª• ['30', '03'] -> '03-30'"""
    if not stl_list or len(stl_list) != 2:
        return None
    sorted_pair = sorted(stl_list)
    return f"{sorted_pair[0]}-{sorted_pair[1]}"  # Key: "03-30"


# ===================================================================================
# (M·ªöI) H√ÄM T√çNH ƒêI·ªÇM T·ªîNG L·ª∞C (GIAI ƒêO·∫†N 2)
# ===================================================================================


def get_top_scored_pairs(stats, consensus, high_win, pending_k2n, gan_stats):
    """
    (M·ªöI) T√≠nh to√°n, ch·∫•m ƒëi·ªÉm v√† x·∫øp h·∫°ng c√°c c·∫∑p s·ªë d·ª±a tr√™n 5 ngu·ªìn d·ªØ li·ªáu.
    """
    try:
        # { '03-30': {'score': 0, 'reasons': [], 'is_gan': False, 'gan_days': 0} }
        scores = {}

        # --- 1. T·∫°o danh s√°ch Loto V·ªÅ Nhi·ªÅu (Top 5) ƒë·ªÉ tra c·ª©u ---
        top_hot_lotos = {loto for loto, nhay, ky in stats[:5]}

        # --- 2. T·∫°o danh s√°ch Loto Gan ƒë·ªÉ tra c·ª©u ---
        gan_map = {loto: days for loto, days in gan_stats}

        # --- 3. Ch·∫•m ƒëi·ªÉm t·ª´ 3 ngu·ªìn ch√≠nh (Consensus, High Win, K2N) ---

        # Ngu·ªìn 2: Consensus (D·ª± ƒëo√°n nhi·ªÅu)
        for pair_key, count, sources in consensus[:3]:  # Top 3
            if pair_key not in scores:
                scores[pair_key] = {
                    "score": 0,
                    "reasons": [],
                    "is_gan": False,
                    "gan_days": 0,
                }
            scores[pair_key]["score"] += 3
            scores[pair_key]["reasons"].append(f"Top {len(scores)} D·ª± ƒêo√°n")

        # Ngu·ªìn 3: C·∫ßu T·ª∑ L·ªá Cao (>=47%)
        for bridge in high_win:
            pair_key = _standardize_pair(bridge["stl"])
            if not pair_key:
                continue
            if pair_key not in scores:
                scores[pair_key] = {
                    "score": 0,
                    "reasons": [],
                    "is_gan": False,
                    "gan_days": 0,
                }
            scores[pair_key]["score"] += 2
            scores[pair_key]["reasons"].append(f"C·∫ßu {bridge['rate']}")

        # Ngu·ªìn 4: C·∫ßu K2N ƒêang Ch·ªù
        for item in pending_k2n:
            pair_key = _standardize_pair(item["stl"])
            if not pair_key:
                continue
            if pair_key not in scores:
                scores[pair_key] = {
                    "score": 0,
                    "reasons": [],
                    "is_gan": False,
                    "gan_days": 0,
                }
            scores[pair_key]["score"] += 2
            scores[pair_key]["reasons"].append(f"Ch·ªù K2N (Chu·ªói {item['streak']})")

        # --- 4. Ch·∫•m ƒëi·ªÉm c·ªông (Loto V·ªÅ Nhi·ªÅu) v√† G·∫Øn c·ªù (L√¥ Gan) ---

        # Duy·ªát qua t·∫•t c·∫£ c√°c c·∫∑p ƒë√£ c√≥ ƒëi·ªÉm
        for pair_key in list(scores.keys()):
            loto1, loto2 = pair_key.split("-")

            # ƒêi·ªÉm c·ªông (Ngu·ªìn 1: Loto V·ªÅ Nhi·ªÅu)
            if loto1 in top_hot_lotos or loto2 in top_hot_lotos:
                scores[pair_key]["score"] += 1
                scores[pair_key]["reasons"].append("Loto Hot")

            # G·∫Øn c·ªù Gan (Ngu·ªìn 5: L√¥ Gan)
            gan_days_1 = gan_map.get(loto1, 0)
            gan_days_2 = gan_map.get(loto2, 0)
            max_gan = max(gan_days_1, gan_days_2)

            if max_gan > 0:
                scores[pair_key]["is_gan"] = True
                scores[pair_key]["gan_days"] = max_gan

        # --- 5. ƒê·ªãnh d·∫°ng l·∫°i v√† S·∫Øp x·∫øp ---
        final_list = []
        for pair_key, data in scores.items():
            final_list.append(
                {
                    "pair": pair_key,
                    "score": data["score"],
                    "reasons": ", ".join(data["reasons"]),
                    "is_gan": data["is_gan"],
                    "gan_days": data["gan_days"],
                }
            )

        # S·∫Øp x·∫øp theo ƒêi·ªÉm (cao -> th·∫•p)
        final_list.sort(key=lambda x: x["score"], reverse=True)

        return final_list

    except Exception as e:
        print(f"L·ªñI get_top_scored_pairs: {e}")
        return []


--------------------------------------------------

=== FILE: logic\backtester.py ===
"""
backtester.py - Main backtesting interface (REFACTORED)

This module has been refactored from 1,303 LOC to ~200 LOC by extracting
functions into specialized modules:
- backtester_helpers.py: Validation and parsing utilities
- backtester_scoring.py: Scoring algorithms
- backtester_aggregation.py: Top bridge aggregation

The large backtest functions are kept in backtester_core.py for stability.
This file provides backward-compatible API by re-exporting all functions.
"""

# Import configuration
try:
    from .config_manager import SETTINGS
except ImportError:
    try:
        from config_manager import SETTINGS
    except ImportError:
        print("L·ªñI: backtester.py kh√¥ng th·ªÉ import config_manager.")
        try:
            from .constants import DEFAULT_SETTINGS
        except ImportError:
            from constants import DEFAULT_SETTINGS
        SETTINGS = type("obj", (object,), DEFAULT_SETTINGS)

# Import database functions
try:
    from .data_repository import get_all_managed_bridges
    from .db_manager import (
        DB_NAME,
        update_bridge_k2n_cache_batch,
        update_bridge_win_rate_batch,
        update_bridge_recent_win_count_batch,
    )
except ImportError:
    print("L·ªói: Kh√¥ng th·ªÉ import db_manager trong backtester.py")
    DB_NAME = "data/xo_so_prizes_all_logic.db"
    
    def get_all_managed_bridges(d, o):
        return []
    
    def update_bridge_win_rate_batch(r, d):
        return False, "L·ªói Import"
    
    def update_bridge_k2n_cache_batch(r, d):
        return False, "L·ªói Import"
    
    def update_bridge_recent_win_count_batch(r, d):
        return False, "L·ªói Import"

# Import bridge functions
try:
    from .bridges.bridges_classic import (
        ALL_15_BRIDGE_FUNCTIONS_V5,
        checkHitSet_V30_K2N,
        getAllLoto_V30,
    )
except ImportError:
    print("L·ªói: Kh√¥ng th·ªÉ import bridges_classic trong backtester.py")
    ALL_15_BRIDGE_FUNCTIONS_V5 = []
    
    def getAllLoto_V30(r):
        return []
    
    def checkHitSet_V30_K2N(p, loto_set):
        return "L·ªói"

try:
    from .bridges.bridges_v16 import (
        get_index_from_name_V16,
        getAllPositions_V17_Shadow,
        getPositionName_V16,
        getPositionName_V17_Shadow,
        taoSTL_V30_Bong,
    )
except ImportError:
    print("L·ªói: Kh√¥ng th·ªÉ import bridges_v16 trong backtester.py")
    
    def getPositionName_V16(i):
        return "L·ªói"
    
    def get_index_from_name_V16(n):
        return None
    
    def taoSTL_V30_Bong(a, b):
        return ["00", "00"]
    
    def getAllPositions_V17_Shadow(r):
        return []
    
    def getPositionName_V17_Shadow(i):
        return "L·ªói V17"

try:
    from .bridges.bridges_memory import (
        calculate_bridge_stl,
        get_27_loto_names,
        get_27_loto_positions,
    )
except ImportError:
    print("L·ªói: Kh√¥ng th·ªÉ import bridges_memory trong backtester.py")
    
    def calculate_bridge_stl(loto_str_1, loto_str_2, algorithm_type):
        """Fallback function for calculate_bridge_stl"""
        return ["00", "00"]
    
    def get_27_loto_names():
        """Fallback function for get_27_loto_names"""
        return []
    
    def get_27_loto_positions(r):
        """Fallback function for get_27_loto_positions"""
        return []

# Import De Manager for sync update
try:
    from .bridges.bridge_manager_de import de_manager
except ImportError:
    de_manager = None

# Import refactored modules (parse_k2n_results moved to backtester_core)
from .backtester_core import parse_k2n_results as _parse_k2n_results

from .backtester_aggregation import (
    tonghop_top_cau_n1 as TONGHOP_TOP_CAU_N1_V5,
    tonghop_top_cau_rate as TONGHOP_TOP_CAU_RATE_V5,
    tonghop_top_cau_core as TONGHOP_TOP_CAU_CORE_V5,
)

# Import large backtest functions from core module
# These are kept in a separate module to maintain stability
from .backtester_core import (
    BACKTEST_15_CAU_K2N_V30_AI_V8,
    BACKTEST_15_CAU_N1_V31_AI_V8,
    BACKTEST_CUSTOM_CAU_V16,
    BACKTEST_MANAGED_BRIDGES_N1,
    BACKTEST_MANAGED_BRIDGES_K1N,
    BACKTEST_MANAGED_BRIDGES_K2N,
    BACKTEST_MEMORY_BRIDGES,
)

# Update functions (kept here as they're relatively small)
def run_and_update_all_bridge_rates(all_data_ai, db_name=DB_NAME):
    """C·∫≠p nh·∫≠t T·ª∑ l·ªá (Win Rate) v√† Phong ƒê·ªô 10 K·ª≥ (recent_win_count_10) cho C·∫ßu ƒê√£ L∆∞u - D√πng logic K1N"""
    try:
        if not all_data_ai:
            return 0, "Kh√¥ng c√≥ d·ªØ li·ªáu A:I ƒë·ªÉ ch·∫°y backtest."

        ky_bat_dau = 2
        ky_ket_thuc = len(all_data_ai) + (ky_bat_dau - 1)

        # S·ª≠ d·ª•ng K1N ƒë·ªÉ t√≠nh to√°n ch√≠nh x√°c (kh√¥ng c√≥ khung 2 ng√†y)
        results_k1n = BACKTEST_MANAGED_BRIDGES_K1N(
            all_data_ai, ky_bat_dau, ky_ket_thuc, db_name, history=False
        )

        if not results_k1n or len(results_k1n) < 4 or "L·ªñI" in str(results_k1n[0][0]):
            if not results_k1n:
                return 0, "Backtest K1N kh√¥ng tr·∫£ v·ªÅ k·∫øt qu·∫£."
            if "Kh√¥ng c√≥ c·∫ßu n√†o" in str(results_k1n[0][1] if len(results_k1n) > 0 else ""):
                return 0, "Kh√¥ng c√≥ c·∫ßu n√†o ƒë∆∞·ª£c B·∫≠t ƒë·ªÉ c·∫≠p nh·∫≠t."
            return 0, f"L·ªói khi ch·∫°y Backtest K1N: {results_k1n[0] if results_k1n else 'Unknown'}"

        headers = results_k1n[0]
        rates = results_k1n[1] if len(results_k1n) > 1 else []
        recent_form = results_k1n[3] if len(results_k1n) > 3 else []  # H√†ng "Phong ƒê·ªô 10 K·ª≥"

        rate_data_list = []
        recent_win_data_list = []
        num_bridges = len(headers) - 1

        if num_bridges == 0:
            return 0, "Kh√¥ng c√≥ c·∫ßu n√†o trong k·∫øt qu·∫£ backtest."

        for i in range(1, num_bridges + 1):
            bridge_name = str(headers[i])
            win_rate_text = str(rates[i]) if rates and i < len(rates) else "0.00%"
            rate_data_list.append((win_rate_text, bridge_name))
            
            # Parse recent_win_count_10 t·ª´ h√†ng "Phong ƒê·ªô 10 K·ª≥"
            if recent_form and i < len(recent_form):
                recent_form_text = str(recent_form[i])
                try:
                    if "/" in recent_form_text:
                        recent_win_count = int(recent_form_text.split("/")[0].strip())
                    else:
                        recent_win_count = int(recent_form_text.strip())
                except (ValueError, IndexError):
                    recent_win_count = 0
            else:
                recent_win_count = 0
            
            recent_win_data_list.append((recent_win_count, bridge_name))

        if not rate_data_list:
            return 0, "Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c d·ªØ li·ªáu t·ª∑ l·ªá."

        # C·∫≠p nh·∫≠t win_rate_text
        success, message = update_bridge_win_rate_batch(rate_data_list, db_name)
        if not success:
            return 0, message

        # C·∫≠p nh·∫≠t recent_win_count_10 t·ª´ k·∫øt qu·∫£ K1N
        success_recent, message_recent = update_bridge_recent_win_count_batch(recent_win_data_list, db_name)
        if not success_recent:
            print(f"C·∫£nh b√°o: Kh√¥ng th·ªÉ c·∫≠p nh·∫≠t recent_win_count_10: {message_recent}")

        if success:
            return len(rate_data_list), f"{message} (ƒê√£ c·∫≠p nh·∫≠t Phong ƒê·ªô 10 K·ª≥ t·ª´ K1N)"
        else:
            return 0, message

    except Exception as e:
        return 0, f"L·ªói nghi√™m tr·ªçng trong run_and_update_all_bridge_rates: {e}"


def run_and_update_all_bridge_K2N_cache(
    all_data_ai, db_name=DB_NAME, data_slice=None, write_to_db=True
):
    """C·∫≠p nh·∫≠t Cache K2N cho C·∫ßu C·ªï ƒêi·ªÉn v√† C·∫ßu ƒê√£ L∆∞u
    
    Returns:
        tuple: (all_pending_dict, cache_count, message)
            - all_pending_dict: Dictionary of pending K2N predictions
            - cache_count: Number of cache entries written
            - message: Status message
    """
    try:
        if not all_data_ai:
            return {}, 0, "Kh√¥ng c√≥ d·ªØ li·ªáu A:I ƒë·ªÉ ch·∫°y backtest."

        ky_bat_dau = 2
        ky_ket_thuc = len(all_data_ai) + (ky_bat_dau - 1)

        # Backtest K2N c·ªï ƒëi·ªÉn
        results_k2n_classic = BACKTEST_15_CAU_K2N_V30_AI_V8(
            all_data_ai, ky_bat_dau, ky_ket_thuc, history=False
        )

        if not results_k2n_classic or len(results_k2n_classic) < 5:
            return {}, 0, "Backtest K2N c·ªï ƒëi·ªÉn kh√¥ng tr·∫£ v·ªÅ k·∫øt qu·∫£ ƒë·∫ßy ƒë·ªß."

        cache_classic, pending_classic = _parse_k2n_results(results_k2n_classic)

        # Backtest K2N managed
        results_k2n_managed = BACKTEST_MANAGED_BRIDGES_K2N(
            all_data_ai, ky_bat_dau, ky_ket_thuc, db_name, history=False
        )

        if not results_k2n_managed or len(results_k2n_managed) < 5:
            cache_managed, pending_managed = [], {}
        else:
            cache_managed, pending_managed = _parse_k2n_results(results_k2n_managed)

        all_cache_data = cache_classic + cache_managed
        all_pending = {**pending_classic, **pending_managed}

        # [FIX CRITICAL V8.7] G·ªçi c·∫≠p nh·∫≠t C·∫ßu ƒê·ªÅ t·∫°i ƒë√¢y
        if de_manager:
            try:
                # Update DE bridges (writes directly to DB)
                count_de, _ = de_manager.update_daily_stats(all_data_ai)
                print(f">>> [Backtester] ƒê√£ ƒë·ªìng b·ªô c·∫≠p nh·∫≠t {count_de} C·∫ßu ƒê·ªÅ.")
            except Exception as e:
                print(f"L·ªói c·∫≠p nh·∫≠t C·∫ßu ƒê·ªÅ trong K2N Cache: {e}")

        if not all_cache_data:
            return {}, 0, "Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c d·ªØ li·ªáu cache K2N."

        if write_to_db:
            success, message = update_bridge_k2n_cache_batch(all_cache_data, db_name)
            if success:
                return all_pending, len(all_cache_data), message
            else:
                return {}, 0, message
        else:
            return all_pending, len(all_cache_data), "Kh√¥ng ghi v√†o DB (ch·∫ø ƒë·ªô xem tr∆∞·ªõc)."

    except Exception as e:
        return {}, 0, f"L·ªói nghi√™m tr·ªçng trong run_and_update_all_bridge_K2N_cache: {e}"


def run_backtest_lo_30_days(bridge_config, all_data):
    """
    Ch·∫°y backtest 30 ng√†y g·∫ßn nh·∫•t cho m·ªôt c·∫ßu c·ª• th·ªÉ.
    
    Args:
        bridge_config: Dict ch·ª©a th√¥ng tin c·∫ßu t·ª´ DB (name, pos1_idx, pos2_idx, ...)
        all_data: To√†n b·ªô d·ªØ li·ªáu A:I (list c√°c row)
    
    Returns:
        list: List c√°c dict v·ªõi format:
            [{'date': 'DD/MM/YYYY', 'pred': 'xx-yy', 'result': 'zz', 'is_win': True/False, 'status': 'ƒÇn/G√£y'}]
    """
    import re
    
    if not all_data or len(all_data) < 2:
        return []
    
    # L·∫•y 30 ng√†y g·∫ßn nh·∫•t (ho·∫∑c t·∫•t c·∫£ n·∫øu √≠t h∆°n 30)
    data_slice = all_data[-30:] if len(all_data) >= 30 else all_data
    results = []
    
    bridge_name = bridge_config.get("name", "")
    pos1_idx = bridge_config.get("pos1_idx")
    pos2_idx = bridge_config.get("pos2_idx")
    
    # Ki·ªÉm tra Memory Bridge (pos1_idx == -1 v√† pos2_idx == -1)
    is_memory_bridge = (pos1_idx == -1 and pos2_idx == -1)
    
    for i in range(len(data_slice) - 1):
        prev_row = data_slice[i]
        actual_row = data_slice[i + 1]
        
        try:
            # L·∫•y ng√†y t·ª´ actual_row (row[0] l√† k·ª≥)
            date_str = f"K·ª≥ {actual_row[0]}" if actual_row[0] else f"Ng√†y {i+1}"
            
            # T√≠nh STL d·ª± ƒëo√°n
            pred_stl = None
            
            if is_memory_bridge:
                # Memory Bridge: Parse t√™n v√† t√≠nh STL
                try:
                    prev_lotos = get_27_loto_positions(prev_row)
                    
                    if "T·ªïng(" in bridge_name:
                        match = re.search(r'T·ªïng\((\d+)\+(\d+)\)', bridge_name)
                        if match:
                            pos1, pos2 = int(match.group(1)), int(match.group(2))
                            if pos1 < len(prev_lotos) and pos2 < len(prev_lotos):
                                loto1, loto2 = prev_lotos[pos1], prev_lotos[pos2]
                                pred_stl = calculate_bridge_stl(loto1, loto2, "sum")
                    elif "Hi·ªáu(" in bridge_name:
                        match = re.search(r'Hi·ªáu\((\d+)-(\d+)\)', bridge_name)
                        if match:
                            pos1, pos2 = int(match.group(1)), int(match.group(2))
                            if pos1 < len(prev_lotos) and pos2 < len(prev_lotos):
                                loto1, loto2 = prev_lotos[pos1], prev_lotos[pos2]
                                pred_stl = calculate_bridge_stl(loto1, loto2, "diff")
                except Exception:
                    pred_stl = None
            else:
                # V17 Bridge: D√πng pos1_idx v√† pos2_idx
                try:
                    positions = getAllPositions_V17_Shadow(prev_row)
                    if (pos1_idx is not None and pos2_idx is not None and 
                        pos1_idx < len(positions) and pos2_idx < len(positions)):
                        p1 = positions[pos1_idx]
                        p2 = positions[pos2_idx]
                        if p1 is not None and p2 is not None:
                            pred_stl = taoSTL_V30_Bong(int(p1), int(p2))
                except Exception:
                    pred_stl = None
            
            if not pred_stl:
                continue
            
            # Format pred_stl th√†nh string "xx-yy"
            if isinstance(pred_stl, list) and len(pred_stl) >= 2:
                pred_str = f"{pred_stl[0]}-{pred_stl[1]}"
            else:
                pred_str = str(pred_stl)
            
            # L·∫•y k·∫øt qu·∫£ th·ª±c t·∫ø
            actual_lotos = set(getAllLoto_V30(actual_row))
            
            # Ki·ªÉm tra th·∫Øng/thua
            check_result = checkHitSet_V30_K2N(pred_stl, actual_lotos)
            is_win = "‚úÖ" in str(check_result) or "ƒÇn" in str(check_result)
            status = "ƒÇn" if is_win else "G√£y"
            
            # L·∫•y s·ªë loto xu·∫•t hi·ªán (format ng·∫Øn g·ªçn)
            if actual_lotos:
                sorted_lotos = sorted(list(actual_lotos))
                if len(sorted_lotos) > 10:
                    result_str = ",".join(sorted_lotos[:10]) + "..."
                else:
                    result_str = ",".join(sorted_lotos)
            else:
                result_str = ""
            
            results.append({
                'date': date_str,
                'pred': pred_str,
                'result': result_str,
                'is_win': is_win,
                'status': status
            })
            
        except Exception:
            # B·ªè qua l·ªói v√† ti·∫øp t·ª•c
            continue
    
    return results


def run_backtest_de_30_days(bridge_config, all_data):
    """
    Ch·∫°y backtest 30 ng√†y cho m·ªôt c·∫ßu ƒê·ªÅ c·ª• th·ªÉ.
    
    Args:
        bridge_config: Dict ch·ª©a c·∫•u h√¨nh c·∫ßu (t·ª´ DB)
        all_data: To√†n b·ªô d·ªØ li·ªáu A:I
    
    Returns:
        list: List c√°c dict v·ªõi format:
            [{'date': 'DD/MM/YYYY', 'pred': 'Ch·∫°m X ho·∫∑c B·ªô Y', 'result': 'GƒêB', 'is_win': True/False, 'status': 'ƒÇn/G√£y'}]
    """
    from logic.de_backtester_core import DeBacktesterCore
    from logic.de_utils import get_gdb_last_2
    
    if not all_data or len(all_data) < 2:
        return []
    
    # L·∫•y 30 ng√†y g·∫ßn nh·∫•t (ho·∫∑c t·∫•t c·∫£ n·∫øu √≠t h∆°n 30)
    data_slice = all_data[-30:] if len(all_data) >= 30 else all_data
    results = []
    
    bridge_name = bridge_config.get("name", "")
    
    # T·∫°o DeBacktesterCore instance
    backtester = DeBacktesterCore(data_slice)
    
    # Ch·∫°y backtest v·ªõi config
    stats = backtester.run_backtest(bridge_config, days_to_test=len(data_slice))
    
    # Ki·ªÉm tra l·ªói
    if "error" in stats:
        return []
    
    # Format k·∫øt qu·∫£ t·ª´ history_log
    history_log = stats.get("history_log", [])
    
    for log_item in history_log:
        try:
            date_str = log_item.get("date", "")
            gdb = log_item.get("gdb", "")
            desc = log_item.get("desc", "")
            is_win = log_item.get("is_win", False)
            
            # Format pred t·ª´ desc
            # VD: "(5+3)%2 -> Ch·∫°m [0, 2]" -> "Ch·∫°m 0,2"
            # VD: "(5) -> Ch·∫°m 5, 0" -> "Ch·∫°m 5,0"
            pred_str = desc
            if "-> Ch·∫°m" in desc:
                # L·∫•y ph·∫ßn sau "-> Ch·∫°m"
                cham_part = desc.split("-> Ch·∫°m")[-1].strip()
                # X·ª≠ l√Ω n·∫øu l√† list format [0, 2] ho·∫∑c string "5, 0"
                # Lo·∫°i b·ªè d·∫•u ngo·∫∑c vu√¥ng v√† kho·∫£ng tr·∫Øng
                cham_part = cham_part.replace("[", "").replace("]", "").replace(" ", "")
                pred_str = f"Ch·∫°m {cham_part}"
            elif "-> B·ªô" in desc:
                pred_str = "B·ªô " + desc.split("-> B·ªô")[-1].strip()
            
            status = "ƒÇn" if is_win else "G√£y"
            
            results.append({
                'date': date_str,
                'pred': pred_str,
                'result': gdb,
                'is_win': is_win,
                'status': status
            })
        except Exception:
            continue
    
    return results


# Export all functions for backward compatibility
__all__ = [
    'SETTINGS',
    'DB_NAME',
    'TONGHOP_TOP_CAU_N1_V5',
    'TONGHOP_TOP_CAU_RATE_V5',
    'TONGHOP_TOP_CAU_CORE_V5',
    'BACKTEST_15_CAU_K2N_V30_AI_V8',
    'BACKTEST_15_CAU_N1_V31_AI_V8',
    'BACKTEST_CUSTOM_CAU_V16',
    'BACKTEST_MANAGED_BRIDGES_N1',
    'BACKTEST_MANAGED_BRIDGES_K2N',
    'BACKTEST_MEMORY_BRIDGES',
    'run_and_update_all_bridge_rates',
    'run_and_update_all_bridge_K2N_cache',
    'run_backtest_lo_30_days',
    'run_backtest_de_30_days',
]

--------------------------------------------------

=== FILE: logic\backtester_aggregation.py ===
"""
backtester_aggregation.py - Top bridge aggregation functions

Extracted from backtester.py to improve maintainability.
Contains: Functions for finding and aggregating top-performing bridges.
"""

from .backtester_scoring import score_by_streak, score_by_rate

try:
    from .bridges.bridges_classic import ALL_15_BRIDGE_FUNCTIONS_V5
except ImportError:
    print("Warning: Could not import ALL_15_BRIDGE_FUNCTIONS_V5")
    ALL_15_BRIDGE_FUNCTIONS_V5 = []


def tonghop_top_cau_core(
    fullBacktestN1Range, lastDataRowForPrediction, topN, scoringFunction
):
    """
    Core function for aggregating top bridges.
    
    Args:
        fullBacktestN1Range: Full backtest results
        lastDataRowForPrediction: Last data row for prediction
        topN: Number of top bridges to return
        scoringFunction: Function to score bridges
        
    Returns:
        list: Formatted output with top bridge predictions
    """
    try:
        if not fullBacktestN1Range or len(fullBacktestN1Range) < 2:
            return [["L·ªñI: 'fullBacktestN1Range' kh√¥ng h·ª£p l·ªá."]]
        if not lastDataRowForPrediction or len(lastDataRowForPrediction) < 10:
            return [["L·ªñI: 'lastDataRowForPrediction' kh√¥ng h·ª£p l·ªá."]]

        lastKy = lastDataRowForPrediction[0]

        # Handle 'int' object
        try:
            ky_int = int(lastKy)
            nextKy = f"K·ª≥ {ky_int + 1}"
        except (ValueError, TypeError):
            nextKy = f"K·ª≥ {lastKy} (Next)"

        headers = fullBacktestN1Range[0]
        dataRows = [
            row
            for row in fullBacktestN1Range[1:]
            if "T·ª∑ L·ªá %" not in str(row[0])
            and "HO√ÄN TH√ÄNH" not in str(row[0])
            and not str(row[0]).startswith("K·ª≥")
            and "(D·ª± ƒëo√°n N1)" not in str(row)
        ]

        numDataRows = len(dataRows)
        if numDataRows == 0:
            return [["L·ªñI: Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu backtest h·ª£p l·ªá."]]

        bridgeColumns = []
        for j, header in enumerate(headers):
            if str(header).startswith("C·∫ßu "):
                bridgeColumns.append(
                    {"name": str(header).split(" (")[0], "colIndex": j}
                )

        if not bridgeColumns:
            return [["L·ªñI: Kh√¥ng t√¨m th·∫•y c·ªôt 'C·∫ßu ' n√†o trong ti√™u ƒë·ªÅ."]]

        bridgeStats = []
        num_cau_functions = len(ALL_15_BRIDGE_FUNCTIONS_V5)

        for i, bridge in enumerate(bridgeColumns):
            if i >= num_cau_functions:
                break
            colIdx = bridge["colIndex"]
            wins, currentStreak = 0, 0

            for k in range(numDataRows):
                if "‚úÖ" in str(dataRows[k][colIdx]):
                    wins += 1
            for k in range(numDataRows - 1, -1, -1):
                if "‚úÖ" in str(dataRows[k][colIdx]):
                    currentStreak += 1
                else:
                    break

            winRate = (wins / numDataRows) if numDataRows > 0 else 0
            score = scoringFunction(winRate, currentStreak)

            bridgeStats.append(
                {
                    "name": bridge["name"],
                    "bridgeFuncIndex": i,
                    "rate": winRate,
                    "streak": currentStreak,
                    "score": score,
                }
            )

        bridgeStats.sort(key=lambda x: x["score"], reverse=True)

        topBridges = bridgeStats[:topN]
        outputParts, seenNumbers = [], set()

        for bridge in topBridges:
            try:
                stl = ALL_15_BRIDGE_FUNCTIONS_V5[bridge["bridgeFuncIndex"]](
                    lastDataRowForPrediction
                )
                bridgeNum = bridge["name"].replace("C·∫ßu ", "")
                num1, num2 = stl[0], stl[1]
                pairPart1, pairPart2 = None, None

                if num1 not in seenNumbers:
                    pairPart1, seenNumbers = num1, seenNumbers | {num1}
                if num2 not in seenNumbers:
                    pairPart2, seenNumbers = f"{num2}({bridgeNum})", seenNumbers | {
                        num2
                    }
                elif pairPart1:
                    pairPart1 = f"{num1}({bridgeNum})"

                if pairPart1 and pairPart2:
                    outputParts.append(f"{pairPart1}, {pairPart2}")
                elif pairPart1:
                    outputParts.append(pairPart1)
                elif pairPart2:
                    outputParts.append(pairPart2)
            except Exception as e:
                print(f"L·ªói khi g·ªçi h√†m c·∫ßu {bridge['name']}: {e}")

        return [[f"{nextKy}: {', '.join(outputParts)}"]]
    except Exception as e:
        print(f"L·ªói TONGHOP_CORE_V5: {e}")
        return [[f"L·ªñI: {e}"]]


def tonghop_top_cau_n1(fullBacktestN1Range, lastDataRowForPrediction, topN=3):
    """
    Find top N1 bridges prioritizing streak.
    
    Args:
        fullBacktestN1Range: Full backtest results
        lastDataRowForPrediction: Last data row for prediction
        topN: Number of top bridges to return
        
    Returns:
        list: Top bridge predictions
    """
    return tonghop_top_cau_core(
        fullBacktestN1Range, lastDataRowForPrediction, topN, score_by_streak
    )


def tonghop_top_cau_rate(fullBacktestN1Range, lastDataRowForPrediction, topN=3):
    """
    Find top bridges prioritizing win rate.
    
    Args:
        fullBacktestN1Range: Full backtest results
        lastDataRowForPrediction: Last data row for prediction
        topN: Number of top bridges to return
        
    Returns:
        list: Top bridge predictions
    """
    return tonghop_top_cau_core(
        fullBacktestN1Range, lastDataRowForPrediction, topN, score_by_rate
    )


--------------------------------------------------

=== FILE: logic\backtester_core.py ===
"""
backtester_core.py - Core backtesting functions
(PHI√äN B·∫¢N V8.10 - FIX N/A ISSUE BY SCANNING ALL BRIDGES)
"""

# ... (Gi·ªØ nguy√™n to√†n b·ªô ph·∫ßn Import v√† Helper Functions ·ªü tr√™n) ...
try:
    from .config_manager import SETTINGS
except ImportError:
    try:
        from config_manager import SETTINGS
    except ImportError:
        try:
            from .constants import DEFAULT_SETTINGS
        except ImportError:
            from constants import DEFAULT_SETTINGS
        SETTINGS = type("obj", (object,), DEFAULT_SETTINGS)

try:
    from .db_manager import DB_NAME
except ImportError:
    DB_NAME = "data/xo_so_prizes_all_logic.db"

try:
    from .data_repository import get_all_managed_bridges
except ImportError:
    def get_all_managed_bridges(d, o):
        return []

try:
    from .bridges.bridges_classic import (
        ALL_15_BRIDGE_FUNCTIONS_V5,
        checkHitSet_V30_K2N,
        getAllLoto_V30,
    )
except ImportError:
    ALL_15_BRIDGE_FUNCTIONS_V5 = []

    def getAllLoto_V30(r):
        return []

    def checkHitSet_V30_K2N(p, loto_set):
        return "L·ªói"

try:
    from .bridges.bridges_v16 import (
        get_index_from_name_V16,
        getAllPositions_V17_Shadow,
        getPositionName_V16,
        getPositionName_V17_Shadow,
        taoSTL_V30_Bong,
    )
except ImportError:
    def getPositionName_V16(i):
        return "L·ªói"

    def get_index_from_name_V16(n):
        return None

    def taoSTL_V30_Bong(a, b):
        return ["00", "00"]

    def getAllPositions_V17_Shadow(r):
        return []

    def getPositionName_V17_Shadow(i):
        return "L·ªói V17"

try:
    from .bridges.bridges_memory import (
        calculate_bridge_stl,
        get_27_loto_names,
        get_27_loto_positions,
    )
except ImportError:
    print("L·ªói: Kh√¥ng th·ªÉ import bridges_memory trong backtester_core.py")

    def calculate_bridge_stl(loto_str_1, loto_str_2, algorithm_type):
        """Fallback function for calculate_bridge_stl"""
        return ["00", "00"]

    def get_27_loto_names():
        """Fallback function for get_27_loto_names"""
        return []

    def get_27_loto_positions(r):
        """Fallback function for get_27_loto_positions"""
        return []

# Import helper functions from common_utils (refactored)
from .common_utils import validate_backtest_params as _validate_backtest_params

# Import re module for bridge name parsing
import re


# =============================================================================
# HELPER FUNCTIONS (Moved from backtester_helpers.py)
# =============================================================================

def parse_k2n_results(results_data):
    """
    Parse K2N backtest results (Dynamic Row Detection).
    [FIXED] Added robust mapping for LO_STL_FIXED bridges.
    """
    cache_data_list = []
    pending_k2n_dict = {}

    if not results_data or len(results_data) < 2:
        return cache_data_list, pending_k2n_dict

    try:
        # 1. X√°c ƒë·ªãnh c√°c h√†ng d·ª±a tr√™n ti√™u ƒë·ªÅ c·ªôt ƒë·∫ßu ti√™n (C·ªôt A)
        headers = results_data[0]

        row_rates = None
        row_streaks = None
        row_recent = None
        row_prediction = None

        for row in results_data[1:]:
            first_col = str(row[0]).strip()
            if "T·ª∑ L·ªá" in first_col:
                row_rates = row
            elif "Chu·ªói" in first_col:
                row_streaks = row
            elif "Phong ƒê·ªô" in first_col:
                row_recent = row
            elif "K·ª≥" in first_col or "Next" in first_col:
                row_prediction = row

        # N·∫øu kh√¥ng t√¨m th·∫•y, fallback v·ªÅ index c≈© (nh∆∞ng r·ªßi ro)
        if not row_rates and len(results_data) > 1: row_rates = results_data[1]
        if not row_streaks and len(results_data) > 2: row_streaks = results_data[2]
        if not row_recent and len(results_data) > 3: row_recent = results_data[3]
        if not row_prediction and len(results_data) > 4: row_prediction = results_data[4]

        num_bridges = len(headers) - 1

        for j in range(1, num_bridges + 1):
            original_name = str(headers[j]).split(" (")[0].strip()
            bridge_name = original_name

            # [FIX LO_STL MAPPING] √Ånh x·∫° t√™n "C·∫ßu X" sang "LO_STL_FIXED_0X"
            if original_name.startswith("C·∫ßu "):
                try:
                    num_part = original_name.replace("C·∫ßu ", "").strip()
                    if num_part.isdigit():
                        bridge_num = int(num_part)
                        if 1 <= bridge_num <= 15:
                            bridge_name = f"LO_STL_FIXED_{bridge_num:02d}"
                except:
                    pass

            # L·∫•y d·ªØ li·ªáu an to√†n
            win_rate_text = str(row_rates[j]) if row_rates and j < len(row_rates) else "0"
            win_streak_text = str(row_streaks[j]) if row_streaks and j < len(row_streaks) else "0"
            recent_form_text = str(row_recent[j]) if row_recent and j < len(row_recent) else "0/10"
            pending_text = str(row_prediction[j]) if row_prediction and j < len(row_prediction) else ""

            # Parse current_streak and max_lose_streak
            current_streak = 0
            max_lose_streak = 0
            if "/" in win_streak_text:
                parts = win_streak_text.split("/")
                try:
                    part0 = parts[0].strip().replace("th·∫Øng", "").replace("thua", "").strip()
                    current_streak = int(part0)
                    if len(parts) > 1:
                        part1 = parts[1].strip().replace("th·∫Øng", "").replace("thua", "").strip()
                        max_lose_streak = int(part1)
                except (ValueError, IndexError):
                    current_streak = 0
                    max_lose_streak = 0
            else:
                try:
                    cleaned = win_streak_text.strip().replace("th·∫Øng", "").replace("thua", "").strip()
                    current_streak = int(cleaned)
                except ValueError:
                    current_streak = 0

            # Parse recent_win_count
            recent_win_count = 0
            try:
                if "/" in recent_form_text:
                    recent_win_count = int(recent_form_text.split("/")[0].strip())
                else:
                    recent_win_count = int(recent_form_text.strip())
            except (ValueError, IndexError):
                recent_win_count = 0

            # Clean STL for Cache
            clean_stl = pending_text.split("(")[0].strip() if "(" in pending_text else pending_text.strip()

            cache_data_list.append((
                win_rate_text,
                current_streak,
                clean_stl if clean_stl else "",
                max_lose_streak,
                recent_win_count,
                bridge_name
            ))

            # L∆∞u pending v·ªõi logic m·ªõi: X√°c ƒë·ªãnh r√µ l√† N1 hay N2
            if pending_text and pending_text.strip() != "":
                is_n2 = "N2" in pending_text or "ch·ªù" in pending_text.lower()

                pending_k2n_dict[bridge_name] = {
                    "stl": clean_stl,
                    "streak": current_streak,
                    "max_lose": max_lose_streak,
                    "is_n2": is_n2
                }

    except Exception as e:
        print(f"L·ªói parse_k2n_results: {e}")

    return cache_data_list, pending_k2n_dict


# =============================================================================
# BACKTEST FUNCTIONS
# =============================================================================

def BACKTEST_15_CAU_K2N_V30_AI_V8(
    toan_bo_A_I, ky_bat_dau_kiem_tra, ky_ket_thuc_kiem_tra, history=True
):
    # ... (Gi·ªØ nguy√™n logic h√†m 15 C·∫ßu K2N) ...
    allData, finalEndRow, startCheckRow, offset, error = _validate_backtest_params(
        toan_bo_A_I, ky_bat_dau_kiem_tra, ky_ket_thuc_kiem_tra
    )
    if error:
        return error
    headers = [
        "K·ª≥ (C·ªôt A)",
        "C·∫ßu 1 (ƒê·ªÅ+5)",
        "C·∫ßu 2 (G6+G7)",
        "C·∫ßu 3 (GƒêB+G1)",
        "C·∫ßu 4 (GƒêB+G1)",
        "C·∫ßu 5 (G7+G7)",
        "C·∫ßu 6 (G7+G7)",
        "C·∫ßu 7 (G5+G7)",
        "C·∫ßu 8 (G3+G4)",
        "C·∫ßu 9 (GƒêB+G1)",
        "C·∫ßu 10 (G2+G3)",
        "C·∫ßu 11 (GƒêB+G3)",
        "C·∫ßu 12 (GƒêB+G3)",
        "C·∫ßu 13 (G7.3+8)",
        "C·∫ßu 14 (G1+2)",
        "C·∫ßu 15 (ƒê·ªÅ+7)",
        "T·ªïng Tr√∫ng",
    ]
    results = [headers]

    in_frame = [False] * 15
    prediction_in_frame = [None] * 15
    current_streak_k2n = [0] * 15

    current_lose_streak_k2n = [0] * 15
    max_lose_streak_k2n = [0] * 15

    cau_functions = ALL_15_BRIDGE_FUNCTIONS_V5

    data_rows = []
    totalTestDays = 0
    win_counts = [0] * 15

    for k in range(startCheckRow, finalEndRow + 1):
        prevRow_idx, actualRow_idx = k - 1 - offset, k - offset
        if actualRow_idx >= len(allData) or prevRow_idx < 0:
            continue
        prevRow, actualRow = allData[prevRow_idx], allData[actualRow_idx]
        if not actualRow or not actualRow[0] or str(actualRow[0]).strip() == "":
            break

        if not prevRow or len(actualRow) < 10 or not actualRow[2] or not actualRow[9]:
            data_rows.append([actualRow[0] or k, "L·ªói d·ªØ li·ªáu h√†ng"] + [""] * 15)
            continue

        actualSoKy, actualLotoSet = actualRow[0] or k, set(getAllLoto_V30(actualRow))
        totalTestDays += 1

        daily_results_row, totalHits = [actualSoKy], 0

        try:
            for j in range(15):
                check_result = ""
                cell_output = ""
                if in_frame[j]:
                    pred = prediction_in_frame[j]
                    check_result = checkHitSet_V30_K2N(pred, actualLotoSet)
                    if "‚úÖ" in check_result:
                        cell_output = f"{','.join(pred)} ‚úÖ (ƒÇn N2)"
                        win_counts[j] += 1
                        current_streak_k2n[j] += 1
                        current_lose_streak_k2n[j] = 0
                    else:
                        cell_output = f"{','.join(pred)} ‚ùå (Tr∆∞·ª£t K2N)"
                        current_streak_k2n[j] = 0
                        current_lose_streak_k2n[j] += 1
                        if current_lose_streak_k2n[j] > max_lose_streak_k2n[j]:
                            max_lose_streak_k2n[j] = current_lose_streak_k2n[j]

                    in_frame[j], prediction_in_frame[j] = False, None
                else:
                    pred = cau_functions[j](prevRow)
                    check_result = checkHitSet_V30_K2N(pred, actualLotoSet)
                    if "‚úÖ" in check_result:
                        cell_output = f"{','.join(pred)} ‚úÖ (ƒÇn N1)"
                        win_counts[j] += 1
                        current_streak_k2n[j] += 1
                        current_lose_streak_k2n[j] = 0
                    else:
                        cell_output = f"{','.join(pred)} (Tr∆∞·ª£t N1...)"
                        in_frame[j], prediction_in_frame[j] = True, pred

                daily_results_row.append(cell_output)
                if "‚úÖ" in check_result:
                    totalHits += 1

            daily_results_row.append(totalHits)
            data_rows.append(daily_results_row)

        except Exception as e:
            data_rows.append([actualSoKy, f"L·ªói: {e}"] + [""] * 15)

    data_rows.reverse()

    rate_row, total_wins = ["T·ª∑ L·ªá %"], 0
    if totalTestDays > 0:
        for count in win_counts:
            rate = (count / totalTestDays) * 100
            rate_row.append(f"{rate:.2f}%")
            total_wins += count
        rate_row.append(f"TB: {(total_wins / totalTestDays):.2f}")
    else:
        for _ in range(15):
            rate_row.append("0.00%")
        rate_row.append("TB: 0.00")
    results.insert(1, rate_row)

    streak_row = ["Chu·ªói Th·∫Øng / Thua Max"]
    for i in range(15):
        streak_row.append(
            f"{current_streak_k2n[i]} th·∫Øng / {max_lose_streak_k2n[i]} thua"
        )
    streak_row.append("---")
    results.insert(2, streak_row)

    recent_win_row = ["Phong ƒê·ªô 10 K·ª≥"]
    for i in range(15):
        recent_wins = 0
        periods_to_check = min(10, len(data_rows))
        for row_idx in range(periods_to_check):
            if row_idx < len(data_rows):
                row = data_rows[row_idx]
                if i + 1 < len(row):
                    cell_value = str(row[i + 1])
                    if "‚úÖ" in cell_value:
                        recent_wins += 1
        recent_win_row.append(f"{recent_wins}/10")
    recent_win_row.append("---")
    results.insert(3, recent_win_row)

    try:
        last_data_row_for_prediction = allData[finalEndRow - offset]
    except IndexError:
        results.append(["L·ªñI D·ª∞ ƒêO√ÅN", "Kh√¥ng c√≥ d·ªØ li·ªáu h√†ng cu·ªëi."])
        return results

    try:
        ky_int = int(last_data_row_for_prediction[0])
        finalRowK = f"K·ª≥ {ky_int + 1}"
    except (ValueError, TypeError):
        finalRowK = f"K·ª≥ {last_data_row_for_prediction[0]} (Next)"

    finalRow, openFrames = [finalRowK], 0
    for j in range(15):
        if in_frame[j]:
            finalRow.append(f"{','.join(prediction_in_frame[j])} (ƒêang ch·ªù N2)")
            openFrames += 1
        else:
            try:
                pred = cau_functions[j](last_data_row_for_prediction)
                finalRow.append(f"{','.join(pred)} (Khung m·ªõi N1)")
            except Exception:
                finalRow.append("L·ªñI PREDICT")
    finalRow.append(f"{openFrames} khung m·ªü" if openFrames > 0 else "0")

    results.insert(4, finalRow)

    if history:
        results.extend(data_rows)

    return results


def BACKTEST_15_CAU_N1_V31_AI_V8(
    toan_bo_A_I, ky_bat_dau_kiem_tra, ky_ket_thuc_kiem_tra
):
    """Backtest 15 C·∫ßu L√¥ N1"""
    allData, finalEndRow, startCheckRow, offset, error = _validate_backtest_params(
        toan_bo_A_I, ky_bat_dau_kiem_tra, ky_ket_thuc_kiem_tra
    )
    if error:
        return error
    headers = [
        "K·ª≥ (C·ªôt A)",
        "C·∫ßu 1 (ƒê·ªÅ+5)",
        "C·∫ßu 2 (G6+G7)",
        "C·∫ßu 3 (GƒêB+G1)",
        "C·∫ßu 4 (GƒêB+G1)",
        "C·∫ßu 5 (G7+G7)",
        "C·∫ßu 6 (G7+G7)",
        "C·∫ßu 7 (G5+G7)",
        "C·∫ßu 8 (G3+G4)",
        "C·∫ßu 9 (GƒêB+G1)",
        "C·∫ßu 10 (G2+G3)",
        "C·∫ßu 11 (GƒêB+G3)",
        "C·∫ßu 12 (GƒêB+G3)",
        "C·∫ßu 13 (G7.3+8)",
        "C·∫ßu 14 (G1+2)",
        "C·∫ßu 15 (ƒê·ªÅ+7)",
        "T·ªïng Tr√∫ng",
    ]
    results = [headers]
    cau_functions = ALL_15_BRIDGE_FUNCTIONS_V5

    data_rows = []

    for k in range(startCheckRow, finalEndRow + 1):
        prevRow_idx, actualRow_idx = k - 1 - offset, k - offset
        if actualRow_idx >= len(allData) or prevRow_idx < 0:
            continue
        prevRow, actualRow = allData[prevRow_idx], allData[actualRow_idx]
        if not actualRow or not actualRow[0] or str(actualRow[0]).strip() == "":
            break
        if not prevRow or len(actualRow) < 10 or not actualRow[2] or not actualRow[9]:
            data_rows.append([actualRow[0] or k, "L·ªói d·ªØ li·ªáu h√†ng"] + [""] * 15)
            continue
        actualSoKy, actualLotoSet = actualRow[0] or k, set(getAllLoto_V30(actualRow))
        daily_results_row, totalHits = [actualSoKy], 0
        try:
            for j in range(15):
                pred = cau_functions[j](prevRow)
                check_result = checkHitSet_V30_K2N(pred, actualLotoSet)
                cell_output = f"{','.join(pred)} {check_result}"
                if "‚úÖ" in check_result:
                    totalHits += 1
                daily_results_row.append(cell_output)
            daily_results_row.append(totalHits)
            data_rows.append(daily_results_row)
        except Exception as e:
            data_rows.append([actualSoKy, f"L·ªói: {e}"] + [""] * 15)

    data_rows.reverse()

    totalTestDays = len(data_rows)
    if totalTestDays > 0:
        win_counts = [0] * 15
        for row in data_rows:
            for j in range(15):
                if "‚úÖ" in str(row[j + 1]):
                    win_counts[j] += 1
        rate_row, total_wins = ["T·ª∑ L·ªá %"], 0
        for count in win_counts:
            rate = (count / totalTestDays) * 100
            rate_row.append(f"{rate:.2f}%")
            total_wins += count
        rate_row.append(f"TB: {(total_wins / totalTestDays):.2f}")
        results.insert(1, rate_row)

    try:
        last_data_row_for_prediction = allData[finalEndRow - offset]
    except IndexError:
        results.append(["L·ªñI D·ª∞ ƒêO√ÅN", "Kh√¥ng c√≥ d·ªØ li·ªáu h√†ng cu·ªëi."])
        return results

    try:
        ky_int = int(last_data_row_for_prediction[0])
        finalRowK = f"K·ª≥ {ky_int + 1}"
    except (ValueError, TypeError):
        finalRowK = f"K·ª≥ {last_data_row_for_prediction[0]} (Next)"

    finalRow = [finalRowK]
    for j in range(15):
        try:
            pred = cau_functions[j](last_data_row_for_prediction)
            finalRow.append(f"{','.join(pred)} (D·ª± ƒëo√°n N1)")
        except Exception:
            finalRow.append("L·ªñI PREDICT")
    finalRow.append("---")

    results.insert(2, finalRow)
    results.extend(data_rows)

    return results


def BACKTEST_CUSTOM_CAU_V16(
    toan_bo_A_I, ky_bat_dau_kiem_tra, ky_ket_thuc_kiem_tra, custom_bridge_name, mode
):
    """Backtest m·ªôt c·∫ßu t√πy ch·ªânh N1/K2N (V17 Shadow)"""
    try:
        parts = custom_bridge_name.split("+")
        name1, name2 = parts[0].strip(), parts[1].strip()

        idx1, idx2 = get_index_from_name_V16(name1), get_index_from_name_V16(name2)

        if idx1 is None or idx2 is None:
            return [["L·ªñI:", f"Kh√¥ng th·ªÉ d·ªãch t√™n c·∫ßu '{custom_bridge_name}'."]]

        allData, finalEndRow, startCheckRow, offset, error = _validate_backtest_params(
            toan_bo_A_I, ky_bat_dau_kiem_tra, ky_ket_thuc_kiem_tra
        )
        if error:
            return error

        results = [["K·ª≥ (C·ªôt A)", "K·∫øt Qu·∫£"]]
        in_frame, prediction_in_frame = False, None
        totalTestDays, win_count = 0, 0

        data_rows = []

        for k in range(startCheckRow, finalEndRow + 1):
            prevRow_idx, actualRow_idx = k - 1 - offset, k - offset
            if actualRow_idx >= len(allData) or prevRow_idx < 0:
                continue
            prevRow_data, actualRow = allData[prevRow_idx], allData[actualRow_idx]
            if not actualRow or not actualRow[0] or str(actualRow[0]).strip() == "":
                break
            if (
                not prevRow_data
                or len(actualRow) < 10
                or not actualRow[2]
                or not actualRow[9]
            ):
                data_rows.append([actualRow[0] or k, "L·ªói d·ªØ li·ªáu h√†ng"])
                continue

            actualSoKy, actualLotoSet = actualRow[0] or k, set(
                getAllLoto_V30(actualRow)
            )

            prevPositions = getAllPositions_V17_Shadow(prevRow_data)

            a, b = prevPositions[idx1], prevPositions[idx2]
            if a is None or b is None:
                data_rows.append([actualSoKy, "L·ªói (v·ªã tr√≠ r·ªóng)"])
                continue

            totalTestDays += 1
            pred = taoSTL_V30_Bong(a, b)
            check_result = checkHitSet_V30_K2N(pred, actualLotoSet)
            cell_output = ""

            if mode == "N1":
                cell_output = f"{','.join(pred)} {check_result}"
                if "‚úÖ" in check_result:
                    win_count += 1
            elif mode == "K2N":
                if in_frame:
                    check_result = checkHitSet_V30_K2N(
                        prediction_in_frame, actualLotoSet
                    )
                    if "‚úÖ" in check_result:
                        cell_output, win_count = (
                            f"{','.join(prediction_in_frame)} ‚úÖ (ƒÇn N2)",
                            win_count + 1,
                        )
                    else:
                        cell_output = f"{','.join(prediction_in_frame)} ‚ùå (Tr∆∞·ª£t K2N)"
                    in_frame, prediction_in_frame = False, None
                else:
                    if "‚úÖ" in check_result:
                        cell_output, win_count = (
                            f"{','.join(pred)} ‚úÖ (ƒÇn N1)",
                            win_count + 1,
                        )
                    else:
                        cell_output, in_frame, prediction_in_frame = (
                            f"{','.join(pred)} (Tr∆∞·ª£t N1...)",
                            True,
                            pred,
                        )
            data_rows.append([actualSoKy, cell_output])

        data_rows.reverse()
        results.extend(data_rows)

        if totalTestDays > 0:
            rate = (win_count / totalTestDays) * 100
            results.insert(1, ["T·ª∑ L·ªá %", f"{rate:.2f}% ({win_count}/{totalTestDays})"])

        if mode == "K2N":
            try:
                ky_int = int(allData[finalEndRow - offset][0])
                finalRowK = f"K·ª≥ {ky_int + 1}"
            except (ValueError, TypeError):
                finalRowK = f"K·ª≥ {allData[finalEndRow - offset][0]} (Next)"

            final_cell = "---"
            if in_frame:
                final_cell = f"{','.join(prediction_in_frame)} (ƒêang ch·ªù N2)"
            results.insert(2, [finalRowK, final_cell])

        return results
    except Exception as e:
        print(f"L·ªói BACKTEST_CUSTOM_CAU_V16: {e}")
        return [["L·ªñI:", str(e)]]


def BACKTEST_MANAGED_BRIDGES_N1(
    toan_bo_A_I, ky_bat_dau_kiem_tra, ky_ket_thuc_kiem_tra, db_name=DB_NAME
):
    """Backtest N1 cho C·∫ßu ƒê√£ L∆∞u (V17 Shadow + B·∫°c Nh·ªõ)"""
    return []  # Placeholder (ƒë·ªÉ tr√°nh l·ªói import, logic ch√≠nh ·ªü backtester.py n·∫øu c·∫ßn)


def BACKTEST_MANAGED_BRIDGES_K1N(
    toan_bo_A_I,
    ky_bat_dau_kiem_tra,
    ky_ket_thuc_kiem_tra,
    db_name=DB_NAME,
    history=True,
):
    """Backtest K1N cho C·∫ßu ƒê√£ L∆∞u (L√¥) - ƒê√£ t√≠ch h·ª£p logic cho LO_STL_FIXED v√† LO_MEM"""
    try:
        # [FIX CRITICAL V8.10] Load ALL bridges (k·ªÉ c·∫£ disabled) ƒë·ªÉ c·∫≠p nh·∫≠t K1N
        bridges_to_test = get_all_managed_bridges(db_name, only_enabled=False)
    except Exception as e:
        print(f"L·ªói t·∫£i c·∫ßu DB: {e}")
        return [["L·ªñI"]]
    
    if not bridges_to_test:
        return [["K·ª≥ (C·ªôt A)"], ["Th√¥ng b√°o", "Kh√¥ng c√≥ c·∫ßu n√†o ƒë∆∞·ª£c B·∫≠t."]]

    # [FILTER] L·ªçc b·ªè C·∫ßu ƒê·ªÅ (DE_*)
    filtered_bridges = []
    for b in bridges_to_test:
        b_name = str(b.get("name", ""))
        b_type = str(b.get("type", ""))
        if not b_name.startswith("DE_") and not b_type.startswith("DE"):
            filtered_bridges.append(b)
    
    bridges_to_test = filtered_bridges
    
    # [FIX] Tr·∫£ v·ªÅ c·∫•u tr√∫c chu·∫©n 5 d√≤ng n·∫øu kh√¥ng c√≥ c·∫ßu L√¥ (ƒë·ªÉ tr√°nh l·ªói index ·ªü backtester.py)
    if not bridges_to_test:
        print(">>> Kh√¥ng c√≥ c·∫ßu L√¥ n√†o ƒë·ªÉ backtest K1N.")
        return [
            ["K·ª≥ (C·ªôt A)"], 
            ["T·ª∑ L·ªá %"], 
            ["Chu·ªói Th·∫Øng / Thua Max"], 
            ["Phong ƒê·ªô 10 K·ª≥"], 
            ["Th√¥ng b√°o", "Kh√¥ng c√≥ c·∫ßu L√¥ n√†o ƒë∆∞·ª£c B·∫≠t."]
        ]

    print(f">>> B·∫Øt ƒë·∫ßu Backtest K1N cho {len(bridges_to_test)} c·∫ßu L√¥...")

    allData, finalEndRow, startCheckRow, offset, error = _validate_backtest_params(
        toan_bo_A_I, ky_bat_dau_kiem_tra, ky_ket_thuc_kiem_tra
    )
    if error: return error

    num_bridges = len(bridges_to_test)
    headers = ["K·ª≥ (C·ªôt A)"]
    for bridge in bridges_to_test:
        headers.append(f"{bridge['name']}")

    results = [headers]
    current_streak = [0] * num_bridges
    max_lose_streak = [0] * num_bridges
    win_counts = [0] * num_bridges
    data_rows = []
    totalTestDays = 0

    for k in range(startCheckRow, finalEndRow + 1):
        prevRow_idx, actualRow_idx = k - 1 - offset, k - offset
        if actualRow_idx >= len(allData) or prevRow_idx < 0: continue
        prevRow, actualRow = allData[prevRow_idx], allData[actualRow_idx]
        if not actualRow or not actualRow[0]: break
        if not prevRow or len(actualRow) < 10: 
            data_rows.append([actualRow[0] or k, "L·ªói d·ªØ li·ªáu"] + [""] * num_bridges)
            continue

        actualSoKy, actualLotoSet = actualRow[0] or k, set(getAllLoto_V30(actualRow))
        prevPositions = getAllPositions_V17_Shadow(prevRow)
        prevLotos = get_27_loto_positions(prevRow)
        totalTestDays += 1
        daily_row = [actualSoKy]

        for j, bridge in enumerate(bridges_to_test):
            try:
                bridge_name = bridge.get("name", "")
                idx1, idx2 = bridge.get("pos1_idx"), bridge.get("pos2_idx")
                pred = []

                # --- 1. LO_STL_FIXED ---
                if "LO_STL_FIXED" in bridge_name:
                    try:
                        num_part = bridge_name.split("_")[-1]
                        if num_part.isdigit():
                            idx_func = int(num_part) - 1
                            if 0 <= idx_func < len(ALL_15_BRIDGE_FUNCTIONS_V5):
                                pred = ALL_15_BRIDGE_FUNCTIONS_V5[idx_func](prevRow)
                    except: pass
                
                # --- 2. LO_MEM ---
                elif idx1 == -1 and idx2 == -1:
                    if "LO_MEM_SUM" in bridge_name:
                        parts = bridge_name.split("_")
                        try:
                            l1, l2 = parts[-2], parts[-1]
                            names = get_27_loto_names()
                            if l1 in names and l2 in names:
                                pred = calculate_bridge_stl(prevLotos[names.index(l1)], prevLotos[names.index(l2)], "sum")
                        except: pass
                    elif "LO_MEM_DIFF" in bridge_name:
                        parts = bridge_name.split("_")
                        try:
                            l1, l2 = parts[-2], parts[-1]
                            names = get_27_loto_names()
                            if l1 in names and l2 in names:
                                pred = calculate_bridge_stl(prevLotos[names.index(l1)], prevLotos[names.index(l2)], "diff")
                        except: pass
                    
                    if not pred: # Fallback old names
                        if "T·ªïng(" in bridge_name:
                            m = re.search(r'T·ªïng\((\d+)\+(\d+)\)', bridge_name)
                            if m: pred = calculate_bridge_stl(prevLotos[int(m.group(1))], prevLotos[int(m.group(2))], "sum")
                        elif "Hi·ªáu(" in bridge_name:
                            m = re.search(r'Hi·ªáu\((\d+)-(\d+)\)', bridge_name)
                            if m: pred = calculate_bridge_stl(prevLotos[int(m.group(1))], prevLotos[int(m.group(2))], "diff")

                # --- 3. V17 ---
                elif idx1 is not None and idx2 is not None:
                    a, b = prevPositions[idx1], prevPositions[idx2]
                    if a is not None and b is not None:
                        pred = taoSTL_V30_Bong(a, b)

                if not pred:
                    daily_row.append("L·ªói CT"); continue

                check_result = checkHitSet_V30_K2N(pred, actualLotoSet)
                cell_output = ""

                if "‚úÖ" in check_result or "ƒÇn" in check_result:
                    cell_output = f"{','.join(pred)} ‚úÖ (ƒÇn N1)"
                    win_counts[j] += 1
                    current_streak[j] += 1
                else:
                    cell_output = f"{','.join(pred)} ‚ùå (Tr∆∞·ª£t N1)"
                    current_streak[j] = 0
                    
                daily_row.append(cell_output)

            except Exception as e: daily_row.append(f"Err: {e}")

        data_rows.append(daily_row)

    data_rows.reverse()

    # Rate Row
    rate_row = ["T·ª∑ L·ªá %"]
    if totalTestDays > 0:
        for count in win_counts:
            rate_row.append(f"{(count / totalTestDays) * 100:.2f}%")
    else:
        rate_row.extend(["0.00%"] * num_bridges)
    results.insert(1, rate_row)

    # Streak Row
    streak_row = ["Chu·ªói Th·∫Øng Max"]
    for i in range(num_bridges):
        streak_row.append(f"{current_streak[i]}")
    results.insert(2, streak_row)

    # Recent Form
    recent_win_row = ["Phong ƒê·ªô 10 K·ª≥"]
    for i in range(num_bridges):
        recent_wins = 0
        periods = min(10, len(data_rows))
        for r_idx in range(periods):
            cell = str(data_rows[r_idx][i+1])
            if "ƒÇn" in cell: recent_wins += 1
        recent_win_row.append(f"{recent_wins}/10")
    results.insert(3, recent_win_row)

    # Prediction
    try:
        last_row = allData[finalEndRow - offset]
        finalRow = [f"K·ª≥ {int(last_row[0])+1}" if str(last_row[0]).isdigit() else "Next"]
        last_positions = getAllPositions_V17_Shadow(last_row)
        last_lotos = get_27_loto_positions(last_row)

        for j, bridge in enumerate(bridges_to_test):
            bridge_name = bridge.get("name", "")
            idx1, idx2 = bridge.get("pos1_idx"), bridge.get("pos2_idx")
            pred = []

            # 1. FIXED
            if "LO_STL_FIXED" in bridge_name:
                try:
                    num = int(bridge_name.split("_")[-1]) - 1
                    pred = ALL_15_BRIDGE_FUNCTIONS_V5[num](last_row)
                except: pass
            
            # 2. MEMORY
            elif idx1 == -1 and idx2 == -1:
                if "LO_MEM_SUM" in bridge_name:
                    p = bridge_name.split("_")
                    try: 
                        names = get_27_loto_names()
                        pred = calculate_bridge_stl(last_lotos[names.index(p[-2])], last_lotos[names.index(p[-1])], "sum")
                    except: pass
                elif "LO_MEM_DIFF" in bridge_name:
                    p = bridge_name.split("_")
                    try:
                        names = get_27_loto_names()
                        pred = calculate_bridge_stl(last_lotos[names.index(p[-2])], last_lotos[names.index(p[-1])], "diff")
                    except: pass
                
                # Fallback
                if not pred:
                    if "T·ªïng(" in bridge_name:
                        m = re.search(r'T·ªïng\((\d+)\+(\d+)\)', bridge_name)
                        if m: pred = calculate_bridge_stl(last_lotos[int(m.group(1))], last_lotos[int(m.group(2))], "sum")
                    elif "Hi·ªáu(" in bridge_name:
                        m = re.search(r'Hi·ªáu\((\d+)-(\d+)\)', bridge_name)
                        if m: pred = calculate_bridge_stl(last_lotos[int(m.group(1))], last_lotos[int(m.group(2))], "diff")

            # 3. V17
            elif idx1 is not None and idx2 is not None:
                a, b = last_positions[idx1], last_positions[idx2]
                if a is not None and b is not None: pred = taoSTL_V30_Bong(a, b)

            finalRow.append(f"{','.join(pred)}" if pred else "L·ªói")
        
        results.insert(4, finalRow)
    except: results.append(["L·ªói Prediction"])

    if history: results.extend(data_rows)
    return results

def BACKTEST_MANAGED_BRIDGES_K2N(
    toan_bo_A_I, ky_bat_dau_kiem_tra, ky_ket_thuc_kiem_tra, db_name=DB_NAME, history=True
):
    """
    Backtest K2N Managed Bridges.
    [FIXED] Fixed NameError 'loto_names' -> 'names'.
    """
    try:
        bridges_to_test = get_all_managed_bridges(db_name, only_enabled=True)
    except:
        return []
    if not bridges_to_test:
        return []

    # [FILTER] L·ªçc b·ªè C·∫ßu ƒê·ªÅ (DE_*)
    filtered_bridges = []
    for b in bridges_to_test:
        b_name = str(b.get("name", ""))
        b_type = str(b.get("type", ""))
        if not b_name.startswith("DE_") and not b_type.startswith("DE"):
            filtered_bridges.append(b)
    
    bridges_to_test = filtered_bridges
    if not bridges_to_test: return []

    allData, finalEndRow, startCheckRow, offset, error = _validate_backtest_params(
        toan_bo_A_I, ky_bat_dau_kiem_tra, ky_ket_thuc_kiem_tra
    )
    if error: return error

    num_bridges = len(bridges_to_test)
    headers = ["K·ª≥ (C·ªôt A)"] + [b['name'] for b in bridges_to_test]
    results = [headers]

    in_frame = [False] * num_bridges
    prediction_in_frame = [None] * num_bridges
    current_streak_k2n = [0] * num_bridges
    max_lose_streak_k2n = [0] * num_bridges
    current_lose_streak_k2n = [0] * num_bridges
    win_counts = [0] * num_bridges
    data_rows = []
    totalTestDays = 0

    for k in range(startCheckRow, finalEndRow + 1):
        prevRow_idx, actualRow_idx = k - 1 - offset, k - offset
        if actualRow_idx >= len(allData) or prevRow_idx < 0: continue
        prevRow, actualRow = allData[prevRow_idx], allData[actualRow_idx]
        if not actualRow or not actualRow[0]: break
        if not prevRow or len(actualRow) < 10: 
            data_rows.append([actualRow[0] or k, "L·ªói d·ªØ li·ªáu"] + [""] * num_bridges)
            continue

        actualSoKy, actualLotoSet = actualRow[0] or k, set(getAllLoto_V30(actualRow))
        prevPositions = getAllPositions_V17_Shadow(prevRow)
        prevLotos = get_27_loto_positions(prevRow)
        totalTestDays += 1
        daily_row = [actualSoKy]

        for j, bridge in enumerate(bridges_to_test):
            try:
                cell_output = ""
                # --- CHECK IN FRAME (N2) ---
                if in_frame[j]:
                    pred = prediction_in_frame[j]
                    check_result = checkHitSet_V30_K2N(pred, actualLotoSet)
                    if "‚úÖ" in check_result or "ƒÇn" in check_result:
                        cell_output = f"{','.join(pred)} ‚úÖ (ƒÇn N2)"
                        win_counts[j] += 1; current_streak_k2n[j] += 1; current_lose_streak_k2n[j] = 0
                    else:
                        cell_output = f"{','.join(pred)} ‚ùå (Tr∆∞·ª£t K2N)"
                        current_streak_k2n[j] = 0; current_lose_streak_k2n[j] += 1
                        if current_lose_streak_k2n[j] > max_lose_streak_k2n[j]: max_lose_streak_k2n[j] = current_lose_streak_k2n[j]
                    in_frame[j], prediction_in_frame[j] = False, None
                
                # --- NEW PREDICTION (N1) ---
                else:
                    idx1, idx2 = bridge["pos1_idx"], bridge["pos2_idx"]
                    pred = []
                    bridge_name = bridge.get("name", "")

                    # 1. FIXED
                    if "LO_STL_FIXED" in bridge_name:
                        try:
                            num = int(bridge_name.split("_")[-1]) - 1
                            pred = ALL_15_BRIDGE_FUNCTIONS_V5[num](prevRow)
                        except: pass
                    
                    # 2. MEMORY
                    elif idx1 == -1 and idx2 == -1:
                        if "LO_MEM_SUM" in bridge_name:
                            parts = bridge_name.split("_")
                            try:
                                l1, l2 = parts[-2], parts[-1]
                                names = get_27_loto_names()
                                if l1 in names and l2 in names:
                                    # [FIXED] Use names.index
                                    p1, p2 = names.index(l1), names.index(l2)
                                    loto1, loto2 = prevLotos[p1], prevLotos[p2]
                                    pred = calculate_bridge_stl(loto1, loto2, "sum")
                            except: pass
                        elif "LO_MEM_DIFF" in bridge_name:
                            parts = bridge_name.split("_")
                            try:
                                l1, l2 = parts[-2], parts[-1]
                                names = get_27_loto_names()
                                if l1 in names and l2 in names:
                                    # [FIXED] Use names.index
                                    p1, p2 = names.index(l1), names.index(l2)
                                    loto1, loto2 = prevLotos[p1], prevLotos[p2]
                                    pred = calculate_bridge_stl(loto1, loto2, "diff")
                            except: pass
                        
                        if not pred: # Fallback
                            if "T·ªïng(" in bridge_name:
                                m = re.search(r'T·ªïng\((\d+)\+(\d+)\)', bridge_name)
                                if m: pred = calculate_bridge_stl(prevLotos[int(m.group(1))], prevLotos[int(m.group(2))], "sum")
                            elif "Hi·ªáu(" in bridge_name:
                                m = re.search(r'Hi·ªáu\((\d+)-(\d+)\)', bridge_name)
                                if m: pred = calculate_bridge_stl(prevLotos[int(m.group(1))], prevLotos[int(m.group(2))], "diff")

                    # 3. V17
                    elif idx1 is not None and idx2 is not None:
                        a, b = prevPositions[idx1], prevPositions[idx2]
                        if a is not None and b is not None:
                            pred = taoSTL_V30_Bong(a, b)
                    
                    if not pred:
                        daily_row.append("Err"); continue

                    check_result = checkHitSet_V30_K2N(pred, actualLotoSet)
                    if "‚úÖ" in check_result or "ƒÇn" in check_result:
                        cell_output = f"{','.join(pred)} ‚úÖ (ƒÇn N1)"
                        win_counts[j] += 1; current_streak_k2n[j] += 1; current_lose_streak_k2n[j] = 0
                    else:
                        cell_output = f"{','.join(pred)} (Tr∆∞·ª£t N1...)"
                        in_frame[j], prediction_in_frame[j] = True, pred
                
                daily_row.append(cell_output)
            except: daily_row.append("Err")
        data_rows.append(daily_row)

    data_rows.reverse()
    
    rate_row = ["T·ª∑ L·ªá %"]
    if totalTestDays > 0:
        for c in win_counts: rate_row.append(f"{(c / totalTestDays) * 100:.2f}%")
    else: rate_row.extend(["0.00%"] * num_bridges)
    results.insert(1, rate_row)

    streak_row = ["Chu·ªói Th·∫Øng / Thua Max"]
    for i in range(num_bridges): streak_row.append(f"{current_streak_k2n[i]} th·∫Øng / {max_lose_streak_k2n[i]} thua")
    results.insert(2, streak_row)
    results.insert(3, ["Phong ƒê·ªô 10 K·ª≥"] + ["---"] * num_bridges)

    # Prediction
    try:
        last_row = allData[finalEndRow - offset]
        try:
            ky_int = int(last_row[0])
            finalRowK = f"K·ª≥ {ky_int + 1}"
        except (ValueError, TypeError):
            finalRowK = f"K·ª≥ {last_row[0]} (Next)"
        
        finalRow = [finalRowK]
        last_positions = getAllPositions_V17_Shadow(last_row)
        last_lotos = get_27_loto_positions(last_row)

        for j, bridge in enumerate(bridges_to_test):
            if in_frame[j]:
                finalRow.append(f"{','.join(prediction_in_frame[j])} (ƒêang ch·ªù N2)")
            else:
                idx1, idx2 = bridge["pos1_idx"], bridge["pos2_idx"]
                pred = []
                bridge_name = bridge.get("name", "")

                # 1. FIXED
                if "LO_STL_FIXED" in bridge_name:
                    try:
                        num = int(bridge_name.split("_")[-1]) - 1
                        pred = ALL_15_BRIDGE_FUNCTIONS_V5[num](last_row)
                    except: pass
                
                # 2. MEMORY
                elif idx1 == -1 and idx2 == -1:
                    if "LO_MEM_SUM" in bridge_name:
                        parts = bridge_name.split("_")
                        try:
                            l1, l2 = parts[-2], parts[-1]
                            names = get_27_loto_names()
                            if l1 in names and l2 in names:
                                pred = calculate_bridge_stl(
                                    last_lotos[names.index(l1)],
                                    last_lotos[names.index(l2)],
                                    "sum",
                                )
                        except: pass
                    elif "LO_MEM_DIFF" in bridge_name:
                        parts = bridge_name.split("_")
                        try:
                            l1, l2 = parts[-2], parts[-1]
                            names = get_27_loto_names()
                            if l1 in names and l2 in names:
                                pred = calculate_bridge_stl(
                                    last_lotos[names.index(l1)],
                                    last_lotos[names.index(l2)],
                                    "diff",
                                )
                        except: pass
                    
                    if not pred:
                        if "T·ªïng(" in bridge_name:
                            m = re.search(r'T·ªïng\((\d+)\+(\d+)\)', bridge_name)
                            if m:
                                pred = calculate_bridge_stl(
                                    last_lotos[int(m.group(1))],
                                    last_lotos[int(m.group(2))],
                                    "sum",
                                )
                        elif "Hi·ªáu(" in bridge_name:
                            m = re.search(r'Hi·ªáu\((\d+)-(\d+)\)', bridge_name)
                            if m:
                                pred = calculate_bridge_stl(
                                    last_lotos[int(m.group(1))],
                                    last_lotos[int(m.group(2))],
                                    "diff",
                                )
                else:
                    a, b = last_positions[idx1], last_positions[idx2]
                    if a is not None and b is not None:
                        pred = taoSTL_V30_Bong(a, b)
                
                finalRow.append(f"{','.join(pred)} (Khung m·ªõi N1)" if pred else "L·ªói")
        
        results.insert(4, finalRow)
    except:
        results.append(["L·ªói Prediction"])

    if history:
        results.extend(data_rows)
    return results

def BACKTEST_MEMORY_BRIDGES(toan_bo_A_I, ky_bat_dau_kiem_tra, ky_ket_thuc_kiem_tra):
    return []

--------------------------------------------------

=== FILE: logic\backtester_scoring.py ===
"""
backtester_scoring.py - Scoring functions for bridge evaluation

Extracted from backtester.py to improve maintainability.
Contains: Scoring algorithms for ranking bridges.
"""


def score_by_streak(rate, streak):
    """
    Score bridges prioritizing streak over rate.
    
    Args:
        rate: Win rate percentage
        streak: Win streak count
        
    Returns:
        float: Calculated score
    """
    return (streak * 1000) + (rate * 100)


def score_by_rate(rate, streak):
    """
    Score bridges prioritizing rate over streak.
    
    Args:
        rate: Win rate percentage
        streak: Win streak count
        
    Returns:
        float: Calculated score
    """
    return (rate * 1000) + (streak * 100)


--------------------------------------------------

=== FILE: logic\bridge_importer.py ===
# logic/bridge_importer.py
"""
Bridge Importer / Orchestrator for K1N-primary detection flow.

Handles importing bridge candidates with policy-based filtering and bulk DB operations.
"""

import time
from typing import List, Dict, Optional, Callable, Any

try:
    from logic.models import Candidate, ImportConfig, ScanResult
    from logic.db_manager import bulk_upsert_managed_bridges, get_all_managed_bridge_names, DB_NAME
    from logic.common_utils import normalize_bridge_name
    from logic.constants import DEFAULT_SETTINGS
except ImportError as e:
    print(f"[ERROR] Import failed in bridge_importer: {e}")
    raise


class BridgeImporter:
    """
    Service for importing bridge candidates with K1N-primary policy.
    
    Features:
    - Policy-based filtering (K1N-primary, K2N-primary, combined)
    - Preview mode (no DB writes)
    - Auto-import with pending/enabled states
    - Progress callback for UI integration
    - Atomic bulk operations
    
    Example:
        >>> config = ImportConfig(policy_type='k1n_primary', threshold_k1n_de=90.0)
        >>> importer = BridgeImporter(config)
        >>> result = importer.import_candidates(candidates)
        >>> print(f"Imported: {result['imported']}, Rejected: {result['rejected']}")
    """
    
    def __init__(
        self, 
        config: Optional[ImportConfig] = None,
        db_name: str = DB_NAME
    ):
        """
        Initialize bridge importer.
        
        Args:
            config: Import configuration (uses defaults if None)
            db_name: Database file path
        """
        self.config = config or self._create_default_config()
        self.db_name = db_name
        self.existing_names: Optional[set] = None
    
    def _create_default_config(self) -> ImportConfig:
        """Create default config from constants."""
        return ImportConfig(
            policy_type=DEFAULT_SETTINGS.get("POLICY_TYPE", "k1n_primary"),
            threshold_k1n_lo=DEFAULT_SETTINGS.get("THRESHOLD_K1N_LO", 85.0),
            threshold_k1n_de=DEFAULT_SETTINGS.get("THRESHOLD_K1N_DE", 90.0),
            threshold_k2n_lo=DEFAULT_SETTINGS.get("THRESHOLD_K2N_LO", 80.0),
            threshold_k2n_de=DEFAULT_SETTINGS.get("THRESHOLD_K2N_DE", 85.0),
            fallback_to_k2n=DEFAULT_SETTINGS.get("FALLBACK_TO_K2N", True),
            default_is_enabled=DEFAULT_SETTINGS.get("AUTO_IMPORT_DEFAULT_ENABLE", False),
            default_is_pending=DEFAULT_SETTINGS.get("AUTO_IMPORT_DEFAULT_PENDING", True),
        )
    
    def refresh_existing_names(self):
        """Load existing bridge names from database."""
        print("[INFO] Loading existing bridge names...")
        self.existing_names = get_all_managed_bridge_names(self.db_name)
        print(f"[INFO] Loaded {len(self.existing_names)} existing bridge names")
    
    def filter_candidates(
        self, 
        candidates: List[Candidate],
        progress_callback: Optional[Callable[[str, int, int], None]] = None
    ) -> Dict[str, List[Candidate]]:
        """
        Filter candidates based on policy and thresholds.
        
        Args:
            candidates: List of bridge candidates
            progress_callback: Optional callback(message, current, total)
            
        Returns:
            Dict with keys:
                - 'accepted': Candidates that pass policy
                - 'rejected': Candidates that fail policy
                - 'duplicates': Candidates already in DB
        """
        if self.existing_names is None:
            self.refresh_existing_names()
        
        result = {
            'accepted': [],
            'rejected': [],
            'duplicates': []
        }
        
        total = len(candidates)
        for idx, candidate in enumerate(candidates):
            if progress_callback:
                progress_callback(f"Filtering candidate {idx+1}/{total}", idx+1, total)
            
            # Check for duplicates
            if candidate.normalized_name in self.existing_names:
                result['duplicates'].append(candidate)
                continue
            
            # Apply policy
            if self.config.meets_threshold(candidate):
                result['accepted'].append(candidate)
                print(f"[INFO] ‚úì Accepted: {candidate.name} (K1N={candidate.get_primary_rate('k1n'):.1f}%)")
            else:
                result['rejected'].append(candidate)
                print(f"[INFO] ‚úó Rejected: {candidate.name} (K1N={candidate.get_primary_rate('k1n'):.1f}% < threshold)")
        
        print(f"[INFO] Filter result: {len(result['accepted'])} accepted, "
              f"{len(result['rejected'])} rejected, {len(result['duplicates'])} duplicates")
        
        return result
    
    def import_candidates(
        self,
        candidates: List[Candidate],
        progress_callback: Optional[Callable[[str, int, int], None]] = None,
        preview_only: bool = False
    ) -> Dict[str, Any]:
        """
        Import bridge candidates to database.
        
        Args:
            candidates: List of bridge candidates to import
            progress_callback: Optional callback for progress updates
            preview_only: If True, skip DB write (preview mode)
            
        Returns:
            Dict with import statistics and results:
                - 'imported': Number successfully imported
                - 'rejected': Number rejected by policy
                - 'duplicates': Number already in DB
                - 'errors': Number with errors
                - 'accepted_list': List of accepted candidates
                - 'rejected_list': List of rejected candidates
                - 'duplicate_list': List of duplicate candidates
        """
        start_time = time.time()
        
        print(f"[INFO] Starting import of {len(candidates)} candidates...")
        print(f"[INFO] Policy: {self.config.policy_type}, Preview: {preview_only}")
        
        # Filter candidates
        filter_result = self.filter_candidates(candidates, progress_callback)
        
        accepted = filter_result['accepted']
        rejected = filter_result['rejected']
        duplicates = filter_result['duplicates']
        
        # Prepare import result
        result = {
            'imported': 0,
            'rejected': len(rejected),
            'duplicates': len(duplicates),
            'errors': 0,
            'accepted_list': accepted,
            'rejected_list': rejected,
            'duplicate_list': duplicates,
            'duration': 0.0
        }
        
        # Preview mode - skip DB write
        if preview_only or self.config.preview_only:
            print(f"[INFO] Preview mode - skipping DB write")
            result['duration'] = time.time() - start_time
            return result
        
        # Prepare bridges for bulk upsert
        bridges_to_import = []
        for candidate in accepted:
            bridge_dict = candidate.to_dict()
            
            # Apply config defaults
            if self.config.auto_approve:
                bridge_dict['is_pending'] = 0
                bridge_dict['is_enabled'] = 1
            else:
                bridge_dict['is_pending'] = 1 if self.config.default_is_pending else 0
                bridge_dict['is_enabled'] = 1 if self.config.default_is_enabled else 0
            
            bridges_to_import.append(bridge_dict)
        
        # Bulk import to DB
        if bridges_to_import:
            print(f"[INFO] Bulk importing {len(bridges_to_import)} bridges...")
            
            try:
                db_stats = bulk_upsert_managed_bridges(
                    bridges_to_import,
                    db_name=self.db_name,
                    transactional=True
                )
                
                result['imported'] = db_stats['added'] + db_stats['updated']
                result['errors'] = db_stats['errors']
                
                print(f"[INFO] Import complete: {result['imported']} imported, {result['errors']} errors")
                
            except Exception as e:
                print(f"[ERROR] Bulk import failed: {e}")
                result['errors'] = len(bridges_to_import)
        
        result['duration'] = time.time() - start_time
        return result
    
    def preview_import(
        self,
        candidates: List[Candidate],
        progress_callback: Optional[Callable[[str, int, int], None]] = None
    ) -> Dict[str, Any]:
        """
        Preview import without writing to database.
        
        Args:
            candidates: List of bridge candidates
            progress_callback: Optional callback for progress updates
            
        Returns:
            Preview result dictionary (same as import_candidates but no DB write)
        """
        return self.import_candidates(candidates, progress_callback, preview_only=True)
    
    def get_import_summary(self, result: Dict[str, Any]) -> str:
        """
        Get human-readable import summary.
        
        Args:
            result: Import result dictionary
            
        Returns:
            Summary string
        """
        summary_lines = [
            f"Import Summary:",
            f"  ‚úì Imported: {result['imported']}",
            f"  ‚úó Rejected: {result['rejected']} (below threshold)",
            f"  ‚äú Duplicates: {result['duplicates']} (already in DB)",
            f"  ‚ö† Errors: {result['errors']}",
            f"  ‚è± Duration: {result['duration']:.2f}s"
        ]
        return "\n".join(summary_lines)


def create_importer_from_settings(settings_dict: Optional[Dict[str, Any]] = None) -> BridgeImporter:
    """
    Factory function to create importer from settings dictionary.
    
    Args:
        settings_dict: Settings dictionary (uses DEFAULT_SETTINGS if None)
        
    Returns:
        Configured BridgeImporter instance
    """
    if settings_dict is None:
        settings_dict = DEFAULT_SETTINGS
    
    config = ImportConfig(
        policy_type=settings_dict.get("POLICY_TYPE", "k1n_primary"),
        threshold_k1n_lo=settings_dict.get("THRESHOLD_K1N_LO", 85.0),
        threshold_k1n_de=settings_dict.get("THRESHOLD_K1N_DE", 90.0),
        threshold_k2n_lo=settings_dict.get("THRESHOLD_K2N_LO", 80.0),
        threshold_k2n_de=settings_dict.get("THRESHOLD_K2N_DE", 85.0),
        fallback_to_k2n=settings_dict.get("FALLBACK_TO_K2N", True),
        default_is_enabled=settings_dict.get("AUTO_IMPORT_DEFAULT_ENABLE", False),
        default_is_pending=settings_dict.get("AUTO_IMPORT_DEFAULT_PENDING", True),
    )
    
    return BridgeImporter(config)


--------------------------------------------------

=== FILE: logic\common_utils.py ===
"""
logic/common_utils.py

Common utility functions used across multiple modules.
Contains: validation helpers, date/time utilities, shared helper functions.

Created during Phase 1 refactoring to reduce code duplication.
V11.2: Enhanced with retry decorator and timestamp helpers for K1N-primary flow.
"""

import re
import time
import functools
import sqlite3
from datetime import datetime
from typing import Any, List, Optional, Tuple, Callable


# =============================================================================
# VALIDATION UTILITIES
# =============================================================================

def is_valid_loto(loto: str) -> bool:
    """
    Validate if a string is a valid 2-digit loto number.

    Args:
        loto: String to validate

    Returns:
        True if valid loto (2 digits, 00-99), False otherwise

    Examples:
        >>> is_valid_loto("05")
        True
        >>> is_valid_loto("99")
        True
        >>> is_valid_loto("123")
        False
        >>> is_valid_loto("ab")
        False
    """
    if not isinstance(loto, str):
        return False
    return bool(re.match(r'^\d{2}$', loto))


def is_valid_ky(ky: Any) -> bool:
    """
    Validate if a value is a valid ky (period) number.

    Args:
        ky: Value to validate (can be string or int)

    Returns:
        True if valid ky (positive integer), False otherwise

    Examples:
        >>> is_valid_ky(1)
        True
        >>> is_valid_ky("123")
        True
        >>> is_valid_ky(0)
        False
        >>> is_valid_ky(-5)
        False
        >>> is_valid_ky("abc")
        False
    """
    try:
        ky_int = int(ky)
        return ky_int > 0
    except (ValueError, TypeError):
        return False


def validate_row_range(start_row: int, end_row: int, data_length: int) -> Tuple[bool, Optional[str]]:
    """
    Validate backtest row range parameters.

    Args:
        start_row: Starting row index (1-based)
        end_row: Ending row index (1-based)
        data_length: Total length of data

    Returns:
        Tuple of (is_valid, error_message)
        If valid: (True, None)
        If invalid: (False, error_message)

    Examples:
        >>> validate_row_range(1, 10, 20)
        (True, None)
        >>> validate_row_range(10, 5, 20)
        (False, "Start row must be less than or equal to end row")
        >>> validate_row_range(0, 10, 20)
        (False, "Start row must be greater than 0")
    """
    if start_row <= 0:
        return False, "Start row must be greater than 0"

    if start_row > end_row:
        return False, "Start row must be less than or equal to end row"

    if end_row > data_length:
        return False, f"End row ({end_row}) exceeds data length ({data_length})"

    if start_row > data_length:
        return False, f"Start row ({start_row}) exceeds data length ({data_length})"

    return True, None


def validate_backtest_params(toan_bo_A_I: List, ky_bat_dau_kiem_tra: Any, ky_ket_thuc_kiem_tra: Any) -> Tuple[Optional[List], Optional[int], Optional[int], Optional[int], Optional[List]]:
    """
    Validate backtest parameters and return processed values.
    (Moved from backtester_helpers.py)

    Args:
        toan_bo_A_I: Complete data list
        ky_bat_dau_kiem_tra: Starting period for testing
        ky_ket_thuc_kiem_tra: Ending period for testing

    Returns:
        tuple: (allData, finalEndRow, startCheckRow, offset, error_list)
               If error_list is not None, other values will be None.
    """
    if not all([toan_bo_A_I, ky_bat_dau_kiem_tra, ky_ket_thuc_kiem_tra]):
        return None, None, None, None, [["L·ªñI:", "C·∫ßn ƒë·ªß tham s·ªë."]]

    try:
        startRow, endRow = int(ky_bat_dau_kiem_tra), int(ky_ket_thuc_kiem_tra)
    except ValueError:
        return None, None, None, None, [["L·ªñI:", "K·ª≥ Bƒê/KT ph·∫£i l√† s·ªë."]]

    if not (startRow > 1 and startRow <= endRow):
        return None, None, None, None, [["L·ªñI:", "K·ª≥ Bƒê/KT kh√¥ng h·ª£p l·ªá."]]

    allData = toan_bo_A_I
    finalEndRow = min(endRow, len(allData) + startRow - 1)
    startCheckRow = startRow + 1

    if startCheckRow > finalEndRow:
        return None, None, None, None, [["L·ªñI:", "D·ªØ li·ªáu kh√¥ng ƒë·ªß ƒë·ªÉ ch·∫°y."]]

    offset = startRow
    return allData, finalEndRow, startCheckRow, offset, None


# =============================================================================
# DATE/TIME UTILITIES
# =============================================================================

def parse_date_string(date_str: str, default_year: Optional[int] = None) -> Optional[datetime]:
    """
    Parse date string from multiple formats.

    Supports:
    - DD/MM/YYYY (Vietnamese format)
    - DD-MM-YYYY
    - DD-MM HH:MM:SS (with auto year)

    Args:
        date_str: Date string to parse
        default_year: Year to use if not in string (defaults to current year)

    Returns:
        datetime object if successful, None if failed

    Examples:
        >>> parse_date_string("25/12/2024")
        datetime.datetime(2024, 12, 25, 0, 0)
        >>> parse_date_string("25-12-2024")
        datetime.datetime(2024, 12, 25, 0, 0)
    """
    if not date_str:
        return None

    date_str = str(date_str).strip()
    if default_year is None:
        default_year = datetime.now().year

    # Try format 1: DD/MM/YYYY
    try:
        return datetime.strptime(date_str, "%d/%m/%Y")
    except ValueError:
        pass

    # Try format 2: DD-MM-YYYY
    try:
        return datetime.strptime(date_str, "%d-%m-%Y")
    except ValueError:
        pass

    # Try format 3: DD-MM HH:MM:SS (partial date)
    try:
        partial_date = date_str.split(" ")[0]  # Get "DD-MM"
        full_date_str = f"{partial_date}-{default_year}"
        return datetime.strptime(full_date_str, "%d-%m-%Y")
    except ValueError:
        pass

    # Try format 4: MM-DD-YYYY (alternative)
    try:
        partial_date = date_str.split(" ")[0]
        full_date_str = f"{partial_date}-{default_year}"
        return datetime.strptime(full_date_str, "%m-%d-%Y")
    except ValueError:
        pass

    return None


def format_date_sql(dt: datetime) -> str:
    """
    Format datetime object to SQL date format (YYYY-MM-DD).

    Args:
        dt: datetime object

    Returns:
        Date string in SQL format

    Examples:
        >>> format_date_sql(datetime(2024, 12, 25))
        '2024-12-25'
    """
    return dt.strftime("%Y-%m-%d")


# =============================================================================
# DATA STRUCTURE UTILITIES
# =============================================================================

def safe_get_list_item(lst: List, index: int, default: Any = None) -> Any:
    """
    Safely get item from list with default value.

    Args:
        lst: List to get item from
        index: Index to access
        default: Default value if index out of range

    Returns:
        Item at index or default value

    Examples:
        >>> safe_get_list_item([1, 2, 3], 1)
        2
        >>> safe_get_list_item([1, 2, 3], 5, default=0)
        0
    """
    try:
        return lst[index] if 0 <= index < len(lst) else default
    except (IndexError, TypeError):
        return default


def clean_stl_string(stl_text: str) -> str:
    """
    Clean STL (Soi Tr√°nh L√¥) string by removing annotations.

    Removes parentheses content like "(N1)", "(N2)", etc.

    Args:
        stl_text: STL string to clean

    Returns:
        Cleaned STL string

    Examples:
        >>> clean_stl_string("12-34 (N1)")
        '12-34'
        >>> clean_stl_string("05-06")
        '05-06'
    """
    if not stl_text:
        return ""

    stl_text = str(stl_text).strip()
    if "(" in stl_text:
        return stl_text.split("(")[0].strip()
    return stl_text


# =============================================================================
# STRING UTILITIES
# =============================================================================

def normalize_bridge_name(name: str) -> str:
    """
    Normalize bridge name for comparison and storage.

    - Strips whitespace
    - Converts to lowercase
    - Removes special characters and Vietnamese diacritics
    - Normalizes to ASCII-safe form

    Args:
        name: Bridge name to normalize

    Returns:
        Normalized bridge name (ASCII-safe)

    Examples:
        >>> normalize_bridge_name("  Bridge 1  ")
        'bridge1'
        >>> normalize_bridge_name("C·∫ßu-ƒê·∫πp")
        'caudep'
    """
    if not name:
        return ""

    import unicodedata
    
    name = str(name).strip().lower()
    
    # Vietnamese character mapping to ASCII
    vietnamese_map = {
        '√†': 'a', '√°': 'a', '·∫£': 'a', '√£': 'a', '·∫°': 'a',
        'ƒÉ': 'a', '·∫±': 'a', '·∫Ø': 'a', '·∫≥': 'a', '·∫µ': 'a', '·∫∑': 'a',
        '√¢': 'a', '·∫ß': 'a', '·∫•': 'a', '·∫©': 'a', '·∫´': 'a', '·∫≠': 'a',
        'ƒë': 'd',
        '√®': 'e', '√©': 'e', '·∫ª': 'e', '·∫Ω': 'e', '·∫π': 'e',
        '√™': 'e', '·ªÅ': 'e', '·∫ø': 'e', '·ªÉ': 'e', '·ªÖ': 'e', '·ªá': 'e',
        '√¨': 'i', '√≠': 'i', '·ªâ': 'i', 'ƒ©': 'i', '·ªã': 'i',
        '√≤': 'o', '√≥': 'o', '·ªè': 'o', '√µ': 'o', '·ªç': 'o',
        '√¥': 'o', '·ªì': 'o', '·ªë': 'o', '·ªï': 'o', '·ªó': 'o', '·ªô': 'o',
        '∆°': 'o', '·ªù': 'o', '·ªõ': 'o', '·ªü': 'o', '·ª°': 'o', '·ª£': 'o',
        '√π': 'u', '√∫': 'u', '·ªß': 'u', '≈©': 'u', '·ª•': 'u',
        '∆∞': 'u', '·ª´': 'u', '·ª©': 'u', '·ª≠': 'u', '·ªØ': 'u', '·ª±': 'u',
        '·ª≥': 'y', '√Ω': 'y', '·ª∑': 'y', '·ªπ': 'y', '·ªµ': 'y'
    }
    
    # Replace Vietnamese characters
    for viet_char, ascii_char in vietnamese_map.items():
        name = name.replace(viet_char, ascii_char)
    
    # Normalize Unicode and remove remaining diacritics
    name = unicodedata.normalize('NFD', name)
    name = ''.join(char for char in name if unicodedata.category(char) != 'Mn')
    
    # Remove all non-alphanumeric characters
    # Note: This removes spaces, hyphens, underscores, and special characters
    # to create an ASCII-safe identifier for duplicate checking
    name = re.sub(r'[^a-z0-9]', '', name)
    return name


# =============================================================================
# RETRY DECORATOR (V11.2)
# =============================================================================

def retry_on_db_lock(max_retries: int = 3, initial_delay: float = 0.1):
    """
    Decorator to retry database operations on sqlite3.OperationalError.
    
    Uses exponential backoff for retries.
    
    Args:
        max_retries: Maximum number of retry attempts
        initial_delay: Initial delay in seconds (doubles each retry)
        
    Example:
        >>> @retry_on_db_lock(max_retries=3)
        ... def my_db_operation():
        ...     # Database code here
        ...     pass
    """
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            delay = initial_delay
            last_exception = None
            
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except sqlite3.OperationalError as e:
                    last_exception = e
                    if "locked" in str(e).lower() and attempt < max_retries - 1:
                        print(f"[WARN] Database locked, retrying in {delay}s... (attempt {attempt+1}/{max_retries})")
                        time.sleep(delay)
                        delay *= 2  # Exponential backoff
                    else:
                        raise
                except Exception:
                    raise
            
            # If we get here, all retries failed
            raise last_exception
        
        return wrapper
    return decorator


# =============================================================================
# TIMESTAMP HELPERS (V11.2)
# =============================================================================

def get_current_timestamp() -> str:
    """
    Get current timestamp in SQL format.
    
    Returns:
        Timestamp string in format 'YYYY-MM-DD HH:MM:SS'
        
    Example:
        >>> get_current_timestamp()
        '2024-12-09 15:30:45'
    """
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


def get_current_date() -> str:
    """
    Get current date in SQL format.
    
    Returns:
        Date string in format 'YYYY-MM-DD'
        
    Example:
        >>> get_current_date()
        '2024-12-09'
    """
    return datetime.now().strftime("%Y-%m-%d")

# [APPEND v√†o logic/common_utils.py]

def calculate_strict_performance(results_recent_to_past: list) -> dict:
    """
    T√≠nh to√°n ch·ªâ s·ªë hi·ªáu su·∫•t v·ªõi ch·∫ø ƒë·ªô Strict Streak (D·ª´ng khi g·∫∑p g√£y).
    Input: List bool [H√¥m nay, H√¥m qua, H√¥m kia...] (M·ªõi -> C≈©)
    """
    streak = 0
    total_wins = 0
    is_broken = False
    total_days = len(results_recent_to_past)
    
    for is_win in results_recent_to_past:
        if is_win:
            total_wins += 1
            if not is_broken:
                streak += 1
        else:
            is_broken = True
            
    # T√≠nh wins trong 10 ng√†y g·∫ßn nh·∫•t
    wins_10 = sum(1 for x in results_recent_to_past[:10] if x)
    win_rate = (total_wins / total_days * 100) if total_days > 0 else 0.0
    
    return {
        "streak": streak,
        "total_wins": total_wins,
        "win_rate": win_rate,
        "wins_10": wins_10
    }

--------------------------------------------------

=== FILE: logic\config_manager.py ===
# T√™n file: git1/logic/config_manager.py
import json
import os
import threading
import traceback

# Import ngu·ªìn ch√¢n l√Ω (Source of Truth)
try:
    from logic.constants import DEFAULT_SETTINGS
except ImportError:
    print("C·∫£nh b√°o: Kh√¥ng th·ªÉ import logic.constants. S·ª≠ d·ª•ng Fallback n·ªôi b·ªô.")
    # Fallback t·ªëi thi·ªÉu n·∫øu m·∫•t file constants
    DEFAULT_SETTINGS = {
        "STATS_DAYS": 7,
        "GAN_DAYS": 15,
        "HIGH_WIN_THRESHOLD": 47.0,
        "AUTO_ADD_MIN_RATE": 50.0,
        "AUTO_PRUNE_MIN_RATE": 40.0,
        "K2N_RISK_START_THRESHOLD": 4,
        "K2N_RISK_PENALTY_PER_FRAME": 0.5,
        "AI_PROB_THRESHOLD": 45.0,
        "AI_MAX_DEPTH": 6,
        "AI_N_ESTIMATORS": 200,
        "AI_LEARNING_RATE": 0.05,
        "AI_OBJECTIVE": "binary:logistic",
        "AI_SCORE_WEIGHT": 0.2,
        "RECENT_FORM_PERIODS": 10,
        "RECENT_FORM_BONUS_HIGH": 3.0,
        "RECENT_FORM_BONUS_MED": 2.0,
        "RECENT_FORM_BONUS_LOW": 1.0,
        "RECENT_FORM_MIN_HIGH": 8,
        "RECENT_FORM_MIN_MED": 6,
        "RECENT_FORM_MIN_LOW": 5,
        "DATA_LIMIT_DASHBOARD": 2000,
        "DATA_LIMIT_RESEARCH": 0,
        "DE_MAX_LOSE_THRESHOLD": 20,  # Ng∆∞·ª°ng chu·ªói G√£y t·ªëi ƒëa cho c·∫ßu ƒê·ªÅ (Phase 4 - Pruning)
        "MANAGER_RATE_MODE": "K1N"  # Ch·∫ø ƒë·ªô backtest cho T·ª∑ l·ªá c·∫ßu trong Manager (K1N/K2N)
    }

CONFIG_FILE = "config.json"

class ConfigManager:
    _instance = None
    _lock = threading.Lock()

    def __new__(cls, *args, **kwargs):
        with cls._lock:
            if cls._instance is None:
                cls._instance = super(ConfigManager, cls).__new__(cls)
                cls._instance._initialized = False
            return cls._instance

    def __init__(self):
        if self._initialized:
            return
            
        self.config_file = CONFIG_FILE
        # 1. Kh·ªüi t·∫°o b·∫±ng gi√° tr·ªã m·∫∑c ƒë·ªãnh chu·∫©n (t·ª´ constants.py)
        self.settings = DEFAULT_SETTINGS.copy()
        
        # 2. T·∫£i gi√° tr·ªã ng∆∞·ªùi d√πng ƒë√£ l∆∞u (ghi ƒë√® l√™n m·∫∑c ƒë·ªãnh)
        self.load_settings()
        
        self._initialized = True

    def load_settings(self):
        """T·∫£i c√†i ƒë·∫∑t t·ª´ file JSON, merge v·ªõi m·∫∑c ƒë·ªãnh."""
        if os.path.exists(self.config_file):
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    user_settings = json.load(f)
                    
                # Merge settings: Ch·ªâ ghi ƒë√® nh·ªØng key c√≥ trong user_settings
                for key, value in user_settings.items():
                    self.settings[key] = value
                
                print(f"ƒê√£ t·∫£i c√†i ƒë·∫∑t t·ª´ {self.config_file}")
            except Exception as e:
                print(f"L·ªói t·∫£i config: {e}. S·ª≠ d·ª•ng m·∫∑c ƒë·ªãnh.")
        else:
            print(f"Ch∆∞a c√≥ file {self.config_file}, s·∫Ω t·∫°o m·ªõi khi l∆∞u.")
        
        # C·∫≠p nh·∫≠t attribute access (ƒë·ªÉ d√πng SETTINGS.KEY)
        self._update_attributes()

    def _update_attributes(self):
        """G√°n c√°c gi√° tr·ªã trong dict settings th√†nh thu·ªôc t√≠nh c·ªßa object."""
        for key, value in self.settings.items():
            setattr(self, key, value)

    def get(self, key, default=None):
        return self.settings.get(key, default)

    def get_all_settings(self):
        return self.settings.copy()

    def update_setting(self, key, value):
        """C·∫≠p nh·∫≠t m·ªôt c√†i ƒë·∫∑t (ch∆∞a l∆∞u file)."""
        try:
            # Validate ki·ªÉu d·ªØ li·ªáu n·∫øu key c√≥ trong DEFAULT
            if key in DEFAULT_SETTINGS:
                default_val = DEFAULT_SETTINGS[key]
                default_type = type(default_val)
                
                if type(value) != default_type:
                    try:
                        if default_type == int: value = int(value)
                        elif default_type == float: value = float(value)
                        elif default_type == bool: value = bool(value)
                        elif default_type == str: value = str(value)
                    except:
                        pass 

            self.settings[key] = value
            setattr(self, key, value)
            
            return self.save_settings()
        except Exception as e:
            return False, str(e)

    def save_settings(self):
        """Ghi c√†i ƒë·∫∑t hi·ªán t·∫°i xu·ªëng file JSON."""
        try:
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(self.settings, f, indent=4)
            return True, "ƒê√£ l∆∞u c√†i ƒë·∫∑t."
        except Exception as e:
            print(traceback.format_exc())
            return False, f"L·ªói ghi file: {e}"

    def reset_to_defaults(self):
        """Kh√¥i ph·ª•c v·ªÅ m·∫∑c ƒë·ªãnh ban ƒë·∫ßu."""
        self.settings = DEFAULT_SETTINGS.copy()
        self._update_attributes()
        self.save_settings()

# --- Kh·ªüi t·∫°o Singleton (C√ì FALLBACK AN TO√ÄN) ---
try:
    SETTINGS = ConfigManager()
    print("ConfigManager (V7.8) ƒë√£ kh·ªüi t·∫°o th√†nh c√¥ng.")
except Exception as e:
    print(f"L·ªñI NGHI√äM TR·ªåNG khi kh·ªüi t·∫°o ConfigManager: {e}")
    
    # Fallback th√¥ng minh: T·ª± ƒë·ªông t·∫°o object t·ª´ DEFAULT_SETTINGS
    # Gi√∫p app kh√¥ng b·ªã crash v√† v·∫´n c√≥ ƒë·ªß tham s·ªë m·ªõi nh·∫•t
    class FallbackSettings:
        def __init__(self):
            self.settings = DEFAULT_SETTINGS.copy()
            for k, v in self.settings.items():
                setattr(self, k, v)
        
        def get_all_settings(self):
            return self.settings
            
        def update_setting(self, key, value):
            return False, "Ch·∫ø ƒë·ªô Fallback (Kh√¥ng th·ªÉ l∆∞u)"
            
        def save_settings(self):
            return False, "Ch·∫ø ƒë·ªô Fallback (L·ªói h·ªá th·ªëng)"
            
        def get(self, key, default=None):
            return self.settings.get(key, default)

    SETTINGS = FallbackSettings()
    print("-> ƒê√£ k√≠ch ho·∫°t ch·∫ø ƒë·ªô Fallback Settings (S·ª≠ d·ª•ng Default).")

--------------------------------------------------

=== FILE: logic\constants.py ===
# logic/constants.py
"""
Central location for all default settings and constants.
This file provides a single source of truth for configuration values.
"""

# Default Configuration Settings
DEFAULT_SETTINGS = {
    "STATS_DAYS": 7,
    "GAN_DAYS": 15,
    "HIGH_WIN_THRESHOLD": 47.0,
    "AUTO_ADD_MIN_RATE": 50.0,
    "AUTO_PRUNE_MIN_RATE": 40.0,
    "K2N_RISK_START_THRESHOLD": 4,
    "K2N_RISK_PENALTY_PER_FRAME": 0.5,
    "AI_PROB_THRESHOLD": 45.0,
    "AI_MAX_DEPTH": 6,
    "AI_N_ESTIMATORS": 200,
    "AI_LEARNING_RATE": 0.05,
    "AI_OBJECTIVE": "binary:logistic",
    "AI_SCORE_WEIGHT": 0.2,
    "RECENT_FORM_PERIODS": 10,
    "RECENT_FORM_BONUS_HIGH": 3.0,
    "RECENT_FORM_BONUS_MED": 2.0,
    "RECENT_FORM_BONUS_LOW": 1.0,
    "RECENT_FORM_MIN_HIGH": 8,
    "RECENT_FORM_MIN_MED": 6,
    "RECENT_FORM_MIN_LOW": 5,
    "DATA_LIMIT_DASHBOARD": 1000, # 0 = All
    "DATA_LIMIT_RESEARCH": 0,     # 0 = All
    "DATA_LIMIT_SCANNER": 500,    # Gi·ªõi h·∫°n s·ªë k·ª≥ khi D√≤ C·∫ßu M·ªõi (0 = Full)
    "DE_MAX_LOSE_THRESHOLD": 20,  # Ng∆∞·ª°ng chu·ªói G√£y t·ªëi ƒëa cho c·∫ßu ƒê·ªÅ (Phase 4 - Pruning)
    
    # [NEW V10.5] Dan 65 Optimization Configuration
    "DAN65_TOP_SETS_COUNT": 5,        # S·ªë l∆∞·ª£ng b·ªô top ∆∞u ti√™n (default: 5)
    "DAN65_MIN_PER_TOP_SET": 1,       # S·ªë t·ªëi thi·ªÉu t·ª´ m·ªói b·ªô top (1-4, default: 1)
    "DAN65_SIZE": 65,                  # K√≠ch th∆∞·ªõc d√†n cu·ªëi c√πng (default: 65)
    "DAN65_LOG_EXCLUDED_THRESHOLD": 30.0,  # Log s·ªë b·ªã lo·∫°i n·∫øu ƒëi·ªÉm >= ng∆∞·ª°ng n√†y
    
    # [NEW V10.7] DE Bridge Filtering & Control Configuration
    "ENABLE_DE_BRIDGES": True,         # Master switch for all DE bridges
    "ENABLE_DE_LO": True,              # Enable LO bridges scanning/display
    "ENABLE_DE_DE": True,              # Enable DE bridges scanning/display
    
    # DE_DYN Filtering (V10.7)
    "DE_DYN_MIN_WINRATE": 93.3,       # Minimum win rate for DE_DYN (28/30 = 93.3%)
    "DE_DYN_MAX_COUNT": 10,            # Maximum DE_DYN bridges to save
    
    # DE Visibility Policy (V11.0 - Hysteresis)
    "DE_WINDOW_KYS": 30,               # Window size for DE metrics (last N periods)
    "DE_DYN_ENABLE_RAW": 28,           # Enable threshold: wins >= 28 out of 30
    "DE_DYN_DISABLE_RAW": 26,          # Disable threshold: wins <= 26 out of 30
    
    # DE_KILLER Filtering (V10.7)
    "DE_KILLER_MAX_COUNT": 0,          # Maximum DE_KILLER bridges (0 = disabled)
    
    # DE_SET Priority (V10.7)
    "DE_SET_MIN_COUNT": 2,             # Minimum DE_SET bridges to guarantee
    
    # K2N Cache Control (V10.7)
    "K2N_CACHE_LO_ENABLED": True,      # Enable K2N cache refresh for LO bridges
    "K2N_CACHE_DE_ENABLED": True,      # Enable K2N cache refresh for DE bridges
    
    # Manager Rate Mode
    "MANAGER_RATE_MODE": "K1N",        # Backtest mode for bridge rate calculation (K1N/K2N)
    
    # [NEW V11.2] K1N-Primary Detection Flow Configuration
    "THRESHOLD_K1N_LO": 85.0,          # K1N threshold for LO bridges (%)
    "THRESHOLD_K1N_DE": 90.0,          # K1N threshold for DE bridges (%)
    "THRESHOLD_K2N_LO": 80.0,          # K2N threshold for LO bridges (%)
    "THRESHOLD_K2N_DE": 85.0,          # K2N threshold for DE bridges (%)
    "POLICY_TYPE": "k1n_primary",      # Import policy: 'k1n_primary', 'k2n_primary', 'combined'
    "FALLBACK_TO_K2N": True,           # Fallback to K2N when K1N is missing
    "AUTO_IMPORT_DEFAULT_ENABLE": False,   # Default enabled state for auto-imported bridges
    "AUTO_IMPORT_DEFAULT_PENDING": True,   # Default pending state for auto-imported bridges
    
    # Combined policy weights (when POLICY_TYPE='combined')
    "WEIGHT_K1N": 0.6,                 # Weight for K1N in combined score
    "WEIGHT_K2N": 0.4,                 # Weight for K2N in combined score
}

# Database Paths
DB_PATH = "data/xo_so_prizes_all_logic.db"

# Machine Learning Model Paths
MODEL_PATH = "logic/ml_model_files/loto_model.joblib"
SCALER_PATH = "logic/ml_model_files/ai_scaler.joblib"

# Lottery Constants
ALL_LOTOS = [str(i).zfill(2) for i in range(100)]
MIN_DATA_TO_TRAIN = 50

# File Upload Limits
MAX_FILE_SIZE_MB = 10
MAX_FILE_SIZE_BYTES = MAX_FILE_SIZE_MB * 1024 * 1024
MAX_LINES = 100_000

# Allowed File Extensions
ALLOWED_FILE_EXTENSIONS = ['.txt', '.json']

# [NEW V3.8] SCORING ENGINE WEIGHTS (T·ªêI ∆ØU H√ìA ƒêI·ªÇM S·ªê)
SCORING_WEIGHTS = {
    # --- L√î SCORING ---
    'LO_STREAK_MULTIPLIER': 1.0,      # H·ªá s·ªë nh√¢n cho chu·ªói th√¥ng (Attack)
    'LO_WINRATE_DIVISOR': 20.0,       # H·ªá s·ªë chia cho WinRate (Attack) -> 100% / 20 = 5 ƒëi·ªÉm
    'LO_MEMORY_DIVISOR': 10.0,        # H·ªá s·ªë chia cho Confidence B·∫°c nh·ªõ
    
    # Ph·∫°t L√¥ Gan (Defense)
    'LO_GAN_PENALTY_LOW': 2.0,        # Gan > 10 ng√†y
    'LO_GAN_PENALTY_MED': 5.0,        # Gan > 15 ng√†y
    'LO_GAN_PENALTY_HIGH': 15.0,      # Gan > 25 ng√†y (S√°t th·ªß)
    
    # Th∆∞·ªüng T·∫ßn Su·∫•t (Bonus)
    'LO_FREQ_BONUS_MAX': 3.0,         # ƒêi·ªÉm th∆∞·ªüng t·ªëi ƒëa cho L√¥ v·ªÅ nhi·ªÅu

    # --- ƒê·ªÄ SCORING ---
    'DE_SET_MULTIPLIER': 2.0,         # H·ªá s·ªë nh√¢n cho C·∫ßu B·ªô (∆Øu ti√™n cao nh·∫•t)
    'DE_NORMAL_MULTIPLIER': 1.0,      # H·ªá s·ªë nh√¢n cho C·∫ßu Ch·∫°m/T·ªïng
    
    # Ph·∫°t C·∫ßu Lo·∫°i (Killer)
    'DE_KILLER_MULTIPLIER': 3.0,      # H·ªá s·ªë ph·∫°t c·ª±c n·∫∑ng ƒë·ªÉ lo·∫°i s·ªë
    
    # Th∆∞·ªüng Th·ªã Tr∆∞·ªùng
    'DE_MARKET_CHAM_BONUS': 2.0,      # Max bonus cho Ch·∫°m Hot
    'DE_MARKET_BO_BONUS': 1.0,        # Max bonus cho B·ªô Hot
}

--------------------------------------------------

=== FILE: logic\dashboard_analytics.py ===
# T√™n file: logic/dashboard_analytics.py
# (PHASE 1 & 2 REFACTORING - WRAPPER MODULE)
# Logic ƒë√£ ƒë∆∞·ª£c di chuy·ªÉn sang logic/analytics/dashboard_scorer.py
# File n√†y gi·ªØ l·∫°i ƒë·ªÉ t∆∞∆°ng th√≠ch ng∆∞·ª£c v·ªõi code c≈©

"""
Wrapper module ƒë·ªÉ t∆∞∆°ng th√≠ch ng∆∞·ª£c.
To√†n b·ªô logic ƒë√£ ƒë∆∞·ª£c di chuy·ªÉn sang logic.analytics.dashboard_scorer.
"""

# Import data repository for new function
try:
    from logic.data_repository import get_all_managed_bridges
except ImportError:
    def get_all_managed_bridges(*args, **kwargs): return []

# Import constants for threshold
try:
    from logic.constants import DEFAULT_SETTINGS
    DE_DYN_MIN_WINRATE = DEFAULT_SETTINGS.get("DE_DYN_MIN_WINRATE", 93.3)
except ImportError:
    DE_DYN_MIN_WINRATE = 93.3

# Import t·∫•t c·∫£ t·ª´ module m·ªõi
try:
    # Th·ª≠ import tuy·ªát ƒë·ªëi tr∆∞·ªõc
    try:
        from logic.analytics.dashboard_scorer import (
            get_loto_stats_last_n_days,
            get_loto_gan_stats,
            get_top_memory_bridge_predictions,
            _standardize_pair,
            get_prediction_consensus,
            get_high_win_rate_predictions,
            get_pending_k2n_bridges,
            get_top_scored_pairs,
            get_consensus_simulation,
            get_high_win_simulation,
            prepare_daily_features,
            calculate_score_from_features,
            get_historical_dashboard_data,
        )
    except ImportError:
        # Fallback: th·ª≠ import t∆∞∆°ng ƒë·ªëi
        from .analytics.dashboard_scorer import (
            get_loto_stats_last_n_days,
            get_loto_gan_stats,
            get_top_memory_bridge_predictions,
            _standardize_pair,
            get_prediction_consensus,
            get_high_win_rate_predictions,
            get_pending_k2n_bridges,
            get_top_scored_pairs,
            get_consensus_simulation,
            get_high_win_simulation,
            prepare_daily_features,
            calculate_score_from_features,
            get_historical_dashboard_data,
        )
except ImportError:
    # Fallback: N·∫øu import l·ªói, t·∫°o c√°c h√†m dummy
    def get_loto_stats_last_n_days(*args, **kwargs): return []
    def get_loto_gan_stats(*args, **kwargs): return []
    def get_top_memory_bridge_predictions(*args, **kwargs): return []
    def _standardize_pair(*args, **kwargs): return None
    def get_prediction_consensus(*args, **kwargs): return []
    def get_high_win_rate_predictions(*args, **kwargs): return []
    def get_pending_k2n_bridges(*args, **kwargs): return []
    def get_top_scored_pairs(*args, **kwargs): return []
    def get_consensus_simulation(*args, **kwargs): return []
    def get_high_win_simulation(*args, **kwargs): return []
    def prepare_daily_features(*args, **kwargs): return None
    def calculate_score_from_features(*args, **kwargs): return []
    def get_historical_dashboard_data(*args, **kwargs): return None
    print("C·∫£nh b√°o: Kh√¥ng th·ªÉ import t·ª´ logic.analytics.dashboard_scorer. S·ª≠ d·ª•ng fallback.")

def _determine_de_dyn_visibility(bridge, enable_threshold_raw, disable_threshold_raw):
    """
    Determine if a DE_DYN bridge should be visible based on visibility policy.
    
    Precedence:
    1. Manual override (de_manual_override == 1): use de_manual_override_value
    2. Auto enabled (de_auto_enabled == 1): show
    3. Computed metrics with hysteresis: check de_win_count_last30
    
    Args:
        bridge: Bridge dict from DB
        enable_threshold_raw: Threshold to enable (e.g., 28)
        disable_threshold_raw: Threshold to disable (e.g., 26)
    
    Returns:
        (visible: bool, reason: str)
    """
    bridge_name = bridge.get("name", "N/A")
    
    # Priority 1: Manual override
    de_manual_override = bridge.get("de_manual_override", 0)
    if de_manual_override == 1:
        de_manual_override_value = bridge.get("de_manual_override_value", 0)
        visible = bool(de_manual_override_value)
        reason = f"manual override (value={de_manual_override_value})"
        return visible, reason
    
    # Priority 2: Auto enabled flag
    de_auto_enabled = bridge.get("de_auto_enabled", 0)
    if de_auto_enabled == 1:
        return True, "auto flag true"
    
    # Priority 3: Computed metrics with hysteresis
    de_win_count_last30 = bridge.get("de_win_count_last30")
    
    if de_win_count_last30 is None:
        # Try legacy fields as fallback
        current_streak = bridge.get("current_streak")
        streak = bridge.get("streak")
        
        if current_streak is not None:
            wins_last30 = int(current_streak) if current_streak <= 30 else int((current_streak / 100.0) * 30)
        elif streak is not None:
            wins_last30 = int(streak) if streak <= 30 else int((streak / 100.0) * 30)
        else:
            # No metrics available - mark for evaluation and hide
            bridge["needs_evaluation"] = True
            return False, "no metrics available (needs evaluation)"
    else:
        wins_last30 = int(de_win_count_last30)
    
    # Apply hysteresis thresholds
    if wins_last30 >= enable_threshold_raw:
        return True, f"wins30={wins_last30} >= enable_threshold={enable_threshold_raw}"
    elif wins_last30 <= disable_threshold_raw:
        return False, f"wins30={wins_last30} <= disable_threshold={disable_threshold_raw}"
    else:
        # In hysteresis zone: check previous auto_enabled state
        prev_auto_enabled = bridge.get("de_auto_enabled", 0)
        if prev_auto_enabled == 1:
            return True, f"wins30={wins_last30} in hysteresis zone, prev_auto=1"
        else:
            return False, f"wins30={wins_last30} in hysteresis zone, prev_auto=0"


# def get_cau_dong_for_tab_soi_cau_de(db_name=None, threshold_thong=None):
#     """
#     V11.0: L·∫•y danh s√°ch c·∫ßu ƒë·ªông ƒë√£ l·ªçc t·ª´ DB cho Tab Soi C·∫ßu ƒê·ªÅ.
    
#     Implements strict visibility policy with auto/manual/hysteresis rules:
#     - Only DE_* bridges are included
#     - DE_KILLER always excluded
#     - DE_DYN visibility determined by: manual override > auto_enabled > computed metrics with hysteresis
    
#     Args:
#         db_name: ƒê∆∞·ªùng d·∫´n database (None = m·∫∑c ƒë·ªãnh)
#         threshold_thong: Legacy parameter (kept for compatibility, not used in new policy)
    
#     Returns:
#         List[Dict]: Danh s√°ch c√°c bridge dict ƒë√£ l·ªçc, v·ªõi needs_evaluation flag n·∫øu thi·∫øu metrics
#     """
#     # Import DB_NAME locally to avoid circular dependencies
#     if db_name is None:
#         try:
#             from logic.db_manager import DB_NAME
#             db_name = DB_NAME
#         except ImportError:
#             db_name = "data/xo_so_prizes_all_logic.db"
    
#     # Load configuration from constants
#     try:
#         from logic.constants import DEFAULT_SETTINGS
#         window_kys = DEFAULT_SETTINGS.get("DE_WINDOW_KYS", 30)
#         enable_threshold_raw = DEFAULT_SETTINGS.get("DE_DYN_ENABLE_RAW", 28)
#         disable_threshold_raw = DEFAULT_SETTINGS.get("DE_DYN_DISABLE_RAW", 26)
#     except ImportError:
#         # Fallback defaults
#         window_kys = 30
#         enable_threshold_raw = 28
#         disable_threshold_raw = 26
    
#     print(f"[get_cau_dong_for_tab_soi_cau_de] DE Visibility Policy:")
#     print(f"  - Window: {window_kys} periods")
#     print(f"  - Enable threshold: {enable_threshold_raw}/{window_kys}")
#     print(f"  - Disable threshold: {disable_threshold_raw}/{window_kys}")
#     print(f"  - Hysteresis zone: {disable_threshold_raw+1} to {enable_threshold_raw-1}")
    
#     # Get all enabled bridges from DB
#     all_bridges = get_all_managed_bridges(db_name, only_enabled=True)
    
#     filtered_bridges = []
#     filtered_count = {
#         "NON_DE": 0,
#         "DE_KILLER": 0, 
#         "DE_DYN_HIDDEN": 0,
#         "NEEDS_EVAL": 0
#     }
    
#     for bridge in all_bridges:
#         bridge_type = (bridge.get("type", "") or "").upper()
#         bridge_name = bridge.get("name", "N/A")
#         bridge_id = bridge.get("id", "?")
        
#         # Rule 0: Only include DE_* bridges in this tab
#         if not bridge_type.startswith("DE_"):
#             filtered_count["NON_DE"] += 1
#             print(f"  [FILTERED] Non-DE bridge: {bridge_name} ({bridge_type})")
#             continue
        
#         # Rule 1: Always exclude DE_KILLER
#         if bridge_type == "DE_KILLER":
#             filtered_count["DE_KILLER"] += 1
#             print(f"  [FILTERED] DE_KILLER: {bridge_name}")
#             continue
        
#         # Rule 2: Dynamic bridge visibility with auto/manual/hysteresis policy
#         # Auto-detect dynamic variants (DE_DYN, DE_DYNAMIC, DE_DYNAMIC_K, etc.)
#         from logic.bridges.de_performance import is_dynamic_bridge_type
        
#         if is_dynamic_bridge_type(bridge_type):
#             visible, reason = _determine_de_dyn_visibility(
#                 bridge, 
#                 enable_threshold_raw, 
#                 disable_threshold_raw
#             )
            
#             if not visible:
#                 filtered_count["DE_DYN_HIDDEN"] += 1
#                 print(f"  [FILTERED] Dynamic bridge hidden: {bridge_name} ({bridge_type}) - {reason}")
                
#                 # Check if it needs evaluation
#                 if bridge.get("needs_evaluation", False):
#                     filtered_count["NEEDS_EVAL"] += 1
                
#                 continue
#             else:
#                 print(f"  [VISIBLE] Dynamic bridge: {bridge_name} ({bridge_type}) - {reason}")
        
#         # Normalize field names for UI compatibility
#         if "current_streak" in bridge and "streak" not in bridge:
#             bridge["streak"] = bridge["current_streak"]
#         if "next_prediction_stl" in bridge and "predicted_value" not in bridge:
#             bridge["predicted_value"] = bridge["next_prediction_stl"]
        
#         filtered_bridges.append(bridge)
    
#     # Summary log
#     print(f"\n[get_cau_dong_for_tab_soi_cau_de] Summary:")
#     print(f"  - Total from DB: {len(all_bridges)}")
#     print(f"  - Filtered Non-DE (LO_*, etc.): {filtered_count['NON_DE']}")
#     print(f"  - Filtered DE_KILLER: {filtered_count['DE_KILLER']}")
#     print(f"  - Filtered DE_DYN (hidden): {filtered_count['DE_DYN_HIDDEN']}")
#     print(f"  - Needs evaluation: {filtered_count['NEEDS_EVAL']}")
#     print(f"  - Final result: {len(filtered_bridges)}")
    
#     return filtered_bridges

def get_cau_dong_for_tab_soi_cau_de(db_name=None, threshold_thong=None):
    """
    Simplified visibility: only apply DE_KILLER exclusion. All other bridges
    (including DE_*, non-DE, dynamic variants, etc.) will be returned as-is,
    except those explicitly of type 'DE_KILLER' which are always excluded.

    Args:
        db_name: ƒê∆∞·ªùng d·∫´n database (None = m·∫∑c ƒë·ªãnh)
        threshold_thong: Legacy parameter (kept for compatibility, not used)

    Returns:
        List[Dict]: Danh s√°ch c√°c bridge dict ƒë√£ l·ªçc
    """
    # Import DB_NAME locally to avoid circular dependencies
    if db_name is None:
        try:
            from logic.db_manager import DB_NAME
            db_name = DB_NAME
        except ImportError:
            db_name = "data/xo_so_prizes_all_logic.db"

    # Get all enabled bridges from DB (preserve existing behaviour)
    all_bridges = get_all_managed_bridges(db_name, only_enabled=True)

    filtered_bridges = []
    filtered_count = {
        "DE_KILLER": 0,
    }

    for bridge in all_bridges:
        bridge_type = (bridge.get("type", "") or "").upper()
        bridge_name = bridge.get("name", "N/A")

        # Only apply Rule 1: exclude DE_KILLER
        if bridge_type == "DE_KILLER":
            filtered_count["DE_KILLER"] += 1
            # Keep a debug print for visibility
            print(f"  [FILTERED] DE_KILLER: {bridge_name}")
            continue

        # No other filtering: include the bridge
        # Normalize field names for UI compatibility (keep existing normalizations)
        if "current_streak" in bridge and "streak" not in bridge:
            bridge["streak"] = bridge["current_streak"]
        if "next_prediction_stl" in bridge and "predicted_value" not in bridge:
            bridge["predicted_value"] = bridge["next_prediction_stl"]

        filtered_bridges.append(bridge)

    # Summary log
    print(f"\n[get_cau_dong_for_tab_soi_cau_de] Summary:")
    print(f"  - Total from DB: {len(all_bridges)}")
    print(f"  - Filtered DE_KILLER: {filtered_count['DE_KILLER']}")
    print(f"  - Final result: {len(filtered_bridges)}")

    return filtered_bridges

__all__ = [
    'get_loto_stats_last_n_days',
    'get_loto_gan_stats',
    'get_top_memory_bridge_predictions',
    '_standardize_pair',
    'get_prediction_consensus',
    'get_high_win_rate_predictions',
    'get_pending_k2n_bridges',
    'get_top_scored_pairs',
    'get_consensus_simulation',
    'get_high_win_simulation',
    'prepare_daily_features',
    'calculate_score_from_features',
    'get_historical_dashboard_data',
    'get_cau_dong_for_tab_soi_cau_de',
]


--------------------------------------------------

=== FILE: logic\data_parser.py ===
# T√™n file: git3/logic/data_parser.py
#
# (N·ªòI DUNG THAY TH·∫æ TO√ÄN B·ªò - S·ª¨A W503)
#
import json
import re
import sqlite3
import traceback
from datetime import datetime

# (S·ª¨A L·ªñI) T√°ch import cho ƒë√∫ng file (S·ª≠ d·ª•ng import V6)
try:
    from .data_repository import get_latest_ky_date
    from .db_manager import delete_all_managed_bridges, setup_database
except ImportError as e:
    print(f"L·ªñI NGHI√äM TR·ªåNG: data_parser.py kh√¥ng th·ªÉ import (TRY BLOCK): {e}")

    # Fallback
    from .data_repository import get_latest_ky_date
    from .db_manager import delete_all_managed_bridges, setup_database

# ==========================================================================
# (V6) LOGIC T√ÅCH BI·ªÜT - PH√ÇN T√çCH C√ö PH√ÅP (PARSING)
# (S·ª≠ d·ª•ng l·∫°i h√†m _parse_single_ky V6 ƒë·ªÉ l·∫•y 27 l√¥)
# ==========================================================================


def _parse_single_ky(ky_data, date_str, ky_str):
    """
    (N√ÇNG C·∫§P V6) Ph√¢n t√≠ch 1 k·ª≥, tr√≠ch xu·∫•t 8 gi·∫£i (chu·∫©n h√≥a) v√† 27 l√¥.
    H·ªó tr·ª£ 3 ƒë·ªãnh d·∫°ng:
    1. JSON V7 (ky_data l√† list 8 chu·ªói)
    2. JSON Web (ky_data l√† list 8 list con [["ƒêB", "123"], ...])
    3. Text Paste (ky_data l√† list 8 chu·ªói)
    """
    try:
        # 1. X·ª≠ l√Ω K·ª≥ (ky)
        ky_str = str(ky_str).strip()
        if not ky_str:
            return None

        # 2. X·ª≠ l√Ω Ng√†y (date)
        date_str = str(date_str).strip()
        dt = None
        try:
            # Th·ª≠ 1: ƒê·ªãnh d·∫°ng V7 / Text Paste (DD/MM/YYYY)
            dt = datetime.strptime(date_str, "%d/%m/%Y")
        except ValueError:
            try:
                # Th·ª≠ 2: ƒê·ªãnh d·∫°ng Web JSON (DD-MM HH:MM:SS) - T·ª± th√™m nƒÉm hi·ªán t·∫°i
                partial_date = date_str.split(" ")[0]  # L·∫•y "DD-MM"
                current_year = datetime.now().year
                full_date_str = f"{partial_date}-{current_year}"
                dt = datetime.strptime(full_date_str, "%d-%m-%Y")
            except ValueError:
                # (S·ª¨A L·ªñI V3) Fallback cho c√°c ƒë·ªãnh d·∫°ng ng√†y kh√°c (v√≠ d·ª•: '08-11 23:59:29' t·ª´ 8 11.json)
                try:
                    partial_date = date_str.split(" ")[0]  # L·∫•y "DD-MM"
                    current_year = datetime.now().year
                    full_date_str = f"{partial_date}-{current_year}"
                    dt = datetime.strptime(full_date_str, "%m-%d-%Y")  # Th·ª≠ MM-DD-YYYY
                except ValueError:
                    print(
                        f"B·ªè qua k·ª≥ {ky_str}: ƒê·ªãnh d·∫°ng ng√†y kh√¥ng h·ª£p l·ªá '{date_str}'"
                    )
                    return None

        date_sql = dt.strftime("%Y-%m-%d")

        # 3. X·ª≠ l√Ω 8 Gi·∫£i (giai) - (N√ÇNG C·∫§P V6)
        prize_data_dict = {}
        giai_keys_v7 = ["gdb", "g1", "g2", "g3", "g4", "g5", "g6", "g7"]

        if isinstance(ky_data, list) and len(ky_data) == 8:
            # Ki·ªÉm tra xem ƒë√¢y l√† format [["ƒêB", "123"], ...] (Web JSON)
            if isinstance(ky_data[0], list) and len(ky_data[0]) >= 2:
                # (S·ª≠a V6) Chuy·ªÉn t√™n gi·∫£i V6 (ƒê·∫∑c Bi·ªát) sang V7 (gdb)
                prize_map = {
                    "ƒë·∫∑c bi·ªát": "gdb",
                    "nh·∫•t": "g1",
                    "nh√¨": "g2",
                    "ba": "g3",
                    "b·ªën": "g4",
                    "nƒÉm": "g5",
                    "s√°u": "g6",
                    "b·∫£y": "g7",
                }
                temp_dict = {}
                for prize in ky_data:
                    temp_dict[prize[0].lower()] = prize[1]

                for key_v6, key_v7 in prize_map.items():
                    prize_data_dict[key_v7] = temp_dict.get(key_v6, "")

            # Hay format ["123", "456", ...] (V7 JSON ho·∫∑c Text Paste)
            elif isinstance(ky_data[0], str):
                prize_data_dict = dict(zip(giai_keys_v7, ky_data))  # "gdb", "g1"...

        if not prize_data_dict:
            print(f"B·ªè qua k·ª≥ {ky_str}: L·ªói c·∫•u tr√∫c ky_data kh√¥ng x√°c ƒë·ªãnh.")
            return None

        # (LOGIC V6 C≈®) Tr√≠ch xu·∫•t t∆∞·ªùng minh v√† chu·∫©n h√≥a d·∫•u ph·∫©y
        gdb_str = prize_data_dict.get("gdb", "")
        g1_str = prize_data_dict.get("g1", "")
        g2_str = prize_data_dict.get("g2", "")
        g3_str = prize_data_dict.get("g3", "")
        g4_str = prize_data_dict.get("g4", "")
        g5_str = prize_data_dict.get("g5", "")
        g6_str = prize_data_dict.get("g6", "")
        g7_str = prize_data_dict.get("g7", "")

        # (LOGIC V6 C≈®) D√πng re.findall (logic V6) ƒë·ªÉ tr√≠ch xu·∫•t CHU·ªñI S·ªê
        gdb_nums = re.findall(r"\d+", gdb_str)
        g1_nums = re.findall(r"\d+", g1_str)
        g2_nums = re.findall(r"\d+", g2_str)
        g3_nums = re.findall(r"\d+", g3_str)
        g4_nums = re.findall(r"\d+", g4_str)
        g5_nums = re.findall(r"\d+", g5_str)
        g6_nums = re.findall(r"\d+", g6_str)
        g7_nums = re.findall(r"\d+", g7_str)

        # Chu·∫©n h√≥a DB (d√πng d·∫•u ph·∫©y)
        giai_values_for_db = [
            ",".join(gdb_nums),
            ",".join(g1_nums),
            ",".join(g2_nums),
            ",".join(g3_nums),
            ",".join(g4_nums),
            ",".join(g5_nums),
            ",".join(g6_nums),
            ",".join(g7_nums),
        ]

        # 4. Tr√≠ch xu·∫•t L√¥ (An to√†n - Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng)
        lotos = []

        # (LOGIC V6 C≈®) Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng l√¥ cho t·ª´ng gi·∫£i
        lotos.extend([num[-2:].zfill(2) for num in gdb_nums][:1])  # 1 L√¥
        lotos.extend([num[-2:].zfill(2) for num in g1_nums][:1])  # 1 L√¥
        lotos.extend([num[-2:].zfill(2) for num in g2_nums][:2])  # 2 L√¥
        lotos.extend([num[-2:].zfill(2) for num in g3_nums][:6])  # 6 L√¥
        lotos.extend([num[-2:].zfill(2) for num in g4_nums][:4])  # 4 L√¥
        lotos.extend([num[-2:].zfill(2) for num in g5_nums][:6])  # 6 L√¥
        lotos.extend([num[-2:].zfill(2) for num in g6_nums][:3])  # 3 L√¥
        lotos.extend([num[-2:].zfill(2) for num in g7_nums][:4])  # 4 L√¥

        # 5. Ki·ªÉm tra 27 L√¥
        if len(lotos) != 27:
            print(f"B·ªè qua k·ª≥ {ky_str}: Kh√¥ng ƒë·ªß 27 l√¥ (t√¨m th·∫•y {len(lotos)}).")
            return None

        # 6. T·∫°o H√†ng (Row) cho CSDL (37 c·ªôt)
        row_A_I = [ky_str, date_sql] + giai_values_for_db + lotos

        return tuple(row_A_I)

    except Exception as e:
        print(f"L·ªñI _parse_single_ky (K·ª≥ {ky_str}, Ng√†y {date_str}): {e}")
        print(traceback.format_exc())
        return None


def _insert_data_batch(cursor, data_list):
    """
    (S·ª¨A L·ªñI V3) Ch√®n h√†ng lo·∫°t v√†o 2 b·∫£ng V6: results_A_I v√† DuLieu_AI
    """
    if not data_list:
        return 0

    # 1. D·ªçn d·∫πp C·∫ßu ƒê√£ L∆∞u (v√¨ n·∫°p l·∫°i t·ª´ ƒë·∫ßu)
    # (S·ª¨A L·ªñI V3) Truy·ªÅn cursor.connection (conn) thay v√¨ cursor
    delete_all_managed_bridges(cursor.connection)

    # 2. Chu·∫©n b·ªã c√¢u l·ªánh SQL

    # (V6) C·∫ßn 37 placeholders (1 ky + 1 date + 8 giai + 27 lotos)
    placeholders_37 = ", ".join(["?"] * 37)

    # (V6) T√™n c·ªôt INSERT (37 c·ªôt) cho results_A_I
    query_A_I = f"""
    INSERT OR IGNORE INTO results_A_I (
        ky, date,
        gdb, g1, g2, g3, g4, g5, g6, g7,
        l0, l1, l2, l3, l4, l5, l6, l7, l8, l9,
        l10, l11, l12, l13, l14, l15, l16, l17, l18, l19,
        l20, l21, l22, l23, l24, l25, l26
    ) VALUES (
        {placeholders_37}
    )"""

    # (S·ª¨A L·ªñI V3) Chu·∫©n b·ªã data cho DuLieu_AI (10 c·ªôt)
    # data_list row format: (ky, date, gdb, g1..g7, l0..l26)
    dulieu_ai_batch = [
        (
            row[0],  # MaSoKy (ky)
            row[0],  # Col_A_Ky (ky)
            row[2],
            row[3],
            row[4],
            row[5],
            row[6],
            row[7],
            row[8],
            row[9],  # gdb (Col_B) -> g7 (Col_I)
        )
        for row in data_list
    ]

    query_DuLieu_AI = """
    INSERT OR IGNORE INTO DuLieu_AI (
        MaSoKy, Col_A_Ky,
        Col_B_GDB, Col_C_G1, Col_D_G2, Col_E_G3,
        Col_F_G4, Col_G_G5, Col_H_G6, Col_I_G7
    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    """

    try:
        # Ch√®n A:I (38 c·ªôt)
        cursor.executemany(query_A_I, data_list)
        count_A_I = cursor.rowcount  # Tr·∫£ v·ªÅ s·ªë h√†ng A:I ƒë√£ ch√®n

        # Ch√®n A:I (10 c·ªôt)
        cursor.executemany(query_DuLieu_AI, dulieu_ai_batch)

        return count_A_I

    except sqlite3.IntegrityError as e:
        print(f"L·ªói Integrity (Tr√πng l·∫∑p) khi ch√®n batch: {e}")
        return 0
    except Exception as e:
        print(f"L·ªói _insert_data_batch (V6 schema): {e}")
        print(traceback.format_exc())
        return 0


def _insert_data_batch_APPEND(cursor, data_list):
    """
    (S·ª¨A L·ªñI V3) Ch√®n h√†ng lo·∫°t (APPEND) v√†o 2 b·∫£ng V6: results_A_I v√† DuLieu_AI.
    KH√îNG X√ìA C·∫¶U.
    """
    if not data_list:
        return 0

    # (V6) C·∫ßn 37 placeholders
    placeholders_37 = ", ".join(["?"] * 37)

    query_A_I = f"""
    INSERT OR IGNORE INTO results_A_I (
        ky, date,
        gdb, g1, g2, g3, g4, g5, g6, g7,
        l0, l1, l2, l3, l4, l5, l6, l7, l8, l9,
        l10, l11, l12, l13, l14, l15, l16, l17, l18, l19,
        l20, l21, l22, l23, l24, l25, l26
    ) VALUES (
        {placeholders_37}
    )"""

    # (S·ª¨A L·ªñI V3) Chu·∫©n b·ªã data cho DuLieu_AI (10 c·ªôt)
    dulieu_ai_batch = [
        (
            row[0],  # MaSoKy (ky)
            row[0],  # Col_A_Ky (ky)
            row[2],
            row[3],
            row[4],
            row[5],
            row[6],
            row[7],
            row[8],
            row[9],  # gdb (Col_B) -> g7 (Col_I)
        )
        for row in data_list
    ]

    query_DuLieu_AI = """
    INSERT OR IGNORE INTO DuLieu_AI (
        MaSoKy, Col_A_Ky,
        Col_B_GDB, Col_C_G1, Col_D_G2, Col_E_G3,
        Col_F_G4, Col_G_G5, Col_H_G6, Col_I_G7
    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    """

    try:
        cursor.executemany(query_A_I, data_list)
        count_A_I = cursor.rowcount

        cursor.executemany(query_DuLieu_AI, dulieu_ai_batch)

        return count_A_I

    except Exception as e:
        print(f"L·ªói _insert_data_batch_APPEND (V6 schema): {e}")
        print(traceback.format_exc())
        return 0


# ==========================================================================
# (V7) API: H√ÄM CH√çNH (G·ªåI T·ª™ CONTROLLER)
# (S·ª≠ d·ª•ng logic ph√°t hi·ªán JSON V7, nh∆∞ng g·ªçi h√†m parse V6)
# ==========================================================================


def parse_and_insert_data(raw_data, conn, cursor):
    """
    (MERGE V7+V6) API: T·ª± ƒë·ªông ph√°t hi·ªán ƒë·ªãnh d·∫°ng (V7 ho·∫∑c Web JSON) v√† ch√®n v√†o DB.
    X√ìA H·∫æT C·∫¶U ƒê√É L∆ØU.
    """
    parsed_data = []
    # (S·ª¨A L·ªñI V3) G·ªçi b·∫±ng conn (Connection) thay v√¨ cursor (Cursor)
    delete_all_managed_bridges(conn)

    try:
        data = json.loads(raw_data)

        # TH·ª¨ 1: ƒê·ªäNH D·∫†NG V7 ({"data": {"ky": ...}})
        if "data" in data and "ky" in data["data"]:
            print("(V7.0) ƒê√£ ph√°t hi·ªán ƒë·ªãnh d·∫°ng JSON (V7).")
            v7_data = data["data"]["ky"]
            sorted_keys = sorted(v7_data.keys(), key=lambda k: int(k))
            for ky_str in sorted_keys:
                ky_info = v7_data[ky_str]
                date_str = ky_info.get("date", "")
                giai_data = ky_info.get("giai", [])  # ƒê√¢y l√† list: ["123", "456"]

                # (S·ª¨A V3) G·ªçi h√†m _parse_single_ky (V6) ƒë·ªÉ l·∫•y 27 l√¥
                parsed_ky = _parse_single_ky(giai_data, date_str, ky_str)
                if parsed_ky:
                    parsed_data.append(parsed_ky)

        # (S·ª¨A L·ªñI V2) TH·ª¨ 2: ƒê·ªäNH D·∫†NG WEB JSON ({"kyInfo": [...], "tablesData": [...]})
        elif "kyInfo" in data and "tablesData" in data:  # <-- 1. S·ª≠a t√™n key
            print("(V7.0) ƒê√£ ph√°t hi·ªán ƒë·ªãnh d·∫°ng JSON (Web).")
            ky_info_list = data["kyInfo"]
            tables_data_list = data["tablesData"]  # <-- 1. S·ª≠a t√™n key

            # (S·ª¨A L·ªñI V2) Ki·ªÉm tra t·ª∑ l·ªá 1:2 (1 k·ª≥ : 2 b·∫£ng)
            if len(ky_info_list) * 2 != len(tables_data_list):
                print(
                    f"L·ªói: JSON (Web) kh√¥ng kh·ªõp. kyInfo ({len(ky_info_list)}) v√† tablesData ({len(tables_data_list)}) kh√¥ng theo t·ª∑ l·ªá 1:2."
                )

            else:
                combined_list = []
                for i in range(len(ky_info_list)):
                    ky_str_check = ky_info_list[i].get("k·ª≥Number")
                    if ky_str_check and ky_str_check.isdigit():
                        # (S·ª¨A L·ªñI V2) Gh√©p kyInfo[i] v·ªõi B·∫£ng Gi·∫£i Th∆∞·ªüng (tablesData[i*2])
                        combined_list.append(
                            (
                                int(ky_str_check),
                                ky_info_list[i],
                                tables_data_list[i * 2],
                            )
                        )

                combined_list.sort(key=lambda x: x[0])  # S·∫Øp x·∫øp theo k·ª≥

                for ky_int, ky_info, table_data in combined_list:
                    ky_str = str(ky_int)
                    date_str = ky_info.get("k·ª≥Date")  # "DD-MM HH:MM:SS"
                    content = table_data.get(
                        "content", []
                    )  # [["ƒê·∫∑c Bi·ªát", "33963"], ...]

                    # <<< B·ªò CHUY·ªÇN ƒê·ªîI (ADAPTER) >>>
                    # Chuy·ªÉn [["ƒêB", "123"], ...] TH√ÄNH ["123", "456", ...]
                    giai_data_list = []
                    # (S·ª¨A L·ªñI V2) Ki·ªÉm tra k·ªπ ƒë√¢y l√† b·∫£ng gi·∫£i (c√≥ "ƒê·∫∑c Bi·ªát")
                    if (
                        isinstance(content, list)
                        and len(content) == 8
                        and isinstance(content[0], list)
                        and len(content[0]) >= 2
                        and ("ƒê·∫∑c Bi·ªát" in content[0][0] or "GDB" in content[0][0])
                    ):

                        for giai_pair in content:
                            giai_data_list.append(
                                giai_pair[1]
                            )  # Ch·ªâ l·∫•y chu·ªói s·ªë (v√≠ d·ª•: "13173 -23763")

                        # (S·ª¨A V3) G·ªçi h√†m _parse_single_ky (V6) ƒë·ªÉ l·∫•y 27 l√¥
                        parsed_ky = _parse_single_ky(giai_data_list, date_str, ky_str)
                        if parsed_ky:
                            parsed_data.append(parsed_ky)
                    else:
                        print(
                            f"B·ªè qua k·ª≥ {ky_str}: L·ªói ƒë·ªãnh d·∫°ng (Web), kh√¥ng ph·∫£i b·∫£ng gi·∫£i th∆∞·ªüng (index ch·∫µn)."
                        )

        else:
            # (S·ª¨A V3) N·∫øu kh√¥ng ph·∫£i 2 d·∫°ng tr√™n, th·ª≠ d·∫°ng Text V6
            print("(V7.0) Kh√¥ng ph·∫£i JSON V7/Web. ƒêang th·ª≠ ƒë·ªãnh d·∫°ng Text (V6)...")
            # (S·ª¨A V3) G·ªçi h√†m parse TEXT (V6)
            # L∆∞u √Ω: H√†m n√†y APPEND, nh∆∞ng v√¨ ƒë√£ g·ªçi delete_all_managed_bridges
            # v√† _insert_data_batch s·∫Ω ch√®n (kh√¥ng IGNORE) n√™n v·∫´n ƒë√∫ng
            total_inserted = parse_and_APPEND_data_TEXT(raw_data, conn, cursor)
            conn.commit()
            return total_inserted

    except json.JSONDecodeError:
        # (S·ª¨A V3) N·∫øu JSON l·ªói -> Th·ª≠ Text V6
        print("(V7.0) Kh√¥ng ph·∫£i JSON. ƒêang th·ª≠ ƒë·ªãnh d·∫°ng Text (V6)...")
        total_inserted = parse_and_APPEND_data_TEXT(raw_data, conn, cursor)
        conn.commit()
        return total_inserted
    except Exception as e:
        print(f"L·ªói parse_and_insert_data (JSON V7/Web): {e}")
        traceback.print_exc()
        return 0

    # (S·ª¨A V3) Ch·ªâ ch·∫°y n·∫øu l√† JSON V7 ho·∫∑c Web
    if not parsed_data:
        return 0

    total_inserted = _insert_data_batch(cursor, parsed_data)

    conn.commit()
    return total_inserted


def parse_and_APPEND_data(raw_data, conn, cursor):
    """
    (MERGE V7+V6) API: T·ª± ƒë·ªông ph√°t hi·ªán (V7 ho·∫∑c Web JSON) v√† ch√®n (APPEND).
    KH√îNG X√ìA C·∫¶U ƒê√É L∆ØU. (D√πng INSERT OR IGNORE)
    """
    # =========================================================================
    # (S·ª¨A L·ªñI V8) ƒê·ªïi cursor th√†nh conn
    latest_ky_str, latest_date_obj = get_latest_ky_date(conn)
    # =========================================================================
    print(f"(Append) K·ª≥ m·ªõi nh·∫•t trong DB: {latest_ky_str} ({latest_date_obj})")

    parsed_data = []

    try:
        data = json.loads(raw_data)

        # TH·ª¨ 1: ƒê·ªäNH D·∫†NG V7 ({"data": {"ky": ...}})
        if "data" in data and "ky" in data["data"]:
            print("(V7.0 - Append) ƒê√£ ph√°t hi·ªán ƒë·ªãnh d·∫°ng JSON (V7).")
            v7_data = data["data"]["ky"]
            sorted_keys = sorted(v7_data.keys(), key=lambda k: int(k))  # Sort keys
            for ky_str in sorted_keys:
                if latest_ky_str is not None and int(ky_str) <= int(latest_ky_str):
                    continue

                ky_info = v7_data[ky_str]
                date_str = ky_info.get("date", "")
                giai_data = ky_info.get("giai", [])  # list: ["123", "456"]
                parsed_ky = _parse_single_ky(giai_data, date_str, ky_str)
                if parsed_ky:
                    parsed_data.append(parsed_ky)

        # (S·ª¨A L·ªñI V2) TH·ª¨ 2: ƒê·ªäNH D·∫†NG WEB JSON ({"kyInfo": [...], "tablesData": [...]})
        elif "kyInfo" in data and "tablesData" in data:  # <-- 1. S·ª≠a t√™n key
            print("(V7.0 - Append) ƒê√£ ph√°t hi·ªán ƒë·ªãnh d·∫°ng JSON (Web).")
            ky_info_list = data["kyInfo"]
            tables_data_list = data["tablesData"]  # <-- 1. S·ª≠a t√™n key

            # (S·ª¨A L·ªñI V2) Ki·ªÉm tra t·ª∑ l·ªá 1:2
            if len(ky_info_list) * 2 != len(tables_data_list):
                print(
                    f"L·ªói: JSON (Web) kh√¥ng kh·ªõp. kyInfo ({len(ky_info_list)}) v√† tablesData ({len(tables_data_list)}) kh√¥ng theo t·ª∑ l·ªá 1:2."
                )

            else:
                combined_list = []
                for i in range(len(ky_info_list)):
                    ky_str_check = ky_info_list[i].get("k·ª≥Number")
                    if ky_str_check and ky_str_check.isdigit():
                        # (S·ª¨A L·ªñI V2) Gh√©p kyInfo[i] v·ªõi B·∫£ng Gi·∫£i Th∆∞·ªüng (tablesData[i*2])
                        combined_list.append(
                            (
                                int(ky_str_check),
                                ky_info_list[i],
                                tables_data_list[i * 2],
                            )
                        )

                combined_list.sort(key=lambda x: x[0])  # S·∫Øp x·∫øp theo k·ª≥

                for ky_int, ky_info, table_data in combined_list:
                    ky_str = str(ky_int)

                    if latest_ky_str is not None and ky_int <= int(latest_ky_str):
                        continue

                    date_str = ky_info.get("k·ª≥Date")  # "DD-MM HH:MM:SS"
                    content = table_data.get(
                        "content", []
                    )  # [["ƒê·∫∑c Bi·ªát", "33963"], ...]

                    # <<< B·ªò CHUY·ªÇN ƒê·ªîI (ADAPTER) >>>
                    giai_data_list = []
                    # (S·ª¨A L·ªñI V2) Ki·ªÉm tra k·ªπ ƒë√¢y l√† b·∫£ng gi·∫£i (c√≥ "ƒê·∫∑c Bi·ªát")
                    if (
                        isinstance(content, list)
                        and len(content) == 8
                        and isinstance(content[0], list)
                        and len(content[0]) >= 2
                        and ("ƒê·∫∑c Bi·ªát" in content[0][0] or "GDB" in content[0][0])
                    ):

                        for giai_pair in content:
                            giai_data_list.append(giai_pair[1])  # Ch·ªâ l·∫•y s·ªë

                        parsed_ky = _parse_single_ky(giai_data_list, date_str, ky_str)
                        if parsed_ky:
                            parsed_data.append(parsed_ky)
                    else:
                        print(
                            f"B·ªè qua k·ª≥ {ky_str}: L·ªói ƒë·ªãnh d·∫°ng (Web), kh√¥ng ph·∫£i b·∫£ng gi·∫£i th∆∞·ªüng (index ch·∫µn)."
                        )

        else:
            # (S·ª¨A V3) N·∫øu kh√¥ng ph·∫£i 2 d·∫°ng tr√™n, th·ª≠ d·∫°ng Text V6
            print(
                "(V7.0 - Append) Kh√¥ng ph·∫£i JSON V7/Web. ƒêang th·ª≠ ƒë·ªãnh d·∫°ng Text (V6)..."
            )
            total_inserted = parse_and_APPEND_data_TEXT(raw_data, conn, cursor)
            conn.commit()
            return total_inserted

    except json.JSONDecodeError:
        # (S·ª¨A V3) N·∫øu JSON l·ªói -> Th·ª≠ Text V6
        print("(V7.0 - Append) Kh√¥ng ph·∫£i JSON. ƒêang th·ª≠ ƒë·ªãnh d·∫°ng Text (V6)...")
        total_inserted = parse_and_APPEND_data_TEXT(raw_data, conn, cursor)
        conn.commit()
        return total_inserted
    except Exception as e:
        print(f"L·ªói parse_and_APPEND_data (JSON V7/Web): {e}")
        traceback.print_exc()
        return 0

    # (S·ª¨A V3) Ch·ªâ ch·∫°y n·∫øu l√† JSON V7 ho·∫∑c Web
    if not parsed_data:
        return 0

    # (S·ª¨A V3) G·ªçi h√†m APPEND V6
    total_inserted = _insert_data_batch_APPEND(cursor, parsed_data)

    conn.commit()
    return total_inserted


def parse_and_APPEND_data_TEXT(raw_data, conn, cursor):
    """
    (N√ÇNG C·∫§P V6) API: Ph√¢n t√≠ch d·ªØ li·ªáu TEXT (d√°n tay) v√† ch√®n v√†o DB.
    (S·ª¨A L·ªñI V9) H·ªó tr·ª£ ƒë·ªãnh d·∫°ng dtky.txt (Web Text) V√Ä x·ª≠ l√Ω ng·∫Øt d√≤ng.
    """
    parsed_data = []
    current_ky_str = None
    current_date_str = None
    current_ky_data = []  # L∆∞u 8 chu·ªói gi·∫£i

    # L·∫•y ng√†y/k·ª≥ m·ªõi nh·∫•t t·ª´ DB ƒë·ªÉ l·ªçc tr√πng
    # =========================================================================
    # (S·ª¨A L·ªñI V8) ƒê·ªïi cursor th√†nh conn
    latest_ky, latest_date = get_latest_ky_date(conn)
    # =========================================================================
    latest_ky_int = 0
    if latest_ky and latest_ky.isdigit():
        latest_ky_int = int(latest_ky)

    lines = raw_data.strip().split("\n")

    for line in lines:
        line = line.strip()
        if not line:
            continue

        # (S·ª≠a V7) H·ªó tr·ª£ c·∫£ 2 ƒë·ªãnh d·∫°ng:
        # 1. K·ª≥ 123(DD/MM/YYYY)
        ky_match_v7 = re.match(r"^\s*(?:K·ª≥\s*)?(\d+)\s*\((.*?)\)", line)
        # 2. K·ª≥ #123 - Ng√†y DD/MM/YYYY
        ky_match_v6 = re.match(
            r"(?:K·ª≥|k·ª≥)\s*#?(\d+)\s*-\s*Ng√†y\s*(\d{1,2}/\d{1,2}/\d{4})", line
        )

        # (S·ª¨A L·ªñI V11) S·ª≠a Regex, x√≥a \s* v√† ch·ªâ ƒë·ªãnh \d{10} cho K·ª≥
        # V√≠ d·ª•: K·ª≥ 251118030017-11 19:29:29 (D√≠nh li·ªÅn)
        ky_match_web = re.match(
            r"^\s*(?:K·ª≥\s*)?(\d{10})(\d{1,2}-\d{1,2}\s+\d{2}:\d{2}:\d{2})", line
        )

        match_found = None
        if ky_match_v7:
            match_found = ky_match_v7
        elif ky_match_v6:
            match_found = ky_match_v6
        # (S·ª¨A L·ªñI V8) ∆Øu ti√™n 3
        elif ky_match_web:
            match_found = ky_match_web

        if match_found:
            # N·∫øu ƒëang c√≥ 1 k·ª≥ c≈©, l∆∞u n√≥ l·∫°i
            if current_ky_str and len(current_ky_data) == 8:
                parsed_ky = _parse_single_ky(
                    current_ky_data, current_date_str, current_ky_str
                )
                if parsed_ky:
                    parsed_data.append(parsed_ky)

            # B·∫Øt ƒë·∫ßu k·ª≥ m·ªõi
            current_ky_str = match_found.group(1).strip()
            current_date_str = match_found.group(2).strip()
            current_ky_data = []

            # =========================================================================
            # (S·ª¨A L·ªñI V12) B·∫¨T L·∫†I KI·ªÇM TRA TR√ôNG L·∫∂P
            try:
                ky_to_check = current_ky_str

                if int(ky_to_check) <= latest_ky_int:
                    current_ky_str = None  # Reset ƒë·ªÉ b·ªè qua c√°c d√≤ng gi·∫£i
                    continue
            except ValueError:
                pass  # B·ªè qua n·∫øu ky kh√¥ng ph·∫£i s·ªë
            continue
            # =========================================================================

        # =========================================================================
        # (S·ª¨A L·ªñI V9) Logic b·∫Øt gi·∫£i th∆∞·ªüng (h·ªó tr·ª£ "Nh·∫•t", "Nh√¨"...)
        giai_match = re.match(
            r"^(GƒêB|ƒêB|ƒê·∫∑c Bi·ªát|G[1-7]|Nh·∫•t|Nh√¨|Ba|B·ªën|NƒÉm|S√°u|B·∫£y)\b",
            line,
            re.IGNORECASE,
        )

        if giai_match and current_ky_str:
            giai_data = line[giai_match.end(0):].strip()
            giai_keyword = giai_match.group(1).upper()

            # N·∫øu l√† GƒêB/ƒêB/ƒê·∫∑c Bi·ªát -> Ph·∫£i l√† gi·∫£i ƒë·∫ßu ti√™n (reset)
            if "ƒêB" in giai_keyword or "ƒê·∫∂C BI·ªÜT" in giai_keyword:
                if giai_data:
                    current_ky_data = [giai_data]

            # N·∫øu l√† c√°c gi·∫£i kh√°c (Nh·∫•t, Nh√¨, G1, G2...)
            elif len(current_ky_data) > 0 and len(current_ky_data) < 8:
                if giai_data:
                    current_ky_data.append(giai_data)

            continue  # ƒê√£ x·ª≠ l√Ω xong d√≤ng n√†y

        # (S·ª¨A L·ªñI V9) X·ª≠ l√Ω c√°c d√≤ng b·ªã ng·∫Øt (v√≠ d·ª•: -659)
        # Ch·ªâ b·∫Øt c√°c d√≤ng CH·ªà C√ì S·ªê / D·∫§U C√ÅCH / D·∫§U G·∫†CH (KH√îNG C√ì D·∫§U PH·∫®Y)
        elif re.match(r"^[ \d-]+$", line) and current_ky_str:
            giai_data = line.strip()
            # N·∫æU d√≤ng n√†y l√† s·ªë/g·∫°ch V√Ä C√ì gi·∫£i tr∆∞·ªõc ƒë√≥
            if giai_data and current_ky_data:
                current_ky_data[-1] = current_ky_data[-1] + " " + giai_data
            continue  # ƒê√£ x·ª≠ l√Ω xong d√≤ng n√†y

        # C√°c d√≤ng L√¥ r√°c (v√≠ d·ª•: 0 7,6) s·∫Ω b·ªã b·ªè qua
        # v√¨ ch√∫ng kh√¥ng kh·ªõp v·ªõi b·∫•t k·ª≥ regex n√†o ·ªü tr√™n.
        # =========================================================================

    if current_ky_str and len(current_ky_data) == 8:
        parsed_ky = _parse_single_ky(current_ky_data, current_date_str, current_ky_str)
        if parsed_ky:
            parsed_data.append(parsed_ky)

    if not parsed_data:
        return 0

    total_inserted = _insert_data_batch_APPEND(cursor, parsed_data)

    # conn.commit() # H√†m cha s·∫Ω commit
    return total_inserted


# ==========================================================================
# (DI CHUY·ªÇN T·ª™ LOTTERY_SERVICE.PY)
# ==========================================================================


def run_and_update_from_text(raw_data):
    # ==========================================================
    print("ƒêANG CH·∫†Y CODE V11 (B·∫¢N ·ªîN ƒê·ªäNH). B·∫ÆT ƒê·∫¶U PARSE...")
    # ==========================================================
    conn = None
    try:
        conn, cursor = setup_database()
        total_keys_added = parse_and_APPEND_data_TEXT(raw_data, conn, cursor)
        conn.commit()  # (S·ª≠a V7) Commit ·ªü ƒë√¢y
        conn.close()

        if total_keys_added > 0:
            return True, f"ƒê√£ th√™m th√†nh c√¥ng {total_keys_added} k·ª≥ m·ªõi."
        else:
            return (
                False,
                "Kh√¥ng c√≥ k·ª≥ n√†o ƒë∆∞·ª£c th√™m (c√≥ th·ªÉ do tr√πng l·∫∑p, sai ƒë·ªãnh d·∫°ng, ho·∫∑c file r·ªóng).",
            )
    except Exception as e:
        if conn:
            conn.close()
        return (
            False,
            f"L·ªói nghi√™m tr·ªçng khi th√™m t·ª´ text: {e}\n{traceback.format_exc()}",
        )


class DataParser:
    def get_positions_map(self, row) -> list:
        """
        L·∫•y m·∫£ng ph·∫≥ng 107 con s·ªë t·ª´ t·∫•t c·∫£ c√°c gi·∫£i (GDB -> G7).
        Logic map v·ªã tr√≠ chu·∫©n V16 (Google Script).
        """
        positions = []
        try:
            def parse_digits(val):
                if not val: return []
                s = str(val)
                return [int(d) for d in s if d.isdigit()]
            # 1. GƒêB (5 s·ªë)
            positions.extend(parse_digits(row.get('GDB', ''))[:5])
            while len(positions) < 5: positions.append(0)
            # 2. G1 (5 s·ªë)
            positions.extend(parse_digits(row.get('G1', ''))[:5])
            while len(positions) < 10: positions.append(0)
            # 3. G2 (2 gi·∫£i * 5)
            g2 = str(row.get('G2', '')).split(',')
            for g in g2: positions.extend(parse_digits(g)[:5])
            while len(positions) < 20: positions.append(0)
            # 4. G3 (6 gi·∫£i * 5)
            g3 = str(row.get('G3', '')).split(',')
            for g in g3: positions.extend(parse_digits(g)[:5])
            while len(positions) < 50: positions.append(0)
            # 5. G4 (4 gi·∫£i * 4)
            g4 = str(row.get('G4', '')).split(',')
            for g in g4: positions.extend(parse_digits(g)[:4])
            while len(positions) < 66: positions.append(0)
            # 6. G5 (6 gi·∫£i * 4)
            g5 = str(row.get('G5', '')).split(',')
            for g in g5: positions.extend(parse_digits(g)[:4])
            while len(positions) < 90: positions.append(0)
            # 7. G6 (3 gi·∫£i * 3)
            g6 = str(row.get('G6', '')).split(',')
            for g in g6: positions.extend(parse_digits(g)[:3])
            while len(positions) < 99: positions.append(0)
            # 8. G7 (4 gi·∫£i * 2)
            g7 = str(row.get('G7', '')).split(',')
            for g in g7: positions.extend(parse_digits(g)[:2])
            # C·∫Øt ho·∫∑c b√π cho ƒë·ªß 107
            if len(positions) > 107: positions = positions[:107]
            while len(positions) < 107: positions.append(0)
            return positions
        except Exception as e:
            print(f"Parser Error: {e}")
            return [0] * 107

--------------------------------------------------

=== FILE: logic\data_repository.py ===
# T√™n file: code6/logic/data_repository.py
# (PHI√äN B·∫¢N V10.2 - FIX: TH√äM get_bridge_by_name ƒê·ªÇ CH·∫†Y BACKTEST POPUP)

import sqlite3
import os
from datetime import datetime
import re

# --- C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N DB TUY·ªÜT ƒê·ªêI ---
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
data_dir = os.path.join(project_root, "data")
DB_NAME = os.path.join(data_dir, "xo_so_prizes_all_logic.db")
# ----------------------------------------

# Import c√°c h√†m x·ª≠ l√Ω c·∫ßu V17
try:
    from logic.bridges.bridges_v16 import getAllPositions_V17_Shadow, taoSTL_V30_Bong, get_index_from_name_V16
except ImportError:
    # Fallback dummy
    def getAllPositions_V17_Shadow(row): return []
    def taoSTL_V30_Bong(p1, p2): return ["00", "00"]
    def get_index_from_name_V16(name): return None

# Import c√°c h√†m x·ª≠ l√Ω Memory Bridge (B·∫°c Nh·ªõ)
try:
    from logic.bridges.bridges_memory import calculate_bridge_stl, get_27_loto_positions
except ImportError:
    def calculate_bridge_stl(loto1, loto2, algorithm_type): return ["00", "00"]
    def get_27_loto_positions(row): return ["00"] * 27

# Import logic ph·ª• tr·ª£ cho C·∫ßu ƒê·ªÅ (M·ªõi b·ªï sung)
try:
    from logic.de_utils import get_touches_by_offset
except ImportError:
    def get_touches_by_offset(b, k): return []

def load_data_ai_from_db(db_name=DB_NAME):
    """T·∫£i to√†n b·ªô d·ªØ li·ªáu A:I t·ª´ DB (10 c·ªôt). Tr·∫£ v·ªÅ (rows, message)"""
    if not os.path.exists(db_name):
        return None, f"L·ªói: Kh√¥ng t√¨m th·∫•y database '{db_name}'. Vui l√≤ng ch·∫°y 'N·∫°p File' tr∆∞·ªõc."

    try:
        conn = sqlite3.connect(db_name)
        cursor = conn.cursor()
        cursor.execute(
            """
        SELECT MaSoKy, Col_A_Ky, Col_B_GDB, Col_C_G1, Col_D_G2, Col_E_G3, Col_F_G4, Col_G_G5, Col_H_G6, Col_I_G7
        FROM DuLieu_AI
        ORDER BY MaSoKy ASC
        """
        )
        rows = cursor.fetchall()
        conn.close()

        if not rows:
            return None, f"L·ªói: Database '{db_name}' r·ªóng."

        return rows, f"ƒê√£ t·∫£i {len(rows)} h√†ng A:I t·ª´ CSDL."
    except Exception as e:
        return None, f"L·ªói SQL khi t·∫£i d·ªØ li·ªáu A:I: {e}"


def get_all_data_ai(db_name=DB_NAME):
    """(V7.9 Extension) Wrapper l·∫•y d·ªØ li·ªáu A:I d·∫°ng list."""
    rows, _ = load_data_ai_from_db(db_name)
    return rows if rows else []


def get_all_managed_bridges(db_name=DB_NAME, only_enabled=False):
    """(V7.1) L·∫•y danh s√°ch C·∫ßu ƒê√£ L∆∞u."""
    conn = None
    try:
        conn = sqlite3.connect(db_name)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()

        sql_query = "SELECT * FROM ManagedBridges"
        if only_enabled:
            sql_query += " WHERE is_enabled = 1"
        sql_query += " ORDER BY name ASC"

        cursor.execute(sql_query)
        # Chuy·ªÉn ƒë·ªïi [sqlite3.Row] th√†nh [dict] ƒë·ªÉ d·ªÖ thao t√°c
        return [dict(row) for row in cursor.fetchall()]

    except Exception:
        return []
    finally:
        if conn: conn.close()


def get_managed_bridges_with_prediction(db_name=DB_NAME, current_data=None, only_enabled=True):
    """
    (V7.9.5 - FIX) L·∫•y danh s√°ch C·∫ßu v√† T√çNH TO√ÅN D·ª∞ ƒêO√ÅN N√ìNG (Real-time).
    H·ªó tr·ª£ gi·∫£i m√£ t√™n c·∫ßu B·∫°c Nh·ªõ (LO_MEM) v√† C·∫ßu ƒê·ªÅ (DE_DYN).
    """
    # 1. L·∫•y danh s√°ch c·∫ßu th√¥ t·ª´ DB
    bridges = get_all_managed_bridges(db_name, only_enabled=only_enabled)
    
    # N·∫øu kh√¥ng c√≥ d·ªØ li·ªáu m·ªõi, tr·∫£ v·ªÅ ngay (kh√¥ng th·ªÉ t√≠nh to√°n)
    if not current_data or len(current_data) == 0:
        return bridges
    
    # Chu·∫©n b·ªã d·ªØ li·ªáu k·ª≥ m·ªõi nh·∫•t
    last_row = current_data[-1]
    positions = getAllPositions_V17_Shadow(last_row) # 214 v·ªã tr√≠ (V17)
    lotos_27 = get_27_loto_positions(last_row)       # 27 gi·∫£i loto (Memory)
    
    for bridge in bridges:
        try:
            # N·∫øu DB ƒë√£ l∆∞u s·∫µn next_prediction_stl th√¨ c√≥ th·ªÉ d√πng lu√¥n, 
            # nh∆∞ng ƒë·ªÉ ƒë·∫£m b·∫£o t√≠nh real-time (khi n·∫°p d·ªØ li·ªáu m·ªõi), ta n√™n t√≠nh l·∫°i.
            
            b_name = bridge.get("name", "")
            
            # === [CASE 1] C·∫¶U B·∫†C NH·ªö L√î (LO_MEM) ===
            # Format: LO_MEM_DIFF_L√¥ G3.5_L√¥ G6.3
            if b_name.startswith("LO_MEM_"):
                parts = b_name.split("_")
                # parts VD: ['LO', 'MEM', 'DIFF', 'L√¥ G3.5', 'L√¥ G6.3']
                if len(parts) >= 5:
                    algo_type = parts[2].lower() # 'diff' ho·∫∑c 'sum'
                    pos1_name = parts[3]
                    pos2_name = parts[4]
                    
                    # Map t√™n v·ªã tr√≠ (L√¥ G3.5) sang index (0-26)
                    idx1 = _map_loto_name_to_index(pos1_name)
                    idx2 = _map_loto_name_to_index(pos2_name)
                    
                    if idx1 is not None and idx2 is not None:
                        # ƒê·∫£m b·∫£o index n·∫±m trong 27 gi·∫£i
                        if idx1 < len(lotos_27) and idx2 < len(lotos_27):
                            val1 = lotos_27[idx1]
                            val2 = lotos_27[idx2]
                            
                            # T√≠nh STL d·ª±a tr√™n thu·∫≠t to√°n b·∫°c nh·ªõ
                            stl = calculate_bridge_stl(val1, val2, algo_type)
                            if stl and isinstance(stl, list) and len(stl) > 0:
                                bridge["next_prediction_stl"] = ",".join(stl)
                                continue

            # === [CASE 2] C·∫¶U ƒê·ªÄ DYNAMIC (DE_DYN) ===
            # Format: DE_DYN_G1_G2_K3
            elif b_name.startswith("DE_DYN_"):
                parts = b_name.split("_")
                if len(parts) >= 5:
                    n1, n2, k_str = parts[2], parts[3], parts[4]
                    k_val = int(k_str.replace("K", ""))
                    
                    # L·∫•y s·ªë cu·ªëi t·ª´ t√™n gi·∫£i (G1, G2...)
                    d1 = _extract_digit_from_col(last_row, n1)
                    d2 = _extract_digit_from_col(last_row, n2)
                    
                    if d1 is not None and d2 is not None:
                        base_sum = (d1 + d2) % 10
                        # H√†m n√†y t·ª´ logic.de_utils
                        touches = get_touches_by_offset(base_sum, k_val)
                        bridge["next_prediction_stl"] = ",".join(map(str, touches))
                        continue

            # === [CASE 3] C·∫¶U V·ªä TR√ç C·ªî ƒêI·ªÇN (G1[0]_G2[1]) ===
            # Format c√≥ ch·ª©a "[...]"
            elif "[" in b_name and "]" in b_name:
                matches = re.findall(r"(?:Bong\()?(?:G\d+|GDB)\.?\d*\[\d+\]\)?", b_name)
                if len(matches) >= 2:
                    idx1 = get_index_from_name_V16(matches[0])
                    idx2 = get_index_from_name_V16(matches[1])
                    
                    if idx1 is not None and idx2 is not None:
                        if idx1 < len(positions) and idx2 < len(positions):
                            v1, v2 = positions[idx1], positions[idx2]
                            if v1 is not None and v2 is not None:
                                if "DE_POS" in b_name:
                                    # C·∫ßu t·ªïng ƒë·ªÅ
                                    res = (int(v1) + int(v2)) % 10
                                    bridge["next_prediction_stl"] = str(res)
                                else:
                                    # C·∫ßu gh√©p l√¥
                                    stl = taoSTL_V30_Bong(int(v1), int(v2))
                                    bridge["next_prediction_stl"] = ",".join(stl)

        except Exception as e:
            # N·∫øu l·ªói t√≠nh to√°n, gi·ªØ nguy√™n gi√° tr·ªã c≈©
            # print(f"Calc error: {e}")
            pass
            
    return bridges

# --- H√ÄM HELPER GI·∫¢I M√É T√äN ---

def _map_loto_name_to_index(name):
    """
    Chuy·ªÉn t√™n v·ªã tr√≠ L√¥ (VD: 'L√¥ G3.5') sang index (0-26).
    D√πng cho C·∫ßu B·∫°c Nh·ªõ L√¥.
    """
    clean_name = name.replace("L√¥ ", "").strip()
    
    # B·∫£ng mapping c∆° s·ªü (Start index c·ªßa t·ª´ng gi·∫£i trong list 27 s·ªë)
    # GDB:0, G1:1, G2:2, G3:4, G4:10, G5:14, G6:20, G7:23
    base_map = {
        "GDB": 0, "G1": 1,
        "G2": 2, "G3": 4, 
        "G4": 10, "G5": 14, 
        "G6": 20, "G7": 23
    }
    
    try:
        if "." in clean_name:
            # D·∫°ng G3.5, G2.1
            parts = clean_name.split(".")
            g_name = parts[0]
            # sub_idx trong t√™n th∆∞·ªùng l√† 1-based (G3.1), c·∫ßn chuy·ªÉn v·ªÅ 0-based
            sub_idx = int(parts[1]) - 1 
            
            base = base_map.get(g_name)
            if base is not None:
                return base + sub_idx
        else:
            # D·∫°ng GDB, G1 (ch·ªâ c√≥ 1 con ho·∫∑c kh√¥ng c√≥ ch·∫•m)
            return base_map.get(clean_name)
            
    except:
        return None
    return None

def _extract_digit_from_col(row, col_name):
    """
    Helper: L·∫•y s·ªë cu·ªëi t·ª´ t√™n c·ªôt trong DB (VD: G1 -> row[3]).
    D√πng cho C·∫ßu ƒê·ªÅ Dynamic.
    """
    # Mapping t√™n c·ªôt sang index trong all_data_ai (10 c·ªôt)
    # 0:Ky, 1:Date, 2:GDB, 3:G1, 4:G2...
    col_map = {
        "GDB": 2, "G1": 3, 
        "G2": 4, "G2.1": 4, "G2.2": 4,
        "G3": 5, "G4": 6, "G5": 7, "G6": 8, "G7": 9
    }
    
    base_name = col_name.split(".")[0]
    idx = col_map.get(base_name)
    
    if idx is None or idx >= len(row): return None
    
    val_str = str(row[idx])
    # L·∫•y s·ªë cu·ªëi c√πng trong chu·ªói gi·∫£i
    digits = ''.join(filter(str.isdigit, val_str))
    if not digits: return None
    
    return int(digits[-1])

def get_latest_ky_date(conn):
    """
    L·∫•y k·ª≥ m·ªõi nh·∫•t v√† ng√†y t∆∞∆°ng ·ª©ng t·ª´ CSDL ƒë·ªÉ ki·ªÉm tra tr√πng l·∫∑p khi n·∫°p th√™m.
    Tr·∫£ v·ªÅ: (latest_ky_str, latest_date_str) ho·∫∑c (None, None)
    """
    try:
        cursor = conn.cursor()
        # ∆Øu ti√™n l·∫•y t·ª´ b·∫£ng results_A_I (d·ªØ li·ªáu ch√≠nh)
        cursor.execute("SELECT ky, date FROM results_A_I ORDER BY CAST(ky AS INTEGER) DESC LIMIT 1")
        row = cursor.fetchone()
        if row:
            return str(row[0]), str(row[1])
            
        # N·∫øu kh√¥ng c√≥, th·ª≠ b·∫£ng DuLieu_AI
        cursor.execute("SELECT Col_A_Ky FROM DuLieu_AI ORDER BY MaSoKy DESC LIMIT 1")
        row = cursor.fetchone()
        if row:
            return str(row[0]), None
            
        return None, None
    except Exception as e:
        print(f"L·ªói get_latest_ky_date: {e}")
        return None, None

def get_bridge_by_name(bridge_name, db_name=DB_NAME):
    """
    [FIXED V10.2] L·∫•y th√¥ng tin chi ti·∫øt m·ªôt c·∫ßu theo t√™n.
    Tr·∫£ v·ªÅ Dict ƒë·∫ßy ƒë·ªß (bao g·ªìm pos1_idx, pos2_idx) ƒë·ªÉ ch·∫°y Backtest Popup.
    """
    conn = None
    try:
        conn = sqlite3.connect(db_name)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        cursor.execute("SELECT * FROM ManagedBridges WHERE name = ?", (bridge_name,))
        row = cursor.fetchone()
        
        if row:
            return dict(row)
        return None
    except Exception as e:
        print(f"L·ªói get_bridge_by_name: {e}")
        return None
    finally:
        if conn: conn.close()


def delete_managed_bridges_batch(
    names: list,
    db_name: str = None,
    transactional: bool = False,
    chunk_size: int = 500,
) -> dict:
    """
    Delete bridges by name in batch.

    Args:
        names: list of bridge names (strings)
        db_name: path to sqlite DB
        transactional: if True try to delete all in a single transaction (may lock)
        chunk_size: when not transactional, delete in chunks of this size

    Returns:
        dict: {
            "requested": int,
            "deleted": [names...],
            "missing": [names...],
            "failed": [{"name": name, "error": str}],
        }
    """
    if db_name is None:
        db_name = DB_NAME

    result = {"requested": len(names), "deleted": [], "missing": [], "failed": []}
    if not names:
        return result

    # Normalize unique names preserving order
    unique_names = list(dict.fromkeys(names))

    def _select_existing(cursor, chunk):
        placeholders = ",".join("?" for _ in chunk)
        cursor.execute(f"SELECT name FROM ManagedBridges WHERE name IN ({placeholders})", chunk)
        return {row[0] for row in cursor.fetchall()}

    try:
        conn = sqlite3.connect(db_name, timeout=30)
        cur = conn.cursor()

        if transactional:
            try:
                conn.execute("BEGIN")
                existing = _select_existing(cur, unique_names)
                missing = [n for n in unique_names if n not in existing]
                if existing:
                    placeholders = ",".join("?" for _ in unique_names)
                    cur.execute(f"DELETE FROM ManagedBridges WHERE name IN ({placeholders})", unique_names)
                conn.commit()
                result["deleted"] = list(existing)
                result["missing"] = missing
            except Exception as e:
                conn.rollback()
                result["failed"].append({"error": str(e)})
            finally:
                conn.close()
            return result

        # Best-effort chunked deletes
        existing = set()
        for i in range(0, len(unique_names), chunk_size):
            chunk = unique_names[i : i + chunk_size]
            existing.update(_select_existing(cur, chunk))
        result["missing"] = [n for n in unique_names if n not in existing]

        # Delete existing in chunks
        for i in range(0, len(unique_names), chunk_size):
            chunk = [n for n in unique_names[i : i + chunk_size] if n in existing]
            if not chunk:
                continue
            try:
                placeholders = ",".join("?" for _ in chunk)
                cur.execute(f"DELETE FROM ManagedBridges WHERE name IN ({placeholders})", chunk)
                conn.commit()
                result["deleted"].extend(chunk)
            except Exception as e:
                conn.rollback()
                for n in chunk:
                    result["failed"].append({"name": n, "error": str(e)})
        conn.close()
    except Exception as e_outer:
        result["failed"].append({"error": str(e_outer)})
    return result

--------------------------------------------------

=== FILE: logic\db_manager.py ===
# T√™n file: logic/db_manager.py
# (PHI√äN B·∫¢N V8.5 - FIX CRITICAL: CACHE WRITE & SELF-HEALING N/A)

import sqlite3
import os
import time
from typing import List, Dict, Set, Optional, Tuple, Any

# --- C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N DB TUY·ªÜT ƒê·ªêI ---
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
data_dir = os.path.join(project_root, "data")

if not os.path.exists(data_dir):
    try:
        os.makedirs(data_dir)
        print(f">>> ƒê√£ t·ª± ƒë·ªông t·∫°o th∆∞ m·ª•c: {data_dir}")
    except Exception as e:
        print(f"L·ªñI: Kh√¥ng th·ªÉ t·∫°o th∆∞ m·ª•c data: {e}")

DB_NAME = os.path.join(data_dir, "xo_so_prizes_all_logic.db")
# ----------------------------------------

# ===================================================================================
# I. H√ÄM THI·∫æT L·∫¨P CSDL
# ===================================================================================

def setup_database(db_name=DB_NAME):
    conn = sqlite3.connect(db_name)
    cursor = conn.cursor()

    # B·∫£ng 1: DuLieu_AI
    cursor.execute(
        """
    CREATE TABLE IF NOT EXISTS DuLieu_AI (
        MaSoKy INTEGER PRIMARY KEY,
        Col_A_Ky TEXT,
        Col_B_GDB TEXT, Col_C_G1 TEXT, Col_D_G2 TEXT, Col_E_G3 TEXT,
        Col_F_G4 TEXT, Col_G_G5 TEXT, Col_H_G6 TEXT, Col_I_G7 TEXT
    )"""
    )

    # B·∫£ng 2: results_A_I
    cursor.execute(
        """
    CREATE TABLE IF NOT EXISTS results_A_I (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        ky TEXT UNIQUE,
        date TEXT,
        gdb TEXT, g1 TEXT, g2 TEXT, g3 TEXT, g4 TEXT, g5 TEXT, g6 TEXT, g7 TEXT,
        l0 TEXT, l1 TEXT, l2 TEXT, l3 TEXT, l4 TEXT, l5 TEXT, l6 TEXT, l7 TEXT, l8 TEXT, l9 TEXT,
        l10 TEXT, l11 TEXT, l12 TEXT, l13 TEXT, l14 TEXT, l15 TEXT, l16 TEXT, l17 TEXT, l18 TEXT, l19 TEXT,
        l20 TEXT, l21 TEXT, l22 TEXT, l23 TEXT, l24 TEXT, l25 TEXT, l26 TEXT
    )"""
    )

    # B·∫£ng 3: ManagedBridges (Update V8.5)
    cursor.execute(
        """
    CREATE TABLE IF NOT EXISTS ManagedBridges (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        name TEXT UNIQUE NOT NULL,
        description TEXT,
        is_enabled INTEGER DEFAULT 1,
        date_added TEXT DEFAULT (datetime('now', 'localtime')),
        win_rate_text TEXT DEFAULT 'N/A',
        current_streak INTEGER DEFAULT 0,
        next_prediction_stl TEXT DEFAULT 'N/A',
        pos1_idx INTEGER,
        pos2_idx INTEGER,
        max_lose_streak_k2n INTEGER DEFAULT 0,
        recent_win_count_10 INTEGER DEFAULT 0,
        search_rate_text TEXT DEFAULT '0.00%',
        search_period INTEGER DEFAULT 0,
        is_pinned INTEGER DEFAULT 0,
        type TEXT DEFAULT 'UNKNOWN'
    )"""
    )

    # Self-Healing: Th√™m c·ªôt n·∫øu thi·∫øu (Migration)
    # V11.2: K1N-primary detection flow - add rate columns
    columns_to_add = [
        ("max_lose_streak_k2n", "INTEGER DEFAULT 0"),
        ("recent_win_count_10", "INTEGER DEFAULT 0"),
        ("is_pinned", "INTEGER DEFAULT 0"),
        ("search_rate_text", "TEXT DEFAULT '0.00%'"),
        ("search_period", "INTEGER DEFAULT 0"),
        ("type", "TEXT DEFAULT 'UNKNOWN'"),
        # K1N/K2N rate columns (V11.2)
        ("k1n_rate_lo", "REAL DEFAULT 0.0"),
        ("k1n_rate_de", "REAL DEFAULT 0.0"),
        ("k2n_rate_lo", "REAL DEFAULT 0.0"),
        ("k2n_rate_de", "REAL DEFAULT 0.0"),
        ("is_pending", "INTEGER DEFAULT 1"),
        ("imported_at", "TEXT DEFAULT (datetime('now','localtime'))")
    ]
    
    for col_name, col_type in columns_to_add:
        try:
            cursor.execute(f"ALTER TABLE ManagedBridges ADD COLUMN {col_name} {col_type}")
        except sqlite3.OperationalError:
            pass

    # Indexes
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_results_ky ON results_A_I(ky)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_dulieu_masoky ON DuLieu_AI(MaSoKy)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_bridges_enabled ON ManagedBridges(is_enabled)")

    conn.commit()
    return conn, cursor

# ===================================================================================
# II. H√ÄM TRUY V·∫§N C∆† B·∫¢N
# ===================================================================================

def get_db_connection(db_name=DB_NAME):
    return sqlite3.connect(db_name)

def get_results_by_ky(ky_id, db_name=DB_NAME):
    conn = None
    try:
        conn = sqlite3.connect(db_name)
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM results_A_I WHERE ky = ?", (ky_id,))
        row = cursor.fetchone()
        return row
    except Exception as e:
        print(f"L·ªói get_results_by_ky: {e}")
        return None
    finally:
        if conn: conn.close()

def get_all_kys_from_db(db_name=DB_NAME):
    conn = None
    try:
        conn = sqlite3.connect(db_name)
        cursor = conn.cursor()
        cursor.execute("SELECT ky, date FROM results_A_I ORDER BY CAST(ky AS INTEGER) DESC")
        return cursor.fetchall()
    except Exception as e:
        print(f"L·ªói get_all_kys_from_db: {e}")
        return []
    finally:
        if conn: conn.close()

def delete_ky_from_db(ky, db_name=DB_NAME):
    conn = None
    try:
        conn = sqlite3.connect(db_name)
        cursor = conn.cursor()
        cursor.execute("DELETE FROM results_A_I WHERE ky = ?", (ky,))
        c1 = cursor.rowcount
        cursor.execute("DELETE FROM DuLieu_AI WHERE Col_A_Ky = ?", (ky,))
        c2 = cursor.rowcount
        conn.commit()
        return True, f"ƒê√£ x√≥a k·ª≥ {ky} ({c1+c2} b·∫£n ghi)"
    except Exception as e:
        return False, f"L·ªói khi x√≥a: {e}"
    finally:
        if conn: conn.close()

# ===================================================================================
# III. H√ÄM QU·∫¢N L√ù C·∫¶U (CRUD - CORE LOGIC)
# ===================================================================================

def delete_all_managed_bridges(conn):
    try:
        conn.cursor().execute("DELETE FROM ManagedBridges")
        print("ƒê√£ x√≥a s·∫°ch C·∫ßu ƒê√£ L∆∞u (ManagedBridges).")
        return True
    except Exception as e:
        print(f"L·ªói delete_all_managed_bridges: {e}")
        return False

def add_managed_bridge(bridge_name, description, db_name=DB_NAME):
    # H√†m n√†y gi·ªØ l·∫°i ƒë·ªÉ t∆∞∆°ng th√≠ch ng∆∞·ª£c, logic ch√≠nh n√™n d√πng upsert
    return upsert_managed_bridge(bridge_name, description, db_name=db_name)

def update_managed_bridge(bridge_id, description=None, is_enabled=None, db_name=DB_NAME, updates=None):
    """
    C·∫≠p nh·∫≠t c·∫ßu trong database v·ªõi h·ªó tr·ª£ c·∫≠p nh·∫≠t ƒë·ªông.
    """
    conn = None
    try:
        conn = sqlite3.connect(db_name)
        cursor = conn.cursor()
        
        if updates is None: updates = {}
        if description is not None: updates['description'] = description
        if is_enabled is not None: updates['is_enabled'] = 1 if is_enabled else 0
        
        set_parts = []
        values = []

        allowed_fields = [
            'description', 'is_enabled', 'win_rate_text', 'max_lose_streak', 'recent_win_count_10',
            'pos1_idx', 'pos2_idx', 'search_rate_text', 'search_period', 'type'
        ]
        
        field_mapping = {'max_lose_streak': 'max_lose_streak_k2n'}
        
        for field in allowed_fields:
            if field in updates:
                db_field = field_mapping.get(field, field)
                set_parts.append(f"{db_field}=?")
                values.append(updates[field])

        if not set_parts: return True, "Kh√¥ng c√≥ tr∆∞·ªùng n√†o ƒë·ªÉ c·∫≠p nh·∫≠t."
        
        sql_update = f"UPDATE ManagedBridges SET {', '.join(set_parts)} WHERE id=?"
        values.append(bridge_id)
        
        cursor.execute(sql_update, values)
        conn.commit()
        return True, "C·∫≠p nh·∫≠t th√†nh c√¥ng."
    except Exception as e:
        return False, f"L·ªói update_managed_bridge: {e}"
    finally:
        if conn: conn.close()

def delete_managed_bridge(bridge_id, db_name=DB_NAME):
    conn = None
    try:
        conn = sqlite3.connect(db_name)
        cursor = conn.cursor()
        cursor.execute("DELETE FROM ManagedBridges WHERE id = ?", (bridge_id,))
        conn.commit()
        return True, "X√≥a c·∫ßu th√†nh c√¥ng."
    except Exception as e:
        return False, f"L·ªói delete_managed_bridge: {e}"
    finally:
        if conn: conn.close()


def delete_managed_bridges(ids_list, db_name=DB_NAME):
    """
    X√≥a nhi·ªÅu c·∫ßu c√πng l√∫c theo danh s√°ch IDs.
    V11.1: Bulk delete operation with logging.
    
    Args:
        ids_list: List of bridge IDs to delete
        db_name: Database name
    
    Returns:
        Tuple (success: bool, message: str, deleted_count: int)
    """
    conn = None
    try:
        if not ids_list:
            return True, "Kh√¥ng c√≥ c·∫ßu n√†o ƒë·ªÉ x√≥a.", 0
        
        conn = sqlite3.connect(db_name)
        cursor = conn.cursor()
        
        # Build placeholders for IN clause
        placeholders = ','.join('?' * len(ids_list))
        sql_delete = f"DELETE FROM ManagedBridges WHERE id IN ({placeholders})"
        
        cursor.execute(sql_delete, ids_list)
        deleted_count = cursor.rowcount
        conn.commit()
        
        return True, f"ƒê√£ x√≥a {deleted_count} c·∫ßu th√†nh c√¥ng.", deleted_count
    except Exception as e:
        if conn:
            conn.rollback()
        return False, f"L·ªói delete_managed_bridges: {e}", 0
    finally:
        if conn: conn.close()

def toggle_pin_bridge(bridge_name, db_name=DB_NAME):
    conn = None
    try:
        conn = sqlite3.connect(db_name)
        cursor = conn.cursor()
        cursor.execute("SELECT is_pinned FROM ManagedBridges WHERE name = ?", (bridge_name,))
        row = cursor.fetchone()
        
        if not row: return False, f"Kh√¥ng t√¨m th·∫•y c·∫ßu '{bridge_name}'", None
        
        current_pin = row[0] if row[0] is not None else 0
        new_pin = 1 if current_pin == 0 else 0
        
        cursor.execute("UPDATE ManagedBridges SET is_pinned = ? WHERE name = ?", (new_pin, bridge_name))
        conn.commit()
        
        action = "ƒë√£ ghim" if new_pin == 1 else "ƒë√£ b·ªè ghim"
        return True, f"C·∫ßu '{bridge_name}' {action}.", bool(new_pin)
    except Exception as e:
        return False, f"L·ªói toggle_pin_bridge: {e}", None
    finally:
        if conn: conn.close()

def _upsert_managed_bridge_impl(conn, bridge_dict, db_name=DB_NAME):
    """
    Implementation c·ªßa upsert_managed_bridge.
    Internal function - n√™n g·ªçi qua wrapper upsert_managed_bridge().
    """
    cursor = conn.cursor()
    
    # Normalize key names
    name = bridge_dict.get('name') or bridge_dict.get('ten') or bridge_dict.get('bridge_name')
    if not name:
        raise ValueError("Bridge name is required")
    
    description = bridge_dict.get('description') or bridge_dict.get('mo_ta', '')
    win_rate_text = bridge_dict.get('win_rate_text') or bridge_dict.get('win_rate') or bridge_dict.get('ty_le', 'N/A')
    pos1_idx = bridge_dict.get('pos1_idx')
    pos2_idx = bridge_dict.get('pos2_idx')
    bridge_type = bridge_dict.get('type') or bridge_dict.get('loai', 'UNKNOWN')
    is_enabled = bridge_dict.get('is_enabled', 1)
    search_rate_text = bridge_dict.get('search_rate_text', '0.00%')
    search_period = bridge_dict.get('search_period', 0)
    max_lose_streak = bridge_dict.get('max_lose_streak', 0)
    recent_win_count_10 = bridge_dict.get('recent_win_count_10', 0)
    
    # Ki·ªÉm tra t·ªìn t·∫°i
    cursor.execute("SELECT * FROM ManagedBridges WHERE name = ?", (name,))
    existing_row = cursor.fetchone()
    
    if existing_row:
        cursor.execute("PRAGMA table_info(ManagedBridges)")
        col_names = [c[1] for c in cursor.fetchall()]
        existing_data = dict(zip(col_names, existing_row))
    else:
        existing_data = None

    if not existing_data:
        # INSERT M·ªöI
        # M·∫∑c ƒë·ªãnh: N·∫øu c√≥ search_rate th√¨ d√πng n√≥ cho c·∫£ win_rate ƒë·ªÉ tr√°nh N/A ban ƒë·∫ßu
        if win_rate_text == 'N/A' and search_rate_text != '0.00%':
            win_rate_text = search_rate_text

        sql_insert = """
        INSERT INTO ManagedBridges (
            name, pos1_idx, pos2_idx, is_enabled, win_rate_text, max_lose_streak_k2n, recent_win_count_10, 
            search_rate_text, search_period, description, type
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """
        values = (
            name, pos1_idx, pos2_idx, is_enabled,
            win_rate_text, max_lose_streak, recent_win_count_10,
            search_rate_text, search_period, description, bridge_type
        )
        cursor.execute(sql_insert, values)
        success_msg = f"ƒê√£ th√™m c·∫ßu m·ªõi '{name}'."
    else:
        # UPDATE
        # Logic: Ch·ªâ c·∫≠p nh·∫≠t search_rate n·∫øu c√≥ input m·ªõi
        # Gi·ªØ nguy√™n c√°c tr∆∞·ªùng n·∫øu input kh√¥ng c√≥
        new_search_rate = search_rate_text if search_rate_text != '0.00%' else existing_data.get('search_rate_text')
        new_win_rate = win_rate_text if win_rate_text != 'N/A' else existing_data.get('win_rate_text')
        
        # Self-Healing: N·∫øu Win Rate c≈© l√† N/A m√† Search Rate m·ªõi c√≥ d·ªØ li·ªáu -> Update Win Rate lu√¥n
        if (not new_win_rate or new_win_rate == 'N/A') and (new_search_rate and new_search_rate != '0.00%'):
            new_win_rate = new_search_rate

        sql_update = """
        UPDATE ManagedBridges SET 
            pos1_idx=?, pos2_idx=?, is_enabled=?, win_rate_text=?, 
            max_lose_streak_k2n=?, recent_win_count_10=?, description=?,
            search_rate_text=?, search_period=?, type=?
        WHERE name=?
        """
        values_update = (
            pos1_idx if pos1_idx is not None else existing_data.get('pos1_idx'),
            pos2_idx if pos2_idx is not None else existing_data.get('pos2_idx'),
            is_enabled,
            new_win_rate,
            max_lose_streak if max_lose_streak > 0 else existing_data.get('max_lose_streak_k2n'),
            recent_win_count_10 if recent_win_count_10 > 0 else existing_data.get('recent_win_count_10'),
            description,
            new_search_rate,
            search_period if search_period > 0 else existing_data.get('search_period'),
            bridge_type,
            name
        )
        cursor.execute(sql_update, values_update)
        success_msg = f"ƒê√£ C·∫¨P NH·∫¨T c·∫ßu '{name}'."

    return True, success_msg


def upsert_managed_bridge(bridge_name=None, description=None, win_rate=None, db_name=DB_NAME, pos1_idx=None, pos2_idx=None, bridge_data=None, **kwargs):
    """
    Ch√®n ho·∫∑c c·∫≠p nh·∫≠t c·∫ßu trong database.
    (V8.5: Logic b·∫£o v·ªá Search Rate v√† Win Rate)
    (V11.1: Shim wrapper h·ªó tr·ª£ dict ho·∫∑c kwargs)
    
    Accepts:
      - upsert_managed_bridge(name="...", description="...", ...)  # kwargs
      - upsert_managed_bridge(bridge_dict={"name": "...", ...})    # dict via kwargs
      - upsert_managed_bridge("name", "desc", ...)                  # positional
    """
    conn = None
    try:
        conn = sqlite3.connect(db_name)
        
        # Determine if we're using dict or individual params
        if bridge_data is not None:
            # Legacy mode: bridge_data dict provided
            bridge_dict = bridge_data.copy()
            if bridge_name: bridge_dict['name'] = bridge_name
            if description: bridge_dict['description'] = description
            if win_rate: bridge_dict['win_rate_text'] = win_rate
            if pos1_idx is not None: bridge_dict['pos1_idx'] = pos1_idx
            if pos2_idx is not None: bridge_dict['pos2_idx'] = pos2_idx
        elif kwargs.get('bridge_dict'):
            # New mode: bridge_dict passed as kwarg
            bridge_dict = kwargs['bridge_dict'].copy()
        elif bridge_name or kwargs:
            # Build dict from individual params
            bridge_dict = kwargs.copy()
            if bridge_name: bridge_dict['name'] = bridge_name
            if description: bridge_dict['description'] = description
            if win_rate: bridge_dict['win_rate_text'] = win_rate
            if pos1_idx is not None: bridge_dict['pos1_idx'] = pos1_idx
            if pos2_idx is not None: bridge_dict['pos2_idx'] = pos2_idx
        else:
            raise ValueError("No bridge data provided")
        
        success, msg = _upsert_managed_bridge_impl(conn, bridge_dict, db_name)
        conn.commit()
        return success, msg

    except Exception as e:
        if conn:
            conn.rollback()
        return False, f"L·ªói upsert_managed_bridge: {e}"
    finally:
        if conn: conn.close()


def update_bridge_k2n_cache_batch(cache_data_list, db_name=DB_NAME):
    """
    [FIXED V8.5] C·∫≠p nh·∫≠t Cache K2N.
    FEATURE: T·ª± ƒë·ªông "v√°" (Self-Heal) win_rate_text n·∫øu n√≥ ƒëang l√† N/A.
    """
    updated_count = 0
    conn = None
    try:
        conn = sqlite3.connect(db_name)
        cursor = conn.cursor()
        
        # 1. Update chu·∫©n: Search Rate, Streak, Pred...
        sql_update_standard = """
        UPDATE ManagedBridges
        SET search_rate_text = ?, current_streak = ?, next_prediction_stl = ?, max_lose_streak_k2n = ?
        WHERE name = ?
        """
        
        # 2. Update Self-Healing: Copy search_rate v√†o win_rate n·∫øu win_rate ƒëang N/A
        sql_update_healing = """
        UPDATE ManagedBridges
        SET win_rate_text = search_rate_text
        WHERE name = ? AND (win_rate_text IS NULL OR win_rate_text = 'N/A' OR win_rate_text = '')
        """
        
        cache_data_fixed = []
        names_to_heal = []
        
        for row in cache_data_list:
            # row: (rate, streak, pred, max_lose, recent_win, name) -> t·ª´ backtester_core
            # Nh∆∞ng h√†m g·ªçi truy·ªÅn v√†o list tuple: (rate, streak, pred, max_lose, name)
            if len(row) >= 5:
                cache_data_fixed.append((row[0], row[1], row[2], row[3], row[4])) # D√πng index 4 cho name n·∫øu len=5
                names_to_heal.append((row[4],)) # Tuple cho executemany
            elif len(row) == 6: # Format ƒë·∫ßy ƒë·ªß t·ª´ backtester
                cache_data_fixed.append((row[0], row[1], row[2], row[3], row[5])) # D√πng index 5 cho name
                names_to_heal.append((row[5],))

        # Th·ª±c thi Update chu·∫©n
        cursor.executemany(sql_update_standard, cache_data_fixed)
        updated_count = cursor.rowcount
        
        # Th·ª±c thi Self-Healing
        cursor.executemany(sql_update_healing, names_to_heal)
        healed_count = cursor.rowcount
        
        conn.commit()
        return True, f"ƒê√£ c·∫≠p nh·∫≠t K2N cho {updated_count} c·∫ßu. (T·ª± v√° l·ªói N/A cho {healed_count} c·∫ßu)"
    except Exception as e:
        return False, f"L·ªói SQL cache K2N: {e}"
    finally:
        if conn: conn.close()

def update_bridge_win_rate_batch(rate_data_list, db_name=DB_NAME):
    """
    C·∫≠p nh·∫≠t K1N (Th·ª±c t·∫ø).
    """
    updated_count = 0
    conn = None
    try:
        conn = sqlite3.connect(db_name)
        cursor = conn.cursor()
        sql_update = "UPDATE ManagedBridges SET win_rate_text = ?, is_enabled = 1 WHERE name = ?"
        cursor.executemany(sql_update, rate_data_list)
        updated_count = cursor.rowcount
        conn.commit()
        return True, f"ƒê√£ c·∫≠p nh·∫≠t T·ª∑ L·ªá N1 cho {updated_count} c·∫ßu."
    except Exception as e:
        return False, f"L·ªói SQL c·∫≠p nh·∫≠t T·ª∑ L·ªá N1: {e}"
    finally:
        if conn: conn.close()

def update_bridge_recent_win_count_batch(recent_win_data_list, db_name=DB_NAME):
    updated_count = 0
    conn = None
    try:
        conn = sqlite3.connect(db_name)
        cursor = conn.cursor()
        sql_update = "UPDATE ManagedBridges SET recent_win_count_10 = ? WHERE name = ?"
        cursor.executemany(sql_update, recent_win_data_list)
        updated_count = cursor.rowcount
        conn.commit()
        return True, f"ƒê√£ c·∫≠p nh·∫≠t Phong ƒê·ªô 10 K·ª≥ cho {updated_count} c·∫ßu."
    except Exception as e:
        return False, f"L·ªói SQL c·∫≠p nh·∫≠t Phong ƒê·ªô 10 K·ª≥: {e}"
    finally:
        if conn: conn.close()


# ===================================================================================
# IV. K1N-PRIMARY BULK IMPORT APIs (V11.2)
# ===================================================================================

def get_all_managed_bridge_names(db_name: str = DB_NAME) -> Set[str]:
    """
    Get all managed bridge names from database.
    
    Returns normalized bridge names for efficient duplicate checking.
    Used by scanner to exclude existing bridges.
    
    Args:
        db_name: Database file path
        
    Returns:
        Set of normalized bridge names (lowercase, no special chars)
        
    Example:
        >>> names = get_all_managed_bridge_names()
        >>> 'cau-de-01' in names  # Fast O(1) lookup
        True
    """
    conn = None
    try:
        conn = sqlite3.connect(db_name)
        cursor = conn.cursor()
        cursor.execute("SELECT name FROM ManagedBridges")
        rows = cursor.fetchall()
        
        # Import normalize function
        try:
            from logic.common_utils import normalize_bridge_name
        except ImportError:
            # Fallback: simple normalization
            def normalize_bridge_name(name):
                return str(name).strip().lower()
        
        return {normalize_bridge_name(row[0]) for row in rows if row[0]}
    except Exception as e:
        print(f"[ERROR] get_all_managed_bridge_names: {e}")
        return set()
    finally:
        if conn:
            conn.close()


def load_rates_cache(db_name: str = DB_NAME) -> Dict[str, Dict[str, float]]:
    """
    Load K1N/K2N rates cache from ManagedBridges table.
    
    Returns a dictionary mapping normalized bridge names to their rates.
    Used by scanners to attach rate information to candidates.
    
    Args:
        db_name: Database file path
        
    Returns:
        Dict[normalized_name, rates_dict] where rates_dict contains:
            - k1n_rate_lo: K1N rate for LO bridges
            - k1n_rate_de: K1N rate for DE bridges  
            - k2n_rate_lo: K2N rate for LO bridges
            - k2n_rate_de: K2N rate for DE bridges
            
    Example:
        >>> cache = load_rates_cache()
        >>> rates = cache.get('cau-de-01', {})
        >>> k1n_de = rates.get('k1n_rate_de', 0.0)
    """
    conn = None
    try:
        conn = sqlite3.connect(db_name)
        cursor = conn.cursor()
        
        # Load all bridges with their rates
        cursor.execute("""
            SELECT name, k1n_rate_lo, k1n_rate_de, k2n_rate_lo, k2n_rate_de
            FROM ManagedBridges
        """)
        rows = cursor.fetchall()
        
        # Import normalize function
        try:
            from logic.common_utils import normalize_bridge_name
        except ImportError:
            # Fallback: simple normalization
            def normalize_bridge_name(name):
                return str(name).strip().lower()
        
        # Build cache dictionary
        cache = {}
        for row in rows:
            if not row[0]:
                continue
                
            name = row[0]
            normalized = normalize_bridge_name(name)
            
            cache[normalized] = {
                'k1n_rate_lo': row[1] if row[1] is not None else 0.0,
                'k1n_rate_de': row[2] if row[2] is not None else 0.0,
                'k2n_rate_lo': row[3] if row[3] is not None else 0.0,
                'k2n_rate_de': row[4] if row[4] is not None else 0.0,
            }
        
        return cache
    except Exception as e:
        print(f"[ERROR] load_rates_cache: {e}")
        return {}
    finally:
        if conn:
            conn.close()


def bulk_upsert_managed_bridges(
    bridges: List[Dict[str, Any]], 
    db_name: str = DB_NAME,
    transactional: bool = True
) -> Dict[str, int]:
    """
    Bulk upsert managed bridges with atomic transaction support.
    
    Performs efficient INSERT/UPDATE operations using executemany.
    Includes retry logic for sqlite3.OperationalError (database locked).
    
    Args:
        bridges: List of bridge dictionaries with keys:
            - name (required): Bridge name
            - description: Bridge description
            - type: Bridge type (LO_*, DE_*)
            - k1n_rate_lo: K1N rate for LO
            - k1n_rate_de: K1N rate for DE
            - k2n_rate_lo: K2N rate for LO
            - k2n_rate_de: K2N rate for DE
            - is_pending: Whether bridge is pending approval (0 or 1)
            - is_enabled: Whether bridge is enabled (0 or 1)
            - pos1_idx, pos2_idx: Position indices
            - Other optional fields...
            
        db_name: Database file path
        transactional: If True, all operations in single transaction (rollback on error)
        
    Returns:
        Dict with keys: 'added', 'updated', 'skipped', 'errors'
        
    Example:
        >>> bridges = [
        ...     {'name': 'Bridge-01', 'type': 'DE_DYN', 'k1n_rate_de': 95.5},
        ...     {'name': 'Bridge-02', 'type': 'LO_V16', 'k1n_rate_lo': 87.3}
        ... ]
        >>> result = bulk_upsert_managed_bridges(bridges)
        >>> print(f"Added: {result['added']}, Updated: {result['updated']}")
    """
    stats = {'added': 0, 'updated': 0, 'skipped': 0, 'errors': 0}
    
    if not bridges:
        return stats
    
    conn = None
    max_retries = 3
    retry_delay = 0.1  # Start with 100ms
    
    for attempt in range(max_retries):
        try:
            conn = sqlite3.connect(db_name, timeout=10.0)
            cursor = conn.cursor()
            
            # Get existing bridges for duplicate check
            cursor.execute("SELECT name FROM ManagedBridges")
            existing_names = {row[0].strip().lower() for row in cursor.fetchall()}
            
            # Prepare batch operations
            to_insert = []
            to_update = []
            
            for bridge in bridges:
                name = bridge.get('name')
                if not name:
                    stats['skipped'] += 1
                    continue
                
                # Check if exists
                is_existing = name.strip().lower() in existing_names
                
                # Prepare values (with defaults)
                description = bridge.get('description', '')
                bridge_type = bridge.get('type', 'UNKNOWN')
                k1n_rate_lo = bridge.get('k1n_rate_lo', 0.0)
                k1n_rate_de = bridge.get('k1n_rate_de', 0.0)
                k2n_rate_lo = bridge.get('k2n_rate_lo', 0.0)
                k2n_rate_de = bridge.get('k2n_rate_de', 0.0)
                is_pending = bridge.get('is_pending', 1)
                is_enabled = bridge.get('is_enabled', 0)  # Default disabled for new bridges
                pos1_idx = bridge.get('pos1_idx')
                pos2_idx = bridge.get('pos2_idx')
                win_rate_text = bridge.get('win_rate_text', 'N/A')
                search_rate_text = bridge.get('search_rate_text', '0.00%')
                current_streak = bridge.get('current_streak', 0)
                next_prediction_stl = bridge.get('next_prediction_stl', 'N/A')
                
                if is_existing:
                    # UPDATE
                    to_update.append((
                        description, bridge_type, k1n_rate_lo, k1n_rate_de,
                        k2n_rate_lo, k2n_rate_de, is_pending, is_enabled,
                        pos1_idx, pos2_idx, win_rate_text, search_rate_text,
                        current_streak, next_prediction_stl,
                        name  # WHERE clause
                    ))
                else:
                    # INSERT
                    to_insert.append((
                        name, description, bridge_type, k1n_rate_lo, k1n_rate_de,
                        k2n_rate_lo, k2n_rate_de, is_pending, is_enabled,
                        pos1_idx, pos2_idx, win_rate_text, search_rate_text,
                        current_streak, next_prediction_stl
                    ))
            
            # Execute batch INSERT
            if to_insert:
                sql_insert = """
                INSERT INTO ManagedBridges (
                    name, description, type, k1n_rate_lo, k1n_rate_de,
                    k2n_rate_lo, k2n_rate_de, is_pending, is_enabled,
                    pos1_idx, pos2_idx, win_rate_text, search_rate_text,
                    current_streak, next_prediction_stl
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """
                cursor.executemany(sql_insert, to_insert)
                # Note: cursor.rowcount with executemany is unreliable in SQLite
                # Use actual count from prepared list
                stats['added'] = len(to_insert)
            
            # Execute batch UPDATE
            if to_update:
                sql_update = """
                UPDATE ManagedBridges SET
                    description=?, type=?, k1n_rate_lo=?, k1n_rate_de=?,
                    k2n_rate_lo=?, k2n_rate_de=?, is_pending=?, is_enabled=?,
                    pos1_idx=?, pos2_idx=?, win_rate_text=?, search_rate_text=?,
                    current_streak=?, next_prediction_stl=?
                WHERE name=?
                """
                cursor.executemany(sql_update, to_update)
                # Note: cursor.rowcount with executemany is unreliable in SQLite
                # Use actual count from prepared list
                stats['updated'] = len(to_update)
            
            # Commit transaction
            if transactional:
                conn.commit()
            
            print(f"[INFO] bulk_upsert: Added {stats['added']}, Updated {stats['updated']}, Skipped {stats['skipped']}")
            return stats
            
        except sqlite3.OperationalError as e:
            # Database locked - retry with exponential backoff
            if attempt < max_retries - 1:
                print(f"[WARN] Database locked, retrying in {retry_delay}s... (attempt {attempt+1}/{max_retries})")
                time.sleep(retry_delay)
                retry_delay *= 2  # Exponential backoff
                if conn:
                    try:
                        conn.close()
                    except:
                        pass
                continue
            else:
                print(f"[ERROR] bulk_upsert failed after {max_retries} attempts: {e}")
                stats['errors'] = len(bridges) - stats['added'] - stats['updated'] - stats['skipped']
                if conn and transactional:
                    conn.rollback()
                return stats
                
        except Exception as e:
            print(f"[ERROR] bulk_upsert_managed_bridges: {e}")
            stats['errors'] = len(bridges) - stats['added'] - stats['updated'] - stats['skipped']
            if conn and transactional:
                conn.rollback()
            return stats
        finally:
            if conn:
                conn.close()
    
    return stats


def update_managed_bridges_batch(
    updates: List[Dict[str, Any]],
    db_name: str = DB_NAME
) -> Dict[str, int]:
    """
    Update multiple managed bridges in a single transaction.
    
    Args:
        updates: List of update dictionaries with 'name' (required) and fields to update
        db_name: Database file path
        
    Returns:
        Dict with keys: 'updated', 'skipped', 'errors'
        
    Example:
        >>> updates = [
        ...     {'name': 'Bridge-01', 'is_enabled': 1, 'k1n_rate_lo': 92.0},
        ...     {'name': 'Bridge-02', 'is_pending': 0}
        ... ]
        >>> result = update_managed_bridges_batch(updates)
    """
    stats = {'updated': 0, 'skipped': 0, 'errors': 0}
    
    if not updates:
        return stats
    
    conn = None
    try:
        conn = sqlite3.connect(db_name)
        cursor = conn.cursor()
        
        allowed_fields = [
            'description', 'type', 'k1n_rate_lo', 'k1n_rate_de',
            'k2n_rate_lo', 'k2n_rate_de', 'is_pending', 'is_enabled',
            'pos1_idx', 'pos2_idx', 'win_rate_text', 'search_rate_text',
            'current_streak', 'next_prediction_stl', 'max_lose_streak_k2n',
            'recent_win_count_10', 'is_pinned'
        ]
        
        for update_dict in updates:
            name = update_dict.get('name')
            if not name:
                stats['skipped'] += 1
                continue
            
            # Build dynamic UPDATE query
            set_parts = []
            values = []
            
            for field in allowed_fields:
                if field in update_dict:
                    set_parts.append(f"{field}=?")
                    values.append(update_dict[field])
            
            if not set_parts:
                stats['skipped'] += 1
                continue
            
            sql_update = f"UPDATE ManagedBridges SET {', '.join(set_parts)} WHERE name=?"
            values.append(name)
            
            cursor.execute(sql_update, values)
            if cursor.rowcount > 0:
                stats['updated'] += 1
            else:
                stats['skipped'] += 1
        
        conn.commit()
        print(f"[INFO] update_batch: Updated {stats['updated']}, Skipped {stats['skipped']}")
        return stats
        
    except Exception as e:
        print(f"[ERROR] update_managed_bridges_batch: {e}")
        stats['errors'] = len(updates) - stats['updated'] - stats['skipped']
        if conn:
            conn.rollback()
        return stats
    finally:
        if conn:
            conn.close()


def delete_managed_bridges_batch(
    names: List[str],
    db_name: str = DB_NAME
) -> Dict[str, int]:
    """
    Delete multiple managed bridges by names in a single transaction.
    
    Args:
        names: List of bridge names to delete
        db_name: Database file path
        
    Returns:
        Dict with keys: 'deleted', 'errors'
        
    Example:
        >>> result = delete_managed_bridges_batch(['Bridge-01', 'Bridge-02'])
        >>> print(f"Deleted: {result['deleted']}")
    """
    stats = {'deleted': 0, 'errors': 0}
    
    if not names:
        return stats
    
    conn = None
    try:
        conn = sqlite3.connect(db_name)
        cursor = conn.cursor()
        
        # Use IN clause for efficient batch delete
        placeholders = ','.join('?' * len(names))
        sql_delete = f"DELETE FROM ManagedBridges WHERE name IN ({placeholders})"
        
        cursor.execute(sql_delete, names)
        stats['deleted'] = cursor.rowcount
        
        conn.commit()
        print(f"[INFO] delete_batch: Deleted {stats['deleted']} bridges")
        return stats
        
    except Exception as e:
        print(f"[ERROR] delete_managed_bridges_batch: {e}")
        stats['errors'] = len(names)
        if conn:
            conn.rollback()
        return stats
    finally:
        if conn:
            conn.close()

--------------------------------------------------

=== FILE: logic\de_analytics.py ===
# T√™n file: code6/logic/de_analytics.py
# (PHI√äN B·∫¢N V3.9.19 - FIX: LINK TO DE_UTILS SOURCE OF TRUTH)

from collections import Counter
from itertools import combinations
from typing import List, Tuple, Optional, Dict, Any
import re

# --- IMPORT NGU·ªíN CHU·∫®N (SOURCE OF TRUTH) ---
try:
    from logic.de_utils import BO_SO_DE, get_gdb_last_2 as utils_get_gdb
except ImportError:
    # Fallback ch·ªâ d√πng khi ch·∫°y ƒë·ªôc l·∫≠p test (kh√¥ng khuy·∫øn kh√≠ch)
    BO_SO_DE = {}
    def utils_get_gdb(r): return "00"

# --- CHUY·ªÇN ƒê·ªîI D·ªÆ LI·ªÜU ---
# Analytics c·∫ßn t√≠nh to√°n s·ªë h·ªçc (int), trong khi de_utils l∆∞u string.
# Ta t·ª± ƒë·ªông convert t·ª´ BO_SO_DE chu·∫©n sang d·∫°ng int.
BO_SO_DICT = {}
if BO_SO_DE:
    for k, v_list in BO_SO_DE.items():
        # Chuy·ªÉn ["01", "10"] -> [1, 10]
        BO_SO_DICT[k] = [int(x) for x in v_list if str(x).isdigit()]
else:
    # Fallback an to√†n (tr√°nh crash n·∫øu import l·ªói)
    BO_SO_DICT = {
        "00": [0, 55, 5, 50], "11": [11, 66, 16, 61], 
        # ... (C√°c b·ªô kh√°c s·∫Ω t·ª± ƒë·ªông c√≥ n·∫øu import th√†nh c√¥ng)
    }

SCORE_CONFIG = {
    "bo_uu_tien_1": 50, "bo_uu_tien_2": 40, "cham_ti_le": 20, "cham_thong": 15,
    'DE_KILLER_MULTIPLIER': 3.0, 'DE_SET_MULTIPLIER': 2.0, 'DE_NORMAL_MULTIPLIER': 1.0,
    'DE_MARKET_CHAM_BONUS': 2.0, 'DE_MARKET_BO_BONUS': 1.0
}
SCORING_WEIGHTS = SCORE_CONFIG

# --- HELPER ---
# S·ª≠ d·ª•ng h√†m t·ª´ utils ƒë·ªÉ ƒë·ªìng b·ªô logic l·∫•y s·ªë
def local_get_gdb_last_2(row):
    return utils_get_gdb(row)

def check_cham(val_str, cham_list):
    try:
        if not val_str: return False
        n1, n2 = int(val_str[0]), int(val_str[1])
        return (n1 in cham_list) or (n2 in cham_list)
    except: return False

# =============================================================================
# LOGIC TH·ªêNG K√ä & T√çNH ƒêI·ªÇM (UPDATED)
# =============================================================================

def analyze_market_trends(all_data_ai, n_days=30):
    if not all_data_ai: return {}, {}, {}, {}, {}, {}
    recent_data = all_data_ai[-n_days:] if len(all_data_ai) > n_days else all_data_ai
    
    freq_cham, freq_tong, freq_bo = Counter(), Counter(), Counter()
    
    # T·∫ßn su·∫•t (Short-term)
    for row in recent_data:
        de = local_get_gdb_last_2(row)
        if de:
            try:
                n_val = int(de)
                n1, n2 = int(de[0]), int(de[1])
                tong = (n1 + n2) % 10
                freq_cham[n1] += 1
                if n1 != n2: freq_cham[n2] += 1
                freq_tong[tong] += 1
                for bo_name, bo_list in BO_SO_DICT.items():
                    if n_val in bo_list: freq_bo[bo_name] += 1; break
            except: continue

    # Gan (Long-term)
    total_len = len(all_data_ai)
    gan_cham = {i: total_len for i in range(10)}
    gan_bo = {bo: total_len for bo in BO_SO_DICT.keys()}
    found_cham, found_bo = set(), set()
    
    for i, row in enumerate(reversed(all_data_ai)):
        de = local_get_gdb_last_2(row)
        if de:
            try:
                n_val = int(de)
                n1, n2 = int(de[0]), int(de[1])
                if n1 not in found_cham: gan_cham[n1] = i; found_cham.add(n1)
                if n2 not in found_cham: gan_cham[n2] = i; found_cham.add(n2)
                for bo_name, bo_list in BO_SO_DICT.items():
                    if bo_name not in found_bo and n_val in bo_list:
                        gan_bo[bo_name] = i; found_bo.add(bo_name); break
            except: pass
        if len(found_cham) == 10 and len(found_bo) == len(BO_SO_DICT): break

    return {
        "freq_cham": dict(freq_cham), "freq_tong": dict(freq_tong), "freq_bo": dict(freq_bo),
        "gan_cham": gan_cham, "gan_tong": {}, "gan_bo": gan_bo
    }

# T√™n file: code6/logic/de_analytics.py
# (PHI√äN B·∫¢N V4.0 - ANTI-INFLATION: PH√ÇN T·∫¶NG ƒêI·ªÇM S·ªê)

def calculate_number_scores(bridges, market_stats=None):
    """
    T√≠nh ƒëi·ªÉm s·ªë h·ªçc [OPTIMIZED V4 - ANTI-INFLATION]:
    NgƒÉn ch·∫∑n vi·ªác spam c·∫ßu r√°c (nhi·ªÅu s·ªë) l·∫•n √°t c·∫ßu ch·∫•t l∆∞·ª£ng (√≠t s·ªë).
    
    C∆° ch·∫ø Ph√¢n T·∫ßng:
    - Tier 1 (<= 12 s·ªë): H·ªá s·ªë chu·∫©n 40.0 (∆Øu ti√™n c·ª±c cao cho B·ªô/K√©p).
    - Tier 2 (> 12 s·ªë):  H·ªá s·ªë chu·∫©n 5.0 (D√¨m ƒëi·ªÉm c·ª±c m·∫°nh cho Ch·∫°m/T·ªïng).
    => T·ª∑ l·ªá ch√™nh l·ªách: 1 C·∫ßu B·ªô = 20 C·∫ßu Ch·∫°m (thay v√¨ 2.5 nh∆∞ tr∆∞·ªõc).
    """
    scores = {f"{i:02d}": 10.0 for i in range(100)}
    bridge_count_per_num = Counter() 
    
    try:
        # --- 1. C·ªòNG ƒêI·ªÇM TH·ªêNG K√ä (Gi·ªØ nguy√™n) ---
        freq_cham = market_stats.get('freq_cham', {}) if market_stats else {}
        gan_cham = market_stats.get('gan_cham', {}) if market_stats else {}
        
        for s in scores:
            try:
                n1, n2 = int(s[0]), int(s[1])
                f_score = (freq_cham.get(n1, 0) + freq_cham.get(n2, 0)) * 0.5
                scores[s] += f_score
                g_max = max(gan_cham.get(n1, 0), gan_cham.get(n2, 0))
                if g_max > 20: scores[s] -= (g_max - 20) * 0.2
            except: pass

        # --- 2. T√çNH ƒêI·ªÇM C·∫¶U (LOGIC PH√ÇN T·∫¶NG V4) ---
        if bridges:
            for bridge in bridges:
                try:
                    streak = float(bridge.get('streak', 0))
                    val = str(bridge.get('predicted_value', ''))
                    b_type = str(bridge.get('type', '')).upper()
                    
                    # A. X√ÅC ƒê·ªäNH S·ªê L∆Ø·ª¢NG S·ªê (Target Numbers)
                    target_numbers = set()
                    
                    # ∆Øu ti√™n l·∫•y list s·ªë tr·ª±c ti·∫øp t·ª´ Scanner
                    if 'numbers' in bridge and isinstance(bridge['numbers'], list):
                        target_numbers.update(bridge['numbers'])
                    else:
                        # Fallback parsing (cho c√°c c·∫ßu c≈© ch∆∞a update scanner)
                        if 'BO' in b_type or 'SET' in b_type or 'B·ªô' in val:
                            for bo_key, bo_nums in BO_SO_DICT.items():
                                if bo_key in val or f"B·ªô {bo_key}" in val:
                                    target_numbers.update([f"{n:02d}" for n in bo_nums])
                        elif 'CHAM' in val or 'Ch·∫°m' in val or ',' in val:
                            parts = [int(v) for v in val.replace("Ch·∫°m","").replace("Lo·∫°i","").split(',') if v.strip().isdigit()]
                            if parts:
                                if 'CHAM' in val or 'Ch·∫°m' in val or 'DYNAMIC' in b_type or 'KILLER' in b_type:
                                    for p in parts:
                                        for i in range(10):
                                            target_numbers.add(f"{p}{i}"); target_numbers.add(f"{i}{p}")
                                else:
                                    target_numbers.update([f"{p:02d}" for p in parts])

                    # B. T√çNH ƒêI·ªÇM PH√ÇN T·∫¶NG (TIERED SCORING - V4)
                    count = len(target_numbers)
                    if count > 0:
                        # --- [V4 CHANGE START] ---
                        # Ph√¢n lo·∫°i giai c·∫•p c·∫ßu
                        if count <= 12: 
                            # Giai c·∫•p Th∆∞·ª£ng L∆∞u (B·ªô, K√©p, D√†n √≠t s·ªë)
                            # Th∆∞·ªüng r·∫•t l·ªõn ƒë·ªÉ b·ª©t ph√°
                            BASE_CONSTANT = 40.0 
                        else:
                            # Giai c·∫•p B√¨nh D√¢n (Ch·∫°m, T·ªïng, D√†n nhi·ªÅu s·ªë)
                            # Ph·∫°t n·∫∑ng ƒë·ªÉ gi·∫£m nhi·ªÖu (Noise Reduction)
                            BASE_CONSTANT = 3.0
                            
                        density_weight = BASE_CONSTANT / float(count)
                        # --- [V4 CHANGE END] ---
                        
                        # H·ªá s·ªë Phong ƒë·ªô (Streak Bonus)
                        # TƒÉng nh·∫π bonus streak ƒë·ªÉ ∆∞u ti√™n c·∫ßu b·ªÅn b·ªâ
                        streak_bonus = 1.0 + (streak * 0.15) 
                        
                        abs_score = density_weight * streak_bonus
                        
                        # C. √ÅP D·ª§NG (TH∆Ø·ªûNG HO·∫∂C PH·∫†T)
                        is_killer = 'KILLER' in b_type or 'LO·∫†I' in val.upper()
                        
                        for num_str in target_numbers:
                            if num_str in scores:
                                if is_killer:
                                    # C·∫ßu Killer lo·∫°i √≠t s·ªë (t·ª± tin cao) s·∫Ω tr·ª´ ƒëi·ªÉm c·ª±c n·∫∑ng
                                    scores[num_str] -= abs_score
                                else:
                                    scores[num_str] += abs_score
                                    bridge_count_per_num[num_str] += 1

                except Exception: continue

    except Exception as e:
        print(f"Scoring Error: {e}")

    # Tr·∫£ v·ªÅ list tuple ƒë√£ sort: [('88', 15.5, '3 c·∫ßu'), ('89', 14.2, '2 c·∫ßu')...]
    return sorted([(k, v, f"{bridge_count_per_num[k]} c·∫ßu") for k, v in scores.items()], key=lambda x: x[1], reverse=True)


def build_dan65_with_bo_priority(all_scores, freq_bo, gan_bo, vip_numbers=None, focus_numbers=None, top_sets_count=None, dan_size=None, min_per_top_set=None):
    """
    [V10.6] Build Dan 65 with VIP/FOCUS PRIORITY + SET PRIORITY
    
    Ensures VIP and focus numbers are ALWAYS included, then adds top-performing
    sets (b·ªô) representation, preventing exclusion of critical numbers.
    
    Args:
        all_scores: List of (number_str, score, info) tuples from calculate_number_scores
        freq_bo: Dict of set frequencies {bo_name: count}
        gan_bo: Dict of set gan days {bo_name: days}
        vip_numbers: List of VIP numbers (10 numbers) - FORCED inclusion
        focus_numbers: List of focus numbers (4 numbers) - FORCED inclusion
        top_sets_count: How many top sets to prioritize (None = use config, default 5)
        dan_size: Final Dan size (None = use config, default 65)
        min_per_top_set: Minimum numbers to include from each top set (None = use config, default 1)
    
    Returns:
        Tuple of (sorted_dan_list, inclusions_dict, excluded_high_scorers)
    """
    try:
        from logic.de_utils import BO_SO_DE
        from logic.constants import DEFAULT_SETTINGS
        
        # Use config values if not provided
        if top_sets_count is None:
            top_sets_count = DEFAULT_SETTINGS.get("DAN65_TOP_SETS_COUNT", 5)
        if dan_size is None:
            dan_size = DEFAULT_SETTINGS.get("DAN65_SIZE", 65)
        if min_per_top_set is None:
            min_per_top_set = DEFAULT_SETTINGS.get("DAN65_MIN_PER_TOP_SET", 1)
        
        excluded_threshold = DEFAULT_SETTINGS.get("DAN65_LOG_EXCLUDED_THRESHOLD", 30.0)
        
        # Normalize VIP/focus numbers
        vip_numbers = vip_numbers or []
        focus_numbers = focus_numbers or []
        
        # === PHASE 0: FORCE INCLUDE VIP AND FOCUS NUMBERS ===
        dan = set()
        vip_added = []
        focus_added = []
        
        print("\n" + "="*70)
        print("üéØ DAN 65 OPTIMIZATION LOG (V10.6)")
        print("="*70)
        
        if vip_numbers or focus_numbers:
            print(f"\n[PHASE 0] Force Include VIP/Focus Numbers:")
            
            # Add VIP numbers (10 numbers)
            for num in vip_numbers:
                if num not in dan:
                    dan.add(num)
                    vip_added.append(num)
            
            if vip_added:
                print(f"  ‚úÖ VIP (10 numbers): {', '.join(vip_added)}")
            
            # Add Focus numbers (4 numbers)
            for num in focus_numbers:
                if num not in dan:
                    dan.add(num)
                    focus_added.append(num)
            
            if focus_added:
                print(f"  ‚úÖ Focus (4 numbers): {', '.join(focus_added)}")
            
            print(f"  üìä Total forced: {len(vip_added) + len(focus_added)} numbers")
        
        # === PHASE 1: IDENTIFY TOP PERFORMING SETS ===
        set_scores = []
        KEP_SETS = ["00", "11", "22", "33", "44"]  # Duplicate sets
        
        for bo_name, nums in BO_SO_DE.items():
            freq = freq_bo.get(bo_name, 0)
            gan = gan_bo.get(bo_name, 0)
            
            # Enhanced scoring formula (matches V10.3 UI evaluation)
            base_score = freq * 1.5
            gan_penalty = gan * 0.3  # Reduced 40% from 0.5
            kep_bonus = 2.0 if bo_name in KEP_SETS else 0.0
            recent_bonus = 1.5 if gan < 7 else 0.0
            trending_bonus = 1.0 if freq >= 3 else 0.0
            
            total = base_score - gan_penalty + kep_bonus + recent_bonus + trending_bonus
            set_scores.append((bo_name, total, freq, gan))
        
        # Sort and get top N sets
        set_scores.sort(key=lambda x: x[1], reverse=True)
        top_sets = [item[0] for item in set_scores[:top_sets_count]]
        
        print(f"\n[PHASE 1] Top {top_sets_count} Sets Identified:")
        for i, (bo_name, score, freq, gan) in enumerate(set_scores[:top_sets_count], 1):
            kep_tag = " [KEP]" if bo_name in KEP_SETS else ""
            print(f"  {i}. B·ªô {bo_name} (Score: {score:.1f}, Freq: {freq}, Gan: {gan}){kep_tag}")
        
        # === PHASE 2: FORCE INCLUDE NUMBERS FROM TOP SETS ===
        # (dan already initialized with VIP/focus numbers)
        included_from_top_sets = {}
        
        print(f"\n[PHASE 2] Add Numbers from Top Sets (after VIP/focus):")
        
        for bo_name in top_sets:
            bo_nums = BO_SO_DE.get(bo_name, [])
            
            # Get numbers from this set, sorted by their individual scores
            bo_candidates = [(num, score) for num, score, _ in all_scores if num in bo_nums]
            bo_candidates.sort(key=lambda x: x[1], reverse=True)
            
            # Force include at least min_per_top_set numbers
            added = 0
            added_nums = []
            for num, score in bo_candidates:
                if added >= min_per_top_set:
                    break
                dan.add(num)
                added_nums.append(num)
                added += 1
            
            included_from_top_sets[bo_name] = added
            if added > 0:
                print(f"  ‚úÖ B·ªô {bo_name}: Added {added} numbers ({', '.join(added_nums)})")
            else:
                print(f"  ‚ö†Ô∏è B·ªô {bo_name}: No numbers available")
        
        # === PHASE 3: FILL REMAINING SLOTS WITH HIGHEST SCORES ===
        excluded_high_scorers = []
        
        for num, score, info in all_scores:
            if len(dan) >= dan_size:
                # Track high scorers that didn't make it
                if score >= excluded_threshold:
                    excluded_high_scorers.append((num, score, "Filled to capacity"))
            else:
                if num not in dan:
                    dan.add(num)
        
        # Log excluded high scorers
        if excluded_high_scorers:
            print(f"\n[PHASE 3] Excluded High Scorers (Score ‚â• {excluded_threshold}):")
            for num, score, reason in excluded_high_scorers[:10]:  # Limit to top 10
                print(f"  ‚ùå {num} (Score: {score:.1f}) - {reason}")
            if len(excluded_high_scorers) > 10:
                print(f"  ... and {len(excluded_high_scorers) - 10} more")
        else:
            print(f"\n[PHASE 3] No high scorers excluded (all fit within Dan {dan_size})")
        
        # === SUMMARY ===
        total_from_top_sets = sum(included_from_top_sets.values())
        total_vip_focus = len(vip_added) + len(focus_added)
        total_from_others = len(dan) - total_from_top_sets - total_vip_focus
        kep_count = sum(1 for bo in top_sets if bo in KEP_SETS and included_from_top_sets.get(bo, 0) > 0)
        
        print(f"\n[SUMMARY] Dan {dan_size} Statistics:")
        print(f"  ‚úì Total numbers: {len(dan)}")
        print(f"  ‚úì VIP/Focus forced: {total_vip_focus} ({len(vip_added)} VIP + {len(focus_added)} focus)")
        print(f"  ‚úì From top {top_sets_count} sets: {total_from_top_sets} ({total_from_top_sets/max(len(dan),1)*100:.1f}%)")
        print(f"  ‚úì From other sources: {total_from_others} ({total_from_others/max(len(dan),1)*100:.1f}%)")
        print(f"  ‚úì Duplicate sets represented: {kep_count}")
        print(f"  ‚úì Total sets represented: {len(set(bo for bo in BO_SO_DE.keys() if any(n in dan for n in BO_SO_DE[bo])))}/15")
        print("="*70 + "\n")
        
        return sorted(dan), included_from_top_sets, excluded_high_scorers
        
    except Exception as e:
        print(f"[ERROR] build_dan65_with_bo_priority failed: {e}")
        import traceback
        traceback.print_exc()
        # Fallback to simple top N selection
        return sorted([x[0] for x in all_scores[:dan_size]]), {}, []

    
def calculate_top_touch_combinations(all_data, num_touches=4, days=15, market_stats=None):
    if not all_data: return []
    try:
        recent = all_data[-days:]
        res = []
        freq = Counter()
        for row in recent:
            de = local_get_gdb_last_2(row)
            if de: freq[int(de[0])] += 1; freq[int(de[1])] += 1
        
        top_digits = [k for k,v in freq.most_common(8)] 
        if len(top_digits) < num_touches: top_digits = list(range(10))

        seen_combos = set()
        for i in combinations(top_digits, num_touches):
            combo = tuple(sorted(list(i)))
            if combo in seen_combos: continue
            seen_combos.add(combo)
            
            t_list = list(combo)
            wins = 0; streak = 0; max_s = 0
            for row in recent:
                de = local_get_gdb_last_2(row)
                if de and check_cham(de, t_list):
                    wins +=1; streak +=1; max_s = max(max_s, streak)
                else: streak = 0
                
            rate = (wins/len(recent))*100 if len(recent)>0 else 0
            if rate > 60 or max_s >= 2:
                res.append({'touches': t_list, 'streak': max_s, 'rate_percent': rate})
                
        res.sort(key=lambda x: (x['streak'], x['rate_percent']), reverse=True)
        return res[:5]
    except: return []

# =============================================================================
# MATRIX V3.9.19 (SMART SET SELECTION - CONSISTENT DATA)
# =============================================================================
def _ai_rows_to_dataframe(all_data_ai):
    try:
        import pandas as pd
        cols = ["Ky", "Ngay", "Giai_Dac_Biet", "Giai_1", "Giai_2", "Giai_3", "Giai_4", "Giai_5", "Giai_6", "Giai_7"]
        df = pd.DataFrame(all_data_ai, columns=cols[:len(all_data_ai[0])] if all_data_ai else None)
        if "Giai_Dac_Biet" in df.columns: df["De"] = df["Giai_Dac_Biet"]
        return df, "OK"
    except Exception as e: return None, str(e)

def analyze_independent_factors(df):
    """
    Ph√¢n t√≠ch c√°c y·∫øu t·ªë ƒë·ªôc l·∫≠p.
    [V3.9.19] S·ª≠ d·ª•ng BO_SO_DICT chu·∫©n t·ª´ de_utils.
    """
    if df is None or df.empty: return [], [], []
    
    # 1. Trend Ch·∫°m
    try:
        de_vals = []
        for x in df.tail(15)['De']:
            s = str(x)
            d = "".join(filter(str.isdigit, s))
            if d: de_vals.append(int(d))
        c = Counter([x%10 for x in de_vals])
        ct = [k for k,v in c.most_common(4)]
    except: ct = [0,1,2,3]
    
    # 2. C·∫ßu V·ªã Tr√≠
    try:
        last_str = str(df.iloc[-1]['De'])
        d = "".join(filter(str.isdigit, last_str))
        last = int(d) if d else 0
        t = (last//10 + last%10)%10
        ctl = list(set([t, (t+5)%10, (t+1)%10, (t-1)%10]))
    except: ctl = [4,5,6,7]
    
    # 3. [SMART LOGIC] CH·ªåN B·ªò - D√πng BO_SO_DICT chu·∫©n
    try:
        recent_de = []
        for x in df.tail(30)['De']:
            s = str(x).strip()
            digits = "".join(filter(str.isdigit, s))
            if len(digits) >= 2: recent_de.append(digits[-2:])
            elif len(digits) == 1: recent_de.append(digits.zfill(2))
        
        bo_stats = {b: {'f': 0, 'last_idx': -1} for b in BO_SO_DICT.keys()}
        
        for idx, val_str in enumerate(recent_de):
            try:
                val = int(val_str)
                for b_name, b_list in BO_SO_DICT.items():
                    if val in b_list:
                        bo_stats[b_name]['f'] += 1
                        bo_stats[b_name]['last_idx'] = idx
                        break
            except: continue
            
        scored_bo = []
        total_len = len(recent_de)
        
        for b_name, stats in bo_stats.items():
            freq = stats['f']
            gan = (total_len - 1 - stats['last_idx']) if stats['last_idx'] != -1 else 30
            
            # H·ªá s·ªë T·∫ßn su·∫•t = 1.5
            score = (freq * 1.5) - (gan * 0.5)
            scored_bo.append((b_name, score))
            
        scored_bo.sort(key=lambda x: x[1], reverse=True)
        top_bo = [item[0] for item in scored_bo[:2]]
        
        if not top_bo:
             top_bo = ["12", "01"] # Fallback
             
        bo = top_bo

    except Exception as e:
        print(f"[SmartMatrix] Error: {e}")
        bo = ["00"]
    
    return ct, ctl, bo

def run_intersection_matrix_analysis(all_data_ai_or_df):
    df = None
    if hasattr(all_data_ai_or_df, "columns"): df = all_data_ai_or_df
    else: df, _ = _ai_rows_to_dataframe(all_data_ai_or_df)
    
    cham_thong, cham_ti_le, bo_chon = analyze_independent_factors(df)
    
    bang_diem = {i: 0 for i in range(100)}
    ghi_chu = {i: [] for i in range(100)}
    
    for i, b in enumerate(bo_chon):
        pts = SCORE_CONFIG["bo_uu_tien_1"] if i==0 else SCORE_CONFIG["bo_uu_tien_2"]
        # L·∫•y s·ªë t·ª´ BO_SO_DICT chu·∫©n (d·∫°ng int)
        for s_int in BO_SO_DICT.get(b, []):
            bang_diem[s_int] += pts; ghi_chu[s_int].append(f"B·ªô {b} (Hot)")
            
    for s in range(100):
        d, u = s//10, s%10
        if d in cham_ti_le or u in cham_ti_le:
            bang_diem[s] += 20; ghi_chu[s].append("C·∫ßu")
        if d in cham_thong or u in cham_thong:
            bang_diem[s] += 15; ghi_chu[s].append("Trend")
            
    final = []
    for s, p in bang_diem.items():
        if p > 0:
            rank = "S" if p>=70 else ("A" if p>=50 else "B")
            final.append({"so": f"{s:02d}", "diem": p, "rank": rank, "note": "+".join(ghi_chu[s])})
            
    return {"ranked": sorted(final, key=lambda x:x["diem"], reverse=True), 
            "cham_thong": cham_thong, "cham_ti_le": cham_ti_le, "bo_so_chon": bo_chon}

# √Ånh x·∫° h√†m ƒë·ªÉ t∆∞∆°ng th√≠ch ng∆∞·ª£c
get_gdb_last_2 = local_get_gdb_last_2

--------------------------------------------------

=== FILE: logic\de_backtester_core.py ===
# T√™n file: logic/de_backtester_core.py
# (PHI√äN B·∫¢N V8.3 - FULL RESTORE & FIX DE_SET)

import sys
import os
import traceback

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from logic.de_utils import (
    get_gdb_last_2, 
    get_touches_by_offset, 
    generate_dan_de_from_touches,
    check_cham,
    # [NEW] Import logic b·ªô
    get_set_name_of_number,
    BO_SO_DE
)

# Import Logic V16 cho C·∫ßu B·ªát
try:
    from logic.bridges.bridges_v16 import getAllPositions_V17_Shadow, getPositionName_V17_Shadow
except ImportError:
    getAllPositions_V17_Shadow = None
    getPositionName_V17_Shadow = None

class DeBacktesterCore:
    def __init__(self, all_data):
        self.data = all_data
        # Map c·ªôt ƒë∆°n gi·∫£n (D·ªØ li·ªáu Compact)
        self.col_map = {"GƒêB": 2, "GDB": 2, "G1": 3, "G2": 4, "G3": 5, "G4": 6, "G5": 7, "G6": 8, "G7": 9}
        
        # X√¢y d·ª±ng Map V16 (V·ªã tr√≠ chi ti·∫øt cho C·∫ßu B·ªát)
        self.v16_map = {}
        if getPositionName_V17_Shadow:
            try:
                # Qu√©t 150 v·ªã tr√≠ ƒë·∫ßu ti√™n
                for i in range(150):
                    name = getPositionName_V17_Shadow(i)
                    if name:
                        self.v16_map[name] = i
            except: pass

    # [RESTORED] Method n√†y ƒë√£ ƒë∆∞·ª£c kh√¥i ph·ª•c nguy√™n tr·∫°ng ƒë·ªÉ ƒë·∫£m b·∫£o kh√¥ng l·ªói c√°c module kh√°c
    def run_backtest(self, config, days_to_test=365):
        """
        Ch·∫°y backtest cho m·ªôt c·∫•u h√¨nh c·∫ßu c·ª• th·ªÉ.
        H·ªó tr·ª£: Dynamic (2 pos), Classic Sum (2 pos), Classic Single (1 pos).
        """
        if not self.data or len(self.data) < days_to_test:
            return {"error": "Kh√¥ng ƒë·ªß d·ªØ li·ªáu."}

        test_data = self.data[-days_to_test:]
        
        stats = {
            "total_days": 0, "wins": 0, "loss": 0,
            "current_streak": 0, "max_win_streak": 0, "max_loss_streak": 0,
            "win_rate": 0.0, 
            "history_log": [] # Tr·∫£ v·ªÅ log chi ti·∫øt
        }

        # ƒê·ªçc c·∫•u h√¨nh c·∫ßu
        pos1_name = config.get('pos1_name')
        pos2_name = config.get('pos2_name')
        k = config.get('k_offset', 0)
        mode = config.get('type', 'DYNAMIC')

        # X·ª¨ L√ù CH·ªà S·ªê (MAPPING)
        idx1, idx2 = None, None
        use_v16 = False

        # ∆Øu ti√™n t√¨m trong Map V16 n·∫øu l√† C·∫ßu B·ªát (CLASSIC)
        if mode == 'CLASSIC' and hasattr(self, 'v16_map') and self.v16_map:
            idx1 = self.v16_map.get(pos1_name)
            if pos2_name: # Ch·ªâ t√¨m idx2 n·∫øu t√™n pos2 t·ªìn t·∫°i
                idx2 = self.v16_map.get(pos2_name)
                if idx1 is not None and idx2 is not None: use_v16 = True
            else:
                # N·∫øu ch·ªâ c√≥ pos1 v√† t√¨m th·∫•y trong v16 map -> D√πng V16
                if idx1 is not None: use_v16 = True 
        
        # N·∫øu kh√¥ng t√¨m th·∫•y trong V16, quay v·ªÅ Map ƒë∆°n gi·∫£n (Compact)
        if idx1 is None: idx1 = self._get_col_idx(pos1_name)
        if idx2 is None and pos2_name: idx2 = self._get_col_idx(pos2_name)

        # Ki·ªÉm tra l·ªói: Pos1 b·∫Øt bu·ªôc ph·∫£i c√≥, Pos2 c√≥ th·ªÉ None (n·∫øu c·∫ßu ƒë∆°n)
        if idx1 is None:
            return {"error": f"Kh√¥ng t√¨m th·∫•y v·ªã tr√≠: {pos1_name}"}
        if pos2_name and idx2 is None:
            return {"error": f"Kh√¥ng t√¨m th·∫•y v·ªã tr√≠: {pos2_name}"}

        current_streak = 0
        
        # V√íNG L·∫∂P BACKTEST
        for i in range(1, len(test_data)):
            row_today = test_data[i]
            row_prev = test_data[i-1]
            
            gdb_today = get_gdb_last_2(row_today)
            if not gdb_today: continue

            try:
                n1, n2 = 0, 0
                has_n2 = (idx2 is not None)
                
                # --- [B∆Ø·ªöC 1: L·∫§Y S·ªê] ---
                if use_v16 and getAllPositions_V17_Shadow:
                    # Logic V16: L·∫•y ch√≠nh x√°c ch·ªØ s·ªë t·∫°i v·ªã tr√≠ (VD: s·ªë th·ª© 2 c·ªßa G1)
                    pos_vals = getAllPositions_V17_Shadow(row_prev)
                    if pos_vals[idx1] is None: continue
                    n1 = int(pos_vals[idx1])
                    if has_n2:
                        if pos_vals[idx2] is None: continue
                        n2 = int(pos_vals[idx2])
                else:
                    # Logic Th∆∞·ªùng: L·∫•y s·ªë cu·ªëi c√πng c·ªßa gi·∫£i
                    v1_str = self._clean_num(row_prev[idx1])
                    if not v1_str: continue
                    n1 = int(v1_str[-1])
                    
                    if has_n2:
                        v2_str = self._clean_num(row_prev[idx2])
                        if v2_str: n2 = int(v2_str[-1])
                        else: continue # N·∫øu c·∫ßn n2 m√† kh√¥ng l·∫•y ƒë∆∞·ª£c th√¨ b·ªè qua

                # --- [B∆Ø·ªöC 2: T√çNH TO√ÅN BASE] ---
                if has_n2:
                    base_sum = (n1 + n2) % 10
                    desc_base = f"({n1}+{n2})"
                else:
                    # N·∫øu ch·ªâ c√≥ 1 v·ªã tr√≠ (B·ªát), l·∫•y ch√≠nh n√≥
                    base_sum = n1 
                    desc_base = f"({n1})"

                # --- [B∆Ø·ªöC 3: SINH D√ÄN & KI·ªÇM TRA] ---
                is_win = False
                desc = ""

                if mode == 'DYNAMIC':
                    touches = get_touches_by_offset(base_sum, k, logic_type="TONG")
                    dan_de = generate_dan_de_from_touches(touches)
                    is_win = gdb_today in dan_de
                    desc = f"{desc_base}%{k} -> Ch·∫°m {touches}"
                else:
                    # CLASSIC: Ch·∫°m (G·ªëc + B√≥ng)
                    t1 = base_sum
                    t2 = (base_sum + 5) % 10
                    is_win = check_cham(gdb_today, [t1, t2])
                    desc = f"{desc_base} -> Ch·∫°m {t1}, {t2}"

                # --- [B∆Ø·ªöC 4: TH·ªêNG K√ä] ---
                stats["total_days"] += 1
                if is_win:
                    stats["wins"] += 1
                    if current_streak >= 0:
                        current_streak += 1
                    else:
                        current_streak = 1
                else:
                    stats["loss"] += 1
                    if current_streak <= 0:
                        current_streak -= 1
                    else:
                        current_streak = -1
                
                # C·∫≠p nh·∫≠t Max Records
                if current_streak > stats["max_win_streak"]: 
                    stats["max_win_streak"] = current_streak
                if current_streak < 0 and abs(current_streak) > stats["max_loss_streak"]:
                    stats["max_loss_streak"] = abs(current_streak)

                # L∆∞u log (Ch·ªâ l∆∞u 60 ng√†y cu·ªëi ƒë·ªÉ t·ªëi ∆∞u hi·ªáu nƒÉng hi·ªÉn th·ªã)
                if i >= len(test_data) - 60:
                    stats["history_log"].append({
                        "date": row_today[0],
                        "gdb": gdb_today,
                        "desc": desc,
                        "result": "‚úÖ ƒÇN" if is_win else "‚ùå X·ªäT",
                        "is_win": is_win
                    })

            except Exception: continue

        # T·ªïng k·∫øt cu·ªëi c√πng
        stats["current_streak"] = current_streak
        stats["win_rate"] = (stats["wins"] / stats["total_days"] * 100) if stats["total_days"] > 0 else 0
        
        return stats

    def _get_col_idx(self, name):
        if not name: return None
        clean = name.split('.')[0].split('_')[0]
        return self.col_map.get(clean)

    def _clean_num(self, val):
        return ''.join(filter(str.isdigit, str(val)))

def _restore_brackets_format(pos_name):
    """Kh√¥i ph·ª•c format G14 -> G1[4] ƒë·ªÉ mapping V16 hi·ªÉu."""
    if not pos_name: return pos_name
    import re
    if '[' in pos_name and ']' in pos_name: return pos_name
    
    match_gdb = re.match(r'^GDB(\d)$', pos_name)
    if match_gdb: return f"GDB[{match_gdb.group(1)}]"
    
    match_dot = re.match(r'^G(\d+)\.(\d+)(\d)$', pos_name)
    if match_dot: return f"G{match_dot.group(1)}.{match_dot.group(2)}[{match_dot.group(3)}]"
    
    match_simple = re.match(r'^G(\d+)(\d)$', pos_name)
    if match_simple: return f"G{match_simple.group(1)}[{match_simple.group(2)}]"
    
    return pos_name

def run_de_bridge_historical_test(bridge_config, all_data, days=30):
    """
    Ch·∫°y backtest l·ªãch s·ª≠ (Phi√™n b·∫£n Fix Sync Dashboard & Pending State).
    ∆Øu ti√™n c·∫•u h√¨nh Index t·ª´ DB ƒë·ªÉ ƒë·ªìng b·ªô k·∫øt qu·∫£ v·ªõi B·∫£ng C·∫ßu ƒê·ªông.
    """
    try:
        # 1. Validation Input
        if not bridge_config:
            return [{'date': 'L·ªñI', 'pred': 'N/A', 'result': 'N/A', 'is_win': False, 'status': 'FAIL: Config None'}]
        if not all_data or len(all_data) < 2:
            return [{'date': 'L·ªñI', 'pred': 'N/A', 'result': 'N/A', 'is_win': False, 'status': 'FAIL: Data < 2'}]
        
        # 2. X√°c ƒë·ªãnh ph·∫°m vi Backtest
        total_len = len(all_data)
        if total_len >= days + 1:
            start_index = total_len - days
            actual_days = days
        else:
            start_index = 1
            actual_days = total_len - 1
        
        end_index = total_len - 1
        results = []
        
        # 3. Parse Config & Bi·∫øn c·ªù
        bridge_name = bridge_config.get("name", "")
        bridge_type = bridge_config.get("type", "UNKNOWN")
        
        is_scanner = bridge_config.get("is_scanner_result", False)
        def_string = bridge_config.get("def_string", bridge_name)
        
        pos1_name = bridge_config.get("pos1_name")
        pos2_name = bridge_config.get("pos2_name")
        k_offset = bridge_config.get("k_offset", 0)
        
        # [FIX] Extract k_offset from bridge name if not provided in config
        # This handles bridges loaded from DB that don't have k_offset field
        if k_offset == 0 and "_K" in bridge_name:
            try:
                parts = bridge_name.split("_K")
                if len(parts) > 1:
                    k_str = parts[-1]
                    # Handle cases like "K4" or just "4"
                    # Only take the numeric part (handles "K4_EXTRA" ‚Üí "4")
                    if k_str and k_str[0].isdigit():
                        # Extract leading digits only
                        import re
                        match = re.match(r'^(\d+)', k_str)
                        if match:
                            k_offset = int(match.group(1))
            except (ValueError, IndexError, AttributeError):
                pass  # Keep default k_offset = 0
        
        # 4. Mapping V·ªã Tr√≠ (Index) - Logic ƒê·ªìng B·ªô Dashboard
        # Kh·ªüi t·∫°o Backtester helper ch·ªâ ƒë·ªÉ d√πng c√°c h√†m ti·ªán √≠ch n·∫øu c·∫ßn
        backtester = DeBacktesterCore(all_data)
        idx1, idx2 = None, None
        use_v16 = False
        
        if not is_scanner:
            # ∆Øu ti√™n l·∫•y Index t·ª´ DB (Ch√≠nh x√°c tuy·ªát ƒë·ªëi)
            pos1_idx = bridge_config.get("pos1_idx")
            pos2_idx = bridge_config.get("pos2_idx")
            
            if pos1_idx is not None:
                idx1 = int(pos1_idx)
                if pos2_idx is not None: idx2 = int(pos2_idx)
                # N·∫øu c√≥ index h·ª£p l·ªá -> D√πng logic V16
                if idx1 >= 0: use_v16 = True
            else:
                # Fallback: Parse t·ª´ t√™n n·∫øu m·∫•t index
                if hasattr(backtester, 'v16_map') and backtester.v16_map:
                    # Helper x·ª≠ l√Ω t√™n c·∫ßu (Inline)
                    def _fix_name_fmt(n):
                        if not n: return n
                        import re
                        if '[' in n and ']' in n: return n
                        m = re.match(r'^G(\d+)\.(\d+)(\d)$', n) # Fix d·∫°ng G1.01
                        if m: return f"G{m.group(1)}[{m.group(3)}]"
                        m = re.match(r'^G(\d+)\.(\d+)$', n) # Fix d·∫°ng G1.0
                        if m: return f"G{m.group(1)}[{m.group(2)}]"
                        return n

                    if pos1_name: idx1 = backtester.v16_map.get(_fix_name_fmt(pos1_name))
                    if pos2_name: idx2 = backtester.v16_map.get(_fix_name_fmt(pos2_name))
                    
                    if idx1 is not None: use_v16 = True
                
                # Fallback cu·ªëi c√πng: Map Compact (C≈©)
                if idx1 is None and pos1_name: idx1 = backtester._get_col_idx(pos1_name)
                if idx2 is None and pos2_name: idx2 = backtester._get_col_idx(pos2_name)

            if idx1 is None and not is_scanner:
                return [{'date': 'L·ªñI', 'pred': 'N/A', 'result': 'N/A', 'is_win': False, 'status': f'FAIL: M·∫•t v·ªã tr√≠ 1 ({pos1_name})'}]

        # 5. V√íNG L·∫∂P BACKTEST CH√çNH
        for i in range(start_index, min(start_index + actual_days + 1, total_len)):
            try:
                row_today = all_data[i]
                row_prev = all_data[i - 1]
                
                date_str = str(row_today[0]) if row_today[0] else f"Ng√†y {i}"
                
                # [QUAN TR·ªåNG] Ki·ªÉm tra xem ng√†y n√†y ƒë√£ c√≥ k·∫øt qu·∫£ ch∆∞a
                # N·∫øu ch∆∞a c√≥ k·∫øt qu·∫£ (None, null, empty), ƒë√°nh d·∫•u l√† PENDING
                gdb_today = get_gdb_last_2(row_today)
                is_pending_day = False
                
                # Logic x√°c ƒë·ªãnh ng√†y ch·ªù: GƒêB r·ªóng ho·∫∑c c√°c k√Ω t·ª± placeholder
                if gdb_today is None or str(gdb_today).strip() in ["", "..", "??", "None"]:
                    is_pending_day = True
                    gdb_today = "??"

                # --- L·∫§Y S·ªê T·∫†I V·ªä TR√ç (H·ª¢P NH·∫§T LOGIC) ---
                n1, n2 = 0, 0
                has_n2 = True 
                
                if is_scanner:
                    # Logic cho c·∫ßu Scanner (GDB.0-G1.0)
                    # H√†m _parse_scanner_def_and_get_values c·∫ßn t·ªìn t·∫°i trong file (ho·∫∑c import)
                    # N·∫øu trong file g·ªëc ch∆∞a c√≥, b·∫°n c·∫ßn ƒë·∫£m b·∫£o h√†m n√†y c√≥ s·∫µn b√™n d∆∞·ªõi
                    try:
                        val1, val2 = _parse_scanner_def_and_get_values(def_string, row_prev)
                        if val1 is None: continue 
                        n1 = val1
                        n2 = val2 if val2 is not None else 0
                        has_n2 = (val2 is not None)
                    except: continue
                else:
                    # Logic V16 (ƒê·ªìng b·ªô v·ªõi Dashboard)
                    has_n2 = (idx2 is not None)
                    
                    # Ki·ªÉm tra v√† d√πng logic V16 Shadow n·∫øu kh·∫£ d·ª•ng
                    if use_v16 and getAllPositions_V17_Shadow:
                        pos_vals = getAllPositions_V17_Shadow(row_prev)
                        
                        # Safety check bounds
                        if idx1 >= len(pos_vals) or pos_vals[idx1] is None: 
                            continue # Skip bad data
                        n1 = int(pos_vals[idx1])
                        
                        if has_n2:
                            if idx2 >= len(pos_vals) or pos_vals[idx2] is None: 
                                continue # Skip bad data
                            n2 = int(pos_vals[idx2])
                    else:
                        # Fallback logic c≈© (Compact)
                        v1 = backtester._clean_num(row_prev[idx1])
                        if not v1: continue
                        n1 = int(v1[-1])
                        if has_n2:
                            v2 = backtester._clean_num(row_prev[idx2])
                            if not v2: continue
                            n2 = int(v2[-1])

                # --- T√çNH TO√ÅN D·ª∞ ƒêO√ÅN ---
                is_win = False
                pred_str = ""
                
                # Logic: B·ªô -> ƒê·ªông -> T·ªïng -> Classic
                if bridge_type == "DE_SET" or "DE_SET_" in bridge_name or (is_scanner and "B·ªô" in bridge_name):
                    if has_n2:
                        pair_val = f"{n1}{n2}"
                        set_name = get_set_name_of_number(pair_val)
                        if set_name and set_name in BO_SO_DE:
                            dan_so = BO_SO_DE[set_name]
                            if is_pending_day:
                                is_win = False # Pending coi nh∆∞ ch∆∞a th·∫Øng (ƒë·ªÉ x·ª≠ l√Ω hi·ªÉn th·ªã sau)
                            else:
                                is_win = gdb_today in dan_so
                            pred_str = f"B·ªô {set_name}"
                        else:
                            is_win = False
                            pred_str = f"B·ªô ?? ({pair_val})"
                    else:
                        pred_str = "L·ªói: C·∫ßu B·ªô thi·∫øu V·ªã tr√≠ 2"
                
                elif bridge_type == "DE_DYNAMIC_K" or "DE_DYN_" in bridge_name or is_scanner:
                    base_sum = (n1 + n2) % 10 if has_n2 else n1
                    touches = get_touches_by_offset(base_sum, k_offset, logic_type="TONG")
                    dan_de = generate_dan_de_from_touches(touches)
                    
                    if is_pending_day:
                        is_win = False
                    else:
                        is_win = gdb_today in dan_de
                        
                    pred_str = f"Ch·∫°m {','.join(map(str, touches))}"
                
                elif bridge_type == "DE_POS_SUM" or "DE_POS_" in bridge_name:
                    base_sum = (n1 + n2) % 10 if has_n2 else n1
                    if is_pending_day:
                        is_win = False
                    else:
                        is_win = check_cham(gdb_today, [base_sum])
                    pred_str = f"Ch·∫°m {base_sum}"
                
                elif bridge_type == "DE_KILLER" or "DE_KILLER_" in bridge_name:
                    # KILLER logic: Predict which touch to ELIMINATE (not appear)
                    killer_touch = (n1 + n2) % 10 if has_n2 else n1
                    if is_pending_day:
                        is_win = False
                    else:
                        # Win = touch does NOT appear in result
                        is_win = not check_cham(gdb_today, [killer_touch])
                    pred_str = f"LO·∫†I Ch·∫°m {killer_touch}"
                
                else: # CLASSIC
                    base_sum = (n1 + n2) % 10 if has_n2 else n1
                    t1, t2 = base_sum, (base_sum + 5) % 10
                    if is_pending_day:
                        is_win = False
                    else:
                        is_win = check_cham(gdb_today, [t1, t2])
                    pred_str = f"Ch·∫°m {t1},{t2}"

                # --- T·∫†O K·∫æT QU·∫¢ ---
                if is_pending_day:
                    status_text = "Ch·ªù"
                    # [M·∫∏O UI] C√≥ th·ªÉ set is_win=True t·∫°m th·ªùi ƒë·ªÉ UI kh√¥ng t√¥ ƒë·ªè n·∫øu c·∫ßn, 
                    # nh∆∞ng ƒë·ªÉ False v√† check status="Ch·ªù" l√† chu·∫©n nh·∫•t.
                    # ·ªû ƒë√¢y ta gi·ªØ is_win=False nh∆∞ng status r√µ r√†ng.
                else:
                    status_text = "ƒÇn" if is_win else "G√£y"
                
                results.append({
                    'date': date_str,
                    'pred': pred_str,
                    'result': gdb_today,
                    'is_win': is_win,
                    'status': status_text
                })

            except Exception as e:
                results.append({'date': date_str, 'pred': 'ERR', 'result': 'N/A', 'is_win': False, 'status': f'ERR: {str(e)[:10]}'})
                continue

        if not results:
            return [{'date': 'L·ªñI', 'pred': 'N/A', 'result': 'N/A', 'is_win': False, 'status': 'FAIL: Kh√¥ng c√≥ k·∫øt qu·∫£ n√†o'}]
            
        return results

    except Exception as e:
        return [{'date': 'L·ªñI', 'pred': 'N/A', 'result': 'N/A', 'is_win': False, 'status': f'CRASH: {str(e)}'}]

def calculate_de_bridge_max_lose_history(bridge_config, all_data):
    """Wrapper cho t√≠nh max lose (Gi·ªØ nguy√™n)"""
    if not bridge_config or not all_data: return -1
    try:
        results = run_de_bridge_historical_test(bridge_config, all_data, days=len(all_data))
        if not results or "FAIL" in str(results[0].get('status', '')): return -1
        
        max_lose = 0
        curr_lose = 0
        for r in results:
            if not r['is_win']:
                curr_lose += 1
                max_lose = max(max_lose, curr_lose)
            else:
                curr_lose = 0
        return max_lose
    except: return -1

# ==============================================================================
# [B·ªî SUNG] C√ÅC H√ÄM HELPER ƒê·ªÇ GI·∫¢I M√É C·∫¶U SCANNER (SMART V2)
# ==============================================================================

def _parse_scanner_def_and_get_values(def_str, row_data):
    """
    Gi·∫£i m√£ chu·ªói ƒë·ªãnh nghƒ©a c·∫ßu (VD: 'GDB.0-G1.0') v√† l·∫•y gi√° tr·ªã t·ª´ d√≤ng d·ªØ li·ªáu.
    """
    try:
        parts = def_str.split('-')
        if len(parts) != 2: return None, None
        
        v1 = _get_single_pos_value(parts[0], row_data)
        v2 = _get_single_pos_value(parts[1], row_data)
        
        return v1, v2
    except:
        return None, None

def _get_single_pos_value(pos_code, row_data):
    """
    L·∫•y gi√° tr·ªã s·ªë t·∫°i 1 v·ªã tr√≠. (Phi√™n b·∫£n V3 - H·ªó tr·ª£ B√≥ng D∆∞∆°ng)
    H·ªó tr·ª£: GDB.0, G1.1, Bong(G1.1)
    """
    try:
        # [NEW] X·ª¨ L√ù B√ìNG D∆Ø∆†NG (Bong(...) ho·∫∑c B(...))
        if "ong(" in pos_code or pos_code.startswith("B("):
            # T√°ch l·∫•y n·ªôi dung b√™n trong d·∫•u ngo·∫∑c
            # VD: Bong(G1.1) -> inner = G1.1
            start = pos_code.find("(") + 1
            end = pos_code.find(")")
            if start > 0 and end > start:
                inner_code = pos_code[start:end]
                # ƒê·ªá quy: L·∫•y gi√° tr·ªã c·ªßa c√°i b√™n trong
                val = _get_single_pos_value(inner_code, row_data)
                if val is not None:
                    # T√≠nh b√≥ng: (val + 5) % 10
                    return (val + 5) % 10
                return None

        # --- LOGIC C≈® (L·∫§Y GI√Å TR·ªä G·ªêC) ---
        code_parts = pos_code.split('.')
        prize_name = code_parts[0]
        
        col_idx = -1
        if prize_name in ["GƒêB", "GDB"]: col_idx = 2
        elif prize_name == "G1": col_idx = 3
        elif prize_name == "G2": col_idx = 4
        elif prize_name == "G3": col_idx = 5
        elif prize_name == "G4": col_idx = 6
        elif prize_name == "G5": col_idx = 7
        elif prize_name == "G6": col_idx = 8
        elif prize_name == "G7": col_idx = 9
        
        if col_idx < 0 or col_idx >= len(row_data): return None

        raw_val = row_data[col_idx]
        val_str = str(raw_val)

        sub_idx = 0
        char_idx = 0
        if len(code_parts) == 2: 
            char_idx = int(code_parts[1])
        elif len(code_parts) == 3:
            sub_idx = int(code_parts[1])
            char_idx = int(code_parts[2])

        if "-" in val_str or ";" in val_str:
            sep = "-" if "-" in val_str else ";"
            sub_nums = val_str.split(sep)
            if sub_idx < len(sub_nums):
                target = sub_nums[sub_idx]
                if char_idx < len(target): return int(target[char_idx])
        else:
            if isinstance(raw_val, list) and sub_idx < len(raw_val):
                s = str(raw_val[sub_idx])
                if char_idx < len(s): return int(s[char_idx])
            
            if char_idx < len(val_str):
                return int(val_str[char_idx])

        return None
    except:
        return None

def _expand_bo_so(root_pair_str):
    """Sinh d√†n 8 s·ªë c·ªßa B·ªô ƒë·ªÅ"""
    try:
        a, b = int(root_pair_str[0]), int(root_pair_str[1])
        a_b, b_b = (a + 5) % 10, (b + 5) % 10
        pairs = {f"{a}{b}", f"{b}{a}", f"{a}{b_b}", f"{b_b}{a}", 
                 f"{a_b}{b}", f"{b}{a_b}", f"{a_b}{b_b}", f"{b_b}{a_b}"}
        return list(pairs)
    except:
        return []    

--------------------------------------------------

=== FILE: logic\de_utils.py ===
# T√™n file: code6/logic/de_utils.py
# (PHI√äN B·∫¢N V3.9.18 - FIX: CHU·∫®N H√ìA L·∫†I ƒê·ªäNH NGHƒ®A 15 B·ªò S·ªê ƒê·ªÄ)

import datetime

# --- 1. ƒê·ªäNH NGHƒ®A D·ªÆ LI·ªÜU C∆† B·∫¢N ---
# C√°c b·ªô s·ªë ƒë·ªÅ c∆° b·∫£n (Mapping t·ª´ T√™n B·ªô -> Danh s√°ch s·ªë)
# ‚ö° FIX: ƒê√£ r√† so√°t v√† chu·∫©n h√≥a l·∫°i to√†n b·ªô 15 b·ªô s·ªë
BO_SO_DE = {
    # --- 5 B·ªô K√©p (4 s·ªë/b·ªô) ---
    "00": ["00", "55", "05", "50"],
    "11": ["11", "66", "16", "61"],
    "22": ["22", "77", "27", "72"],
    "33": ["33", "88", "38", "83"],
    "44": ["44", "99", "49", "94"],
    
    # --- 10 B·ªô Th∆∞·ªùng (8 s·ªë/b·ªô) ---
    "01": ["01", "10", "06", "60", "51", "15", "56", "65"],
    "02": ["02", "20", "07", "70", "52", "25", "57", "75"],
    "03": ["03", "30", "08", "80", "53", "35", "58", "85"],
    "04": ["04", "40", "09", "90", "54", "45", "59", "95"],
    "12": ["12", "21", "17", "71", "26", "62", "76", "67"],
    "13": ["13", "31", "18", "81", "36", "63", "86", "68"],
    "14": ["14", "41", "19", "91", "46", "64", "96", "69"],
    "23": ["23", "32", "28", "82", "37", "73", "87", "78"],
    "24": ["24", "42", "29", "92", "47", "74", "97", "79"],
    "34": ["34", "43", "39", "93", "48", "84", "98", "89"]
}

# ‚ö° DEBUG: Ki·ªÉm tra BO_SO_DE sau khi kh·ªüi t·∫°o
if not BO_SO_DE or len(BO_SO_DE) == 0:
    print("[ERROR de_utils] BO_SO_DE is EMPTY after initialization!")
    raise ValueError("BO_SO_DE cannot be empty!")
else:
    # In ra ƒë·ªÉ x√°c nh·∫≠n khi ch·∫°y
    print(f"[DEBUG de_utils] BO_SO_DE initialized successfully: {len(BO_SO_DE)} sets (Standardized)")

# B√≥ng d∆∞∆°ng: 0->5, 1->6...
BONG_DUONG_MAP = {0: 5, 1: 6, 2: 7, 3: 8, 4: 9, 5: 0, 6: 1, 7: 2, 8: 3, 9: 4}

# --- 2. C√îNG C·ª§ X·ª¨ L√ù S·ªê ---

def get_gdb_last_2(row_data):
    """Tr√≠ch xu·∫•t 2 s·ªë cu·ªëi Gi·∫£i ƒê·∫∑c Bi·ªát."""
    try:
        if len(row_data) < 3: return None
        gdb = str(row_data[2])
        gdb = ''.join(filter(str.isdigit, gdb))
        if not gdb or len(gdb) < 2: return None
        return gdb[-2:]
    except Exception: return None

def check_cham(so_de_str, cham_list):
    """Ki·ªÉm tra s·ªë ƒë·ªÅ c√≥ d√≠nh ch·∫°m kh√¥ng."""
    if not so_de_str or len(so_de_str) < 2: return False
    try:
        n1, n2 = int(so_de_str[0]), int(so_de_str[1])
        for c in cham_list:
            if int(c) == n1 or int(c) == n2: return True
    except ValueError: return False
    return False

def check_tong(so_de_str, tong_list):
    """Ki·ªÉm tra s·ªë ƒë·ªÅ c√≥ thu·ªôc t·ªïng kh√¥ng."""
    if not so_de_str or len(so_de_str) < 2: return False
    try:
        n1, n2 = int(so_de_str[0]), int(so_de_str[1])
        tong = (n1 + n2) % 10
        for t in tong_list:
            if int(t) == tong: return True
    except ValueError: return False
    return False

# --- 3. LOGIC TH√îNG MINH M·ªöI (STRICT MODE & V77 UTILS) ---

def get_bo_name_by_pair(n1, n2):
    """(V77) T√¨m t√™n b·ªô s·ªë t·ª´ 2 s·ªë b·∫•t k·ª≥ (gh√©p l·∫°i)."""
    pair_str = f"{n1}{n2}"
    for bo_name, nums in BO_SO_DE.items():
        if pair_str in nums: return bo_name
    return None

def get_set_name_of_number(number_str):
    """
    T√¨m t√™n b·ªô s·ªë ƒë·∫°i di·ªán t·ª´ m·ªôt s·ªë ƒë·ªÅ.
    
    Args:
        number_str: M·ªôt s·ªë d·∫°ng chu·ªói (vd: "05", "50", "55")
    
    Returns:
        str: T√™n ƒë·∫°i di·ªán c·ªßa b·ªô ƒë√≥ (VD: "00" n·∫øu thu·ªôc 'Bo 00'). 
             None n·∫øu kh√¥ng t√¨m th·∫•y.
    """
    if not number_str or len(number_str) < 2:
        return None
    
    # ƒê·∫£m b·∫£o s·ªë c√≥ 2 ch·ªØ s·ªë
    number_str = number_str.zfill(2)
    if len(number_str) > 2:
        number_str = number_str[-2:]
    
    # T√¨m trong BO_SO_DE
    for bo_name, nums in BO_SO_DE.items():
        if number_str in nums:
            return bo_name
    
    return None

def get_touches_by_offset(base_val, k, logic_type="TONG"):
    """
    (V77) Sinh 4 ch·∫°m d·ª±a tr√™n s·ªë g·ªëc v√† ƒë·ªô l·ªách K.
    logic_type: "TONG" (Bi·∫øn thi√™n) ho·∫∑c "VITRI" (C·ªë ƒë·ªãnh).
    """
    touches = set()
    if logic_type == "TONG":
        # C√¥ng th·ª©c: (G·ªëc + K) v√† (G·ªëc + K + 1)
        v1 = (base_val + k) % 10
        v2 = (base_val + k + 1) % 10
        touches.update([v1, (v1+5)%10, v2, (v2+5)%10])
    else:
        # Logic V·ªã tr√≠: L·∫•y th·∫≥ng gi√° tr·ªã + b√≥ng
        v = (base_val + k) % 10
        touches.update([v, (v+5)%10])
    return sorted(list(touches))

def get_4_touches_smart(numbers_list):
    """
    (Gi·ªØ nguy√™n Logic c≈©) T·ª´ danh s√°ch h·∫°t gi·ªëng tr·∫£ v·ªÅ Ch·∫°m (G·ªëc + B√≥ng).
    """
    touches = set()
    base_nums = [n % 10 for n in numbers_list]
    for n in base_nums:
        touches.add(n)
    
    current_touches = list(touches)
    for t in current_touches:
        touches.add(BONG_DUONG_MAP.get(t, (t+5)%10))
            
    return sorted(list(touches))

def generate_dan_de_from_touches(touch_list, bo_filter_seeds=None):
    """
    (Gi·ªØ nguy√™n Logic c≈©) T·∫°o d√†n ƒë·ªÅ t·ª´ list ch·∫°m v√† l·ªçc b·∫±ng B·ªô (Set).
    """
    full_dan = set()
    for i in range(100):
        s = f"{i:02d}"
        d1, d2 = int(s[0]), int(s[1])
        if d1 in touch_list or d2 in touch_list:
            full_dan.add(s)
            
    if not bo_filter_seeds:
        return sorted(list(full_dan))
        
    valid_bo_nums = set()
    seeds = [n % 10 for n in bo_filter_seeds]
    
    pairs_formed = set()
    for i in range(len(seeds)):
        for j in range(len(seeds)): 
            p1 = f"{seeds[i]}{seeds[j]}"
            pairs_formed.add(p1)

    for pair in pairs_formed:
        for bo_name, bo_values in BO_SO_DE.items():
            if pair in bo_values:
                valid_bo_nums.update(bo_values)
                break
    
    if not valid_bo_nums:
        return sorted(list(full_dan))

    final_dan = full_dan.intersection(valid_bo_nums)
    return sorted(list(final_dan))

# --- 4. ADAPTER ---
def convert_data_for_de_backtest(all_data_ai):
    de_data = []
    for row in all_data_ai:
        gdb_tail = get_gdb_last_2(row)
        if gdb_tail:
            header = row[:2]
            prizes = tuple([gdb_tail] * 27)
            fake_row = header + prizes
            de_data.append(fake_row)
        else:
            de_data.append(row) 
    return de_data

--------------------------------------------------

=== FILE: logic\logger.py ===
# T√™n file: logic/logger.py
# Module Logging t·∫≠p trung cho XS-DAS
import logging
import os
from logging.handlers import RotatingFileHandler

def setup_logger(name, log_file='logs/xsdas.log', level=logging.INFO):
    """
    Thi·∫øt l·∫≠p logger v·ªõi RotatingFileHandler.
    
    Args:
        name: T√™n logger (th∆∞·ªùng l√† __name__)
        log_file: ƒê∆∞·ªùng d·∫´n file log (m·∫∑c ƒë·ªãnh: logs/xsdas.log)
        level: Log level (m·∫∑c ƒë·ªãnh: INFO)
    
    Returns:
        logging.Logger: Logger instance ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh
    """
    # T·∫°o th∆∞ m·ª•c logs n·∫øu ch∆∞a c√≥
    log_dir = os.path.dirname(log_file) if os.path.dirname(log_file) else 'logs'
    if log_dir and not os.path.exists(log_dir):
        try:
            os.makedirs(log_dir, exist_ok=True)
        except OSError:
            pass  # B·ªè qua n·∫øu kh√¥ng t·∫°o ƒë∆∞·ª£c
    
    # T·∫°o logger
    logger = logging.getLogger(name)
    logger.setLevel(level)
    
    # Tr√°nh th√™m handler nhi·ªÅu l·∫ßn (n·∫øu logger ƒë√£ c√≥ handlers)
    if logger.handlers:
        return logger
    
    # T·∫°o formatter
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # RotatingFileHandler: Max 10MB, gi·ªØ 5 file backup
    try:
        file_handler = RotatingFileHandler(
            log_file,
            maxBytes=10 * 1024 * 1024,  # 10MB
            backupCount=5,
            encoding='utf-8'
        )
        file_handler.setLevel(level)
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)
    except (OSError, IOError) as e:
        # Fallback: d√πng console handler n·∫øu kh√¥ng ghi ƒë∆∞·ª£c file
        console_handler = logging.StreamHandler()
        console_handler.setLevel(level)
        console_handler.setFormatter(formatter)
        logger.addHandler(console_handler)
        logger.warning(f"Kh√¥ng th·ªÉ t·∫°o file log '{log_file}': {e}. S·ª≠ d·ª•ng console logging.")
    
    return logger

# Logger m·∫∑c ƒë·ªãnh cho to√†n b·ªô ·ª©ng d·ª•ng
default_logger = setup_logger('xsdas')



--------------------------------------------------

=== FILE: logic\lo_analytics.py ===
# logic/lo_analytics.py (FIXED V3.8.1)
from collections import Counter
try:
    from logic.constants import SCORING_WEIGHTS
except ImportError:
    # Fallback
    SCORING_WEIGHTS = {
        'LO_STREAK_MULTIPLIER': 1.0, 'LO_WINRATE_DIVISOR': 20.0, 'LO_MEMORY_DIVISOR': 10.0,
        'LO_GAN_PENALTY_LOW': 2.0, 'LO_GAN_PENALTY_MED': 5.0, 'LO_GAN_PENALTY_HIGH': 15.0,
        'LO_FREQ_BONUS_MAX': 3.0
    }

def calculate_lo_scores(bridges, gan_stats, freq_stats, top_memory=None):
    """
    T√≠nh ƒëi·ªÉm L√¥ t√¥ (00-99) d·ª±a tr√™n c√¥ng th·ª©c Attack - Defense + Bonus.
    (Fixed Tuple/Dict Handling)
    """
    # Kh·ªüi t·∫°o b·∫£ng ƒëi·ªÉm 00-99
    scores = {f"{i:02d}": 0.0 for i in range(100)}
    
    # --- 1. ATTACK: C·ªòNG ƒêI·ªÇM T·ª™ C·∫¶U (BRIDGES) ---
    if bridges:
        for b in bridges:
            pred = str(b.get('next_prediction_stl', ''))
            nums = []
            
            if '-' in pred:
                nums = pred.split('-')
            elif pred.strip().isdigit():
                nums = [pred.strip()]
            
            try:
                streak = float(b.get('current_streak', 1))
                wr_text = str(b.get('win_rate_text', '0')).replace('%', '')
                win_rate = float(wr_text) if wr_text else 0
            except:
                streak, win_rate = 1.0, 50.0
            
            # Attack Score
            attack_score = (streak * SCORING_WEIGHTS['LO_STREAK_MULTIPLIER']) + \
                           (win_rate / SCORING_WEIGHTS['LO_WINRATE_DIVISOR'])
            
            for n in nums:
                n = n.strip()
                if n in scores:
                    scores[n] += attack_score

    # --- 1b. ATTACK BONUS: C·∫¶U B·∫†C NH·ªö ---
    if top_memory:
        for item in top_memory:
            try:
                pred_mem = str(item.get('prediction', '')) 
                nums = pred_mem.split('-') if '-' in pred_mem else [pred_mem]
                conf = float(item.get('confidence', 0))
                bonus = conf / SCORING_WEIGHTS['LO_MEMORY_DIVISOR']
                for n in nums:
                    n = n.strip()
                    if n in scores:
                        scores[n] += bonus
            except: continue

    # --- 2. DEFENSE: PH·∫†T L√î GAN (KILLER) - ƒê√É FIX L·ªñI TUPLE ---
    if gan_stats:
        for item in gan_stats:
            try:
                # X·ª≠ l√Ω ƒëa h√¨nh (Polymorphism) cho Dict v√† Tuple
                if isinstance(item, dict):
                    so = item.get('so')
                    ngay_gan = item.get('so_ngay_gan', item.get('gan', 0))
                elif isinstance(item, (list, tuple)) and len(item) >= 2:
                    so = item[0]
                    ngay_gan = item[1]
                else:
                    continue

                if so in scores and ngay_gan > 10:
                    penalty = 0
                    if 10 < ngay_gan <= 15: penalty = SCORING_WEIGHTS['LO_GAN_PENALTY_LOW']
                    elif 15 < ngay_gan <= 25: penalty = SCORING_WEIGHTS['LO_GAN_PENALTY_MED']
                    elif ngay_gan > 25: penalty = SCORING_WEIGHTS['LO_GAN_PENALTY_HIGH']
                    scores[so] -= penalty
            except Exception as e: 
                # print(f"L·ªói t√≠nh gan: {e}") 
                continue

    # --- 3. BONUS: TH∆Ø·ªûNG T·∫¶N SU·∫§T ---
    if freq_stats:
        max_freq = 0
        freq_map = {}
        for item in freq_stats:
            try:
                if isinstance(item, dict):
                    so = item.get('so')
                    count = item.get('so_lan_ve', item.get('freq', 0))
                elif isinstance(item, (list, tuple)) and len(item) >= 2:
                    so = item[0]
                    count = item[1]
                else:
                    continue
                
                freq_map[so] = count
                if count > max_freq: max_freq = count
            except: continue
            
        if max_freq > 0:
            for so, count in freq_map.items():
                if so in scores:
                    bonus = (count / max_freq) * SCORING_WEIGHTS['LO_FREQ_BONUS_MAX']
                    scores[so] += bonus

    return sorted(scores.items(), key=lambda x: x[1], reverse=True)

--------------------------------------------------

=== FILE: logic\meta_learner.py ===
# logic/meta_learner.py
"""
V7.7 Phase 3 Meta-Learner Implementation

This module implements a second-level AI (Meta-Learner) that learns to optimally
combine XGBoost predictions with manual bridge scores to make final decisions.

The Meta-Learner uses Logistic Regression to balance:
- AI probability scores
- Manual bridge scores
- Confidence indicators
- Vote counts
- Recent form factors

After training on 100+ periods of historical data, it can make better decisions
than either AI or manual scoring alone.
"""

import os
import joblib
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score

# Model file paths
META_MODEL_PATH = "logic/ml_model_files/meta_learner.joblib"
META_SCALER_PATH = "logic/ml_model_files/meta_scaler.joblib"


class MetaLearner:
    """
    Second-level AI that learns to combine XGBoost predictions
    with manual scoring to make final decisions.
    """

    def __init__(self):
        self.model = LogisticRegression(
            penalty='l2',
            C=1.0,
            class_weight='balanced',
            random_state=42,
            max_iter=1000
        )
        self.scaler = StandardScaler()
        self.is_trained = False

    def prepare_meta_features(self, ai_prob, manual_score, confidence,
                              vote_count, recent_form_score):
        """
        Create meta-features from base predictions and scores.

        Args:
            ai_prob: AI probability (0-100)
            manual_score: Manual bridge score (0-10)
            confidence: Confidence level (1-7)
            vote_count: Total number of votes
            recent_form_score: Recent form bonus score

        Returns:
            Array of 10 meta-features
        """
        features = [
            ai_prob / 100.0,                           # F1: AI probability (normalized)
            manual_score / 10.0,                       # F2: Manual score (normalized)
            confidence / 7.0,                          # F3: Confidence (normalized)
            min(vote_count / 10.0, 1.0),              # F4: Vote count (capped)
            recent_form_score / 5.0,                   # F5: Recent form (normalized)
            (ai_prob / 100.0) * (manual_score / 10.0), # F6: AI √ó Manual interaction
            (ai_prob / 100.0) * (confidence / 7.0),    # F7: AI √ó Confidence
            (manual_score / 10.0) * (confidence / 7.0),# F8: Manual √ó Confidence
            abs((ai_prob / 100.0) - (manual_score / 10.0)),  # F9: Agreement metric
            min(ai_prob / 100.0, manual_score / 10.0)  # F10: Conservative score
        ]
        return np.array(features).reshape(1, -1)

    def train(self, historical_data):
        """
        Train meta-learner on historical decisions and outcomes.

        Args:
            historical_data: List of dicts with keys:
                - ai_probability: AI prediction (0-100)
                - manual_score: Manual score (0-10)
                - confidence: Confidence level (1-7)
                - vote_count: Number of votes
                - recent_form_score: Recent form bonus
                - actual_outcome: 1 if loto appeared, 0 if not

        Returns:
            tuple: (success, message, metrics_dict)
        """
        if len(historical_data) < 100:
            return False, f"Insufficient data: {len(historical_data)} samples (need 100+)", {}

        try:
            X = []
            y = []

            for record in historical_data:
                features = self.prepare_meta_features(
                    ai_prob=record.get('ai_probability', 0.0),
                    manual_score=record.get('manual_score', 0.0),
                    confidence=record.get('confidence', 0),
                    vote_count=record.get('vote_count', 0),
                    recent_form_score=record.get('recent_form_score', 0.0)
                )
                X.append(features[0])
                y.append(record['actual_outcome'])

            X = np.array(X)
            y = np.array(y)

            # Scale features
            X_scaled = self.scaler.fit_transform(X)

            # Train model
            self.model.fit(X_scaled, y)
            self.is_trained = True

            # Calculate cross-validation scores
            cv_scores = cross_val_score(self.model, X_scaled, y, cv=5, scoring='f1')
            training_score = self.model.score(X_scaled, y)

            metrics = {
                'training_accuracy': training_score,
                'cv_f1_mean': cv_scores.mean(),
                'cv_f1_std': cv_scores.std(),
                'samples_used': len(historical_data)
            }

            message = (f"Meta-Learner trained successfully!\n"
                       f"Training Accuracy: {training_score * 100:.2f}%\n"
                       f"CV F1-Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\n"
                       f"Samples: {len(historical_data)}")

            return True, message, metrics

        except Exception as e:
            return False, f"Error training Meta-Learner: {e}", {}

    def predict_final_decision(self, ai_prob, manual_score, confidence,
                               vote_count, recent_form_score,
                               thresholds=None):
        """
        Make final decision by combining all inputs through the Meta-Learner.

        Args:
            ai_prob: AI probability (0-100)
            manual_score: Manual score (0-10)
            confidence: Confidence level (1-7)
            vote_count: Number of votes
            recent_form_score: Recent form bonus
            thresholds: Optional dict with 'CHOI' and 'XEM_XET' thresholds

        Returns:
            tuple: (final_probability, decision_label)
                - final_probability: Calibrated probability (0-100)
                - decision_label: 'CH∆†I', 'XEM X√âT', or 'B·ªé QUA'
        """
        if not self.is_trained:
            # Fallback to simple heuristic if not trained
            combined = (ai_prob + manual_score * 10) / 2
            if combined >= 70:
                return combined, 'CH∆†I'
            elif combined >= 50:
                return combined, 'XEM X√âT'
            else:
                return combined, 'B·ªé QUA'

        try:
            # Prepare meta-features
            meta_features = self.prepare_meta_features(
                ai_prob, manual_score, confidence, vote_count, recent_form_score
            )

            # Scale features
            meta_features_scaled = self.scaler.transform(meta_features)

            # Get probability from meta-learner
            final_prob = self.model.predict_proba(meta_features_scaled)[0, 1] * 100

            # Apply thresholds
            if thresholds is None:
                thresholds = {'CHOI': 65, 'XEM_XET': 40}

            if final_prob >= thresholds.get('CHOI', 65):
                decision = 'CH∆†I'
            elif final_prob >= thresholds.get('XEM_XET', 40):
                decision = 'XEM X√âT'
            else:
                decision = 'B·ªé QUA'

            return final_prob, decision

        except Exception as e:
            print(f"Error in Meta-Learner prediction: {e}")
            # Fallback
            combined = (ai_prob + manual_score * 10) / 2
            if combined >= 70:
                return combined, 'CH∆†I'
            elif combined >= 50:
                return combined, 'XEM X√âT'
            else:
                return combined, 'B·ªé QUA'

    def save(self, model_path=None, scaler_path=None):
        """Save trained Meta-Learner and scaler to disk."""
        if not self.is_trained:
            raise ValueError("Cannot save untrained Meta-Learner")

        model_path = model_path or META_MODEL_PATH
        scaler_path = scaler_path or META_SCALER_PATH

        os.makedirs(os.path.dirname(model_path), exist_ok=True)

        joblib.dump(self.model, model_path)
        joblib.dump(self.scaler, scaler_path)

        return model_path, scaler_path

    def load(self, model_path=None, scaler_path=None):
        """Load trained Meta-Learner and scaler from disk."""
        model_path = model_path or META_MODEL_PATH
        scaler_path = scaler_path or META_SCALER_PATH

        if not os.path.exists(model_path) or not os.path.exists(scaler_path):
            raise FileNotFoundError("Meta-Learner model files not found")

        self.model = joblib.load(model_path)
        self.scaler = joblib.load(scaler_path)
        self.is_trained = True

        return True

    def get_feature_importance(self):
        """
        Get feature importance/coefficients from the trained model.

        Returns:
            dict: Feature names mapped to their coefficients
        """
        if not self.is_trained:
            return {}

        feature_names = [
            'AI_Probability',
            'Manual_Score',
            'Confidence',
            'Vote_Count',
            'Recent_Form',
            'AI_x_Manual',
            'AI_x_Confidence',
            'Manual_x_Confidence',
            'Agreement_Metric',
            'Conservative_Score'
        ]

        coefficients = self.model.coef_[0]
        return dict(zip(feature_names, coefficients))


def train_meta_learner_from_db():
    """
    Convenience function to train Meta-Learner from collected database data.

    Returns:
        tuple: (success, message, meta_learner_instance)
    """
    try:
        from logic.db_manager import get_db_connection

        conn = get_db_connection()
        cursor = conn.cursor()

        # Fetch all complete records
        cursor.execute("""
            SELECT ai_probability, manual_score, confidence,
                   vote_count, recent_form_score, actual_outcome
            FROM meta_learning_history
            WHERE actual_outcome IS NOT NULL
        """)

        rows = cursor.fetchall()
        conn.close()

        if len(rows) < 100:
            return False, f"Insufficient data: {len(rows)} records (need 100+)", None

        # Convert to list of dicts
        historical_data = []
        for row in rows:
            historical_data.append({
                'ai_probability': row[0] or 0.0,
                'manual_score': row[1] or 0.0,
                'confidence': row[2] or 0,
                'vote_count': row[3] or 0,
                'recent_form_score': row[4] or 0.0,
                'actual_outcome': row[5]
            })

        # Train Meta-Learner
        meta_learner = MetaLearner()
        success, message, metrics = meta_learner.train(historical_data)

        if success:
            # Save the trained model
            meta_learner.save()
            message += f"\n\nModel saved to:\n  - {META_MODEL_PATH}\n  - {META_SCALER_PATH}"

        return success, message, meta_learner

    except Exception as e:
        return False, f"Error training Meta-Learner from database: {e}", None


def load_meta_learner():
    """
    Convenience function to load a trained Meta-Learner.

    Returns:
        MetaLearner instance or None if not found
    """
    try:
        meta_learner = MetaLearner()
        meta_learner.load()
        return meta_learner
    except Exception as e:
        print(f"Could not load Meta-Learner: {e}")
        return None


--------------------------------------------------

=== FILE: logic\ml_model.py ===
# T√™n file: git1/logic/ml_model.py
#
# (PHI√äN B·∫¢N V7.9 - FIX PATH TUY·ªÜT ƒê·ªêI CHO MODEL FILES)
#
import os
import traceback

import joblib
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler

# --- C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N TUY·ªÜT ƒê·ªêI ---
# L·∫•y th∆∞ m·ª•c hi·ªán t·∫°i c·ªßa file n√†y (th∆∞ m·ª•c logic)
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
# ƒê∆∞·ªùng d·∫´n t·ªõi th∆∞ m·ª•c l∆∞u model (logic/ml_model_files)
MODEL_DIR = os.path.join(CURRENT_DIR, "ml_model_files")

# ƒê·∫£m b·∫£o th∆∞ m·ª•c t·ªìn t·∫°i ngay khi import
if not os.path.exists(MODEL_DIR):
    try:
        os.makedirs(MODEL_DIR)
    except OSError:
        pass

# C·∫≠p nh·∫≠t ƒë∆∞·ªùng d·∫´n file
MODEL_FILE_PATH = os.path.join(MODEL_DIR, "loto_model.joblib")
SCALER_FILE_PATH = os.path.join(MODEL_DIR, "ai_scaler.joblib")
# -------------------------------------

ALL_LOTOS = [str(i).zfill(2) for i in range(100)]
MIN_DATA_TO_TRAIN = 50


def _standardize_pair(stl_list):
    """Helper: ['30', '01'] -> '01-30'"""
    if not stl_list or len(stl_list) != 2:
        return None
    return "-".join(sorted(stl_list))


# --- H√ÄM N·ªòI B·ªò H·ªñ TR·ª¢ (ƒê∆Ø·ª¢C GI·ªÆ L·∫†I ƒê·ªÇ T√çNH LOTO/GAN) ---
try:
    # C·ªë g·∫Øng import b·∫±ng relative import (khi ch·∫°y trong package)
    from .bridges.bridges_classic import getAllLoto_V30
except ImportError:
    # Fallback (n·∫øu ch·∫°y ƒë·ªôc l·∫≠p ho·∫∑c l·ªói)
    print("L·ªñI: ml_model.py kh√¥ng th·ªÉ import getAllLoto_V30.")

    def getAllLoto_V30(row):
        return []


def _get_loto_gan_history(all_data_ai):
    """
    N·ªôi b·ªô: T√≠nh to√°n l·ªãch s·ª≠ gan (s·ªë ng√†y ch∆∞a v·ªÅ) cho T·∫§T C·∫¢ loto T·∫§T C·∫¢ c√°c ng√†y.
    R·∫•t n·∫∑ng, ch·ªâ ch·∫°y khi hu·∫•n luy·ªán.
    (V7.7 Phase 2) Also calculates change in gan for F14 feature.
    Tr·∫£ v·ªÅ:
        gan_history_map: { 'ky_str': {'00': 0, '01': 5, ...}, ... }
        gan_change_map: { 'ky_str': {'00': 0, '01': 1, ...}, ... }
    """
    print("... (AI Train) B·∫Øt ƒë·∫ßu t√≠nh to√°n L·ªãch s·ª≠ L√¥ Gan (n·∫∑ng)...")
    gan_history_map = {}
    gan_change_map = {}
    current_gan = {loto: 0 for loto in ALL_LOTOS}
    prev_gan = {loto: 0 for loto in ALL_LOTOS}

    # B·ªè qua ng√†y ƒë·∫ßu ti√™n (kh√¥ng c√≥ g√¨ ƒë·ªÉ t√≠nh)
    for row in all_data_ai[1:]:
        ky_str = str(row[0])
        lotos_this_row = set(getAllLoto_V30(row))

        # 1. C·∫≠p nh·∫≠t gan cho ng√†y HI·ªÜN T·∫†I
        for loto in ALL_LOTOS:
            if loto in lotos_this_row:
                current_gan[loto] = 0  # Reset gan
            else:
                current_gan[loto] += 1  # TƒÉng gan

        # 2. L∆∞u tr·ªØ b·∫£n sao c·ªßa gan (ƒë·ªÉ d√πng cho ng√†y MAI)
        # (V√¨ d·ª± ƒëo√°n cho ng√†y mai d·ª±a tr√™n gan c·ªßa ng√†y h√¥m nay)
        gan_history_map[ky_str] = current_gan.copy()
        
        # (V7.7 Phase 2: F14) Calculate change in gan
        # Change = current_gan - prev_gan
        gan_change = {}
        for loto in ALL_LOTOS:
            gan_change[loto] = current_gan[loto] - prev_gan[loto]
        gan_change_map[ky_str] = gan_change
        
        # Update prev_gan for next iteration
        prev_gan = current_gan.copy()

    print(f"... (AI Train) ƒê√£ t√≠nh xong L·ªãch s·ª≠ L√¥ Gan ({len(gan_history_map)} ng√†y).")
    return gan_history_map, gan_change_map


# ===================================================================
# II. H√ÄM T·∫†O B·ªò D·ªÆ LI·ªÜU (TRAINING DATASET) (V7.0)
# ===================================================================


def _create_ai_dataset(all_data_ai, daily_bridge_predictions_map):
    """
    (V7.0) T·∫°o b·ªô d·ªØ li·ªáu X (features) v√† y (target) t·ª´ 2 ngu·ªìn:
    1. all_data_ai (d·ªØ li·ªáu KQXS)
    2. daily_bridge_predictions_map (d·ªØ li·ªáu features c·∫ßu ƒë√£ t√≠nh to√°n tr∆∞·ªõc)
    """
    X = []  # Features
    y = []  # Target (0 = tr∆∞·ª£t, 1 = tr√∫ng)

    # 1. T√≠nh to√°n L·ªãch s·ª≠ Gan (Feature F1) and Gan Change (Feature F14)
    gan_history_map, gan_change_map = _get_loto_gan_history(all_data_ai)

    # 2. L·∫∑p qua c√°c ng√†y (b·ªè ng√†y ƒë·∫ßu ti√™n, kh√¥ng c√≥ target)
    # Ch√∫ng ta d·ª± ƒëo√°n cho K(n) d·ª±a tr√™n d·ªØ li·ªáu K(n-1)
    for k in range(1, len(all_data_ai)):
        # D·ªØ li·ªáu c·ªßa ng√†y h√¥m tr∆∞·ªõc (K(n-1))
        prev_row = all_data_ai[k - 1]
        prev_ky_str = str(prev_row[0])

        # D·ªØ li·ªáu c·ªßa ng√†y h√¥m nay (K(n)) - D√πng l√†m TARGET
        actual_row = all_data_ai[k]
        actual_ky_str = str(actual_row[0])
        actual_loto_set = set(getAllLoto_V30(actual_row))

        # L·∫•y features t·ª´ c√°c ngu·ªìn ƒë√£ t√≠nh to√°n tr∆∞·ªõc
        gan_features_for_prev_ky = gan_history_map.get(prev_ky_str, {})
        gan_change_for_prev_ky = gan_change_map.get(prev_ky_str, {})
        bridge_features_for_actual_ky = daily_bridge_predictions_map.get(
            actual_ky_str, {}
        )

        if not gan_features_for_prev_ky or not bridge_features_for_actual_ky:
            # print(f"B·ªè qua k·ª≥ {actual_ky_str}: Thi·∫øu d·ªØ li·ªáu gan ho·∫∑c c·∫ßu.")
            continue

        # 3. T·∫°o 100 h√†ng d·ªØ li·ªáu (m·ªói loto 1 h√†ng) cho ng√†y n√†y
        for loto in ALL_LOTOS:
            features = []

            # === TARGET (y) ===
            # (Loto c√≥ v·ªÅ trong ng√†y K(n) kh√¥ng?)
            target = 1 if loto in actual_loto_set else 0
            y.append(target)

            # === FEATURES (X) ===
            # (D·ª±a tr√™n d·ªØ li·ªáu c·ªßa K(n-1))

            # S·ª¨A L·ªñI NAMERROR T·∫†I ƒê√ÇY: D√πng bridge_features_for_actual_ky
            loto_features = bridge_features_for_actual_ky.get(loto, {})

            # --- FEATURE SET 1: GAN (F1) ---
            # F1: Loto n√†y ƒë√£ gan bao nhi√™u ng√†y (t√≠nh ƒë·∫øn K(n-1))
            features.append(gan_features_for_prev_ky.get(loto, 0))

            # --- FEATURE SET 2: VOTE COUNTS (F2 -> F4) ---
            # (ƒê√¢y l√† d·ªØ li·ªáu c·ªßa K(n), nh∆∞ng ƒë∆∞·ª£c t√≠nh b·∫±ng K(n-1))
            # F2: S·ªë vote t·ª´ 15 C·∫ßu C·ªï ƒêi·ªÉn
            features.append(loto_features.get("v5_count", 0))
            # F3: S·ªë vote t·ª´ C·∫ßu ƒê√£ L∆∞u (V17)
            features.append(loto_features.get("v17_count", 0))
            # F4: S·ªë vote t·ª´ C·∫ßu B·∫°c Nh·ªõ (756 c·∫ßu)
            features.append(loto_features.get("memory_count", 0))

            # --- FEATURE SET 3: T·ªîNG H·ª¢P VOTE (F5 -> F6) ---
            features.append(
                loto_features.get("v5_count", 0)
                + loto_features.get("v17_count", 0)
                + loto_features.get("memory_count", 0)
            )
            f6 = (
                (1 if loto_features.get("v5_count", 0) > 0 else 0)
                + (1 if loto_features.get("v17_count", 0) > 0 else 0)
                + (1 if loto_features.get("memory_count", 0) > 0 else 0)
            )
            features.append(f6)

            # --- FEATURE SET 4: CH·∫§T L∆Ø·ª¢NG (Q) FEATURES (F7 -> F9) ---
            # F7: T·ª∑ l·ªá th·∫Øng trung b√¨nh (Managed Bridges)
            features.append(loto_features.get("q_avg_win_rate", 0.0))

            # F8: R·ªßi ro K2N t·ªëi thi·ªÉu
            features.append(loto_features.get("q_min_k2n_risk", 999.0))

            # F9: Chu·ªói Th·∫Øng/Thua hi·ªán t·∫°i t·ªëi ƒëa (Max Current Streak)
            features.append(loto_features.get("q_max_curr_streak", -999.0))

            # --- FEATURE SET 5: PHASE 2 NEW Q-FEATURES (F10 -> F12) ---
            # F10: Chu·ªói thua li√™n ti·∫øp hi·ªán t·∫°i t·ªëi ƒëa (Max Current Lose Streak)
            features.append(loto_features.get("q_max_current_lose_streak", 0))

            # F11: Binary indicator - G·∫ßn ng∆∞·ª°ng ph·∫°t K2N (Is K2N Risk Close)
            features.append(loto_features.get("q_is_k2n_risk_close", 0))

            # F12: ƒê·ªô l·ªách chu·∫©n Win Rate (100 k·ª≥) - ƒêo ·ªïn ƒë·ªãnh c·ªßa c·∫ßu
            features.append(loto_features.get("q_avg_win_rate_stddev_100", 0.0))

            # --- FEATURE SET 6: V7.7 PHASE 2 NEW FEATURES (F13 -> F14) ---
            # F13: Binary indicator - Loto c√≥ v·ªÅ trong 3 k·ª≥ g·∫ßn ƒë√¢y kh√¥ng
            features.append(loto_features.get("q_hit_in_last_3_days", 0))

            # F14: Thay ƒë·ªïi gi√° tr·ªã Gan (Change_in_Gan)
            features.append(gan_change_for_prev_ky.get(loto, 0))

            # Th√™m h√†ng features n√†y v√†o X
            X.append(features)

    return np.array(X), np.array(y)


# ===================================================================
# III. H√ÄM API CH√çNH (G·ªåI T·ª™ LOTTERY_SERVICE) (V7.0)
# ===================================================================


def _tune_hyperparameters(X_train, y_train, scale_pos_weight):
    """
    (Phase 3: Model Optimization) T·ª± ƒë·ªông t√¨m hyperparameters t·ªëi ∆∞u v·ªõi GridSearchCV.
    
    Args:
        X_train: Training features
        y_train: Training labels
        scale_pos_weight: Weight for positive class
        
    Returns:
        dict: Best hyperparameters found
    """
    print("... (Phase 3) B·∫Øt ƒë·∫ßu Hyperparameter Tuning v·ªõi GridSearchCV...")
    
    # Define parameter grid to search
    param_grid = {
        'n_estimators': [100, 150, 200],
        'max_depth': [3, 4, 5, 6],
        'learning_rate': [0.01, 0.05, 0.1],
        'min_child_weight': [1, 3, 5],
        'subsample': [0.8, 1.0],
        'colsample_bytree': [0.8, 1.0]
    }
    
    # Base model for grid search
    base_model = xgb.XGBClassifier(
        objective="binary:logistic",
        eval_metric="logloss",
        scale_pos_weight=scale_pos_weight,
        random_state=42
    )
    
    # GridSearchCV with 3-fold cross-validation
    grid_search = GridSearchCV(
        estimator=base_model,
        param_grid=param_grid,
        cv=3,
        scoring='accuracy',
        n_jobs=-1,
        verbose=1
    )
    
    grid_search.fit(X_train, y_train)
    
    print(f"... (Phase 3) Best hyperparameters: {grid_search.best_params_}")
    print(f"... (Phase 3) Best CV score: {grid_search.best_score_:.4f}")
    
    return grid_search.best_params_


def train_ai_model(all_data_ai, daily_bridge_predictions_map, use_hyperparameter_tuning=False):
    """
    (V7.0) API: Hu·∫•n luy·ªán, chu·∫©n h√≥a (scale), v√† l∆∞u m√¥ h√¨nh AI.
    """
    try:
        if not all_data_ai or len(all_data_ai) < MIN_DATA_TO_TRAIN:
            return (
                False,
                f"L·ªói Hu·∫•n luy·ªán AI: C·∫ßn √≠t nh·∫•t {MIN_DATA_TO_TRAIN} k·ª≥ d·ªØ li·ªáu.",
            )

        # 1. T·∫°o b·ªô d·ªØ li·ªáu
        print("... (AI Train) ƒêang t·∫°o b·ªô d·ªØ li·ªáu X, y...")
        X, y = _create_ai_dataset(all_data_ai, daily_bridge_predictions_map)
        if X.shape[0] == 0 or y.shape[0] == 0:
            return False, "L·ªói Hu·∫•n luy·ªán AI: Kh√¥ng th·ªÉ t·∫°o b·ªô d·ªØ li·ªáu (X, y r·ªóng)."
        print(f"... (AI Train) ƒê√£ t·∫°o b·ªô d·ªØ li·ªáu (Shape: {X.shape}, {y.shape})")

        # 2. Chu·∫©n h√≥a (Scaling)
        print("... (AI Train) ƒêang chu·∫©n h√≥a (StandardScaler)...")
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        # 3. Ph√¢n chia Train/Test
        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y, test_size=0.2, random_state=42, stratify=y
        )

        # 4. Hu·∫•n luy·ªán (XGBoost)
        print("... (AI Train) B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh XGBoost...")
        # (V7.0) Tinh ch·ªânh XGBoost
        # C√¢n b·∫±ng tr·ªçng s·ªë l·ªõp (v√¨ l·ªõp 1 (tr√∫ng) √≠t h∆°n l·ªõp 0 (tr∆∞·ª£t))
        scale_pos_weight = (len(y) - sum(y)) / sum(y)
        
        # (Phase 3: Model Optimization) Hyperparameter tuning option
        if use_hyperparameter_tuning:
            best_params = _tune_hyperparameters(X_train, y_train, scale_pos_weight)
            model = xgb.XGBClassifier(
                objective="binary:logistic",
                eval_metric="logloss",
                scale_pos_weight=scale_pos_weight,
                random_state=42,
                **best_params  # Use optimized hyperparameters
            )
        else:
            # Use default good parameters from config
            try:
                from .config_manager import SETTINGS
                n_estimators = getattr(SETTINGS, "AI_N_ESTIMATORS", 200)
                learning_rate = getattr(SETTINGS, "AI_LEARNING_RATE", 0.05)
                max_depth = getattr(SETTINGS, "AI_MAX_DEPTH", 6)
            except ImportError:
                n_estimators = 200
                learning_rate = 0.05
                max_depth = 6
                
            model = xgb.XGBClassifier(
                objective="binary:logistic",
                eval_metric="logloss",
                n_estimators=n_estimators,
                learning_rate=learning_rate,
                max_depth=max_depth,
                scale_pos_weight=scale_pos_weight,
                random_state=42,
            )

        model.fit(X_train, y_train)
        print("... (AI Train) Hu·∫•n luy·ªán ho√†n t·∫•t.")
        
        # (Phase 3: Model Optimization) Cross-validation score
        print("... (Phase 3) ƒêang t√≠nh Cross-Validation score...")
        cv_scores = cross_val_score(model, X_scaled, y, cv=5, scoring='accuracy')
        print(f"... (Phase 3) CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")

        # 5. (Phase 3: Model Optimization) Extract and save feature importance
        print("... (Phase 3) Tr√≠ch xu·∫•t Feature Importance...")
        feature_names = [
            "F1_Gan",
            "F2_V5_Count",
            "F3_V17_Count",
            "F4_Memory_Count",
            "F5_Total_Votes",
            "F6_Source_Diversity",
            "F7_Avg_Win_Rate",
            "F8_Min_K2N_Risk",
            "F9_Max_Curr_Streak",
            "F10_Max_Lose_Streak",
            "F11_Is_K2N_Risk_Close",
            "F12_Win_Rate_StdDev",
            "F13_Hit_Last_3_Days",
            "F14_Change_In_Gan"
        ]
        
        feature_importance = dict(zip(feature_names, model.feature_importances_))
        sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)
        
        print("... (Phase 3) Top 5 Features quan tr·ªçng nh·∫•t:")
        for i, (feature, importance) in enumerate(sorted_features[:5], 1):
            print(f"    {i}. {feature}: {importance:.4f}")
        
        # [FIX] ƒê·∫£m b·∫£o th∆∞ m·ª•c t·ªìn t·∫°i tr∆∞·ªõc khi l∆∞u
        os.makedirs(MODEL_DIR, exist_ok=True)
        feature_importance_file = os.path.join(MODEL_DIR, "feature_importance.joblib")
        joblib.dump(feature_importance, feature_importance_file)
        
        # 6. L∆∞u m√¥ h√¨nh v√† Scaler
        # os.makedirs(os.path.dirname(MODEL_FILE_PATH), exist_ok=True) # ƒê√£ l√†m ·ªü tr√™n
        joblib.dump(model, MODEL_FILE_PATH)
        joblib.dump(scaler, SCALER_FILE_PATH)
        print(f"... (AI Train) ƒê√£ l∆∞u m√¥ h√¨nh v√†o '{MODEL_FILE_PATH}'")

        # 7. ƒê√°nh gi√° (T√πy ch·ªçn)
        test_accuracy = model.score(X_test, y_test)
        cv_mean = cv_scores.mean()
        msg = (f"Hu·∫•n luy·ªán AI (V7.7 - Phase 2) th√†nh c√¥ng!\n"
               f"Test Accuracy: {test_accuracy * 100:.2f}%\n"
               f"CV Accuracy: {cv_mean * 100:.2f}% (+/- {cv_scores.std() * 2 * 100:.2f}%)\n"
               f"Features: 14 (F13: Hit_Last_3_Days, F14: Change_In_Gan added)")
        print(f"... (AI Train) {msg}")
        return True, msg

    except Exception as e:
        return (
            False,
            f"L·ªói nghi√™m tr·ªçng khi Hu·∫•n luy·ªán AI: {e}\n{traceback.format_exc()}",
        )


def get_ai_predictions(all_data_ai, bridge_predictions_for_today):
    """
    (V7.0) API: T·∫£i m√¥ h√¨nh ƒë√£ l∆∞u v√† d·ª± ƒëo√°n 100 loto cho ng√†y mai.
    """
    try:
        # 1. T·∫£i m√¥ h√¨nh v√† Scaler
        if not os.path.exists(MODEL_FILE_PATH) or not os.path.exists(SCALER_FILE_PATH):
            return (
                None,
                "L·ªói AI: Kh√¥ng t√¨m th·∫•y file 'loto_model.joblib' ho·∫∑c 'ai_scaler.joblib'. Vui l√≤ng Hu·∫•n luy·ªán AI.",
            )
        model = joblib.load(MODEL_FILE_PATH)
        scaler = joblib.load(SCALER_FILE_PATH)

        # 2. L·∫•y d·ªØ li·ªáu Gan m·ªõi nh·∫•t (F1) and Gan Change (F14)
        # Ch·ªâ c·∫ßn t√≠nh cho ng√†y cu·ªëi c√πng
        # L∆∞u √Ω: D·ª± ƒëo√°n cho ng√†y mai d·ª±a tr√™n d·ªØ li·ªáu ng√†y h√¥m nay (last_ky_str)
        # Logic ƒë·ªìng nh·∫•t v·ªõi training: l·∫•y gan_change c·ªßa ng√†y tr∆∞·ªõc ƒë√≥ ƒë·ªÉ d·ª± ƒëo√°n
        gan_history_map, gan_change_map = _get_loto_gan_history(all_data_ai)
        last_ky_str = str(all_data_ai[-1][0])  # Ng√†y h√¥m nay (t∆∞∆°ng ƒë∆∞∆°ng prev_ky trong training)
        gan_features_today = gan_history_map.get(last_ky_str)
        gan_change_for_last_ky = gan_change_map.get(last_ky_str, {})  # gan_change c·ªßa ng√†y h√¥m nay

        if not gan_features_today:
            return None, "L·ªói AI: Kh√¥ng th·ªÉ t√≠nh L√¥ Gan cho ng√†y d·ª± ƒëo√°n."

        # 3. T·∫°o 100 h√†ng (loto) features (X_new)
        X_new = []
        for loto in ALL_LOTOS:
            features = []
            loto_features = bridge_predictions_for_today.get(loto, {})

            # --- FEATURE SET 1: GAN (F1) ---
            features.append(gan_features_today.get(loto, 0))

            # --- FEATURE SET 2: VOTE COUNTS (F2 -> F4) ---
            features.append(loto_features.get("v5_count", 0))
            features.append(loto_features.get("v17_count", 0))
            features.append(loto_features.get("memory_count", 0))

            # --- FEATURE SET 3: T·ªîNG H·ª¢P VOTE (F5 -> F6) ---
            features.append(
                loto_features.get("v5_count", 0)
                + loto_features.get("v17_count", 0)
                + loto_features.get("memory_count", 0)
            )
            f6 = (
                (1 if loto_features.get("v5_count", 0) > 0 else 0)
                + (1 if loto_features.get("v17_count", 0) > 0 else 0)
                + (1 if loto_features.get("memory_count", 0) > 0 else 0)
            )
            features.append(f6)

            # --- FEATURE SET 4: CH·∫§T L∆Ø·ª¢NG (Q) FEATURES (F7 -> F9) ---
            # F7: T·ª∑ l·ªá th·∫Øng trung b√¨nh (Managed Bridges)
            features.append(loto_features.get("q_avg_win_rate", 0.0))

            # F8: R·ªßi ro K2N t·ªëi thi·ªÉu
            features.append(loto_features.get("q_min_k2n_risk", 999.0))

            # F9: Chu·ªói Th·∫Øng/Thua hi·ªán t·∫°i t·ªëi ƒëa (Max Current Streak)
            features.append(loto_features.get("q_max_curr_streak", -999.0))

            # --- FEATURE SET 5: PHASE 2 NEW Q-FEATURES (F10 -> F12) ---
            # F10: Chu·ªói thua li√™n ti·∫øp hi·ªán t·∫°i t·ªëi ƒëa (Max Current Lose Streak)
            features.append(loto_features.get("q_max_current_lose_streak", 0))

            # F11: Binary indicator - G·∫ßn ng∆∞·ª°ng ph·∫°t K2N (Is K2N Risk Close)
            features.append(loto_features.get("q_is_k2n_risk_close", 0))

            # F12: ƒê·ªô l·ªách chu·∫©n Win Rate (100 k·ª≥) - ƒêo ·ªïn ƒë·ªãnh c·ªßa c·∫ßu
            features.append(loto_features.get("q_avg_win_rate_stddev_100", 0.0))

            # --- FEATURE SET 6: V7.7 PHASE 2 NEW FEATURES (F13 -> F14) ---
            # F13: Binary indicator - Loto c√≥ v·ªÅ trong 3 k·ª≥ g·∫ßn ƒë√¢y kh√¥ng
            features.append(loto_features.get("q_hit_in_last_3_days", 0))

            # F14: Thay ƒë·ªïi gi√° tr·ªã Gan (Change_in_Gan)
            features.append(gan_change_for_last_ky.get(loto, 0))

            # Th√™m h√†ng features n√†y v√†o X_new
            X_new.append(features)

        X_new_scaled = scaler.transform(np.array(X_new))

        # D·ª± ƒëo√°n x√°c su·∫•t (Probability)
        probabilities = model.predict_proba(X_new_scaled)[
            :, 1
        ]  # L·∫•y x√°c su·∫•t c·ªßa l·ªõp 1 (C√≥ v·ªÅ)

        results = []
        for i, loto in enumerate(ALL_LOTOS):
            results.append(
                {"loto": loto, "probability": probabilities[i] * 100}  # Chuy·ªÉn sang %
            )

        # S·∫Øp x·∫øp theo x√°c su·∫•t gi·∫£m d·∫ßn
        results.sort(key=lambda x: x["probability"], reverse=True)

        return results, "D·ª± ƒëo√°n AI (V7.7 - 14 Features) th√†nh c√¥ng."

    except Exception as e:
        return None, f"L·ªói nghi√™m tr·ªçng khi D·ª± ƒëo√°n AI: {e}\n{traceback.format_exc()}"

--------------------------------------------------

=== FILE: logic\models.py ===
# logic/models.py
"""
Data models for K1N-primary detection flow.

Defines dataclasses for bridge candidates, scan results, and import configurations.
"""

from dataclasses import dataclass, field
from typing import Optional, List, Dict, Any
from datetime import datetime


def _get_current_timestamp() -> str:
    """Factory function for default timestamp (proper default factory)."""
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


@dataclass
class Candidate:
    """
    Represents a bridge candidate detected by scanner.
    
    Used by scanners to return detected bridges without writing to DB.
    Contains both K1N and K2N rates for policy-based filtering.
    
    Attributes:
        name: Bridge name/identifier
        normalized_name: Normalized name for duplicate checking (lowercase, no special chars)
        type: Bridge type ('lo' or 'de')
        kind: Bridge kind ('single' for individual bridges, 'set' for grouped bridges)
        k1n_lo: K1N (real) rate for LO bridges (0-100)
        k1n_de: K1N (real) rate for DE bridges (0-100)
        k2n_lo: K2N (simulated) rate for LO bridges (0-100)
        k2n_de: K2N (simulated) rate for DE bridges (0-100)
        stl: Soi Tr√°nh L√¥ prediction string
        reason: Detection reason/algorithm name
        detected_at: Timestamp of detection
        pos1_idx: Position 1 index (for V17 bridges)
        pos2_idx: Position 2 index (for V17 bridges)
        description: Bridge description
        streak: Current winning streak
        win_count_10: Wins in last 10 periods
        rate_missing: Whether rates are missing from cache
        metadata: Additional bridge-specific metadata
    """
    
    # Required fields
    name: str
    normalized_name: str
    type: str  # 'lo' or 'de'
    kind: str  # 'single' or 'set'
    
    # K1N rates (real backtest)
    k1n_lo: float = 0.0
    k1n_de: float = 0.0
    
    # K2N rates (simulated/cache)
    k2n_lo: float = 0.0
    k2n_de: float = 0.0
    
    # Bridge details
    stl: str = "N/A"
    reason: str = ""
    detected_at: str = field(default_factory=_get_current_timestamp)
    
    # Position indices
    pos1_idx: Optional[int] = None
    pos2_idx: Optional[int] = None
    
    # Optional fields
    description: str = ""
    streak: int = 0
    win_count_10: int = 0
    rate_missing: bool = False
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def get_primary_rate(self, policy_type: str = "k1n") -> float:
        """
        Get primary rate based on bridge type and policy.
        
        Args:
            policy_type: 'k1n' or 'k2n'
            
        Returns:
            Rate value (0-100)
        """
        if policy_type == "k1n":
            return self.k1n_lo if self.type == "lo" else self.k1n_de
        else:
            return self.k2n_lo if self.type == "lo" else self.k2n_de
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert candidate to dictionary for DB operations."""
        return {
            'name': self.name,
            'description': self.description,
            'type': f"{self.type.upper()}_{'SET' if self.kind == 'set' else 'SINGLE'}",
            'k1n_rate_lo': self.k1n_lo,
            'k1n_rate_de': self.k1n_de,
            'k2n_rate_lo': self.k2n_lo,
            'k2n_rate_de': self.k2n_de,
            'pos1_idx': self.pos1_idx,
            'pos2_idx': self.pos2_idx,
            'win_rate_text': f"{self.get_primary_rate('k1n'):.1f}%",
            'search_rate_text': f"{self.get_primary_rate('k2n'):.1f}%",
            'current_streak': self.streak,
            'next_prediction_stl': self.stl,
            'recent_win_count_10': self.win_count_10,
            'is_pending': 1,  # Default to pending
            'is_enabled': 0,  # Default to disabled
        }


@dataclass
class ScanResult:
    """
    Result of a bridge scanning operation.
    
    Attributes:
        candidates: List of detected bridge candidates
        total_scanned: Total number of bridges scanned
        excluded_count: Number of bridges excluded (duplicates)
        scan_duration: Scan duration in seconds
        metadata: Additional scan metadata (algorithm params, etc.)
    """
    candidates: List[Candidate] = field(default_factory=list)
    total_scanned: int = 0
    excluded_count: int = 0
    scan_duration: float = 0.0
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def summary(self) -> str:
        """Get human-readable scan summary."""
        return (
            f"Scan completed in {self.scan_duration:.2f}s: "
            f"{len(self.candidates)} candidates found, "
            f"{self.excluded_count} excluded (duplicates)"
        )


@dataclass
class ImportConfig:
    """
    Configuration for bridge import operations.
    
    Attributes:
        policy_type: Import policy ('k1n_primary', 'k2n_primary', 'combined')
        threshold_k1n_lo: K1N threshold for LO bridges
        threshold_k1n_de: K1N threshold for DE bridges
        threshold_k2n_lo: K2N threshold for LO bridges
        threshold_k2n_de: K2N threshold for DE bridges
        fallback_to_k2n: Whether to fallback to K2N if K1N missing
        default_is_enabled: Default enabled state for imported bridges
        default_is_pending: Default pending state for imported bridges
        preview_only: If True, don't write to DB (preview mode)
        auto_approve: If True, set is_pending=0 and is_enabled=1
    """
    policy_type: str = "k1n_primary"
    threshold_k1n_lo: float = 85.0
    threshold_k1n_de: float = 90.0
    threshold_k2n_lo: float = 80.0
    threshold_k2n_de: float = 85.0
    fallback_to_k2n: bool = True
    default_is_enabled: bool = False
    default_is_pending: bool = True
    preview_only: bool = False
    auto_approve: bool = False
    
    def meets_threshold(self, candidate: Candidate) -> bool:
        """
        Check if candidate meets import threshold.
        
        Args:
            candidate: Bridge candidate to check
            
        Returns:
            True if candidate meets threshold
        """
        if self.policy_type == "k1n_primary":
            # Check K1N first
            k1n_rate = candidate.get_primary_rate("k1n")
            threshold = self.threshold_k1n_lo if candidate.type == "lo" else self.threshold_k1n_de
            
            if k1n_rate >= threshold:
                return True
            
            # Fallback to K2N if enabled and K1N is zero/missing
            if self.fallback_to_k2n and k1n_rate == 0.0:
                k2n_rate = candidate.get_primary_rate("k2n")
                threshold_k2n = self.threshold_k2n_lo if candidate.type == "lo" else self.threshold_k2n_de
                return k2n_rate >= threshold_k2n
            
            return False
        
        elif self.policy_type == "k2n_primary":
            k2n_rate = candidate.get_primary_rate("k2n")
            threshold = self.threshold_k2n_lo if candidate.type == "lo" else self.threshold_k2n_de
            return k2n_rate >= threshold
        
        elif self.policy_type == "combined":
            # Both K1N and K2N must meet threshold
            k1n_rate = candidate.get_primary_rate("k1n")
            k2n_rate = candidate.get_primary_rate("k2n")
            threshold_k1n = self.threshold_k1n_lo if candidate.type == "lo" else self.threshold_k1n_de
            threshold_k2n = self.threshold_k2n_lo if candidate.type == "lo" else self.threshold_k2n_de
            return k1n_rate >= threshold_k1n and k2n_rate >= threshold_k2n
        
        return False


--------------------------------------------------

=== FILE: logic\performance_monitor.py ===
# logic/performance_monitor.py
"""
V7.7 Phase 3 Performance Monitoring System

This module tracks model performance over time and detects degradation.
It provides:
- Performance metrics tracking (F1-Score, Accuracy)
- Degradation detection
- Alerting mechanism
- Historical analysis
"""

from datetime import datetime
import numpy as np


class PerformanceMonitor:
    """
    Track model performance over time and detect degradation.
    """

    def __init__(self, degradation_threshold=0.02, lookback_periods=7):
        """
        Initialize Performance Monitor.

        Args:
            degradation_threshold: F1-Score drop threshold to trigger alert (default: 0.02)
            lookback_periods: Number of periods for moving average (default: 7)
        """
        self.performance_history = []  # List of performance records
        self.degradation_threshold = degradation_threshold
        self.lookback_periods = lookback_periods
        self.alerts = []

    def record_performance(self, date, predictions, actuals, model_version=None):
        """
        Calculate and record performance metrics.

        Args:
            date: Date of the predictions
            predictions: List of predicted labels (0/1)
            actuals: List of actual outcomes (0/1)
            model_version: Optional model version string

        Returns:
            dict: Calculated metrics
        """
        try:
            from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score

            # Calculate metrics
            f1 = f1_score(actuals, predictions, zero_division=0)
            acc = accuracy_score(actuals, predictions)
            precision = precision_score(actuals, predictions, zero_division=0)
            recall = recall_score(actuals, predictions, zero_division=0)

            record = {
                'date': date,
                'f1_score': f1,
                'accuracy': acc,
                'precision': precision,
                'recall': recall,
                'samples': len(predictions),
                'model_version': model_version,
                'timestamp': datetime.now()
            }

            self.performance_history.append(record)

            # Check for degradation
            if self._check_degradation():
                self._trigger_alert(record)

            return record

        except Exception as e:
            print(f"Error recording performance: {e}")
            return {}

    def _check_degradation(self, lookback=None):
        """
        Check if recent performance is degrading.

        Uses moving average comparison.

        Args:
            lookback: Number of periods to compare (default: self.lookback_periods)

        Returns:
            bool: True if degradation detected
        """
        if lookback is None:
            lookback = self.lookback_periods

        if len(self.performance_history) < lookback * 2:
            return False

        recent = self.performance_history[-lookback:]
        previous = self.performance_history[-lookback * 2:-lookback]

        recent_avg = np.mean([x['f1_score'] for x in recent])
        previous_avg = np.mean([x['f1_score'] for x in previous])

        degradation = previous_avg - recent_avg
        return degradation > self.degradation_threshold

    def _trigger_alert(self, record):
        """
        Trigger alert for performance degradation.

        Args:
            record: Performance record that triggered the alert
        """
        alert = {
            'timestamp': datetime.now(),
            'type': 'DEGRADATION',
            'f1_score': record['f1_score'],
            'message': f"Performance degradation detected! F1-Score: {record['f1_score']:.4f}",
            'severity': 'HIGH' if record['f1_score'] < 0.5 else 'MEDIUM'
        }

        self.alerts.append(alert)
        print(f"üö® ALERT: {alert['message']}")

    def get_recent_performance(self, periods=7):
        """
        Get performance for recent periods.

        Args:
            periods: Number of recent periods to retrieve

        Returns:
            list: Recent performance records
        """
        if len(self.performance_history) == 0:
            return []

        return self.performance_history[-periods:]

    def get_performance_summary(self):
        """
        Get summary statistics of model performance.

        Returns:
            dict: Summary with mean, std, min, max for each metric
        """
        if len(self.performance_history) == 0:
            return {
                'count': 0,
                'message': 'No performance data available'
            }

        f1_scores = [x['f1_score'] for x in self.performance_history]
        accuracies = [x['accuracy'] for x in self.performance_history]

        return {
            'count': len(self.performance_history),
            'f1_score': {
                'mean': np.mean(f1_scores),
                'std': np.std(f1_scores),
                'min': np.min(f1_scores),
                'max': np.max(f1_scores),
                'current': f1_scores[-1] if f1_scores else None
            },
            'accuracy': {
                'mean': np.mean(accuracies),
                'std': np.std(accuracies),
                'min': np.min(accuracies),
                'max': np.max(accuracies),
                'current': accuracies[-1] if accuracies else None
            },
            'trend': self._calculate_trend(),
            'alerts_count': len(self.alerts)
        }

    def _calculate_trend(self):
        """
        Calculate performance trend (improving/degrading/stable).

        Returns:
            str: 'IMPROVING', 'DEGRADING', or 'STABLE'
        """
        if len(self.performance_history) < 5:
            return 'INSUFFICIENT_DATA'

        recent_5 = [x['f1_score'] for x in self.performance_history[-5:]]

        # Simple linear regression
        x = np.arange(len(recent_5))
        coeffs = np.polyfit(x, recent_5, 1)
        slope = coeffs[0]

        if slope > 0.01:
            return 'IMPROVING'
        elif slope < -0.01:
            return 'DEGRADING'
        else:
            return 'STABLE'

    def get_alerts(self, recent_only=True, count=10):
        """
        Get performance alerts.

        Args:
            recent_only: Only return recent alerts
            count: Maximum number of alerts to return

        Returns:
            list: Alert records
        """
        if recent_only:
            return self.alerts[-count:]
        return self.alerts

    def clear_alerts(self):
        """Clear all alerts."""
        self.alerts = []

    def save_to_database(self):
        """
        Save performance history to database.

        Returns:
            tuple: (success, message)
        """
        try:
            from logic.db_manager import get_db_connection

            conn = get_db_connection()
            cursor = conn.cursor()

            # Save recent performance records
            for record in self.performance_history[-10:]:  # Save last 10 records
                cursor.execute("""
                    INSERT INTO model_performance_log
                    (log_date, model_version, f1_score, accuracy, training_type, notes)
                    VALUES (?, ?, ?, ?, ?, ?)
                """, (
                    record['date'],
                    record.get('model_version', 'V7.7'),
                    record['f1_score'],
                    record['accuracy'],
                    'evaluation',
                    f"Precision: {record['precision']:.4f}, Recall: {record['recall']:.4f}"
                ))

            conn.commit()
            conn.close()

            return True, f"Saved {len(self.performance_history[-10:])} performance records"

        except Exception as e:
            return False, f"Error saving to database: {e}"

    def load_from_database(self, days=30):
        """
        Load performance history from database.

        Args:
            days: Number of days to load (default: 30)

        Returns:
            tuple: (success, message)
        """
        try:
            from logic.db_manager import get_db_connection

            conn = get_db_connection()
            cursor = conn.cursor()

            # Load recent records
            cursor.execute("""
                SELECT log_date, model_version, f1_score, accuracy, notes
                FROM model_performance_log
                WHERE training_type = 'evaluation'
                AND log_date >= date('now', ?)
                ORDER BY log_date
            """, (f'-{days} days',))

            rows = cursor.fetchall()
            conn.close()

            # Convert to performance history format
            for row in rows:
                # Parse precision and recall from notes if available
                precision, recall = 0.0, 0.0
                if row[4]:  # notes
                    try:
                        parts = row[4].split(',')
                        precision = float(parts[0].split(':')[1].strip())
                        recall = float(parts[1].split(':')[1].strip())
                    except Exception:
                        pass

                record = {
                    'date': row[0],
                    'model_version': row[1],
                    'f1_score': row[2],
                    'accuracy': row[3],
                    'precision': precision,
                    'recall': recall,
                    'samples': 0,  # Not stored
                    'timestamp': datetime.now()
                }
                self.performance_history.append(record)

            return True, f"Loaded {len(rows)} performance records"

        except Exception as e:
            return False, f"Error loading from database: {e}"


# Singleton instance
_monitor_instance = None


def get_performance_monitor():
    """Get singleton instance of PerformanceMonitor."""
    global _monitor_instance
    if _monitor_instance is None:
        _monitor_instance = PerformanceMonitor()
    return _monitor_instance


--------------------------------------------------

=== FILE: logic\phase3_data_collector.py ===
# logic/phase3_data_collector.py
"""
V7.7 Phase 3 Data Collection Module

This module collects prediction data alongside actual outcomes to train
the Meta-Learner in Phase 3. It automatically logs:
- AI probability predictions
- Manual scores (from bridge analysis)
- Confidence levels
- Vote counts
- Actual outcomes

After collecting 100+ periods, this data will be used to train the Meta-Learner.
"""

from datetime import datetime
import traceback


class Phase3DataCollector:
    """
    Collects prediction data for Phase 3 Meta-Learner training.
    
    Usage:
        collector = Phase3DataCollector()
        collector.log_prediction(ky, loto, ai_prob, manual_score, confidence, votes)
        collector.log_outcome(ky, loto, actual_outcome)
    """
    
    def __init__(self):
        self.db_conn = None
    
    def _get_connection(self):
        """Get database connection."""
        if self.db_conn is None:
            import sqlite3
            from logic.db_manager import DB_NAME
            self.db_conn = sqlite3.connect(DB_NAME)
        return self.db_conn
    
    def log_prediction(self, ky, loto, ai_probability, manual_score,
                       confidence, vote_count, recent_form_score=0.0):
        """
        Log a prediction for a specific ky and loto.
        
        Args:
            ky: Period identifier (e.g., '20001')
            loto: Loto number (e.g., '00', '01', ...)
            ai_probability: AI model probability (0-100)
            manual_score: Manual bridge score (0-10)
            confidence: Confidence level (1-7)
            vote_count: Total number of votes
            recent_form_score: Recent form bonus score
        
        Returns:
            bool: True if successful, False otherwise
        """
        try:
            conn = self._get_connection()
            cursor = conn.cursor()
            
            # Insert or update prediction data
            cursor.execute("""
                INSERT OR REPLACE INTO meta_learning_history
                (ky, loto, ai_probability, manual_score, confidence,
                 vote_count, recent_form_score, actual_outcome, decision_time)
                VALUES (?, ?, ?, ?, ?, ?, ?, NULL, ?)
            """, (
                str(ky),
                str(loto),
                float(ai_probability),
                float(manual_score),
                int(confidence),
                int(vote_count),
                float(recent_form_score),
                datetime.now()
            ))
            
            conn.commit()
            return True
            
        except Exception as e:
            print(f"Error logging prediction for {ky}/{loto}: {e}")
            traceback.print_exc()
            return False
    
    def log_outcome(self, ky, loto, actual_outcome):
        """
        Log the actual outcome for a specific ky and loto.
        
        Args:
            ky: Period identifier
            loto: Loto number
            actual_outcome: 1 if loto appeared, 0 if not
        
        Returns:
            bool: True if successful, False otherwise
        """
        try:
            conn = self._get_connection()
            cursor = conn.cursor()
            
            # Update the actual outcome
            cursor.execute("""
                UPDATE meta_learning_history
                SET actual_outcome = ?
                WHERE ky = ? AND loto = ?
            """, (int(actual_outcome), str(ky), str(loto)))
            
            conn.commit()
            
            if cursor.rowcount == 0:
                print(f"Warning: No prediction found for {ky}/{loto} to update outcome")
                return False
            
            return True
            
        except Exception as e:
            print(f"Error logging outcome for {ky}/{loto}: {e}")
            traceback.print_exc()
            return False
    
    def log_batch_predictions(self, ky, predictions_list):
        """
        Log a batch of predictions for a specific ky.
        
        Args:
            ky: Period identifier
            predictions_list: List of dicts with keys:
                - loto
                - ai_probability
                - manual_score
                - confidence
                - vote_count
                - recent_form_score (optional)
        
        Returns:
            tuple: (success_count, total_count)
        """
        success_count = 0
        total_count = len(predictions_list)
        
        for pred in predictions_list:
            result = self.log_prediction(
                ky=ky,
                loto=pred['loto'],
                ai_probability=pred.get('ai_probability', 0.0),
                manual_score=pred.get('manual_score', 0.0),
                confidence=pred.get('confidence', 0),
                vote_count=pred.get('vote_count', 0),
                recent_form_score=pred.get('recent_form_score', 0.0)
            )
            if result:
                success_count += 1
        
        return success_count, total_count
    
    def log_batch_outcomes(self, ky, lotos_appeared):
        """
        Log actual outcomes for a specific ky.
        
        Args:
            ky: Period identifier
            lotos_appeared: List or set of lotos that appeared (e.g., ['00', '15', '27'])
        
        Returns:
            int: Number of outcomes logged
        """
        lotos_appeared_set = set(lotos_appeared)
        count = 0
        
        try:
            conn = self._get_connection()
            cursor = conn.cursor()
            
            # Get all predictions for this ky
            cursor.execute("""
                SELECT loto FROM meta_learning_history
                WHERE ky = ? AND actual_outcome IS NULL
            """, (str(ky),))
            
            predicted_lotos = [row[0] for row in cursor.fetchall()]
            
            # Update all outcomes
            for loto in predicted_lotos:
                outcome = 1 if loto in lotos_appeared_set else 0
                if self.log_outcome(ky, loto, outcome):
                    count += 1
            
            return count
            
        except Exception as e:
            print(f"Error logging batch outcomes for {ky}: {e}")
            traceback.print_exc()
            return count
    
    def get_collection_stats(self):
        """
        Get statistics about collected data.
        
        Returns:
            dict: Statistics including:
                - total_predictions: Total predictions logged
                - predictions_with_outcomes: Predictions with known outcomes
                - unique_periods: Number of unique periods
                - oldest_period: Oldest period with data
                - newest_period: Newest period with data
                - ready_for_training: Whether we have enough data (100+ periods)
        """
        try:
            conn = self._get_connection()
            cursor = conn.cursor()
            
            # Total predictions
            cursor.execute("SELECT COUNT(*) FROM meta_learning_history")
            total_predictions = cursor.fetchone()[0]
            
            # Predictions with outcomes
            cursor.execute("""
                SELECT COUNT(*) FROM meta_learning_history
                WHERE actual_outcome IS NOT NULL
            """)
            predictions_with_outcomes = cursor.fetchone()[0]
            
            # Unique periods
            cursor.execute("""
                SELECT COUNT(DISTINCT ky) FROM meta_learning_history
                WHERE actual_outcome IS NOT NULL
            """)
            unique_periods = cursor.fetchone()[0]
            
            # Oldest and newest periods
            cursor.execute("""
                SELECT MIN(ky), MAX(ky) FROM meta_learning_history
                WHERE actual_outcome IS NOT NULL
            """)
            oldest, newest = cursor.fetchone()
            
            return {
                'total_predictions': total_predictions,
                'predictions_with_outcomes': predictions_with_outcomes,
                'unique_periods': unique_periods,
                'oldest_period': oldest,
                'newest_period': newest,
                'ready_for_training': unique_periods >= 100,
                'progress_percentage': min(100, (unique_periods / 100) * 100) if unique_periods else 0
            }
            
        except Exception as e:
            print(f"Error getting collection stats: {e}")
            traceback.print_exc()
            return {
                'total_predictions': 0,
                'predictions_with_outcomes': 0,
                'unique_periods': 0,
                'oldest_period': None,
                'newest_period': None,
                'ready_for_training': False,
                'progress_percentage': 0
            }
    
    def close(self):
        """Close database connection."""
        if self.db_conn:
            self.db_conn.close()
            self.db_conn = None


# Convenience functions for easy integration

_collector_instance = None


def get_collector():
    """Get singleton instance of Phase3DataCollector."""
    global _collector_instance
    if _collector_instance is None:
        _collector_instance = Phase3DataCollector()
    return _collector_instance


def log_prediction(ky, loto, ai_probability, manual_score, confidence, vote_count, recent_form_score=0.0):
    """
    Convenience function to log a prediction.
    See Phase3DataCollector.log_prediction() for details.
    """
    collector = get_collector()
    return collector.log_prediction(ky, loto, ai_probability, manual_score,
                                    confidence, vote_count, recent_form_score)


def log_outcome(ky, loto, actual_outcome):
    """
    Convenience function to log an outcome.
    See Phase3DataCollector.log_outcome() for details.
    """
    collector = get_collector()
    return collector.log_outcome(ky, loto, actual_outcome)


def get_stats():
    """
    Convenience function to get collection statistics.
    See Phase3DataCollector.get_collection_stats() for details.
    """
    collector = get_collector()
    return collector.get_stats()


--------------------------------------------------

=== FILE: logic\resilience.py ===
# T√™n file: logic/resilience.py
# Module Retry/Resilience Logic cho XS-DAS
import time
import functools
from typing import Callable, Any, Optional, Tuple

def retry(
    max_attempts: int = 3,
    delay: float = 1.0,
    backoff: float = 2.0,
    exceptions: Tuple = (Exception,),
    on_failure: Optional[Callable] = None
):
    """
    Decorator ƒë·ªÉ th·ª≠ l·∫°i h√†m khi g·∫∑p l·ªói.
    
    Args:
        max_attempts: S·ªë l·∫ßn th·ª≠ t·ªëi ƒëa (m·∫∑c ƒë·ªãnh: 3)
        delay: Th·ªùi gian ch·ªù ban ƒë·∫ßu gi·ªØa c√°c l·∫ßn th·ª≠ (gi√¢y, m·∫∑c ƒë·ªãnh: 1.0)
        backoff: H·ªá s·ªë tƒÉng th·ªùi gian ch·ªù (m·∫∑c ƒë·ªãnh: 2.0)
        exceptions: Tuple c√°c exception c·∫ßn b·∫Øt (m·∫∑c ƒë·ªãnh: (Exception,))
        on_failure: H√†m callback khi t·∫•t c·∫£ l·∫ßn th·ª≠ ƒë·ªÅu th·∫•t b·∫°i (optional)
    
    Returns:
        Decorated function
    
    Example:
        @retry(max_attempts=3, delay=1.0, exceptions=(sqlite3.OperationalError,))
        def connect_database():
            return sqlite3.connect(DB_NAME)
    """
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        def wrapper(*args, **kwargs) -> Any:
            current_delay = delay
            last_exception = None
            
            for attempt in range(1, max_attempts + 1):
                try:
                    return func(*args, **kwargs)
                except exceptions as e:
                    last_exception = e
                    if attempt < max_attempts:
                        time.sleep(current_delay)
                        current_delay *= backoff
                    else:
                        # T·∫•t c·∫£ l·∫ßn th·ª≠ ƒë·ªÅu th·∫•t b·∫°i
                        if on_failure:
                            try:
                                on_failure(func, e, attempt)
                            except:
                                pass
                        raise
            
            # Fallback (kh√¥ng bao gi·ªù ƒë·∫øn ƒë√¢y, nh∆∞ng ƒë·ªÉ type checker h√†i l√≤ng)
            if last_exception:
                raise last_exception
                
        return wrapper
    return decorator

def retry_db_operation(max_attempts: int = 3):
    """
    Decorator chuy√™n d·ª•ng cho c√°c thao t√°c database.
    
    Args:
        max_attempts: S·ªë l·∫ßn th·ª≠ t·ªëi ƒëa (m·∫∑c ƒë·ªãnh: 3)
    
    Returns:
        Decorated function
    """
    try:
        import sqlite3
        db_exceptions = (sqlite3.OperationalError, sqlite3.DatabaseError, OSError)
    except ImportError:
        db_exceptions = (OSError, IOError)
    
    return retry(
        max_attempts=max_attempts,
        delay=0.5,
        backoff=2.0,
        exceptions=db_exceptions
    )

def retry_file_operation(max_attempts: int = 3):
    """
    Decorator chuy√™n d·ª•ng cho c√°c thao t√°c file I/O.
    
    Args:
        max_attempts: S·ªë l·∫ßn th·ª≠ t·ªëi ƒëa (m·∫∑c ƒë·ªãnh: 3)
    
    Returns:
        Decorated function
    """
    return retry(
        max_attempts=max_attempts,
        delay=0.3,
        backoff=1.5,
        exceptions=(OSError, IOError, PermissionError)
    )



--------------------------------------------------

=== FILE: logic\utils.py ===
import logging
import sys

def setup_logger(name="Logic"):
    """C·∫•u h√¨nh Logger ƒë∆°n gi·∫£n."""
    logger = logging.getLogger(name)
    if not logger.handlers:
        logger.setLevel(logging.INFO)
        handler = logging.StreamHandler(sys.stdout)
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
    return logger

# ===================================================================================
# C·∫§U H√åNH V√Ä H√ÄM H·ªñ TR·ª¢ C·ªêT L√ïI (V25 / V30)
# ===================================================================================

BONG_DUONG_V30 = {
    "0": "5",
    "1": "6",
    "2": "7",
    "3": "8",
    "4": "9",
    "5": "0",
    "6": "1",
    "7": "2",
    "8": "3",
    "9": "4",
}


def getBongDuong_V30(digit):
    return BONG_DUONG_V30.get(str(digit), str(digit))


def taoSTL_V30_Bong(a, b):
    strA, strB = str(a), str(b)
    if strA == strB:
        kep = f"{strA}{strB}".zfill(2)
        bongDigit = getBongDuong_V30(strA)
        bongKep = f"{bongDigit}{bongDigit}".zfill(2)
        return [kep, bongKep]
    else:
        lo1 = f"{strA}{strB}".zfill(2)
        lo2 = f"{strB}{strA}".zfill(2)
        return [lo1, lo2]


def getAllLoto_V30(row):
    """L·∫•y t·∫•t c·∫£ 27 loto t·ª´ 1 h√†ng DuLieu_AI (ƒë√£ s·∫Øp x·∫øp c·ªôt B->I)"""
    lotos = []
    try:
        # row[0]=MaSoKy, row[1]=Col_A_Ky
        lotos.append(str(row[2] or "0").strip()[-2:].zfill(2))  # GƒêB (row[2])
        lotos.append(str(row[3] or "0").strip()[-2:].zfill(2))  # G1 (row[3])
        for i in range(4, 10):  # G2 (row[4]) -> G7 (row[9])
            if row[i]:
                for g in str(row[i]).split(","):
                    lotos.append(g.strip()[-2:].zfill(2))
    except Exception as e:
        print(f"L·ªói getAllLoto_V30: {e}")
        pass
    # (S·ª¨A E741) ƒê·ªïi 'l' th√†nh 'loto'
    return [loto for loto in lotos if loto and len(loto) == 2 and loto.isdigit()]


def checkHitSet_V30_K2N(stlPair, lotoSet):
    """Ki·ªÉm tra 1 c·∫∑p STL [a,b] c√≥ trong 1 set loto hay kh√¥ng."""
    try:
        hit1 = stlPair[0] in lotoSet
        hit2 = stlPair[1] in lotoSet
        if hit1 and hit2:
            return "‚úÖ (ƒÇn 2)"
        if hit1 or hit2:
            return "‚úÖ (ƒÇn 1)"
        return "‚ùå"
    except Exception:
        return "L·ªói check"


--------------------------------------------------

=== FILE: logic\validators.py ===
# logic/validators.py
"""
Input validation utilities for security and data integrity.
"""
import os

from .constants import (
    ALLOWED_FILE_EXTENSIONS,
    DEFAULT_SETTINGS,
    MAX_FILE_SIZE_BYTES,
    MAX_LINES,
)


class ValidationError(Exception):
    """Custom exception for validation errors"""
    pass


def validate_file_upload(file_path, content=None):
    """
    Validate file upload for security and size limits.
    
    Args:
        file_path: Path to the file
        content: Optional pre-loaded content string
    
    Raises:
        ValidationError: If validation fails
    
    Returns:
        True if validation passes
    """
    # Check file extension
    _, ext = os.path.splitext(file_path)
    if ext.lower() not in ALLOWED_FILE_EXTENSIONS:
        raise ValidationError(
            f"Invalid file type: {ext}. "
            f"Allowed: {', '.join(ALLOWED_FILE_EXTENSIONS)}"
        )
    
    # Check file size if file exists
    if os.path.exists(file_path):
        size = os.path.getsize(file_path)
        if size > MAX_FILE_SIZE_BYTES:
            raise ValidationError(
                f"File too large: {size / 1024 / 1024:.1f}MB. "
                f"Max: {MAX_FILE_SIZE_BYTES / 1024 / 1024}MB"
            )
    
    # Check content size if provided
    if content:
        if len(content) > MAX_FILE_SIZE_BYTES:
            raise ValidationError(
                f"Content too large: {len(content) / 1024 / 1024:.1f}MB"
            )
        
        # Check line count
        lines = content.split('\n')
        if len(lines) > MAX_LINES:
            raise ValidationError(
                f"Too many lines: {len(lines):,}. Max: {MAX_LINES:,}"
            )
    
    return True


def validate_config_value(key, value):
    """
    Validate configuration values for type and range.
    
    Args:
        key: Configuration key name
        value: Value to validate
    
    Raises:
        ValidationError: If validation fails
    
    Returns:
        Validated value (possibly converted to correct type)
    """
    if key not in DEFAULT_SETTINGS:
        raise ValidationError(f"Unknown configuration key: {key}")
    
    expected_type = type(DEFAULT_SETTINGS[key])
    
    # Type conversion and validation
    try:
        if expected_type == int:
            value = int(value)
        elif expected_type == float:
            value = float(value)
        elif expected_type == str:
            value = str(value)
    except (ValueError, TypeError):
        raise ValidationError(
            f"Invalid type for {key}: expected {expected_type.__name__}, got {type(value).__name__}"
        )
    
    # Range validations for specific keys
    if key == "STATS_DAYS":
        if not (1 <= value <= 30):
            raise ValidationError(f"STATS_DAYS must be between 1 and 30, got {value}")
    
    elif key == "GAN_DAYS":
        if not (1 <= value <= 100):
            raise ValidationError(f"GAN_DAYS must be between 1 and 100, got {value}")
    
    elif key == "HIGH_WIN_THRESHOLD":
        if not (0 <= value <= 100):
            raise ValidationError(f"HIGH_WIN_THRESHOLD must be between 0 and 100, got {value}")
    
    elif key == "AUTO_ADD_MIN_RATE":
        if not (0 <= value <= 100):
            raise ValidationError(f"AUTO_ADD_MIN_RATE must be between 0 and 100, got {value}")
    
    elif key == "AUTO_PRUNE_MIN_RATE":
        if not (0 <= value <= 100):
            raise ValidationError(f"AUTO_PRUNE_MIN_RATE must be between 0 and 100, got {value}")
    
    elif key == "K2N_RISK_START_THRESHOLD":
        if not (0 <= value <= 20):
            raise ValidationError(f"K2N_RISK_START_THRESHOLD must be between 0 and 20, got {value}")
    
    elif key == "K2N_RISK_PENALTY_PER_FRAME":
        if not (0 <= value <= 10):
            raise ValidationError(f"K2N_RISK_PENALTY_PER_FRAME must be between 0 and 10, got {value}")
    
    elif key == "AI_PROB_THRESHOLD":
        if not (0 <= value <= 100):
            raise ValidationError(f"AI_PROB_THRESHOLD must be between 0 and 100, got {value}")
    
    elif key == "AI_MAX_DEPTH":
        if not (1 <= value <= 20):
            raise ValidationError(f"AI_MAX_DEPTH must be between 1 and 20, got {value}")
    
    elif key == "AI_N_ESTIMATORS":
        if not (10 <= value <= 1000):
            raise ValidationError(f"AI_N_ESTIMATORS must be between 10 and 1000, got {value}")
    
    elif key == "AI_LEARNING_RATE":
        if not (0.001 <= value <= 1.0):
            raise ValidationError(f"AI_LEARNING_RATE must be between 0.001 and 1.0, got {value}")
    
    elif key == "AI_SCORE_WEIGHT":
        if not (0 <= value <= 1.0):
            raise ValidationError(f"AI_SCORE_WEIGHT must be between 0 and 1.0, got {value}")
    
    return value


def validate_config_dict(config_dict):
    """
    Validate an entire configuration dictionary.
    
    Args:
        config_dict: Dictionary of configuration values
    
    Raises:
        ValidationError: If any validation fails
    
    Returns:
        Validated configuration dictionary
    """
    validated = {}
    
    for key, value in config_dict.items():
        validated[key] = validate_config_value(key, value)
    
    return validated


--------------------------------------------------

=== FILE: logic\__init__.py ===


--------------------------------------------------

=== FILE: logic\analytics\dashboard_scorer.py ===
# T√™n file: logic/analytics/dashboard_scorer.py
# (MOVED FROM logic/dashboard_analytics.py - Phase 1 & 2 Refactoring)
from collections import Counter
import itertools

# Import SETTINGS
try:
    from ..config_manager import SETTINGS
except ImportError:
    try:
        from logic.config_manager import SETTINGS
    except ImportError:
        print("L·ªñI: dashboard_scorer.py kh√¥ng th·ªÉ import SETTINGS. S·ª≠ d·ª•ng fallback.")
        SETTINGS = type("obj", (object,), {
            "STATS_DAYS": 7, "GAN_DAYS": 15, "HIGH_WIN_THRESHOLD": 47.0,
            "K2N_RISK_START_THRESHOLD": 6, "K2N_RISK_PENALTY_PER_FRAME": 1.0,
            "AI_PROB_THRESHOLD": 45.0, "AI_SCORE_WEIGHT": 0.2,
            "RECENT_FORM_MIN_LOW": 5, "RECENT_FORM_MIN_MED": 7, "RECENT_FORM_MIN_HIGH": 9,
            "RECENT_FORM_BONUS_LOW": 0.5, "RECENT_FORM_BONUS_MED": 1.0, "RECENT_FORM_BONUS_HIGH": 1.5,
        })

# Import Bridge/DB Logic v√† Helpers
try:
    from ..backtester import BACKTEST_15_CAU_K2N_V30_AI_V8, BACKTEST_MANAGED_BRIDGES_K2N
    from ..backtester_core import parse_k2n_results as _parse_k2n_results
    from ..bridges.bridges_classic import ALL_15_BRIDGE_FUNCTIONS_V5, checkHitSet_V30_K2N, getAllLoto_V30
    from ..bridges.bridges_memory import calculate_bridge_stl, get_27_loto_names, get_27_loto_positions
    from ..bridges.bridges_v16 import getAllPositions_V17_Shadow, taoSTL_V30_Bong
    from ..data_repository import get_all_managed_bridges
    from ..db_manager import DB_NAME
except ImportError:
    print("L·ªói: Kh√¥ng th·ªÉ import bridge/backtester helpers trong dashboard_scorer.py")
    def getAllLoto_V30(r): return []
    def checkHitSet_V30_K2N(p, loto_set): return "L·ªói"
    def getAllPositions_V17_Shadow(r): return []
    def taoSTL_V30_Bong(a, b): return ["00", "00"]
    def get_27_loto_names(): return []
    def get_27_loto_positions(r): return []
    def calculate_bridge_stl(l1, l2, type): return ["00", "00"]
    def _parse_k2n_results(r): return [], {}
    def BACKTEST_MANAGED_BRIDGES_K2N(a, b, c, d, e): return []
    def BACKTEST_15_CAU_K2N_V30_AI_V8(a, b, c, d): return []
    DB_NAME = "xo_so_prizes_all_logic.db"
    def get_all_managed_bridges(d, o): return []

# [PH·∫¶N 1-4: Gi·ªØ nguy√™n to√†n b·ªô code t·ª´ dashboard_analytics.py]
# I. H√ÄM ANALYTICS C∆† B·∫¢N
def get_loto_stats_last_n_days(all_data_ai, n=None):
    """L·∫•y th·ªëng k√™ t·∫ßn su·∫•t loto (hot/l·∫°nh)."""
    try:
        if n is None:
            n = getattr(SETTINGS, "STATS_DAYS", 7)
        if not all_data_ai or len(all_data_ai) == 0:
            return []
        if len(all_data_ai) < n:
            n = len(all_data_ai)
        last_n_rows = all_data_ai[-n:]
        all_lotos_hits = []
        day_appearance_counter = Counter()
        for row in last_n_rows:
            lotos_in_this_row = getAllLoto_V30(row)
            all_lotos_hits.extend(lotos_in_this_row)
            unique_lotos_in_this_row = set(lotos_in_this_row)
            day_appearance_counter.update(unique_lotos_in_this_row)
        loto_hit_counts = Counter(all_lotos_hits)
        sorted_lotos_by_hits = sorted(loto_hit_counts.items(), key=lambda item: item[1], reverse=True)
        final_stats = []
        for loto, hit_count in sorted_lotos_by_hits:
            day_count = day_appearance_counter.get(loto, 0)
            final_stats.append((loto, hit_count, day_count))
        return final_stats
    except Exception as e:
        print(f"L·ªói get_loto_stats_last_n_days: {e}")
        return []

def get_loto_gan_stats(all_data_ai, n_days=None):
    """T√¨m c√°c loto (00-99) ƒë√£ kh√¥ng xu·∫•t hi·ªán trong n_days g·∫ßn nh·∫•t (L√¥ Gan)."""
    gan_stats = []
    try:
        if n_days is None:
            n_days = getattr(SETTINGS, "GAN_DAYS", 15)
        if not all_data_ai or len(all_data_ai) < n_days:
            return []
        all_100_lotos = {str(i).zfill(2) for i in range(100)}
        recent_lotos = set()
        recent_rows = all_data_ai[-n_days:]
        for row in recent_rows:
            lotos_in_this_row = getAllLoto_V30(row)
            recent_lotos.update(lotos_in_this_row)
        gan_lotos = all_100_lotos - recent_lotos
        if not gan_lotos:
            return []
        full_history = all_data_ai[:]
        full_history.reverse()
        for loto in gan_lotos:
            days_gan = 0
            found = False
            for i, row in enumerate(full_history):
                if i < n_days:
                    days_gan += 1
                    continue
                loto_set_this_day = set(getAllLoto_V30(row))
                if loto in loto_set_this_day:
                    found = True
                    break
                else:
                    days_gan += 1
            if found:
                gan_stats.append((loto, days_gan))
            else:
                gan_stats.append((loto, len(full_history)))
        gan_stats.sort(key=lambda x: x[1], reverse=True)
        return gan_stats
    except Exception as e:
        print(f"L·ªói get_loto_gan_stats: {e}")
        return []

def get_top_memory_bridge_predictions(all_data_ai, last_row, top_n=5):
    """Ch·∫°y backtest N1 756 c·∫ßu b·∫°c nh·ªõ ng·∫ßm v√† tr·∫£ v·ªÅ d·ª± ƒëo√°n c·ªßa TOP N c·∫ßu t·ªët nh·∫•t."""
    print("... (BTH) B·∫Øt ƒë·∫ßu ch·∫°y backtest 756 c·∫ßu B·∫°c Nh·ªõ ng·∫ßm...")
    def _validate_data(data):
        return not data or len(data) < 2
    if _validate_data(all_data_ai):
        return []
    loto_names = get_27_loto_names()
    num_positions = len(loto_names)
    algorithms = []
    for i in range(num_positions):
        for j in range(i, num_positions):
            algorithms.append((i, j, "sum"))
            algorithms.append((i, j, "diff"))
    num_algorithms = len(algorithms)
    processedData = []
    startCheckRow = 2
    offset = 1
    finalEndRow = len(all_data_ai)
    for k in range(startCheckRow, finalEndRow + 1):
        prevRow_idx, actualRow_idx = k - 1 - offset, k - offset
        if actualRow_idx >= len(all_data_ai) or prevRow_idx < 0:
            continue
        prevRow, actualRow = all_data_ai[prevRow_idx], all_data_ai[actualRow_idx]
        if (not prevRow or not actualRow or not actualRow[0] or str(actualRow[0]).strip() == "" or len(actualRow) < 10 or not actualRow[9]):
            continue
        processedData.append({"prevLotos": get_27_loto_positions(prevRow), "actualLotoSet": set(getAllLoto_V30(actualRow))})
    totalTestDays = len(processedData)
    if totalTestDays == 0:
        return []
    win_counts = [0] * num_algorithms
    for dayData in processedData:
        actualLotoSet = dayData["actualLotoSet"]
        prevLotos = dayData["prevLotos"]
        for j in range(num_algorithms):
            alg = algorithms[j]
            idx1, idx2, alg_type = alg[0], alg[1], alg[2]
            loto1, loto2 = prevLotos[idx1], prevLotos[idx2]
            pred_stl = calculate_bridge_stl(loto1, loto2, alg_type)
            if pred_stl[0] in actualLotoSet or pred_stl[1] in actualLotoSet:
                win_counts[j] += 1
    bridge_stats = []
    for j in range(num_algorithms):
        rate = (win_counts[j] / totalTestDays) * 100
        bridge_stats.append((rate, j))
    bridge_stats.sort(key=lambda x: x[0], reverse=True)
    top_n_bridges = bridge_stats[:top_n]
    predictions_for_dashboard = []
    last_lotos = get_27_loto_positions(last_row)
    for rate, alg_index in top_n_bridges:
        alg = algorithms[alg_index]
        idx1, idx2, alg_type = alg[0], alg[1], alg[2]
        loto1, loto2 = last_lotos[idx1], last_lotos[idx2]
        pred_stl = calculate_bridge_stl(loto1, loto2, alg_type)
        if alg_type == "sum":
            name = f"T·ªïng({loto_names[idx1]}+{loto_names[idx2]})"
        else:
            name = f"Hi·ªáu(|{loto_names[idx1]}-{loto_names[idx2]}|)"
        predictions_for_dashboard.append({"name": name, "stl": pred_stl, "prediction": ", ".join(map(str, pred_stl)), "rate": f"{rate:.2f}%"})
    return predictions_for_dashboard

# II. H√ÄM ANALYTICS N√ÇNG CAO
def _standardize_pair(stl_list):
    """H√†m n·ªôi b·ªô: Chu·∫©n h√≥a 1 c·∫∑p STL. V√≠ d·ª• ['30', '03'] -> '03-30'"""
    if not stl_list or len(stl_list) != 2:
        return None
    sorted_pair = sorted(stl_list)
    return f"{sorted_pair[0]}-{sorted_pair[1]}"

def get_prediction_consensus(last_row=None, db_name=DB_NAME):
    """L·∫•y d·ª± ƒëo√°n t·ª´ "15 C·∫ßu" v√† "C·∫ßu ƒê√£ L∆∞u" ƒë·ªÉ ƒë·∫øm vote THEO C·∫∂P.
    N·∫øu c√≥ last_row, t√≠nh to√°n tr·ª±c ti·∫øp. N·∫øu kh√¥ng, l·∫•y t·ª´ cache (next_prediction_stl trong DB)."""
    try:
        prediction_sources = {}
        
        def get_pair_key(stl_list):
            """Chu·∫©n h√≥a 1 c·∫∑p STL. V√≠ d·ª• ['30', '03'] -> '03-30'"""
            if not stl_list or len(stl_list) != 2:
                return None
            sorted_pair = sorted(stl_list)
            return f"{sorted_pair[0]}-{sorted_pair[1]}"
        
        # N·∫øu c√≥ last_row, t√≠nh to√°n tr·ª±c ti·∫øp (∆∞u ti√™n)
        if last_row and len(last_row) >= 10:
            try:
                # Import c√°c h√†m c·∫ßn thi·∫øt (ƒë√£ import ·ªü ƒë·∫ßu file, ch·ªâ c·∫ßn d√πng)
                # getAllPositions_V16, taoSTL_V30_Bong, calculate_bridge_stl, get_27_loto_positions, ALL_15_BRIDGE_FUNCTIONS_V5 ƒë√£ c√≥
                import re
                
                # 1. L·∫•y t·ª´ 15 C·∫ßu C·ªï ƒêi·ªÉn
                for i, bridge_func in enumerate(ALL_15_BRIDGE_FUNCTIONS_V5):
                    try:
                        stl = bridge_func(last_row)
                        pair_key = get_pair_key(stl)
                        if pair_key:
                            source_name = f"C{i + 1}"
                            if pair_key not in prediction_sources:
                                prediction_sources[pair_key] = []
                            if source_name not in prediction_sources[pair_key]:
                                prediction_sources[pair_key].append(source_name)
                    except Exception:
                        pass
                
                # 2. L·∫•y t·ª´ C·∫ßu ƒê√£ L∆∞u (t√≠nh to√°n tr·ª±c ti·∫øp)
                managed_bridges = get_all_managed_bridges(db_name, only_enabled=True)
                if managed_bridges:
                    # D√πng getAllPositions_V17_Shadow (ƒë√£ import) thay v√¨ getAllPositions_V16
                    last_positions = getAllPositions_V17_Shadow(last_row)
                    last_lotos = get_27_loto_positions(last_row)
                    
                    for bridge in managed_bridges:
                        try:
                            idx1, idx2 = bridge.get("pos1_idx"), bridge.get("pos2_idx")
                            
                            # Memory Bridge
                            if idx1 == -1 and idx2 == -1:
                                bridge_name = bridge.get("name", "")
                                stl = None
                                
                                if "T·ªïng(" in bridge_name:
                                    match = re.search(r'T·ªïng\((\d+)\+(\d+)\)', bridge_name)
                                    if match:
                                        pos1, pos2 = int(match.group(1)), int(match.group(2))
                                        if pos1 < len(last_lotos) and pos2 < len(last_lotos):
                                            loto1, loto2 = last_lotos[pos1], last_lotos[pos2]
                                            if loto1 and loto2:
                                                stl = calculate_bridge_stl(loto1, loto2, "sum")
                                elif "Hi·ªáu(" in bridge_name:
                                    match = re.search(r'Hi·ªáu\((\d+)-(\d+)\)', bridge_name)
                                    if match:
                                        pos1, pos2 = int(match.group(1)), int(match.group(2))
                                        if pos1 < len(last_lotos) and pos2 < len(last_lotos):
                                            loto1, loto2 = last_lotos[pos1], last_lotos[pos2]
                                            if loto1 and loto2:
                                                stl = calculate_bridge_stl(loto1, loto2, "diff")
                                
                                if stl:
                                    pair_key = get_pair_key(stl)
                                    if pair_key:
                                        source_name = bridge["name"]
                                        if pair_key not in prediction_sources:
                                            prediction_sources[pair_key] = []
                                        if source_name not in prediction_sources[pair_key]:
                                            prediction_sources[pair_key].append(source_name)
                                continue
                            
                            # V17 Bridge
                            if idx1 is not None and idx2 is not None and idx1 >= 0 and idx2 >= 0:
                                if idx1 < len(last_positions) and idx2 < len(last_positions):
                                    a, b = last_positions[idx1], last_positions[idx2]
                                    if a is not None and b is not None:
                                        stl = taoSTL_V30_Bong(a, b)
                                        pair_key = get_pair_key(stl)
                                        if pair_key:
                                            source_name = bridge["name"]
                                            if pair_key not in prediction_sources:
                                                prediction_sources[pair_key] = []
                                            if source_name not in prediction_sources[pair_key]:
                                                prediction_sources[pair_key].append(source_name)
                        except Exception:
                            pass
            except Exception as e:
                print(f"L·ªói t√≠nh to√°n consensus t·ª´ last_row: {e}")
                # Fallback: d√πng cache
                last_row = None
        
        # N·∫øu kh√¥ng c√≥ last_row ho·∫∑c t√≠nh to√°n th·∫•t b·∫°i, l·∫•y t·ª´ cache
        if not last_row or len(prediction_sources) == 0:
            managed_bridges = get_all_managed_bridges(db_name, only_enabled=True)
            if managed_bridges:
                for bridge in managed_bridges:
                    try:
                        prediction_stl_str = bridge.get("next_prediction_stl")
                        if (not prediction_stl_str or "N2" in prediction_stl_str or "L·ªñI" in prediction_stl_str or "," not in prediction_stl_str):
                            continue
                        stl = prediction_stl_str.split(",")
                        pair_key = get_pair_key(stl)
                        if not pair_key:
                            continue
                        source_name = bridge["name"]
                        if source_name.startswith("C·∫ßu "):
                            source_name = f"C{source_name.split(' ')[1]}"
                        if pair_key not in prediction_sources:
                            prediction_sources[pair_key] = []
                        if source_name not in prediction_sources[pair_key]:
                            prediction_sources[pair_key].append(source_name)
                    except Exception as e:
                        print(f"L·ªói d·ª± ƒëo√°n C·∫ßu (consensus cache) {bridge.get('name')}: {e}")
        
        consensus_list = []
        for pair_key, sources in prediction_sources.items():
            count = len(sources)
            sources_str = ", ".join(sources)
            consensus_list.append((pair_key, count, sources_str))
        consensus_list.sort(key=lambda item: item[1], reverse=True)
        return consensus_list
    except Exception as e:
        print(f"L·ªói get_prediction_consensus: {e}")
        return []

def get_high_win_rate_predictions(last_row=None, threshold=None, db_name=DB_NAME):
    """
    L·∫•y d·ª± ƒëo√°n t·ª´ C·∫ßu ƒê√£ L∆∞u C√ì T·ª∂ L·ªÜ CAO (d·ª±a tr√™n cache K2N).
    
    - C·∫ßu L√î (LOTO): L·ªçc theo win_rate_text >= threshold
    - C·∫ßu ƒê·ªÄ (DE): L·ªçc theo recent_win_count_10 >= DE_HIGH_RATE_MIN_WINS_10
    
    Returns:
        list: List of dicts v·ªõi keys: {'name': str, 'value': str, 'rate': str, 'type': str}
    """
    try:
        if threshold is None:
            threshold = getattr(SETTINGS, "HIGH_WIN_THRESHOLD", 47.0)
        de_min_wins = getattr(SETTINGS, "DE_HIGH_RATE_MIN_WINS_10", 7)
        
        predictions = []
        managed_bridges = get_all_managed_bridges(db_name, only_enabled=True)
        if not managed_bridges:
            return []
        
        for bridge in managed_bridges:
            try:
                bridge_type = bridge.get("type", "").upper()
                prediction_stl_str = bridge.get("next_prediction_stl")
                
                if not prediction_stl_str or "N2" in prediction_stl_str or "L·ªñI" in prediction_stl_str or "," not in prediction_stl_str:
                    continue
                
                stl = prediction_stl_str.split(",")
                
                # X·ª≠ l√Ω c·∫ßu ƒê·ªÄ (DE)
                if bridge_type in ["DE", "DE_DYNAMIC_K", "DE_POS_SUM"]:
                    recent_wins = bridge.get("recent_win_count_10", 0)
                    if isinstance(recent_wins, str):
                        try:
                            recent_wins = int(recent_wins)
                        except ValueError:
                            recent_wins = 0
                    
                    if recent_wins >= de_min_wins:
                        # Chuy·ªÉn ƒë·ªïi STL sang D√†n ƒê·ªÅ
                        try:
                            from logic.de_utils import generate_dan_de_from_touches
                            de_values = generate_dan_de_from_touches(stl)
                            for de_value in de_values:
                                predictions.append({
                                    "name": bridge["name"],
                                    "value": de_value,
                                    "rate": f"{recent_wins}/10",
                                    "type": "DE"
                                })
                        except Exception as e:
                            print(f"L·ªói chuy·ªÉn ƒë·ªïi DE cho c·∫ßu {bridge['name']}: {e}")
                
                # X·ª≠ l√Ω c·∫ßu L√î (LOTO)
                else:
                    rate_str = str(bridge.get("win_rate_text", "0%")).replace("%", "")
                    if not rate_str or rate_str == "N/A":
                        continue
                    win_rate = float(rate_str)
                    
                    if win_rate >= threshold:
                        # Th√™m t·ª´ng gi√° tr·ªã STL nh∆∞ m·ªôt prediction ri√™ng
                        for stl_value in stl:
                            predictions.append({
                                "name": bridge["name"],
                                "value": stl_value.strip(),
                                "rate": f"{win_rate:.2f}%",
                                "type": "LOTO"
                            })
            except Exception as e:
                print(f"L·ªói ki·ªÉm tra t·ª∑ l·ªá c·∫ßu {bridge.get('name', 'Unknown')}: {e}")
        
        return predictions
    except Exception as e:
        print(f"L·ªói get_high_win_rate_predictions: {e}")
        return []

def get_pending_k2n_bridges(last_row, prev_row):
    """L·∫•y c√°c c·∫ßu ƒë√£ tr∆∞·ª£t N1 ·ªü k·ª≥ tr∆∞·ªõc v√† ƒëang ch·ªù N2 (D√πng ƒë·ªÉ t√≠nh Penalty)."""
    pending_bridges = []
    try:
        if not last_row or not prev_row:
            return []
        actualLotoSet = set(getAllLoto_V30(last_row))
        if not actualLotoSet:
            return []
        for i, bridge_func in enumerate(ALL_15_BRIDGE_FUNCTIONS_V5):
            try:
                stl = bridge_func(prev_row)
                check_result = checkHitSet_V30_K2N(stl, actualLotoSet)
                if "‚ùå" in check_result:
                    pending_bridges.append({"name": f"C·∫ßu {i + 1}", "stl": stl})
            except Exception:
                pass
        managed_bridges = get_all_managed_bridges(DB_NAME, only_enabled=True)
        if managed_bridges:
            prev_positions = getAllPositions_V17_Shadow(prev_row)
            for bridge in managed_bridges:
                try:
                    idx1, idx2 = bridge["pos1_idx"], bridge["pos2_idx"]
                    a, b = prev_positions[idx1], prev_positions[idx2]
                    if a is None or b is None:
                        continue
                    stl = taoSTL_V30_Bong(a, b)
                    check_result = checkHitSet_V30_K2N(stl, actualLotoSet)
                    if "‚ùå" in check_result:
                        pending_bridges.append({"name": bridge["name"], "stl": stl})
                except Exception:
                    pass
        return pending_bridges
    except Exception as e:
        print(f"L·ªói get_pending_k2n_bridges: {e}")
        return []

# III. H√ÄM CH·∫§M ƒêI·ªÇM C·ªêT L√ïI (V7.5 - GOM NH√ìM PHONG ƒê·ªò & R·ª¶I RO)
def get_top_scored_pairs(stats, consensus, high_win, pending_k2n, gan_stats, top_memory_bridges, ai_predictions=None, recent_data=None):
    """(V7.5) T√≠nh to√°n, ch·∫•m ƒëi·ªÉm v√† x·∫øp h·∫°ng c√°c c·∫∑p s·ªë."""
    try:
        # ƒê·∫£m b·∫£o t·∫•t c·∫£ tham s·ªë l√† list/dict h·ª£p l·ªá
        if stats is None:
            stats = []
        if consensus is None:
            consensus = []
        if high_win is None:
            high_win = []
        if pending_k2n is None:
            pending_k2n = {}
        if gan_stats is None:
            gan_stats = []
        if top_memory_bridges is None:
            top_memory_bridges = []
        if ai_predictions is None:
            ai_predictions = []
        
        scores = {}
        K2N_RISK_START_THRESHOLD = getattr(SETTINGS, "K2N_RISK_START_THRESHOLD", 6)
        K2N_RISK_PENALTY_FIXED = getattr(SETTINGS, "K2N_RISK_PENALTY_PER_FRAME", 1.0)
        ai_score_weight = getattr(SETTINGS, "AI_SCORE_WEIGHT", 0.2)
        loto_prob_map = {}
        if ai_predictions:
            for pred in ai_predictions:
                loto_prob_map[pred["loto"]] = pred["probability"] / 100.0
        top_hot_lotos = {loto for loto, count, days in stats if count > 0} if stats else set()
        gan_map = {loto: days for loto, days in gan_stats} if gan_stats else {}
        vote_weight = getattr(SETTINGS, "VOTE_SCORE_WEIGHT", 0.3)
        for pair_key, count, _ in consensus:
            if pair_key not in scores:
                scores[pair_key] = {"score": 0.0, "reasons": [], "is_gan": False, "gan_days": 0, "gan_loto": "", "sources": 0}
            import math
            vote_score = math.sqrt(count) * vote_weight
            scores[pair_key]["score"] += vote_score
            scores[pair_key]["reasons"].append(f"Vote x{count} (+{vote_score:.1f})")
            scores[pair_key]["sources"] += 1
        high_win_bonus = getattr(SETTINGS, "HIGH_WIN_SCORE_BONUS", 2.5)
        
        # ‚ö° FIX: X·ª≠ l√Ω c·∫£ format c≈© (c√≥ 'stl') v√† format m·ªõi (c√≥ 'value')
        # Group values by bridge name ƒë·ªÉ t·∫°o pairs t·ª´ format m·ªõi
        bridge_values_map = {}
        for bridge in high_win:
            # Format c≈©: c√≥ 'stl' (list of values)
            if "stl" in bridge:
                pair_key = _standardize_pair(bridge["stl"])
                if pair_key:
                    if pair_key not in scores:
                        scores[pair_key] = {"score": 0.0, "reasons": [], "is_gan": False, "gan_days": 0, "gan_loto": "", "sources": 0}
                    scores[pair_key]["score"] += high_win_bonus
                    scores[pair_key]["reasons"].append(f"Cao ({bridge.get('rate', 'N/A')})")
                    scores[pair_key]["sources"] += 1
            # Format m·ªõi: c√≥ 'value' (individual value) - c·∫ßn group theo bridge name
            elif "value" in bridge:
                bridge_name = bridge.get("name", "unknown")
                if bridge_name not in bridge_values_map:
                    bridge_values_map[bridge_name] = {"values": [], "rate": bridge.get("rate", "N/A")}
                bridge_values_map[bridge_name]["values"].append(bridge["value"])
        
        # X·ª≠ l√Ω format m·ªõi: t·∫°o pairs t·ª´ c√°c values c√πng bridge
        for bridge_name, data in bridge_values_map.items():
            values = data["values"]
            rate = data["rate"]
            # N·∫øu c√≥ ƒë√∫ng 2 values, t·∫°o pair
            if len(values) == 2:
                pair_key = _standardize_pair(values)
                if pair_key:
                    if pair_key not in scores:
                        scores[pair_key] = {"score": 0.0, "reasons": [], "is_gan": False, "gan_days": 0, "gan_loto": "", "sources": 0}
                    scores[pair_key]["score"] += high_win_bonus
                    scores[pair_key]["reasons"].append(f"Cao ({rate})")
                    scores[pair_key]["sources"] += 1
            # N·∫øu c√≥ nhi·ªÅu h∆°n 2 values, t·∫°o pairs t·ª´ t·∫•t c·∫£ combinations
            elif len(values) > 2:
                for val1, val2 in itertools.combinations(values, 2):
                    pair_key = _standardize_pair([val1, val2])
                    if pair_key:
                        if pair_key not in scores:
                            scores[pair_key] = {"score": 0.0, "reasons": [], "is_gan": False, "gan_days": 0, "gan_loto": "", "sources": 0}
                        scores[pair_key]["score"] += high_win_bonus
                        scores[pair_key]["reasons"].append(f"Cao ({rate})")
                        scores[pair_key]["sources"] += 1
        K2N_RISK_PROGRESSIVE = getattr(SETTINGS, "K2N_RISK_PROGRESSIVE", True)
        k2n_risks = {}
        for bridge_name, data in pending_k2n.items():
            pair_key = _standardize_pair(data["stl"].split(","))
            max_lose = data.get("max_lose", 0)
            if K2N_RISK_PROGRESSIVE:
                penalty = 2.0 if max_lose >= 10 else (1.0 if max_lose >= 6 else (0.5 if max_lose >= 3 else 0.0))
            else:
                penalty = K2N_RISK_PENALTY_FIXED if max_lose >= K2N_RISK_START_THRESHOLD else 0.0
            if pair_key and penalty > 0:
                if pair_key not in k2n_risks:
                    k2n_risks[pair_key] = {"count": 0, "total_penalty": 0.0, "max_frames": 0}
                k2n_risks[pair_key]["count"] += 1
                k2n_risks[pair_key]["total_penalty"] += penalty
                k2n_risks[pair_key]["max_frames"] = max(k2n_risks[pair_key]["max_frames"], max_lose)
        for pair_key, info in k2n_risks.items():
            if pair_key not in scores:
                scores[pair_key] = {"score": 0.0, "reasons": [], "is_gan": False, "gan_days": 0, "gan_loto": "", "sources": 0}
            scores[pair_key]["score"] -= info["total_penalty"]
            scores[pair_key]["sources"] += 1
            if info["count"] > 1:
                scores[pair_key]["reasons"].append(f"R·ªßi ro K2N (x{info['count']}, max {info['max_frames']}kh) -{info['total_penalty']:.1f}")
            else:
                scores[pair_key]["reasons"].append(f"R·ªßi ro K2N ({info['max_frames']}kh) -{info['total_penalty']:.1f})")
        for bridge in top_memory_bridges:
            pair_key = _standardize_pair(bridge["stl"])
            if pair_key:
                if pair_key not in scores:
                    scores[pair_key] = {"score": 0.0, "reasons": [], "is_gan": False, "gan_days": 0, "gan_loto": "", "sources": 0}
                scores[pair_key]["score"] += 1.5
                scores[pair_key]["reasons"].append(f"BN ({bridge['rate']})")
                scores[pair_key]["sources"] += 1
        try:
            try:
                from ..db_manager import DB_NAME as db_name_param
            except ImportError:
                db_name_param = "xo_so_prizes_all_logic.db"
            managed_bridges = get_all_managed_bridges(db_name=db_name_param)
            RF_MIN_LOW = getattr(SETTINGS, "RECENT_FORM_MIN_LOW", 3)
            RF_MIN_MED = getattr(SETTINGS, "RECENT_FORM_MIN_MED", 5)
            RF_MIN_HIGH = getattr(SETTINGS, "RECENT_FORM_MIN_HIGH", 7)
            RF_MIN_VERY_HIGH = getattr(SETTINGS, "RECENT_FORM_MIN_VERY_HIGH", 9)
            RF_BONUS_LOW = getattr(SETTINGS, "RECENT_FORM_BONUS_LOW", 1.0)
            RF_BONUS_MED = getattr(SETTINGS, "RECENT_FORM_BONUS_MED", 2.0)
            RF_BONUS_HIGH = getattr(SETTINGS, "RECENT_FORM_BONUS_HIGH", 3.0)
            RF_BONUS_VERY_HIGH = getattr(SETTINGS, "RECENT_FORM_BONUS_VERY_HIGH", 4.0)
            recent_form_groups = {}
            for bridge in managed_bridges:
                if not bridge.get("is_enabled"): continue
                recent_wins = bridge.get("recent_win_count_10", 0)
                if isinstance(recent_wins, str):
                    try: recent_wins = int(recent_wins)
                    except (ValueError, TypeError): recent_wins = 0
                elif recent_wins is None: recent_wins = 0
                prediction_stl_str = bridge.get("next_prediction_stl", "")
                if not prediction_stl_str or "," not in prediction_stl_str or "N2" in prediction_stl_str or "L·ªñI" in prediction_stl_str: continue
                stl = prediction_stl_str.split(",")
                pair_key = _standardize_pair(stl)
                if pair_key and recent_wins >= RF_MIN_LOW:
                    if pair_key not in scores:
                        scores[pair_key] = {"score": 0.0, "reasons": [], "is_gan": False, "gan_days": 0, "gan_loto": "", "sources": 0}
                    bonus = 0.0
                    if recent_wins >= RF_MIN_VERY_HIGH: bonus = RF_BONUS_VERY_HIGH
                    elif recent_wins >= RF_MIN_HIGH: bonus = RF_BONUS_HIGH
                    elif recent_wins >= RF_MIN_MED: bonus = RF_BONUS_MED
                    elif recent_wins >= RF_MIN_LOW: bonus = RF_BONUS_LOW
                    if bonus > 0:
                        if pair_key not in recent_form_groups:
                            recent_form_groups[pair_key] = {"count": 0, "total_bonus": 0.0, "best_wins": 0}
                        group = recent_form_groups[pair_key]
                        group["count"] += 1
                        group["total_bonus"] += bonus
                        if recent_wins > group["best_wins"]: group["best_wins"] = recent_wins
            for pair_key, info in recent_form_groups.items():
                scores[pair_key]["score"] += info["total_bonus"]
                scores[pair_key]["sources"] += 1
                if info["count"] > 1:
                    scores[pair_key]["reasons"].append(f"Phong ƒë·ªô (x{info['count']}) +{info['total_bonus']:.1f}")
                else:
                    scores[pair_key]["reasons"].append(f"Phong ƒë·ªô ({info['best_wins']}/10) +{info['total_bonus']:.1f}")
        except Exception as e:
            print(f"L·ªói t√≠nh ƒëi·ªÉm phong ƒë·ªô: {e}")
        for pair_key in list(scores.keys()):
            loto1, loto2 = pair_key.split("-")
            if loto1 in top_hot_lotos or loto2 in top_hot_lotos:
                scores[pair_key]["score"] += 1.0
                scores[pair_key]["reasons"].append("Loto Hot")
                scores[pair_key]["sources"] += 1
            gan_days_1 = gan_map.get(loto1, 0)
            gan_days_2 = gan_map.get(loto2, 0)
            max_gan = max(gan_days_1, gan_days_2)
            if max_gan > 0:
                scores[pair_key]["is_gan"] = True
                scores[pair_key]["gan_days"] = max_gan
                scores[pair_key]["gan_loto"] = loto1 if gan_days_1 >= gan_days_2 else loto2
            if loto_prob_map:
                prob_1 = loto_prob_map.get(loto1, 0.0)
                prob_2 = loto_prob_map.get(loto2, 0.0)
                max_prob = max(prob_1, prob_2)
                if max_prob > 0:
                    ai_score_contribution = max_prob * ai_score_weight
                    scores[pair_key]["score"] += ai_score_contribution
                    scores[pair_key]["sources"] += 1
                    scores[pair_key]["reasons"].append(f"AI: +{ai_score_contribution:.2f} ({max_prob * 100.0:.1f}%)")
        if loto_prob_map:
            for loto1_str in [str(i).zfill(2) for i in range(100)]:
                if loto1_str[0] == loto1_str[1]: continue
                loto2_str = str(int(loto1_str[::-1])).zfill(2)
                stl_pair = _standardize_pair([loto1_str, loto2_str])
                if stl_pair in scores: continue
                prob1 = loto_prob_map.get(loto1_str, 0.0)
                prob2 = loto_prob_map.get(loto2_str, 0.0)
                max_prob = max(prob1, prob2)
                if max_prob > 0.0:
                    ai_score_contribution = max_prob * ai_score_weight
                    if stl_pair not in scores:
                        scores[stl_pair] = {"score": 0.0, "reasons": [], "is_gan": False, "gan_days": 0, "gan_loto": ""}
                    scores[stl_pair]["score"] += ai_score_contribution
                    scores[stl_pair]["reasons"].append(f"AI S·∫†CH: +{ai_score_contribution:.2f} ({max_prob * 100.0:.1f}%)")
                    l1, l2 = stl_pair.split("-")
                    max_gan = max(gan_map.get(l1, 0), gan_map.get(l2, 0))
                    if max_gan > 0:
                        scores[stl_pair]["is_gan"] = True
                        scores[stl_pair]["gan_days"] = max_gan
        if recent_data and len(recent_data) > 0:
            last_7 = recent_data[-7:] if len(recent_data) >= 7 else recent_data
            last_3 = recent_data[-3:] if len(recent_data) >= 3 else recent_data
            recent_pairs_3 = set()
            recent_pairs_7 = set()
            for row in last_3:
                try:
                    lotos = getAllLoto_V30(row)
                    for i, loto1 in enumerate(lotos):
                        for loto2 in lotos[i+1:]:
                            pair_key = _standardize_pair([loto1, loto2])
                            if pair_key: recent_pairs_3.add(pair_key)
                except Exception: pass
            for row in last_7:
                try:
                    lotos = getAllLoto_V30(row)
                    for i, loto1 in enumerate(lotos):
                        for loto2 in lotos[i+1:]:
                            pair_key = _standardize_pair([loto1, loto2])
                            if pair_key: recent_pairs_7.add(pair_key)
                except Exception: pass
            for pair_key in scores.keys():
                if pair_key in recent_pairs_3:
                    scores[pair_key]["score"] += 2.0
                    scores[pair_key]["reasons"].append("V·ªÅ 3k·ª≥ (+2.0)")
                    if "sources" not in scores[pair_key]: scores[pair_key]["sources"] = 0
                    scores[pair_key]["sources"] += 1
                elif pair_key in recent_pairs_7:
                    scores[pair_key]["score"] += 1.0
                    scores[pair_key]["reasons"].append("V·ªÅ 7k·ª≥ (+1.0)")
                    if "sources" not in scores[pair_key]: scores[pair_key]["sources"] = 0
                    scores[pair_key]["sources"] += 1
        final_list = []
        for pair_key, data in scores.items():
            num_sources = data.get("sources", 0)
            confidence = round(num_sources / 7.0, 2)
            loto1, loto2 = pair_key.split("-")
            ai_prob = 0.0
            if loto_prob_map:
                prob_1 = loto_prob_map.get(loto1, 0.0)
                prob_2 = loto_prob_map.get(loto2, 0.0)
                ai_prob = max(prob_1, prob_2)
            score_val = data["score"]
            confidence_stars = num_sources
            if score_val >= 7 and confidence_stars >= 4: recommendation = "CH∆†I"
            elif score_val >= 5 or confidence_stars >= 3: recommendation = "XEM X√âT"
            else: recommendation = "B·ªé QUA"
            final_list.append({
                "pair": pair_key, "score": round(data["score"], 2), "reasons": ", ".join(data["reasons"]),
                "is_gan": data["is_gan"], "gan_days": data["gan_days"], "gan_loto": data.get("gan_loto", ""),
                "confidence": confidence, "sources": num_sources, "ai_probability": round(ai_prob, 3),
                "recommendation": recommendation,
            })
        final_list.sort(key=lambda x: x["score"], reverse=True)
        return final_list
    except Exception as e:
        import traceback
        print(f"L·ªñI get_top_scored_pairs: {e}")
        print(traceback.format_exc())
        return []

# IV. H√ÄM M√î PH·ªéNG L·ªäCH S·ª¨
def get_consensus_simulation(data_slice, last_row):
    """B·∫£n sao c·ªßa get_prediction_consensus (ch·∫°y N1 trong b·ªô nh·ªõ)."""
    prediction_sources = {}
    def _standardize_pair(stl_list):
        if not stl_list or len(stl_list) != 2:
            return None
        sorted_pair = sorted(stl_list)
        return f"{sorted_pair[0]}-{sorted_pair[1]}"
    for i, bridge_func in enumerate(ALL_15_BRIDGE_FUNCTIONS_V5):
        try:
            stl = bridge_func(last_row)
            pair_key = _standardize_pair(stl)
            if not pair_key:
                continue
            source_name = f"C{i + 1}"
            if pair_key not in prediction_sources:
                prediction_sources[pair_key] = []
            prediction_sources[pair_key].append(source_name)
        except Exception:
            pass
    bridges_to_test = get_all_managed_bridges(DB_NAME, only_enabled=True)
    if bridges_to_test:
        last_positions = getAllPositions_V17_Shadow(last_row)
        for bridge in bridges_to_test:
            try:
                idx1, idx2 = bridge["pos1_idx"], bridge["pos2_idx"]
                if idx1 == -1:
                    continue
                a, b = last_positions[idx1], last_positions[idx2]
                if a is None or b is None:
                    continue
                stl = taoSTL_V30_Bong(a, b)
                pair_key = _standardize_pair(stl)
                if not pair_key:
                    continue
                source_name = bridge["name"]
                if pair_key not in prediction_sources:
                    prediction_sources[pair_key] = []
                if source_name not in prediction_sources[pair_key]:
                    prediction_sources[pair_key].append(source_name)
            except Exception:
                pass
    consensus_list = []
    for pair_key, sources in prediction_sources.items():
        count = len(sources)
        sources_str = ", ".join(sources)
        consensus_list.append((pair_key, count, sources_str))
    consensus_list.sort(key=lambda item: item[1], reverse=True)
    return consensus_list

def get_high_win_simulation(data_slice, last_row, threshold):
    """B·∫£n sao c·ªßa get_high_win_rate_predictions (ch·∫°y K2N trong b·ªô nh·ªõ)."""
    high_win_bridges = []
    cache_list, _ = _parse_k2n_results(BACKTEST_MANAGED_BRIDGES_K2N(data_slice, 2, len(data_slice) + 1, DB_NAME, history=False))
    cache_list_15, _ = _parse_k2n_results(BACKTEST_15_CAU_K2N_V30_AI_V8(data_slice, 2, len(data_slice) + 1, history=False))
    cache_list.extend(cache_list_15)
    if not cache_list:
        return []
    for win_rate_text, _, next_prediction_stl, _, _, bridge_name in cache_list:
        try:
            win_rate = float(str(win_rate_text).replace("%", ""))
            if win_rate >= threshold:
                if (not next_prediction_stl or "N2" in next_prediction_stl or "L·ªñI" in next_prediction_stl or "," not in next_prediction_stl):
                    continue
                stl = next_prediction_stl.split(",")
                high_win_bridges.append({"name": bridge_name, "stl": stl, "rate": f"{win_rate:.2f}%"})
        except (ValueError, TypeError):
            continue
    return high_win_bridges

def prepare_daily_features(all_data_ai, day_index):
    """T√≠nh to√°n t·∫•t c·∫£ d·ªØ li·ªáu th√¥ (Raw Features) t·ªën k√©m cho dashboard m·ªôt ng√†y c·ª• th·ªÉ."""
    data_slice = all_data_ai[: day_index + 1]
    if len(data_slice) < 2:
        return None
    last_row = data_slice[-1]
    n_days_stats = getattr(SETTINGS, "STATS_DAYS", 7)
    n_days_gan = getattr(SETTINGS, "GAN_DAYS", 15)
    high_win_thresh = getattr(SETTINGS, "HIGH_WIN_THRESHOLD", 47.0)
    stats_n_day = get_loto_stats_last_n_days(data_slice, n=n_days_stats)
    _, pending_k2n_data = _parse_k2n_results(BACKTEST_15_CAU_K2N_V30_AI_V8(data_slice, 2, len(data_slice) + 1, history=False))
    consensus = get_consensus_simulation(data_slice, last_row)
    high_win = get_high_win_simulation(data_slice, last_row, threshold=high_win_thresh)
    top_memory_bridges = get_top_memory_bridge_predictions(data_slice, last_row, top_n=5)
    gan_stats = get_loto_gan_stats(data_slice, n_days=n_days_gan)
    ai_predictions = None
    return {"stats_n_day": stats_n_day, "consensus": consensus, "high_win": high_win, "gan_stats": gan_stats,
            "pending_k2n": pending_k2n_data, "top_memory": top_memory_bridges, "ai_predictions": ai_predictions, "recent_data": data_slice}

def calculate_score_from_features(features_dict, config_dict):
    """Inject config_dict params into SETTINGS before calculating scores."""
    for k, v in config_dict.items():
        try:
            setattr(SETTINGS, k, v)
        except Exception:
            pass
    return get_top_scored_pairs(features_dict["stats_n_day"], features_dict["consensus"], features_dict["high_win"],
            features_dict["pending_k2n"], features_dict["gan_stats"], features_dict["top_memory"],
            features_dict.get("ai_predictions"), features_dict.get("recent_data"))

def get_historical_dashboard_data(all_data_ai, day_index, temp_settings):
    """H√†m "ch·ªß" ƒë·ªÉ m√¥ ph·ªèng B·∫£ng T·ªïng H·ª£p t·∫°i m·ªôt ng√†y trong qu√° kh·ª©."""
    features = prepare_daily_features(all_data_ai, day_index)
    if not features:
        return None
    return calculate_score_from_features(features, temp_settings)



--------------------------------------------------

=== FILE: logic\analytics\__init__.py ===
# Analytics modules - Refactored from dashboard_analytics.py
"""
Exports c√°c h√†m analytics ch√≠nh t·ª´ dashboard_scorer module.
"""

from .dashboard_scorer import (
    get_loto_stats_last_n_days,
    get_loto_gan_stats,
    get_top_memory_bridge_predictions,
    get_prediction_consensus,
    get_high_win_rate_predictions,
    get_pending_k2n_bridges,
    get_top_scored_pairs,
    get_consensus_simulation,
    get_high_win_simulation,
    prepare_daily_features,
    calculate_score_from_features,
    get_historical_dashboard_data,
)

__all__ = [
    'get_loto_stats_last_n_days',
    'get_loto_gan_stats',
    'get_top_memory_bridge_predictions',
    'get_prediction_consensus',
    'get_high_win_rate_predictions',
    'get_pending_k2n_bridges',
    'get_top_scored_pairs',
    'get_consensus_simulation',
    'get_high_win_simulation',
    'prepare_daily_features',
    'calculate_score_from_features',
    'get_historical_dashboard_data',
]


--------------------------------------------------

=== FILE: logic\backtest\__init__.py ===
# Backtest modules - Refactored from backtester.py



--------------------------------------------------

=== FILE: logic\bridges\bridges_classic.py ===
# T√™n file: du-an-backup/logic/bridges/bridges_classic.py
#
# (N·ªòI DUNG THAY TH·∫æ TO√ÄN B·ªò - S·ª¨A E741)
#
# ===================================================================================
# I. C·∫§U H√åNH V√Ä H√ÄM H·ªñ TR·ª¢ C·ªêT L√ïI (V25)
# ===================================================================================

BONG_DUONG_V30 = {
    "0": "5",
    "1": "6",
    "2": "7",
    "3": "8",
    "4": "9",
    "5": "0",
    "6": "1",
    "7": "2",
    "8": "3",
    "9": "4",
}


def getBongDuong_V30(digit):
    return BONG_DUONG_V30.get(str(digit), str(digit))


def taoSTL_V30_Bong(a, b):
    strA, strB = str(a), str(b)
    if strA == strB:
        kep = f"{strA}{strB}".zfill(2)
        bongDigit = getBongDuong_V30(strA)
        bongKep = f"{bongDigit}{bongDigit}".zfill(2)
        return [kep, bongKep]
    else:
        lo1 = f"{strA}{strB}".zfill(2)
        lo2 = f"{strB}{strA}".zfill(2)
        return [lo1, lo2]


def getAllLoto_V30(row):
    lotos = []
    try:
        lotos.append(str(row[2] or "0").strip()[-2:].zfill(2))  # GƒêB (row[2])
        lotos.append(str(row[3] or "0").strip()[-2:].zfill(2))  # G1 (row[3])
        for i in range(4, 10):  # G2 (row[4]) -> G7 (row[9])
            if row[i]:
                for g in str(row[i]).split(","):
                    lotos.append(g.strip()[-2:].zfill(2))
    except Exception as e:
        print(f"L·ªói getAllLoto_V30: {e}")
        pass
    # (S·ª¨A E741) ƒê·ªïi 'l' th√†nh 'loto'
    return [loto for loto in lotos if loto and len(loto) == 2 and loto.isdigit()]


def checkHitSet_V30_K2N(stlPair, lotoSet):
    try:
        hit1 = stlPair[0] in lotoSet
        hit2 = stlPair[1] in lotoSet
        if hit1 and hit2:
            return "‚úÖ (ƒÇn 2)"
        if hit1 or hit2:
            return "‚úÖ (ƒÇn 1)"
        return "‚ùå"
    except Exception:
        return "L·ªói check"


# ===================================================================================
# II. 15 H√ÄM LOGIC C·∫¶U L√î (A:I) (V5) - (ƒê√£ s·ª≠a l·ªói l·ªách c·ªôt)
# ===================================================================================


def getCau1_STL_P5_V30_V5(row):
    try:
        gdb = str(row[2] or "00000").strip()
        de = gdb[-2:].zfill(2)
        a, b = int(de[0]), int(de[1])
        x, y = (a + 5) % 10, (b + 5) % 10
        return taoSTL_V30_Bong(x, y)
    except Exception:
        return ["00", "55"]


def getCau2_VT1_V30_V5(row):
    try:
        g6 = str(row[8] or ",,").split(",")
        g7 = str(row[9] or ",,,").split(",")
        a = (g6[2] if len(g6) > 2 else "0").strip()[-1:]
        b = (g7[3] if len(g7) > 3 else "0").strip()[-1:]
        return taoSTL_V30_Bong(a or "0", b or "0")
    except Exception:
        return ["00", "55"]


def getCau3_VT2_V30_V5(row):
    try:
        a = str(row[2] or "0").strip()[-1:]
        b = str(row[3] or "0").strip()[-1:]
        return taoSTL_V30_Bong(a or "0", b or "0")
    except Exception:
        return ["00", "55"]


def getCau4_VT3_V30_V5(row):
    try:
        a = str(row[2] or "00000").strip()[-2:-1]
        b = str(row[3] or "0").strip()[-1:]
        return taoSTL_V30_Bong(a or "0", b or "0")
    except Exception:
        return ["00", "55"]


def getCau5_TDB1_V30_V5(row):
    try:
        g7 = str(row[9] or ",,,").split(",")
        a = (g7[0] or "0").strip()[:1]
        b = (g7[3] if len(g7) > 3 else "0").strip()[-1:]
        return taoSTL_V30_Bong(a or "0", b or "0")
    except Exception:
        return ["00", "55"]


def getCau6_VT5_V30_V5(row):
    try:
        g7 = str(row[9] or ",,,").split(",")
        a = (g7[1] if len(g7) > 1 else "0").strip()[-1:]
        b = (g7[2] if len(g7) > 2 else "0").strip()[:1]
        return taoSTL_V30_Bong(a or "0", b or "0")
    except Exception:
        return ["00", "55"]


def getCau7_Moi1_V30_V5(row):
    try:
        g5 = str(row[7] or ",,,,,").split(",")
        g7 = str(row[9] or ",,,").split(",")
        a = (g5[0] or "0").strip()[:1]
        b = (g7[0] or "0").strip()[:1]
        return taoSTL_V30_Bong(a or "0", b or "0")
    except Exception:
        return ["00", "55"]


def getCau8_Moi2_V30_V5(row):
    try:
        g3 = str(row[5] or ",,,,,").split(",")
        g4 = str(row[6] or ",,,").split(",")
        a = (g3[0] or "0").strip()[:1]
        b = (g4[0] or "0").strip()[:1]
        return taoSTL_V30_Bong(a or "0", b or "0")
    except Exception:
        return ["00", "55"]


def getCau9_Moi3_V30_V5(row):
    try:
        a = str(row[2] or "0").strip()[:1]
        b = str(row[3] or "0").strip()[:1]
        return taoSTL_V30_Bong(a or "0", b or "0")
    except Exception:
        return ["00", "55"]


def getCau10_Moi4_V30_V5(row):
    try:
        g2 = str(row[4] or ",0").split(",")
        g3 = str(row[5] or ",,0").split(",")
        a = (g2[1] if len(g2) > 1 else "00").strip()[1:2]
        b = (g3[2] if len(g3) > 2 else "00000").strip()[-1:]
        return taoSTL_V30_Bong(a or "0", b or "0")
    except Exception:
        return ["00", "55"]


def getCau11_Moi5_V30_V5(row):
    try:
        gdb = str(row[2] or "00").strip()
        g3 = str(row[5] or ",0").split(",")
        a = gdb[1:2]
        b = (g3[1] if len(g3) > 1 else "00000").strip()[-1:]
        return taoSTL_V30_Bong(a or "0", b or "0")
    except Exception:
        return ["00", "55"]


def getCau12_Moi6_V30_V5(row):
    try:
        gdb = str(row[2] or "00000").strip()
        g3 = str(row[5] or ",,0").split(",")
        a = gdb[-1:]
        b = (g3[2] if len(g3) > 2 else "000").strip()[2:3]
        return taoSTL_V30_Bong(a or "0", b or "0")
    except Exception:
        return ["00", "55"]


def getCau13_G7_3_P8_V30_V5(row):
    try:
        g7 = str(row[9] or ",,0").split(",")
        baseNum = (g7[2] if len(g7) > 2 else "0").strip().zfill(2)
        a, b = int(baseNum[0]), int(baseNum[1])
        x, y = (a + 8) % 10, (b + 8) % 10
        return taoSTL_V30_Bong(x, y)
    except Exception:
        return ["00", "55"]


def getCau14_G1_P2_V30_V5(row):
    try:
        g1 = str(row[3] or "00").strip()
        baseNum = g1[-2:].zfill(2)
        a, b = int(baseNum[0]), int(baseNum[1])
        x, y = (a + 2) % 10, (b + 2) % 10
        return taoSTL_V30_Bong(x, y)
    except Exception:
        return ["00", "55"]


def getCau15_DE_P7_V30_V5(row):
    try:
        gdb = str(row[2] or "00000").strip()
        baseNum = gdb[-2:].zfill(2)
        a, b = int(baseNum[0]), int(baseNum[1])
        x, y = (a + 7) % 10, (b + 7) % 10
        return taoSTL_V30_Bong(x, y)
    except Exception:
        return ["00", "55"]


ALL_15_BRIDGE_FUNCTIONS_V5 = [
    getCau1_STL_P5_V30_V5,
    getCau2_VT1_V30_V5,
    getCau3_VT2_V30_V5,
    getCau4_VT3_V30_V5,
    getCau5_TDB1_V30_V5,
    getCau6_VT5_V30_V5,
    getCau7_Moi1_V30_V5,
    getCau8_Moi2_V30_V5,
    getCau9_Moi3_V30_V5,
    getCau10_Moi4_V30_V5,
    getCau11_Moi5_V30_V5,
    getCau12_Moi6_V30_V5,
    getCau13_G7_3_P8_V30_V5,
    getCau14_G1_P2_V30_V5,
    getCau15_DE_P7_V30_V5,
]

# --- H√†m Th·ªëng K√™ Loto ---
# (H√†m n√†y ƒë∆∞·ª£c analytics.py s·ª≠ d·ª•ng, nh∆∞ng n√≥ ph·ª• thu·ªôc nhi·ªÅu v√†o
# getAllLoto_V30, v√¨ v·∫≠y ƒë·ªÉ n√≥ ·ªü ƒë√¢y l√† h·ª£p l√Ω)


def calculate_loto_stats(loto_list):
    dau_stats = {i: [] for i in range(10)}
    duoi_stats = {i: [] for i in range(10)}
    for loto in loto_list:
        if len(loto) == 2 and loto.isdigit():
            dau_int, duoi_int = int(loto[0]), int(loto[1])
            dau_stats[dau_int].append(loto[1])
            duoi_stats[duoi_int].append(loto[0])
    return dau_stats, duoi_stats


--------------------------------------------------

=== FILE: logic\bridges\bridges_memory.py ===
# ƒê√¢y l√† file m·ªõi: logic/bridges_memory.py

# Import c√°c h√†m h·ªó tr·ª£ t·ª´ .bridges_classic
try:
    from .bridges_classic import taoSTL_V30_Bong
except ImportError:
    from bridges_classic import taoSTL_V30_Bong

# ===================================================================================
# I. ƒê·ªäNH NGHƒ®A 27 V·ªä TR√ç L√î
# ===================================================================================

# Danh s√°ch t√™n c·ªßa 27 v·ªã tr√≠ l√¥
_LOTO_POSITION_NAMES = [
    "L√¥ GƒêB",
    "L√¥ G1",
    "L√¥ G2.1",
    "L√¥ G2.2",
    "L√¥ G3.1",
    "L√¥ G3.2",
    "L√¥ G3.3",
    "L√¥ G3.4",
    "L√¥ G3.5",
    "L√¥ G3.6",
    "L√¥ G4.1",
    "L√¥ G4.2",
    "L√¥ G4.3",
    "L√¥ G4.4",
    "L√¥ G5.1",
    "L√¥ G5.2",
    "L√¥ G5.3",
    "L√¥ G5.4",
    "L√¥ G5.5",
    "L√¥ G5.6",
    "L√¥ G6.1",
    "L√¥ G6.2",
    "L√¥ G6.3",
    "L√¥ G7.1",
    "L√¥ G7.2",
    "L√¥ G7.3",
    "L√¥ G7.4",
]


def get_27_loto_names():
    """Tr·∫£ v·ªÅ danh s√°ch 27 t√™n c·ªßa c√°c v·ªã tr√≠ l√¥."""
    return _LOTO_POSITION_NAMES


def get_27_loto_positions(row):
    """
    (M·ªöI) L·∫•y 27 con l√¥ (2 s·ªë cu·ªëi) t·ª´ 1 h√†ng d·ªØ li·ªáu DB.
    Tr·∫£ v·ªÅ m·ªôt danh s√°ch 27 chu·ªói (string) 2 ch·ªØ s·ªë.
    """
    lotos = []
    try:
        # 1. GƒêB (row[2])
        lotos.append(str(row[2] or "0").strip()[-2:].zfill(2))
        # 2. G1 (row[3])
        lotos.append(str(row[3] or "0").strip()[-2:].zfill(2))

        # 3. G2 (row[4]) - 2 gi·∫£i
        g2 = str(row[4] or ",").split(",")
        lotos.append(str(g2[0] or "0").strip()[-2:].zfill(2))
        lotos.append(str(g2[1] if len(g2) > 1 else "0").strip()[-2:].zfill(2))

        # 4. G3 (row[5]) - 6 gi·∫£i
        g3 = str(row[5] or ",,,,,").split(",")
        for i in range(6):
            lotos.append(str(g3[i] if len(g3) > i else "0").strip()[-2:].zfill(2))

        # 5. G4 (row[6]) - 4 gi·∫£i
        g4 = str(row[6] or ",,,").split(",")
        for i in range(4):
            lotos.append(str(g4[i] if len(g4) > i else "0").strip()[-2:].zfill(2))

        # 6. G5 (row[7]) - 6 gi·∫£i
        g5 = str(row[7] or ",,,,,").split(",")
        for i in range(6):
            lotos.append(str(g5[i] if len(g5) > i else "0").strip()[-2:].zfill(2))

        # 7. G6 (row[8]) - 3 gi·∫£i
        g6 = str(row[8] or ",,").split(",")
        for i in range(3):
            lotos.append(str(g6[i] if len(g6) > i else "0").strip()[-2:].zfill(2))

        # 8. G7 (row[9]) - 4 gi·∫£i
        g7 = str(row[9] or ",,,").split(",")
        for i in range(4):
            lotos.append(str(g7[i] if len(g7) > i else "0").strip()[-2:].zfill(2))

        return lotos  # T·ªïng 1+1+2+6+4+6+3+4 = 27

    except Exception as e:
        print(f"L·ªói get_27_loto_positions: {e}")
        return ["00"] * 27


# ===================================================================================
# II. ƒê·ªäNH NGHƒ®A C√ÅC THU·∫¨T TO√ÅN B·∫†C NH·ªö
# ===================================================================================


def calculate_bridge_stl(loto_str_1, loto_str_2, algorithm_type):
    """
    (M·ªöI) T√≠nh to√°n v√† tr·∫£ v·ªÅ m·ªôt c·∫∑p STL [l√¥, l·ªôn]
    d·ª±a tr√™n 2 con l√¥ ƒë·∫ßu v√†o v√† 1 thu·∫≠t to√°n.
    """
    try:
        loto1 = int(loto_str_1)
        loto2 = int(loto_str_2)
        btl = 0  # L√¥ B·∫°ch Th·ªß

        if algorithm_type == "sum":
            # 1. Thu·∫≠t to√°n T·ªîNG
            btl = (loto1 + loto2) % 100
        elif algorithm_type == "diff":
            # 2. Thu·∫≠t to√°n HI·ªÜU
            btl = abs(loto1 - loto2)
        else:
            return ["00", "00"]

        btl_str = str(btl).zfill(2)

        # 3. T·∫°o STL (L√¥ v√† L·ªôn)
        # Ki·ªÉm tra xem c√≥ ph·∫£i l√¥ k√©p kh√¥ng
        if btl_str[0] == btl_str[1]:
            # N·∫øu l√† k√©p, d√πng h√†m taoSTL_V30_Bong ƒë·ªÉ l·∫•y b√≥ng
            # (H√†m n√†y ƒë√£ x·ª≠ l√Ω k√©p -> k√©p, b√≥ng k√©p)
            return taoSTL_V30_Bong(btl_str[0], btl_str[1])
        else:
            # N·∫øu kh√¥ng ph·∫£i k√©p, tr·∫£ v·ªÅ [l√¥, l·ªôn]
            return [btl_str, btl_str[1] + btl_str[0]]

    except Exception as e:
        print(f"L·ªói calculate_bridge_stl: {e}")
        return ["00", "00"]


--------------------------------------------------

=== FILE: logic\bridges\bridges_v16.py ===
import re

# Import c√°c h√†m h·ªó tr·ª£ t·ª´ .bridges_classic
try:
    # (M·ªöI) Th√™m BONG_DUONG_V30 v√†o import
    from .bridges_classic import BONG_DUONG_V30, getAllLoto_V30, taoSTL_V30_Bong
except ImportError:
    # Fallback
    try:
        from bridges_classic import BONG_DUONG_V30, getAllLoto_V30, taoSTL_V30_Bong
    except ImportError:
        print("L·ªói: Kh√¥ng th·ªÉ import bridges_classic trong bridges_v16.py")

        def getAllLoto_V30(r):
            return []

        def taoSTL_V30_Bong(a, b):
            return ["00", "00"]

        BONG_DUONG_V30 = {}  # Gi·∫£ l·∫≠p

# ===================================================================================
# V. H√ÄM C√îNG KHAI: D√í C·∫¶U & TEST C·∫¶U (V16)
# ===================================================================================


def getDigits_V16(s):
    if not s:
        return []
    return [int(d) for d in str(s) if d.isdigit()]


def getAllPositions_V16(row):
    positions = []
    try:
        positions.extend(
            getDigits_V16(str(row[2] or "0").strip().zfill(5))
        )  # GƒêB (row[2])
        positions.extend(
            getDigits_V16(str(row[3] or "0").strip().zfill(5))
        )  # G1 (row[3])
        g2 = str(row[4] or "").split(",")  # G2
        for g in g2:
            positions.extend(getDigits_V16(g.strip().zfill(5)))
        while len(positions) < 20:
            positions.append(None)
        g3 = str(row[5] or "").split(",")  # G3
        for g in g3:
            positions.extend(getDigits_V16(g.strip().zfill(5)))
        while len(positions) < 50:
            positions.append(None)
        g4 = str(row[6] or "").split(",")  # G4
        for g in g4:
            positions.extend(getDigits_V16(g.strip().zfill(4)))
        while len(positions) < 66:
            positions.append(None)
        g5 = str(row[7] or "").split(",")  # G5
        for g in g5:
            positions.extend(getDigits_V16(g.strip().zfill(4)))
        while len(positions) < 90:
            positions.append(None)
        g6 = str(row[8] or "").split(",")  # G6
        for g in g6:
            positions.extend(getDigits_V16(g.strip().zfill(3)))
        while len(positions) < 99:
            positions.append(None)
        g7 = str(row[9] or "").split(",")  # G7
        for g in g7:
            positions.extend(getDigits_V16(g.strip().zfill(2)))
        while len(positions) < 107:
            positions.append(None)
        return positions[:107]
    except Exception as e:
        print(f"L·ªói getAllPositions_V16: {e}")
        return [None] * 107


def getPositionName_V16(index):
    if index < 0 or index > 106:
        return "NULL"
    if index < 5:
        return f"GDB[{index}]"
    if index < 10:
        return f"G1[{index - 5}]"
    if index < 20:
        return f"G2.{(index - 10) // 5 + 1}[{(index - 10) % 5}]"
    if index < 50:
        return f"G3.{(index - 20) // 5 + 1}[{(index - 20) % 5}]"
    if index < 66:
        return f"G4.{(index - 50) // 4 + 1}[{(index - 50) % 4}]"
    if index < 90:
        return f"G5.{(index - 66) // 4 + 1}[{(index - 66) % 4}]"
    if index < 99:
        return f"G6.{(index - 90) // 3 + 1}[{(index - 90) % 3}]"
    if index < 107:
        return f"G7.{(index - 99) // 2 + 1}[{(index - 99) % 2}]"
    return "ERROR"


def get_index_from_name_V16(name_str):
    """
    (M·ªöI - C·∫¨P NH·∫¨T) H√†m n√†y ƒë√£ ƒë∆∞·ª£c n√¢ng c·∫•p ƒë·ªÉ hi·ªÉu t√™n V17.
    N√≥ c√≥ th·ªÉ ph√¢n t√≠ch "GDB[0]" (tr·∫£ v·ªÅ 0) v√† "Bong(GDB[0])" (tr·∫£ v·ªÅ 107).
    """
    processed_name = name_str.strip()
    is_bong = False

    # 1. Ki·ªÉm tra xem c√≥ ph·∫£i c·∫ßu b√≥ng kh√¥ng
    if processed_name.startswith("Bong(") and processed_name.endswith(")"):
        is_bong = True
        # L·∫•y ph·∫ßn t√™n g·ªëc b√™n trong, v√≠ d·ª•: "Bong(GDB[0])" -> "GDB[0]"
        processed_name = processed_name[5:-1].strip()

    # 2. Ph√¢n t√≠ch t√™n g·ªëc
    match = re.match(r"(G\d+|GDB)\.?(\d+)?\[(\d+)\]", processed_name)
    if not match:
        print(f"L·ªói regex: Kh√¥ng th·ªÉ ph√¢n t√≠ch '{name_str}'")
        return None

    g_name, g_num, g_idx = match.groups()
    base_index = None

    try:
        g_num = int(g_num) if g_num else 1
        g_idx = int(g_idx)

        if g_name == "GDB":
            if 0 <= g_idx <= 4:
                base_index = g_idx
        elif g_name == "G1":
            if 0 <= g_idx <= 4:
                base_index = 5 + g_idx
        elif g_name == "G2":
            if 1 <= g_num <= 2 and 0 <= g_idx <= 4:
                base_index = 10 + (g_num - 1) * 5 + g_idx
        elif g_name == "G3":
            if 1 <= g_num <= 6 and 0 <= g_idx <= 4:
                base_index = 20 + (g_num - 1) * 5 + g_idx
        elif g_name == "G4":
            if 1 <= g_num <= 4 and 0 <= g_idx <= 3:
                base_index = 50 + (g_num - 1) * 4 + g_idx
        elif g_name == "G5":
            if 1 <= g_num <= 6 and 0 <= g_idx <= 3:
                base_index = 66 + (g_num - 1) * 4 + g_idx
        elif g_name == "G6":
            if 1 <= g_num <= 3 and 0 <= g_idx <= 2:
                base_index = 90 + (g_num - 1) * 3 + g_idx
        elif g_name == "G7":
            if 1 <= g_num <= 4 and 0 <= g_idx <= 1:
                base_index = 99 + (g_num - 1) * 2 + g_idx

        if base_index is None:
            print(f"L·ªói logic: T√™n c·∫ßu kh√¥ng h·ª£p l·ªá '{name_str}'")
            return None

        # 3. Tr·∫£ v·ªÅ ch·ªâ s·ªë cu·ªëi c√πng
        if is_bong:
            return base_index + 107  # Tr·∫£ v·ªÅ ch·ªâ s·ªë trong d·∫£i b√≥ng (107-213)
        else:
            return base_index  # Tr·∫£ v·ªÅ ch·ªâ s·ªë g·ªëc (0-106)

    except Exception as e:
        print(f"L·ªói get_index_from_name_V16: {e}")
        return None


# ===================================================================================
# (M·ªöI) H√ÄM M·ªû R·ªòNG V17 - (Th√™m 107 v·ªã tr√≠ B√≥ng)
# ===================================================================================


def getAllPositions_V17_Shadow(row):
    """
    (M·ªöI) L·∫•y 214 v·ªã tr√≠ = 107 v·ªã tr√≠ g·ªëc + 107 v·ªã tr√≠ b√≥ng.
    """
    # 1. L·∫•y 107 v·ªã tr√≠ g·ªëc (d√πng h√†m ƒë√£ c√≥)
    positions_goc = getAllPositions_V16(row)

    # 2. T·∫°o 107 v·ªã tr√≠ b√≥ng
    positions_bong = []
    for digit in positions_goc:
        if digit is None:
            positions_bong.append(None)
        else:
            try:
                # Chuy·ªÉn s·ªë (int) v·ªÅ chu·ªói (str) ƒë·ªÉ tra c·ª©u b√≥ng
                bong_digit_str = BONG_DUONG_V30.get(str(digit), str(digit))
                positions_bong.append(int(bong_digit_str))
            except Exception:
                positions_bong.append(None)

    # 3. N·ªëi hai danh s√°ch l·∫°i
    positions_goc.extend(positions_bong)
    return positions_goc  # Tr·∫£ v·ªÅ danh s√°ch 214 v·ªã tr√≠


def getPositionName_V17_Shadow(index):
    """
    (M·ªöI) L·∫•y t√™n c·ªßa v·ªã tr√≠ trong 214 v·ªã tr√≠.
    """
    if index < 0 or index > 213:
        return "NULL"

    if index < 107:
        # 0-106 l√† v·ªã tr√≠ g·ªëc
        return getPositionName_V16(index)  # D√πng h√†m ƒë√£ c√≥
    else:
        # 107-213 l√† v·ªã tr√≠ b√≥ng
        index_goc = index - 107
        name_goc = getPositionName_V16(index_goc)
        return f"Bong({name_goc})"


--------------------------------------------------

=== FILE: logic\bridges\bridge_factory.py ===
# logic/bridges/bridge_factory.py

from typing import Any, Dict, List, Type

# Import c√°c l·ªõp Bridge c·ª• th·ªÉ
# L∆∞u √Ω: C·∫ßn ƒë·∫£m b·∫£o c√°c l·ªõp n√†y ƒë√£ t·ªìn t·∫°i v√† tu√¢n th·ªß IBridgeStrategy
from .bridges_classic import ClassicBridge
from .bridges_memory import MemoryBridge
from .bridges_v16 import V16Bridge
from .i_bridge_strategy import IBridgeStrategy

# S·ª≠ d·ª•ng Dict[str, Type[IBridgeStrategy]] ƒë·ªÉ √°nh x·∫° KEY t·ªõi Class
# D√πng m·ªôt instance t·∫°m th·ªùi (None, None) ƒë·ªÉ l·∫•y KEY m·ªôt c√°ch an to√†n
STRATEGY_MAP: Dict[str, Type[IBridgeStrategy]] = {
    "classic": ClassicBridge,
    "memory": MemoryBridge,
    "v16": V16Bridge,
    # Th√™m c√°c Strategy m·ªõi v√†o ƒë√¢y khi ph√°t tri·ªÉn
}


def create_bridge_strategy(
    strategy_key: str, data_repository: Any, config_manager: Any
) -> IBridgeStrategy:
    """
    Factory method ƒë·ªÉ kh·ªüi t·∫°o v√† tr·∫£ v·ªÅ ƒë·ªëi t∆∞·ª£ng Bridge Strategy ph√π h·ª£p.
    """
    key = strategy_key.lower()
    strategy_class = STRATEGY_MAP.get(key)

    if strategy_class:
        # Kh·ªüi t·∫°o ƒë·ªëi t∆∞·ª£ng Strategy v·ªõi c√°c dependency c·∫ßn thi·∫øt
        return strategy_class(data_repository, config_manager)
    else:
        raise ValueError(
            f"Strategy type '{strategy_key}' is not supported or does not exist."
        )


def get_available_strategies() -> List[str]:
    """
    Tr·∫£ v·ªÅ danh s√°ch c√°c kh√≥a chi·∫øn l∆∞·ª£c c√≥ s·∫µn.
    """
    return list(STRATEGY_MAP.keys())


--------------------------------------------------

=== FILE: logic\bridges\bridge_manager_core.py ===
# T√™n file: logic/bridges/bridge_manager_core.py
# (PHI√äN B·∫¢N V10.0 - REFACTORED: SEPARATED SCANNING FROM MANAGEMENT)
#
# M·ª•c ƒë√≠ch: Ch·ªâ gi·ªØ logic QU·∫¢N L√ù (Management) c·∫ßu L√¥.
#           Logic D√í T√åM (Scanning) ƒë√£ ƒë∆∞·ª£c t√°ch sang lo_bridge_scanner.py.

import os
import sqlite3
import sys
from typing import List, Optional, Dict

# =========================================================================
# PATH FIX
# =========================================================================
try:
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(os.path.dirname(current_dir))
    if project_root not in sys.path:
        sys.path.insert(0, project_root)
except Exception:
    pass

# =========================================================================
# IMPORTS
# =========================================================================
try:
    from logic.config_manager import SETTINGS
except ImportError:
    SETTINGS = type("obj", (object,), {"AUTO_ADD_MIN_RATE": 50.0, "AUTO_PRUNE_MIN_RATE": 40.0})

try:
    from logic.data_repository import get_all_managed_bridges
    from logic.db_manager import (
        DB_NAME, update_managed_bridge
    )
except ImportError:
    DB_NAME = "data/xo_so_prizes_all_logic.db"
    def update_managed_bridge(*args, **kwargs): return False, "L·ªói Import"
    def get_all_managed_bridges(*args, **kwargs): return []

try:
    from logic.bridges.bridges_memory import get_27_loto_names
except ImportError:
    pass

# Import scanning functions from lo_bridge_scanner
try:
    from logic.bridges.lo_bridge_scanner import (
        TIM_CAU_TOT_NHAT_V16,
        TIM_CAU_BAC_NHO_TOT_NHAT,
        update_fixed_lo_bridges,
        _ensure_core_db_columns
    )
except ImportError:
    print("WARNING: Could not import scanning functions from lo_bridge_scanner")
    def TIM_CAU_TOT_NHAT_V16(*args, **kwargs): return []
    def TIM_CAU_BAC_NHO_TOT_NHAT(*args, **kwargs): return []
    def update_fixed_lo_bridges(*args, **kwargs): return 0
    def _ensure_core_db_columns(*args, **kwargs): pass

# ===================================================================================
# MANAGEMENT FUNCTIONS (C√°c h√†m qu·∫£n l√Ω c·∫ßu)
# ===================================================================================
# Note: Scanning functions (TIM_CAU_TOT_NHAT_V16, TIM_CAU_BAC_NHO_TOT_NHAT, 
#       update_fixed_lo_bridges) have been moved to lo_bridge_scanner.py

def find_and_auto_manage_bridges(all_data_ai, db_name=DB_NAME):
    """
    T·ª± ƒë·ªông d√≤ t√¨m v√† qu·∫£n l√Ω c·∫ßu L√¥.
    
    Calls scanning functions from lo_bridge_scanner module.
    
    Args:
        all_data_ai: D·ªØ li·ªáu to√†n b·ªô k·ª≥ quay
        db_name: ƒê∆∞·ªùng d·∫´n database
        
    Returns:
        String message about bridges found/updated
    """
    try:
        if not all_data_ai:
            return "L·ªói: Kh√¥ng c√≥ d·ªØ li·ªáu."
        msg = []
        
        print("... [Auto] D√≤ V17 Shadow (K2N Scan) ...")
        res_v17 = TIM_CAU_TOT_NHAT_V16(all_data_ai, 2, len(all_data_ai)+1, db_name)
        msg.append(f"V17 (Scan): {len(res_v17)-1 if res_v17 else 0} c·∫ßu")
        
        print("... [Auto] D√≤ B·∫°c Nh·ªõ (K2N Scan) ...")
        res_bn = TIM_CAU_BAC_NHO_TOT_NHAT(all_data_ai, 2, len(all_data_ai)+1, db_name)
        msg.append(f"B·∫°c Nh·ªõ (Scan): {len(res_bn)-1 if res_bn else 0} c·∫ßu")
        
        print("... [Auto] C·∫≠p nh·∫≠t Fixed (K1N Real) ...")
        c_fix = update_fixed_lo_bridges(all_data_ai, db_name)
        msg.append(f"Fixed (K1N): {c_fix} c·∫ßu")
        
        return " | ".join(msg)
    except Exception as e:
        return f"L·ªói: {e}"

def prune_bad_bridges(all_data_ai, db_name=DB_NAME):
    """
    L·ªçc v√† t·∫Øt c√°c c·∫ßu y·∫øu (Low performance bridges).
    
    Args:
        all_data_ai: D·ªØ li·ªáu to√†n b·ªô k·ª≥ quay (unused but kept for API compatibility)
        db_name: ƒê∆∞·ªùng d·∫´n database
        
    Returns:
        String message about pruning results
    """
    try:
        AUTO_PRUNE_MIN_RATE = SETTINGS.AUTO_PRUNE_MIN_RATE
    except:
        AUTO_PRUNE_MIN_RATE = 40.0

    disabled_count = 0
    skipped_pinned = 0
    try:
        bridges = get_all_managed_bridges(db_name, only_enabled=True)
        if not bridges:
            return "Kh√¥ng c√≥ c·∫ßu ƒë·ªÉ l·ªçc."
        
        for b in bridges:
            try:
                is_pinned = b.get("is_pinned", 0)
                if is_pinned:
                    skipped_pinned += 1
                    continue
                
                k2n_str = str(b.get("search_rate_text", "0")).replace("%", "")
                try:
                    k2n_val = float(k2n_str)
                except:
                    k2n_val = 0.0
                
                k1n_str = str(b.get("win_rate_text", "0")).replace("%", "")
                try:
                    k1n_val = float(k1n_str)
                except:
                    k1n_val = 0.0

                should_disable = False
                
                if k2n_val > 0 or k1n_val > 0:
                    is_k2n_ok = (k2n_val >= AUTO_PRUNE_MIN_RATE)
                    is_k1n_ok = (k1n_val >= AUTO_PRUNE_MIN_RATE)
                    if not is_k2n_ok and not is_k1n_ok:
                        should_disable = True
                else:
                    should_disable = False

                if should_disable:
                    update_managed_bridge(b["id"], b["description"], 0, db_name)
                    disabled_count += 1
                    
            except Exception as e_inner:
                print(f"L·ªói check c·∫ßu {b.get('name')}: {e_inner}")
                pass
                
    except Exception as e:
        return f"L·ªói l·ªçc c·∫ßu: {e}"

    msg = f"L·ªçc c·∫ßu ho√†n t·∫•t. ƒê√£ T·∫ÆT {disabled_count} c·∫ßu y·∫øu (C·∫£ K1N & K2N < {AUTO_PRUNE_MIN_RATE}%)."
    if skipped_pinned > 0:
        msg += f" B·ªè qua {skipped_pinned} c·∫ßu ƒë√£ ghim."
    return msg


def auto_manage_bridges(all_data_ai, db_name=DB_NAME):
    """
    Wrapper function for automatic bridge management.
    Currently just calls prune_bad_bridges.
    
    Args:
        all_data_ai: D·ªØ li·ªáu to√†n b·ªô k·ª≥ quay
        db_name: ƒê∆∞·ªùng d·∫´n database
        
    Returns:
        String message about management results
    """
    return prune_bad_bridges(all_data_ai, db_name)

def init_all_756_memory_bridges_to_db(db_name=DB_NAME, progress_callback=None, enable_all=False):
    """
    Kh·ªüi t·∫°o to√†n b·ªô 756 c·∫ßu B·∫°c Nh·ªõ v√†o database.
    
    Args:
        db_name: ƒê∆∞·ªùng d·∫´n database
        progress_callback: Optional callback function for progress updates
        enable_all: N·∫øu True, k√≠ch ho·∫°t t·∫•t c·∫£ c·∫ßu; n·∫øu False, ƒë·ªÉ m·∫∑c ƒë·ªãnh t·∫Øt
        
    Returns:
        Tuple: (success, message, added_count, error_count)
    """
    print("Kh·ªüi t·∫°o B·∫°c Nh·ªõ chu·∫©n V2.1...")
    loto_names = get_27_loto_names()
    added = 0
    conn = sqlite3.connect(db_name)
    cursor = conn.cursor()
    _ensure_core_db_columns(cursor)
    
    for i in range(len(loto_names)):
        for j in range(i, len(loto_names)):
            sid = f"LO_MEM_SUM_{loto_names[i]}_{loto_names[j]}"
            sdesc = f"B·∫°c Nh·ªõ: T·ªïng({loto_names[i]} + {loto_names[j]})"
            cursor.execute("INSERT OR IGNORE INTO ManagedBridges (name, description, type, is_enabled) VALUES (?, ?, 'LO_MEM', ?)", (sid, sdesc, 1 if enable_all else 0))
            if cursor.rowcount > 0:
                added += 1
            
            did = f"LO_MEM_DIFF_{loto_names[i]}_{loto_names[j]}"
            ddesc = f"B·∫°c Nh·ªõ: Hi·ªáu(|{loto_names[i]} - {loto_names[j]}|)"
            cursor.execute("INSERT OR IGNORE INTO ManagedBridges (name, description, type, is_enabled) VALUES (?, ?, 'LO_MEM', ?)", (did, ddesc, 1 if enable_all else 0))
            if cursor.rowcount > 0:
                added += 1
            
    conn.commit()
    conn.close()
    return True, f"Th√™m {added} c·∫ßu B·∫°c Nh·ªõ chu·∫©n.", added, 0

--------------------------------------------------

=== FILE: logic\bridges\bridge_manager_de.py ===
# T√™n file: logic/bridges/bridge_manager_de.py
# (PHI√äN B·∫¢N V8.0 - RESTORED & FIXED INDENTATION)

import os
import sys
import sqlite3
import re

# Import c√°c t√†i nguy√™n chung
from logic.de_utils import get_touches_by_offset, generate_dan_de_from_touches, get_bo_name_by_pair, BO_SO_DE, get_gdb_last_2, get_set_name_of_number
try:
    from logic.config_manager import SETTINGS
    from logic.db_manager import DB_NAME, upsert_managed_bridge
    from logic.bridges.bridges_v16 import (
        getAllPositions_V17_Shadow,
        getPositionName_V17_Shadow,
        taoSTL_V30_Bong,
        get_index_from_name_V16,
    )
except ImportError as e:
    print(f"L·ªói Import trong bridge_manager_de: {e}")
    SETTINGS = None
    # Fallback path
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(os.path.dirname(current_dir))
    DB_NAME = os.path.join(project_root, "data", "xo_so_prizes_all_logic.db")

# ===================================================================================
# HELPER FUNCTIONS
# ===================================================================================
def _ensure_db_columns(cursor):
    """[SELF-HEALING] Ki·ªÉm tra v√† t·ª± ƒë·ªông th√™m c√°c c·ªôt thi·∫øu trong DB."""
    try:
        cursor.execute("PRAGMA table_info(ManagedBridges)")
        columns = [info[1] for info in cursor.fetchall()]

        if "recent_win_count_10" not in columns:
            cursor.execute("ALTER TABLE ManagedBridges ADD COLUMN recent_win_count_10 INTEGER DEFAULT 0")
        
        if "type" not in columns:
            cursor.execute("ALTER TABLE ManagedBridges ADD COLUMN type TEXT DEFAULT 'UNKNOWN'")
            
        if "next_prediction_stl" not in columns:
            cursor.execute("ALTER TABLE ManagedBridges ADD COLUMN next_prediction_stl TEXT DEFAULT ''")
            
    except Exception as e:
        print(f"L·ªói Self-Healing DB: {e}")

# ===================================================================================
# V2.5: DE BRIDGE MANAGER
# ===================================================================================

class DeBridgeManager:
    """
    Tr√¨nh qu·∫£n l√Ω C·∫ßu ƒê·ªÅ (V2.5)
    """
    def __init__(self):
        self.max_health = 3
        self.lookback_window = 10

    def update_daily_stats(self, all_data_ai):
        if not all_data_ai or len(all_data_ai) < self.lookback_window + 2: return 0, []
        
        print(">>> [DE MANAGER] C·∫≠p nh·∫≠t H·ªì S∆° Phong ƒê·ªô...")
        last_row = all_data_ai[-1]; prev_row = all_data_ai[-2]
        gdb_today = get_gdb_last_2(last_row)
        pos_today = getAllPositions_V17_Shadow(last_row)
        
        conn = sqlite3.connect(DB_NAME)
        cursor = conn.cursor()

        try:
            _ensure_db_columns(cursor)
            conn.commit()
            cursor.execute("SELECT id, name, type, current_streak, recent_win_count_10, description FROM ManagedBridges WHERE is_enabled=1 AND (type LIKE 'DE_%' OR type LIKE 'CAU_DE%')")
            active_bridges = cursor.fetchall()
        except sqlite3.OperationalError as e:
            print(f"L·ªói ƒê·ªçc DB: {e}")
            conn.close()
            return 0, []
        
        updated_count = 0
        active_list_ui = []
        
        for br_id, name, b_type, streak, hp_db, desc in active_bridges:
            try:
                # PARSER V2.1: Ph√¢n t√≠ch ID C·∫ßu
                parsed_info = self._parse_bridge_id_v2(name, b_type)
                if not parsed_info:
                    parsed_info = self._parse_bridge_id_legacy(name)
                
                if not parsed_info: continue 

                idx1, idx2, k_offset, mode = parsed_info

                # 1. T√≠nh k·∫øt qu·∫£ (Streak)
                pos_prev = getAllPositions_V17_Shadow(prev_row)
                dan_today = self._calculate_dan_logic(pos_prev, idx1, idx2, k_offset, mode, return_string=False)
                
                is_win = (gdb_today in dan_today) if (gdb_today and dan_today) else False
                
                current_hp = hp_db if (hp_db is not None and 0 <= hp_db <= self.max_health) else self.max_health
                new_streak = streak + 1 if is_win else 0
                new_hp = self.max_health if is_win else current_hp - 1
                
                # 2. Backtest 10 k·ª≥
                wins_10 = 0
                recent_data = all_data_ai[-11:] if len(all_data_ai) >= 11 else all_data_ai
                
                for i in range(min(10, len(recent_data) - 1)):
                    idx_today = len(recent_data) - 1 - i
                    idx_prev = idx_today - 1
                    if idx_prev < 0: break
                    
                    row_today_k = recent_data[idx_today]
                    row_prev_k = recent_data[idx_prev]
                    g_today = get_gdb_last_2(row_today_k)
                    if not g_today: continue
                    p_prev = getAllPositions_V17_Shadow(row_prev_k)
                    d_prev = self._calculate_dan_logic(p_prev, idx1, idx2, k_offset, mode, return_string=False)
                    if g_today in d_prev:
                        wins_10 += 1

                # T√≠nh Search Rate
                search_rate_val = (wins_10 / 10.0) * 100
                new_search_rate = f"{search_rate_val:.0f}%"

                # 3. Sinh t·ªìn & X·∫øp h·∫°ng
                is_enabled = 1 if new_hp > 0 else 0
                rank_score = (new_streak * 10) + (wins_10 * 5)
                
                # 4. D·ª± ƒëo√°n ng√†y mai
                pred_display = ""
                if is_enabled:
                    pred_display = self._calculate_dan_logic(pos_today, idx1, idx2, k_offset, mode, return_string=True, display_mode=True)
                
                # 5. C·∫≠p nh·∫≠t DB
                new_desc = desc.split(".")[0] if desc and "." in desc else (desc or name)
                new_desc += f". HP:{new_hp}/{self.max_health} | Win10:{wins_10}"
                
                cursor.execute("""
                    UPDATE ManagedBridges 
                    SET current_streak=?, recent_win_count_10=?, is_enabled=?, next_prediction_stl=?, description=?, search_rate_text=? 
                    WHERE id=?""", 
                    (new_streak, wins_10, is_enabled, pred_display, new_desc, new_search_rate, br_id))
                
                if is_enabled:
                    active_list_ui.append({
                        "name": name, 
                        "type": b_type, 
                        "streak": new_streak, 
                        "recent_win_count_10": wins_10,
                        "wins_10": wins_10,
                        "rank_score": rank_score, 
                        "predicted_value": pred_display,
                        "next_prediction_stl": pred_display,
                        "prediction": pred_display,
                        "hp": new_hp, 
                        "description": new_desc
                    })
                    updated_count += 1
            except Exception as e: 
                # print(f"L·ªói x·ª≠ l√Ω c·∫ßu {name}: {e}")
                continue
                
        conn.commit(); conn.close()
        return updated_count, sorted(active_list_ui, key=lambda x: x['rank_score'], reverse=True)

    def _parse_bridge_id_v2(self, name, b_type):
        """
        [FIXED] Parser h·ªó tr·ª£ c·∫£ t√™n c≈© v√† t√™n m·ªõi (d·∫•u ch·∫•m/ngo·∫∑c).
        S·ª≠ d·ª•ng _map_safe_name_to_index ƒë·ªÉ ƒë·∫£m b·∫£o ƒë·ªçc ƒë∆∞·ª£c m·ªçi ƒë·ªãnh d·∫°ng.
        """
        try:
            if "DE_DYN" in name or b_type == "DE_DYNAMIC_K":
                parts = name.split("_")
                k_str = "0"
                for p in parts:
                    if p.startswith("K") and p[1:].isdigit():
                        k_str = p[1:]
                        break
                
                match = re.search(r"DE_DYN_(.+)_([^_]+)_K(\d+)", name)
                if match:
                    p1_str, p2_str, _ = match.groups()
                    idx1 = self._map_safe_name_to_index(p1_str) 
                    idx2 = self._map_safe_name_to_index(p2_str)
                    if idx1 is not None and idx2 is not None:
                        return idx1, idx2, int(k_str), "DYNAMIC"

            elif "DE_POS" in name or b_type == "DE_POS_SUM":
                match = re.search(r"DE_POS_(.+)_([^_]+)", name)
                if match:
                    p1_str, p2_str = match.groups()
                    idx1 = self._map_safe_name_to_index(p1_str)
                    idx2 = self._map_safe_name_to_index(p2_str)
                    if idx1 is not None and idx2 is not None:
                        return idx1, idx2, 0, "POS_SUM"
            
            elif "DE_SET" in name or b_type == "DE_SET":
                match = re.search(r"DE_SET_(.+)_([^_]+)", name)
                if match:
                    p1_str, p2_str = match.groups()
                    idx1 = self._map_safe_name_to_index(p1_str)
                    idx2 = self._map_safe_name_to_index(p2_str)
                    
                    if idx1 is None: idx1 = self._map_std_name_to_index(p1_str)
                    if idx2 is None: idx2 = self._map_std_name_to_index(p2_str)
                    
                    if idx1 is not None and idx2 is not None:
                        return idx1, idx2, 0, "SET"
                    
        except: return None
        return None

    def _parse_bridge_id_legacy(self, name):
        try:
            match = re.match(r"(.+)\+(.+) \((.+)\)", name)
            if match:
                p1, p2, suffix = match.groups()
                idx1 = get_index_from_name_V16(p1.strip())
                idx2 = get_index_from_name_V16(p2.strip())
                return idx1, idx2, 0, "LEGACY_V17"
        except: pass
        return None

    def _map_std_name_to_index(self, std_name):
        mapping = {
            "GDB": 4, "G1": 9, "G2": 19, "G3": 49, 
            "G4": 65, "G5": 89, "G6": 98, "G7": 106
        }
        return mapping.get(std_name, None)

    def _map_safe_name_to_index(self, safe_name):
        """
        [FIXED] Ph√¢n t√≠ch t√™n v·ªã tr√≠ linh ho·∫°t.
        H·ªó tr·ª£: G2.1[0], G2.1.0, G2.1[0
        """
        try:
            # Regex m·ªõi ch·∫•p nh·∫≠n d·∫•u . v√† [
            match = re.match(r"(G\d+\.?\d*|GDB)[\[\.]?(\d+)", safe_name)
            
            if match:
                g_name, g_idx = match.groups()
                # T√°i t·∫°o v·ªÅ format chu·∫©n m√† th∆∞ vi·ªán V16 hi·ªÉu
                reconstructed = f"{g_name}[{g_idx}]"
                return get_index_from_name_V16(reconstructed)
            return None
        except: return None

    def _calculate_dan_logic(self, positions, idx1, idx2, k_offset, mode, return_string=False, display_mode=False):
        try:
            if idx1 is None or idx2 is None: return [] if not return_string else ""
            
            # Ki·ªÉm tra bounds
            if idx1 >= len(positions) or idx2 >= len(positions):
                 return [] if not return_string else ""

            v1_raw = positions[idx1]
            v2_raw = positions[idx2]
            
            if v1_raw is None or v2_raw is None:
                return [] if not return_string else ""

            v1 = int(v1_raw)
            v2 = int(v2_raw)

            base_sum = 0
            if mode == "DYNAMIC":
                base_sum = (v1 + v2) % 10
            elif mode == "POS_SUM" or mode == "LEGACY_V17":
                base_sum = (v1 + v2) % 10
            elif mode == "SET":
                combined_number = f"{v1}{v2}"
                set_name = get_set_name_of_number(combined_number)
                if set_name:
                    set_numbers = BO_SO_DE.get(set_name, [])
                    if display_mode:
                        return f"B·ªô {set_name}"
                    if return_string:
                        return ",".join(set_numbers)
                    else:
                        return set_numbers
                else:
                    return [] if not return_string else ""
            
            # T√≠nh c√°c ch·∫°m
            touches = []
            if mode == "DYNAMIC":
                 touches = get_touches_by_offset(base_sum, k_offset) 
            else:
                 touches = [base_sum, (base_sum+5)%10]
            
            if display_mode:
                t_str = ", ".join(map(str, sorted(list(set(touches)))))
                return t_str
            
            final_dan = generate_dan_de_from_touches(touches)
            return ",".join(final_dan) if return_string else final_dan

        except: return [] if not return_string else ""

de_manager = DeBridgeManager()

def find_and_auto_manage_bridges_de(all_data_ai, db_name=DB_NAME):
    from logic.bridges.de_bridge_scanner import run_de_scanner
    count, _ = run_de_scanner(all_data_ai)
    return f"ƒê√£ c·∫≠p nh·∫≠t {count} c·∫ßu ƒê·ªÅ."


--------------------------------------------------

=== FILE: logic\bridges\de_bridge_scanner.py ===
# T√™n file: logic/bridges/de_bridge_scanner.py
# (PHI√äN B·∫¢N V11.3 - CLEAN CODE REFACTOR)
# Update: T√°ch logic t√≠nh to√°n Streak/Rate ra method ri√™ng (DRY Principle).
# Fix: Logic t√≠nh streak d·ª´ng ngay khi g·∫∑p g√£y (Strict Mode).

import sqlite3
from collections import Counter
from typing import List, Dict, Any, Optional, Tuple, Set

# Fallback imports
try:
    from logic.db_manager import DB_NAME, get_all_managed_bridge_names, load_rates_cache
    from logic.bridges.bridges_v16 import getAllPositions_V17_Shadow, getPositionName_V17_Shadow
    from logic.common_utils import normalize_bridge_name, calculate_strict_performance # <--- Th√™m h√†m n√†y
    from logic.de_utils import (
        get_gdb_last_2, check_cham, get_touches_by_offset, 
        generate_dan_de_from_touches, get_set_name_of_number, BO_SO_DE
    )
    from logic.models import Candidate
    from logic.common_utils import normalize_bridge_name
except ImportError:
    DB_NAME = "lottery.db"
    pass 

class DeBridgeScanner:
    """
    B·ªô qu√©t c·∫ßu ƒê·ªÅ t·ª± ƒë·ªông (Automated DE Bridge Scanner)
    Phi√™n b·∫£n: V11.3 (Clean Code Refactor)
    Chi·∫øn thu·∫≠t: S·ª≠ d·ª•ng Ma tr·∫≠n s·ªë nguy√™n (Integer Matrix) ƒë·ªÉ lo·∫°i b·ªè chi ph√≠ x·ª≠ l√Ω chu·ªói.
    """

    def __init__(self):
        # [CONFIGURATION]
        self.min_streak = 3        # C·∫ßu L√¥/V·ªã tr√≠
        self.min_streak_bo = 1     # C·∫ßu B·ªô
        self.scan_depth = 30       # S·ªë k·ª≥ qu√©t (Short-term)
        self.memory_depth = 90     # S·ªë k·ª≥ qu√©t B·∫°c Nh·ªõ (Long-term)
        
        self.history_check_len = 10 
        self.min_wins_required = 4  
        self.validation_len = 15   
        self.min_val_wins = 2      
        
        # C·∫•u h√¨nh Killer & Memory
        self.min_killer_streak = 12 
        self.min_memory_confidence = 60.0 

        # C·ª©u C·∫ßu
        self.rescue_wins_10 = 7    
        self.min_wins_bo_10 = 2    

    def _preprocess_data(self, all_data_ai: List[List[str]]) -> List[List[Optional[int]]]:
        """
        [OPTIMIZATION CORE] Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu th√¥ sang ma tr·∫≠n s·ªë nguy√™n 1 l·∫ßn duy nh·∫•t.
        Tr·∫£ v·ªÅ: List c√°c h√†ng, m·ªói h√†ng l√† list 214 s·ªë nguy√™n (v·ªã tr√≠ V17).
        """
        matrix = []
        for row in all_data_ai:
            try:
                # D√πng h√†m V17 ƒë·ªÉ l·∫•y 214 v·ªã tr√≠ (bao g·ªìm b√≥ng)
                # H√†m n√†y tr·∫£ v·ªÅ list c√°c s·ªë nguy√™n ho·∫∑c None
                positions = getAllPositions_V17_Shadow(row)
                matrix.append(positions)
            except:
                matrix.append([None] * 214) # Fallback n·∫øu l·ªói
        return matrix

    # def _calculate_performance_metrics(self, results_recent_to_past: List[bool]) -> Dict[str, Any]:
    #     """
    #     [CLEAN CODE HELPER] T√≠nh to√°n c√°c ch·ªâ s·ªë hi·ªáu su·∫•t t·ª´ danh s√°ch k·∫øt qu·∫£.
    #     Input: List bool [H√¥m nay, H√¥m qua, H√¥m kia...] (M·ªõi -> C≈©)
    #     Output: Dict ch·ª©a streak, total_wins, win_rate, wins_10
    #     """
    #     streak = 0
    #     total_wins = 0
    #     is_broken = False
        
    #     # T√≠nh to√°n tr√™n to√†n b·ªô danh s√°ch (m·∫∑c ƒë·ªãnh l√† scan_depth = 30)
    #     total_days = len(results_recent_to_past)
        
    #     for idx, is_win in enumerate(results_recent_to_past):
    #         if is_win:
    #             total_wins += 1
    #             if not is_broken:
    #                 streak += 1
    #         else:
    #             is_broken = True
        
    #     # T√≠nh wins trong 10 ng√†y g·∫ßn nh·∫•t
    #     wins_10 = sum(1 for x in results_recent_to_past[:10] if x)
        
    #     win_rate = (total_wins / total_days * 100) if total_days > 0 else 0.0
        
    #     return {
    #         "streak": streak,
    #         "total_wins": total_wins,
    #         "win_rate": win_rate,
    #         "wins_10": wins_10,
    #         "total_days": total_days
    #     }

    def scan_all(
        self, 
        all_data_ai: List[List[str]], 
        db_name: str = DB_NAME
    ) -> Tuple[List[Candidate], Dict[str, Any]]:
        """
        Scan for DE bridges and return Candidate objects (READ-ONLY, no DB writes).
        """
        if not self._validate_input_data(all_data_ai):
            return [], {'found_total': 0, 'excluded_existing': 0, 'returned_count': 0}

        print(f">>> [DE SCANNER V11.3] B·∫Øt ƒë·∫ßu qu√©t (Clean Code & Strict Streak)...")
        
        # 1. [OPTIMIZATION] Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu sang d·∫°ng s·ªë
        data_matrix = self._preprocess_data(all_data_ai)
        
        found_bridges: List[Dict[str, Any]] = []

        # 2. CHI·∫æN THU·∫¨T TO√ÅN H·ªåC (S·ª≠ d·ª•ng data_matrix)
        found_bridges.extend(self._scan_dynamic_offset(all_data_ai, data_matrix))
        found_bridges.extend(self._scan_algorithm_sum(all_data_ai, data_matrix))
        found_bridges.extend(self._scan_set_bridges(all_data_ai, data_matrix))
        found_bridges.extend(self._scan_pascal_topology(all_data_ai))

        # 3. CHI·∫æN THU·∫¨T KHAI PH√Å D·ªÆ LI·ªÜU (DATA MINING)
        bridges_memory = self._scan_memory_pattern(all_data_ai)
        print(f">>> [DE SCANNER] B·∫°c Nh·ªõ t√¨m th·∫•y: {len(bridges_memory)}")
        found_bridges.extend(bridges_memory)

        # 4. CHI·∫æN THU·∫¨T LO·∫†I TR·ª™ (KILLER) (S·ª≠ d·ª•ng data_matrix)
        bridges_killer = self._scan_killer_bridges(all_data_ai, data_matrix)
        print(f">>> [DE SCANNER] C·∫ßu Lo·∫°i t√¨m th·∫•y: {len(bridges_killer)}")
        found_bridges.extend(bridges_killer)

        # 5. RANK AND CONVERT TO CANDIDATES (NO DB WRITE)
        self._rank_bridges(found_bridges)
        found_total = len(found_bridges)
        
        # 6. LOAD EXISTING NAMES AND RATES CACHE (SINGLE DB CALL EACH)
        print(f">>> [DE SCANNER] Loading existing bridges and rates cache...")
        existing_names = get_all_managed_bridge_names(db_name)
        rates_cache = load_rates_cache(db_name)
        
        # 7. CONVERT TO CANDIDATES WITH RATES AND EXCLUDE EXISTING
        candidates = self._convert_to_candidates(found_bridges, existing_names, rates_cache)
        excluded_count = found_total - len(candidates)
        
        meta = {
            'found_total': found_total,
            'excluded_existing': excluded_count,
            'returned_count': len(candidates)
        }
        
        print(f">>> [DE SCANNER] K·∫øt qu·∫£: {found_total} t√¨m th·∫•y, {excluded_count} ƒë√£ t·ªìn t·∫°i, {len(candidates)} tr·∫£ v·ªÅ.")
        return candidates, meta

    # --- CORE HELPERS ---

    def _validate_input_data(self, data: List[List[str]]) -> bool:
        required_len = self.scan_depth + self.validation_len
        if not data or len(data) < required_len:
            if data and len(data) >= self.scan_depth:
                self.validation_len = 0 
                return True
            return False
        return True

    def _clean_str(self, raw_val) -> str:
        if not raw_val: return ""
        return ''.join(filter(str.isdigit, str(raw_val)))

    def _calculate_ranking_score(self, streak: int, wins_10: int, bridge_type: str) -> float:
        type_bonus = 0.0
        if bridge_type == 'DE_SET': type_bonus = 2.0
        elif bridge_type == 'DE_PASCAL': type_bonus = 1.0
        elif bridge_type == 'DE_MEMORY': return 15.0 + (wins_10 / 2)
        elif bridge_type == 'DE_KILLER': return streak * 2.0

        stability_bonus = 1.5 if wins_10 >= 8 else 0.0
        return (streak * 1.5) + (wins_10 * 1.0) + type_bonus + stability_bonus

    def _rank_bridges(self, bridges: List[Dict[str, Any]]) -> None:
        for b in bridges:
            streak = b.get('streak', 0)
            try:
                wr = float(b.get('win_rate', 0))
                wins_10 = int((wr / 100.0) * 10)
            except (ValueError, TypeError):
                wins_10 = 0
            b['ranking_score'] = self._calculate_ranking_score(streak, wins_10, b.get('type', ''))
        bridges.sort(key=lambda x: x['ranking_score'], reverse=True)
    
    def _convert_to_candidates(
        self, 
        bridges: List[Dict[str, Any]], 
        existing_names: Set[str],
        rates_cache: Dict[str, Dict[str, float]]
    ) -> List[Candidate]:
        """Convert bridge dicts to Candidate objects with K1N/K2N rates attached."""
        candidates = []
        
        for b in bridges:
            name = b.get('name', '')
            if not name:
                continue
            
            # Normalize name for duplicate checking
            norm_name = normalize_bridge_name(name)
            
            # Skip if already exists
            if norm_name in existing_names:
                continue
            
            # Get rates from cache
            rates = rates_cache.get(norm_name, {})
            k1n_lo = rates.get('k1n_rate_lo', 0.0)
            k1n_de = rates.get('k1n_rate_de', 0.0)
            k2n_lo = rates.get('k2n_rate_lo', 0.0)
            k2n_de = rates.get('k2n_rate_de', 0.0)
            
            # Set rate_missing flag if no rates found
            rate_missing = (k1n_de == 0.0 and k2n_de == 0.0)
            
            # Build description
            desc = b.get('display_desc', '')
            full_dan = b.get('full_dan', '')
            final_desc = f"{desc}. D√†n: {full_dan}" if full_dan else desc
            streak = b.get('streak', 0)
            final_desc += f". Th√¥ng {streak} k·ª≥."
            
            # Determine kind (single vs set)
            bridge_type = b.get('type', '')
            kind = 'set' if bridge_type == 'DE_SET' else 'single'
            
            # Calculate win_count_10 from win_rate
            try:
                wr = float(b.get('win_rate', 0))
                win_count_10 = int((wr / 100.0) * 10)
            except (ValueError, TypeError):
                win_count_10 = 0
            
            # Create Candidate object
            candidate = Candidate(
                name=name,
                normalized_name=norm_name,
                type='de',
                kind=kind,
                k1n_lo=k1n_lo,
                k1n_de=k1n_de,
                k2n_lo=k2n_lo,
                k2n_de=k2n_de,
                stl=b.get('predicted_value', 'N/A'),
                reason=bridge_type,
                pos1_idx=b.get('pos1_idx'),
                pos2_idx=b.get('pos2_idx'),
                description=final_desc,
                streak=streak,
                win_count_10=win_count_10,
                rate_missing=rate_missing,
                metadata={
                    'win_rate': b.get('win_rate', 0.0),
                    'full_dan': full_dan,
                    'ranking_score': b.get('ranking_score', 0.0)
                }
            )
            
            candidates.append(candidate)
        
        return candidates

    def _validate_bridge(self, all_data_ai, data_matrix, idx1, idx2, k_param, mode) -> bool:
        """
        H√†m validate s·ª≠ d·ª•ng data_matrix ƒë·ªÉ tƒÉng t·ªëc.
        """
        if self.validation_len <= 0: return True
        start_idx = len(all_data_ai) - self.scan_depth - self.validation_len
        end_idx = len(all_data_ai) - self.scan_depth
        if start_idx < 1: return True

        val_wins = 0
        scan_slice_indices = range(start_idx, end_idx)
        
        for real_idx in scan_slice_indices:
            row_curr = all_data_ai[real_idx] 
            row_prev_vals = data_matrix[real_idx - 1] 
            
            gdb = get_gdb_last_2(row_curr)
            if not gdb: continue
            
            try:
                is_win = False
                v1 = row_prev_vals[idx1]
                v2 = row_prev_vals[idx2] if idx2 is not None else None
                
                if v1 is None or (idx2 is not None and v2 is None): continue
                
                if mode == "DYNAMIC":
                    touches = get_touches_by_offset((v1 + v2) % 10, k_param)
                    is_win = check_cham(gdb, touches)
                elif mode == "DE_POS_SUM":
                    pred = (v1 + v2) % 10
                    is_win = check_cham(gdb, [pred])
                elif mode == "SET":
                    s_name = get_set_name_of_number(f"{v1}{v2}")
                    if s_name:
                        is_win = gdb in BO_SO_DE.get(s_name, [])
                if is_win: val_wins += 1
            except Exception: continue
            
        return val_wins >= self.min_val_wins

    # =========================================================================
    # MODULE 1: B·∫†C NH·ªö (Gi·ªØ nguy√™n v√¨ logic kh√°c bi·ªát)
    # =========================================================================
    
    def _scan_memory_pattern(self, all_data_ai: List[List[str]]) -> List[Dict[str, Any]]:
        results = []
        mining_depth = min(len(all_data_ai) - 1, self.memory_depth)
        mining_data = all_data_ai[-mining_depth:]
        
        triggers = [
            (2, "GDB_Tail", "ƒêu√¥i ƒêB"), 
            (2, "GDB_Head", "ƒê·∫ßu ƒêB"),
            (3, "G1_Tail", "ƒêu√¥i G1"),
        ]

        last_row = all_data_ai[-1]

        for col_idx, trigger_code, trigger_name in triggers:
            current_signal = self._get_signal_value(last_row, col_idx, trigger_code)
            if current_signal is None: continue

            matching_next_days_gdb = []
            
            for k in range(len(mining_data) - 2):
                row_k = mining_data[k]
                hist_signal = self._get_signal_value(row_k, col_idx, trigger_code)
                
                if hist_signal == current_signal:
                    row_next = mining_data[k+1]
                    gdb_next = get_gdb_last_2(row_next)
                    if gdb_next:
                        matching_next_days_gdb.append(gdb_next)

            if len(matching_next_days_gdb) < 5: continue

            touch_counts = Counter()
            for gdb in matching_next_days_gdb:
                if len(gdb) == 2:
                    touch_counts[int(gdb[0])] += 1
                    touch_counts[int(gdb[1])] += 1
            
            total_matches = len(matching_next_days_gdb)
            if total_matches == 0: continue
            
            best_touch, count = touch_counts.most_common(1)[0]
            confidence = (count / total_matches) * 100

            if confidence >= self.min_memory_confidence:
                touches = [best_touch]
                final_dan = generate_dan_de_from_touches(touches)
                
                results.append({
                    "name": f"DE_MEM_{trigger_code}_{current_signal}",
                    "type": "DE_MEMORY",
                    "streak": int(confidence),
                    "predicted_value": f"CH·∫†M {best_touch}",
                    "full_dan": ",".join(final_dan),
                    "win_rate": confidence,
                    "display_desc": f"B·∫°c nh·ªõ: Khi {trigger_name} v·ªÅ {current_signal} -> Hay v·ªÅ Ch·∫°m {best_touch} ({count}/{total_matches} l·∫ßn)"
                })
        return results

    def _get_signal_value(self, row: List[str], col_idx: int, code: str) -> Optional[int]:
        try:
            val_str = self._clean_str(row[col_idx])
            if not val_str: return None
            
            if "Tail" in code:
                return int(val_str[-1])
            elif "Head" in code:
                if len(val_str) >= 2:
                    return int(val_str[0])
            return None
        except:
            return None

    # =========================================================================
    # MODULE 2: C·∫¶U LO·∫†I (KILLER) - OPTIMIZED SCAN
    # =========================================================================

    def _scan_killer_bridges(self, all_data_ai: List[List[str]], data_matrix: List[List[Optional[int]]]) -> List[Dict[str, Any]]:
        results = []
        try:
            limit_pos = 117
            scan_end_idx = len(all_data_ai)
            
            for i in range(limit_pos):
                for j in range(i, limit_pos):
                    killer_streak = 0
                    # Qu√©t ng∆∞·ª£c t·ª´ g·∫ßn nh·∫•t v·ªÅ qu√° kh·ª©
                    for k in range(scan_end_idx - 1, 0, -1):
                        if scan_end_idx - k > self.scan_depth: break
                        
                        gdb = get_gdb_last_2(all_data_ai[k])
                        row_prev_vals = data_matrix[k-1]
                        
                        v1, v2 = row_prev_vals[i], row_prev_vals[j]
                        if not gdb or v1 is None or v2 is None: break
                        
                        pred_touch = (v1 + v2) % 10
                        has_touch = check_cham(gdb, [pred_touch])
                        
                        # C·∫ßu lo·∫°i c·∫ßn "KH√îNG ch·∫°m", n·∫øu c√≥ ch·∫°m l√† G√ÉY
                        if not has_touch: 
                            killer_streak += 1
                        else: 
                            break # STRICT BREAK

                    if killer_streak >= self.min_killer_streak:
                        curr_vals = data_matrix[-1]
                        v1, v2 = curr_vals[i], curr_vals[j]
                        
                        if v1 is not None and v2 is not None:
                            next_killer_touch = (v1 + v2) % 10
                            p1_n = getPositionName_V17_Shadow(i).replace('[', '.').replace(']', '')
                            p2_n = getPositionName_V17_Shadow(j).replace('[', '.').replace(']', '')
                            
                            results.append({
                                "name": f"DE_KILLER_{p1_n}_{p2_n}",
                                "type": "DE_KILLER",
                                "streak": killer_streak,
                                "predicted_value": f"LO·∫†I CH·∫†M {next_killer_touch}",
                                "full_dan": "",
                                "win_rate": 0,
                                "display_desc": f"LO·∫†I Ch·∫°m {next_killer_touch} (Th√¥ng {killer_streak} k·ª≥). T·ª´: {p1_n}+{p2_n}",
                                "pos1_idx": i,
                                "pos2_idx": j
                            })
        except Exception as e:
            print(f">>> [ERROR] L·ªói qu√©t C·∫ßu Lo·∫°i: {e}")
        
        results.sort(key=lambda x: x['streak'], reverse=True)
        return results[:15]

    # =========================================================================
    # MODULE 3: C·∫¶U PASCAL
    # =========================================================================

    def _scan_pascal_topology(self, all_data_ai: List[List[str]]) -> List[Dict[str, Any]]:
        results = []
        scan_data = all_data_ai[-self.scan_depth:]
        sources = [
            {"name": "GDB", "cols": [2]},
            {"name": "G1", "cols": [3]},
            {"name": "GDB_G1", "cols": [2, 3]}
        ]

        for src in sources:
            # 1. Qu√©t t√¨m c·∫ßu ti·ªÅm nƒÉng (Strict Streak)
            consecutive_streak = 0
            wins_10 = 0
            
            for k in range(len(scan_data) - 1, 0, -1):
                row_curr = scan_data[k]
                row_prev = scan_data[k-1]
                gdb = get_gdb_last_2(row_curr)
                if not gdb: break
                
                input_digits = []
                valid_input = True
                for col_idx in src["cols"]:
                    val_str = self._clean_str(row_prev[col_idx])
                    if not val_str: valid_input = False; break
                    input_digits.extend([int(d) for d in val_str])
                
                if not valid_input or len(input_digits) < 2: continue
                
                final_pair = self._compute_pascal_reduction(input_digits)
                if final_pair is None: continue
                
                pred_val = f"{final_pair[0]}{final_pair[1]}"
                rev_val = f"{final_pair[1]}{final_pair[0]}"
                is_win = (gdb == pred_val or gdb == rev_val)
                days_ago = len(scan_data) - 1 - k
                
                if is_win:
                    if consecutive_streak == days_ago: consecutive_streak += 1
                    if days_ago < self.history_check_len: wins_10 += 1
                else:
                    if consecutive_streak > 0: break # STRICT BREAK
            
            if consecutive_streak >= self.min_streak or wins_10 >= self.rescue_wins_10:
                # 2. Thu th·∫≠p k·∫øt qu·∫£ v√† d√πng Helper ƒë·ªÉ t√≠nh Metrics
                results_bool = [] # M·ªõi -> C≈©
                
                for k in range(len(scan_data) - 1, 0, -1):
                    row_curr = scan_data[k]
                    row_prev = scan_data[k-1]
                    gdb = get_gdb_last_2(row_curr)
                    if not gdb: continue
                    
                    input_digits = []
                    valid_input = True
                    for col_idx in src["cols"]:
                        val_str = self._clean_str(row_prev[col_idx])
                        if not val_str: valid_input = False; break
                        input_digits.extend([int(d) for d in val_str])
                    
                    if not valid_input or len(input_digits) < 2: continue
                    final_pair = self._compute_pascal_reduction(input_digits)
                    if final_pair is None: continue
                    
                    pred_val = f"{final_pair[0]}{final_pair[1]}"
                    rev_val = f"{final_pair[1]}{final_pair[0]}"
                    is_win = (gdb == pred_val or gdb == rev_val)
                    results_bool.append(is_win)

                # S·ª≠ d·ª•ng Helper Function
                metrics = calculate_strict_performance(results_bool)

                last_row = all_data_ai[-1]
                next_input = []
                for col_idx in src["cols"]:
                    v = self._clean_str(last_row[col_idx])
                    if v: next_input.extend([int(d) for d in v])
                next_pair = self._compute_pascal_reduction(next_input)
                if next_pair:
                    val_str = f"{next_pair[0]}{next_pair[1]}"
                    rev_str = f"{next_pair[1]}{next_pair[0]}"
                    display_val = f"{val_str},{rev_str}" if val_str != rev_str else val_str
                    results.append({
                        "name": f"DE_PASCAL_{src['name']}",
                        "type": "DE_PASCAL",
                        "streak": metrics["streak"],
                        "predicted_value": display_val,
                        "full_dan": display_val,
                        "win_rate": metrics["win_rate"],
                        "display_desc": f"C·∫ßu Pascal ({src['name']}) - STL: {display_val}"
                    })
        return results

    def _compute_pascal_reduction(self, digits: List[int]) -> Optional[Tuple[int, int]]:
        current_layer = digits
        while len(current_layer) > 2:
            next_layer = []
            for i in range(len(current_layer) - 1):
                sum_val = (current_layer[i] + current_layer[i+1]) % 10
                next_layer.append(sum_val)
            current_layer = next_layer
        if len(current_layer) == 2:
            return (current_layer[0], current_layer[1])
        return None

    # =========================================================================
    # MODULE 4: DYNAMIC & SUM (CLASSIC) - OPTIMIZED SCAN
    # =========================================================================

    def _scan_dynamic_offset(self, all_data_ai: List[List[str]], data_matrix: List[List[Optional[int]]]) -> List[Dict[str, Any]]:
        results = []
        scan_len = len(all_data_ai)
        
        last_row_vals = data_matrix[-1]
        num_cols = 117
        
        pairs = []
        for i in range(num_cols):
            for j in range(i + 1, num_cols):
                pairs.append((i, j))
        
        for idx1, idx2 in pairs:
            val1_last = last_row_vals[idx1]
            val2_last = last_row_vals[idx2]
            if val1_last is None or val2_last is None: continue
            
            for k in range(10): 
                # 1. Validation nhanh (10 k·ª≥ g·∫ßn nh·∫•t)
                total_wins_check = 0
                valid_history = True
                
                for day_idx in range(scan_len - 1, scan_len - 1 - self.history_check_len, -1):
                    if day_idx < 1: break
                    gdb_today = get_gdb_last_2(all_data_ai[day_idx])
                    if not gdb_today: continue
                    
                    row_prev_vals = data_matrix[day_idx-1]
                    d1, d2 = row_prev_vals[idx1], row_prev_vals[idx2]
                    
                    if d1 is None or d2 is None: 
                        valid_history = False; break
                    
                    base_sum = (d1 + d2) % 10
                    touches = get_touches_by_offset(base_sum, k)
                    if check_cham(gdb_today, touches): total_wins_check += 1
                
                if not valid_history: continue
                
                # 2. N·∫øu ƒë·∫°t chu·∫©n, thu th·∫≠p k·∫øt qu·∫£ v√† t√≠nh to√°n (30 ng√†y)
                if total_wins_check >= self.min_wins_required:
                    if self._validate_bridge(all_data_ai, data_matrix, idx1, idx2, k, "DYNAMIC"):
                        
                        results_bool = [] # M·ªõi -> C≈©

                        for day_idx in range(scan_len - 1, max(0, scan_len - 1 - self.scan_depth), -1):
                            if day_idx < 1: break
                            gdb_today = get_gdb_last_2(all_data_ai[day_idx])
                            if not gdb_today: continue
                            
                            row_prev_vals = data_matrix[day_idx-1]
                            d1, d2 = row_prev_vals[idx1], row_prev_vals[idx2]
                            if d1 is None or d2 is None: continue
                            
                            base_sum = (d1 + d2) % 10
                            touches = get_touches_by_offset(base_sum, k)
                            results_bool.append(check_cham(gdb_today, touches))

                        # S·ª≠ d·ª•ng Helper Function
                        metrics = calculate_strict_performance(results_bool)

                        base_last = (val1_last + val2_last) % 10
                        final_touches = get_touches_by_offset(base_last, k)
                        final_dan = generate_dan_de_from_touches(final_touches)
                        
                        name1 = getPositionName_V17_Shadow(idx1).replace('[', '.').replace(']', '')
                        name2 = getPositionName_V17_Shadow(idx2).replace('[', '.').replace(']', '')
                        
                        results.append({
                            "name": f"DE_DYN_{name1}_{name2}_K{k}",
                            "type": "DE_DYNAMIC_K",
                            "streak": metrics["streak"],
                            "predicted_value": ",".join(map(str, final_touches)),
                            "full_dan": ",".join(final_dan),
                            "win_rate": metrics["win_rate"],
                            "display_desc": f"ƒêu√¥i {name1} + ƒêu√¥i {name2} (K={k})",
                            "pos1_idx": idx1,
                            "pos2_idx": idx2,
                            "k_offset": k
                        })
        return results

    def _scan_algorithm_sum(self, all_data_ai: List[List[str]], data_matrix: List[List[Optional[int]]]) -> List[Dict[str, Any]]:
        results = []
        try:
            limit_pos = 117
            scan_len = len(all_data_ai)
            
            for i in range(limit_pos):
                for j in range(i, limit_pos):
                    # 1. Qu√©t s∆° b·ªô t√¨m ·ª©ng vi√™n
                    consecutive_streak = 0
                    wins_10 = 0
                    
                    for k in range(scan_len - 1, 0, -1):
                        if scan_len - k > self.scan_depth: break
                        
                        gdb = get_gdb_last_2(all_data_ai[k])
                        row_prev_vals = data_matrix[k-1]
                        v1, v2 = row_prev_vals[i], row_prev_vals[j]
                        if not gdb or v1 is None or v2 is None: break
                        
                        pred = (v1 + v2) % 10
                        is_win = check_cham(gdb, [pred])
                        days_ago = scan_len - 1 - k
                        
                        if is_win:
                            if consecutive_streak == days_ago: consecutive_streak += 1 
                            if days_ago < self.history_check_len: wins_10 += 1
                        else:
                            if consecutive_streak > 0: break 
                    
                    # 2. N·∫øu ƒë·∫°t chu·∫©n, thu th·∫≠p k·∫øt qu·∫£ v√† t√≠nh to√°n
                    if consecutive_streak >= self.min_streak or wins_10 >= self.rescue_wins_10:
                        if self._validate_bridge(all_data_ai, data_matrix, i, j, 0, "DE_POS_SUM"):
                            
                            results_bool = [] # M·ªõi -> C≈©

                            for k in range(scan_len - 1, max(0, scan_len - 1 - self.scan_depth), -1):
                                if k < 1: break
                                gdb = get_gdb_last_2(all_data_ai[k])
                                if not gdb: continue
                                
                                row_prev_vals = data_matrix[k-1]
                                v1, v2 = row_prev_vals[i], row_prev_vals[j]
                                if v1 is None or v2 is None: continue
                                
                                pred = (v1 + v2) % 10
                                results_bool.append(check_cham(gdb, [pred]))

                            # S·ª≠ d·ª•ng Helper Function
                            metrics = calculate_strict_performance(results_bool)
                            
                            curr_vals = data_matrix[-1]
                            v1, v2 = curr_vals[i], curr_vals[j]
                            next_val = (v1 + v2) % 10
                            
                            p1_name = getPositionName_V17_Shadow(i).replace('[', '.').replace(']', '')
                            p2_name = getPositionName_V17_Shadow(j).replace('[', '.').replace(']', '')
                            note = f" (C·ª©u: {wins_10}/10)" if consecutive_streak < self.min_streak else ""
                            
                            results.append({
                                "name": f"DE_POS_{p1_name}_{p2_name}",
                                "type": "DE_POS_SUM",
                                "streak": metrics["streak"],
                                "predicted_value": str(next_val),
                                "full_dan": "",
                                "win_rate": metrics["win_rate"],
                                "display_desc": f"T·ªïng v·ªã tr√≠: {p1_name} + {p2_name}{note}",
                                "pos1_idx": i,
                                "pos2_idx": j
                            })
        except Exception as e:
            print(f">>> [ERROR] L·ªói qu√©t c·∫ßu s·ªë h·ªçc: {e}")
        return results

    def _scan_set_bridges(self, all_data_ai: List[List[str]], data_matrix: List[List[Optional[int]]]) -> List[Dict[str, Any]]:
        results = []
        try:
            limit_pos = 117
            scan_len = len(all_data_ai)
            
            for i in range(limit_pos):
                for j in range(i + 1, limit_pos):
                    # 1. Qu√©t s∆° b·ªô
                    consecutive_streak = 0
                    wins_10 = 0
                    for k in range(scan_len - 1, 0, -1):
                        if scan_len - k > self.scan_depth: break
                        
                        gdb = get_gdb_last_2(all_data_ai[k])
                        row_prev_vals = data_matrix[k-1]
                        v1, v2 = row_prev_vals[i], row_prev_vals[j]
                        if not gdb or v1 is None or v2 is None: break
                        
                        set_name = get_set_name_of_number(f"{v1}{v2}")
                        if not set_name: break
                        set_nums = BO_SO_DE.get(set_name, [])
                        if not set_nums: break
                        
                        is_win = gdb in set_nums
                        days_ago = scan_len - 1 - k
                        
                        if is_win:
                            if consecutive_streak == days_ago: consecutive_streak += 1
                            if days_ago < self.history_check_len: wins_10 += 1
                        else:
                            if consecutive_streak > 0: break 
                            
                    if consecutive_streak >= self.min_streak_bo and wins_10 >= self.min_wins_bo_10:
                        if self._validate_bridge(all_data_ai, data_matrix, i, j, 0, "SET"):
                            
                            results_bool = [] # M·ªõi -> C≈©

                            for k in range(scan_len - 1, max(0, scan_len - 1 - self.scan_depth), -1):
                                if k < 1: break
                                gdb = get_gdb_last_2(all_data_ai[k])
                                if not gdb: continue
                                
                                row_prev_vals = data_matrix[k-1]
                                v1, v2 = row_prev_vals[i], row_prev_vals[j]
                                if v1 is None or v2 is None: continue
                                
                                set_name = get_set_name_of_number(f"{v1}{v2}")
                                if not set_name: continue
                                set_nums = BO_SO_DE.get(set_name, [])
                                if not set_nums: continue
                                
                                results_bool.append(gdb in set_nums)

                            # S·ª≠ d·ª•ng Helper Function
                            metrics = calculate_strict_performance(results_bool)
                            
                            curr_vals = data_matrix[-1]
                            v1_curr, v2_curr = curr_vals[i], curr_vals[j]
                            pred_set_name = get_set_name_of_number(f"{v1_curr}{v2_curr}")
                            
                            if pred_set_name:
                                p1_n = getPositionName_V17_Shadow(i).replace('[', '.').replace(']', '')
                                p2_n = getPositionName_V17_Shadow(j).replace('[', '.').replace(']', '')
                                results.append({
                                    "name": f"DE_SET_{p1_n}_{p2_n}",
                                    "type": "DE_SET",
                                    "streak": metrics["streak"],
                                    "predicted_value": pred_set_name,
                                    "full_dan": ",".join(BO_SO_DE.get(pred_set_name, [])),
                                    "win_rate": metrics["win_rate"],
                                    "display_desc": f"B·ªô: {p1_n} + {p2_n} (B·ªô {pred_set_name})",
                                    "pos1_idx": i,
                                    "pos2_idx": j
                                })
        except Exception as e:
            print(f">>> [ERROR] L·ªói qu√©t c·∫ßu b·ªô: {e}")
        return results

    def _get_standard_prize_name(self, idx: int, total_cols: int) -> str:
        if total_cols <= 11:
            mapping = {2: "GDB", 3: "G1", 4: "G2", 5: "G3", 6: "G4", 7: "G5", 8: "G6", 9: "G7"}
            return mapping.get(idx, f"C{idx}")
        return getPositionName_V17_Shadow(idx).replace('[', '.').replace(']', '')

def run_de_scanner(data, db_name=DB_NAME):
    """
    V11.2 K1N-Primary: Returns (candidates, meta) instead of (count, bridges).
    """
    return DeBridgeScanner().scan_all(data, db_name)

--------------------------------------------------

=== FILE: logic\bridges\de_performance.py ===
# logic/bridges/de_performance.py
"""
DE Performance Evaluator (Auto-Detection Enhanced)

Pure functions for evaluating DE bridge visibility and performance.
No database writes - evaluation only.

Features:
- Auto-detects dynamic bridge variants (DE_DYN, DE_DYNAMIC, etc.)
- Evaluates visibility with manual override, auto flags, and hysteresis
- No side effects, no DB access

Usage:
    from logic.bridges.de_performance import evaluate_de_visibility
    
    visible, reason, needs_eval = evaluate_de_visibility(bridge, thresholds)
"""


def is_dynamic_bridge_type(bridge_type):
    """
    Check if a bridge type is a dynamic variant.
    
    Matches patterns like:
    - DE_DYN
    - DE_DYNAMIC
    - DE_DYNAMIC_K
    - DE_DYNAMIC-*
    - etc.
    
    Args:
        bridge_type: String bridge type (case-insensitive)
    
    Returns:
        bool: True if dynamic type, False otherwise
    """
    if not bridge_type:
        return False
    
    bridge_type_upper = bridge_type.upper()
    
    # Match DE_DYN* or DE_DYNAMIC*
    return (
        bridge_type_upper.startswith('DE_DYN') or
        bridge_type_upper.startswith('DE_DYNAMIC')
    )


def evaluate_de_visibility(bridge, thresholds=None):
    """
    Evaluate if a dynamic DE bridge should be visible based on performance metrics.
    
    Auto-detects dynamic bridge variants (DE_DYN, DE_DYNAMIC, etc.)
    
    Implements the visibility policy with precedence:
    1. Manual override (de_manual_override == 1): use de_manual_override_value
    2. Auto enabled (de_auto_enabled == 1): show
    3. Computed metrics with hysteresis: check de_win_count_last30
    
    Args:
        bridge: Bridge dict with metrics from DB
        thresholds: Optional dict with 'enable', 'disable', 'window' keys
                   If None, uses defaults: enable=28, disable=26, window=30
    
    Returns:
        tuple: (visible: bool, reason: str, needs_evaluation: bool)
        
    Examples:
        >>> bridge = {"type": "DE_DYN", "de_manual_override": 1, "de_manual_override_value": 1}
        >>> visible, reason, needs_eval = evaluate_de_visibility(bridge)
        >>> print(visible, reason)
        True "manual override (value=1)"
        
        >>> bridge = {"type": "DE_DYNAMIC", "de_auto_enabled": 1, "de_win_count_last30": 20}
        >>> visible, reason, needs_eval = evaluate_de_visibility(bridge)
        >>> print(visible)
        True
        
        >>> bridge = {"type": "DE_DYN", "de_win_count_last30": 28, "de_auto_enabled": 0}
        >>> visible, reason, needs_eval = evaluate_de_visibility(bridge)
        >>> print(visible)
        True
    """
    # Load thresholds
    if thresholds is None:
        thresholds = {
            "enable": 28,
            "disable": 26,
            "window": 30
        }
    
    enable_threshold = thresholds.get("enable", 28)
    disable_threshold = thresholds.get("disable", 26)
    window = thresholds.get("window", 30)
    
    bridge_name = bridge.get("name", "N/A")
    bridge_type = bridge.get("type", "")
    
    # Check if this is a dynamic bridge (auto-detect variants)
    if not is_dynamic_bridge_type(bridge_type):
        # Non-dynamic bridges don't use this visibility logic
        return True, f"non-dynamic type ({bridge_type}), always visible", False
    
    # Priority 1: Manual override
    de_manual_override = bridge.get("de_manual_override", 0)
    if de_manual_override == 1:
        de_manual_override_value = bridge.get("de_manual_override_value", 0)
        visible = bool(de_manual_override_value)
        reason = f"manual override (value={de_manual_override_value})"
        return visible, reason, False
    
    # Priority 2: Auto enabled flag
    de_auto_enabled = bridge.get("de_auto_enabled", 0)
    if de_auto_enabled == 1:
        return True, "auto flag true", False
    
    # Priority 3: Computed metrics with hysteresis
    de_win_count_last30 = bridge.get("de_win_count_last30")
    
    if de_win_count_last30 is None:
        # Try legacy fields as fallback
        current_streak = bridge.get("current_streak")
        streak = bridge.get("streak")
        
        if current_streak is not None:
            wins_last30 = int(current_streak) if current_streak <= window else int((current_streak / 100.0) * window)
        elif streak is not None:
            wins_last30 = int(streak) if streak <= window else int((streak / 100.0) * window)
        else:
            # No metrics available - mark for evaluation and hide
            return False, "no metrics available", True
    else:
        wins_last30 = int(de_win_count_last30)
    
    # Apply hysteresis thresholds
    if wins_last30 >= enable_threshold:
        return True, f"wins30={wins_last30} >= enable_threshold={enable_threshold}", False
    elif wins_last30 <= disable_threshold:
        return False, f"wins30={wins_last30} <= disable_threshold={disable_threshold}", False
    else:
        # In hysteresis zone: check previous auto_enabled state
        prev_auto_enabled = bridge.get("de_auto_enabled", 0)
        if prev_auto_enabled == 1:
            return True, f"wins30={wins_last30} in hysteresis zone, prev_auto=1", False
        else:
            return False, f"wins30={wins_last30} in hysteresis zone, prev_auto=0", False


def compute_de_score(wins_count, total_periods=30):
    """
    Compute a simple DE performance score.
    
    Args:
        wins_count: Number of wins in the period
        total_periods: Total number of periods evaluated (default 30)
    
    Returns:
        float: Score from 0.0 to 10.0
    """
    if total_periods <= 0:
        return 0.0
    
    win_rate = wins_count / total_periods
    score = win_rate * 10.0
    return round(score, 2)


def format_de_status(bridge, thresholds=None):
    """
    Format a human-readable status string for a DE bridge.
    
    Args:
        bridge: Bridge dict with metrics
        thresholds: Optional thresholds dict
    
    Returns:
        str: Formatted status string
    """
    visible, reason, needs_eval = evaluate_de_visibility(bridge, thresholds)
    
    status_icon = "‚úì" if visible else "‚úó"
    eval_flag = " [NEEDS EVAL]" if needs_eval else ""
    
    wins = bridge.get("de_win_count_last30", "?")
    rate = bridge.get("de_win_rate_last30", "?")
    score = bridge.get("de_score", "?")
    
    return f"{status_icon} Visible={visible} | Wins={wins}/30 ({rate}%) | Score={score} | {reason}{eval_flag}"


def get_visibility_summary(bridges, thresholds=None):
    """
    Get a summary of visibility status for multiple bridges.
    
    Args:
        bridges: List of bridge dicts
        thresholds: Optional thresholds dict
    
    Returns:
        dict: Summary with counts and lists
    """
    summary = {
        "total": len(bridges),
        "visible": 0,
        "hidden": 0,
        "needs_evaluation": 0,
        "manual_override": 0,
        "auto_enabled": 0,
        "metric_based": 0
    }
    
    visible_bridges = []
    hidden_bridges = []
    needs_eval_bridges = []
    
    for bridge in bridges:
        visible, reason, needs_eval = evaluate_de_visibility(bridge, thresholds)
        
        if visible:
            summary["visible"] += 1
            visible_bridges.append(bridge)
        else:
            summary["hidden"] += 1
            hidden_bridges.append(bridge)
        
        if needs_eval:
            summary["needs_evaluation"] += 1
            needs_eval_bridges.append(bridge)
        
        # Categorize by decision type
        if "manual override" in reason:
            summary["manual_override"] += 1
        elif "auto flag" in reason:
            summary["auto_enabled"] += 1
        else:
            summary["metric_based"] += 1
    
    summary["visible_bridges"] = visible_bridges
    summary["hidden_bridges"] = hidden_bridges
    summary["needs_eval_bridges"] = needs_eval_bridges
    
    return summary


__all__ = [
    "is_dynamic_bridge_type",
    "evaluate_de_visibility",
    "compute_de_score",
    "format_de_status",
    "get_visibility_summary"
]


--------------------------------------------------

=== FILE: logic\bridges\i_bridge_strategy.py ===
# logic/bridges/i_bridge_strategy.py

from abc import ABC, abstractmethod
from typing import Any, Dict


class IBridgeStrategy(ABC):
    """
    Interface (Abstract Base Class) cho m·ªçi Chi·∫øn l∆∞·ª£c Ph√¢n t√≠ch (Bridge).
    M·ªçi Bridge c·ª• th·ªÉ ph·∫£i k·∫ø th·ª´a l·ªõp n√†y v√† tri·ªÉn khai c√°c ph∆∞∆°ng th·ª©c tr·ª´u t∆∞·ª£ng.
    """

    def __init__(self, data_repository: Any, config_manager: Any):
        """
        Kh·ªüi t·∫°o Strategy v·ªõi c√°c Dependency c·∫ßn thi·∫øt.
        (Thay th·∫ø Any b·∫±ng ki·ªÉu d·ªØ li·ªáu ch√≠nh x√°c c·ªßa DataRepository v√† ConfigManager trong h·ªá th·ªëng c·ªßa b·∫°n)
        """
        self.data_repo = data_repository
        self.config_manager = config_manager

    @abstractmethod
    def analyze(self, current_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Th·ª±c hi·ªán ph√¢n t√≠ch d·ªØ li·ªáu v√† tr·∫£ v·ªÅ k·∫øt qu·∫£ d·ª± ƒëo√°n.
        """
        pass

    @abstractmethod
    def get_info(self) -> Dict[str, str]:
        """
        Tr·∫£ v·ªÅ t√™n, phi√™n b·∫£n v√† m√¥ t·∫£ ng·∫Øn g·ªçn c·ªßa chi·∫øn l∆∞·ª£c.
        """
        pass

    @property
    @abstractmethod
    def STRATEGY_KEY(self) -> str:
        """
        Kh√≥a ƒë·ªãnh danh duy nh·∫•t (d·∫°ng chu·ªói vi·∫øt th∆∞·ªùng) cho chi·∫øn l∆∞·ª£c n√†y, d√πng trong Factory.
        """
        pass


--------------------------------------------------

=== FILE: logic\bridges\lo_bridge_scanner.py ===
# T√™n file: logic/bridges/lo_bridge_scanner.py
# (PHI√äN B·∫¢N V11.2 - K1N-PRIMARY REFACTOR: READ-ONLY SCANNER)
#
# Returns Candidate objects instead of writing to DB directly.

import os
import sqlite3
import sys
from typing import Dict, List, Tuple, Set, Any

# =========================================================================
# PATH FIX
# =========================================================================
try:
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(os.path.dirname(current_dir))
    if project_root not in sys.path:
        sys.path.insert(0, project_root)
except Exception:
    pass

# =========================================================================
# IMPORTS
# =========================================================================
try:
    from logic.config_manager import SETTINGS
except ImportError:
    SETTINGS = type("obj", (object,), {"AUTO_ADD_MIN_RATE": 50.0, "AUTO_PRUNE_MIN_RATE": 40.0})

try:
    from logic.data_repository import get_all_managed_bridges
    from logic.db_manager import (
        DB_NAME, get_all_managed_bridge_names, load_rates_cache
    )
    from logic.models import Candidate
    from logic.common_utils import normalize_bridge_name
except ImportError:
    DB_NAME = "data/xo_so_prizes_all_logic.db"
    def get_all_managed_bridge_names(*args, **kwargs): return set()
    def load_rates_cache(*args, **kwargs): return {}
    def get_all_managed_bridges(*args, **kwargs): return []
    def normalize_bridge_name(name): return str(name).lower().strip()

try:
    from logic.bridges.bridges_classic import (
        checkHitSet_V30_K2N, getAllLoto_V30,
        getCau1_STL_P5_V30_V5, getCau2_VT1_V30_V5, getCau3_VT2_V30_V5,
        getCau4_VT3_V30_V5, getCau5_TDB1_V30_V5, getCau6_VT5_V30_V5,
        getCau7_Moi1_V30_V5, getCau8_Moi2_V30_V5, getCau9_Moi3_V30_V5,
        getCau10_Moi4_V30_V5, getCau11_Moi5_V30_V5, getCau12_Moi6_V30_V5,
        getCau13_G7_3_P8_V30_V5, getCau14_G1_P2_V30_V5, getCau15_DE_P7_V30_V5
    )
    from logic.bridges.bridges_memory import (
        calculate_bridge_stl, get_27_loto_names, get_27_loto_positions,
    )
    from logic.bridges.bridges_v16 import (
        getAllPositions_V17_Shadow, getPositionName_V17_Shadow, taoSTL_V30_Bong,
    )
except ImportError:
    pass

# =========================================================================
# MAPPING C·∫¶U C·ªê ƒê·ªäNH
# =========================================================================
LO_BRIDGE_MAP = {
    "LO_STL_FIXED_01": {"func": getCau1_STL_P5_V30_V5, "desc": "C·∫ßu L√¥ 01 (GƒêB+5)"},
    "LO_STL_FIXED_02": {"func": getCau2_VT1_V30_V5,    "desc": "C·∫ßu L√¥ 02 (G6.2+G7.3)"},
    "LO_STL_FIXED_03": {"func": getCau3_VT2_V30_V5,    "desc": "C·∫ßu L√¥ 03 (ƒêu√¥i GƒêB+G1)"},
    "LO_STL_FIXED_04": {"func": getCau4_VT3_V30_V5,    "desc": "C·∫ßu L√¥ 04 (GƒêB S√°t ƒêu√¥i)"},
    "LO_STL_FIXED_05": {"func": getCau5_TDB1_V30_V5,   "desc": "C·∫ßu L√¥ 05 (ƒê·∫ßu G7.0+ƒêu√¥i G7.3)"},
    "LO_STL_FIXED_06": {"func": getCau6_VT5_V30_V5,    "desc": "C·∫ßu L√¥ 06 (G7.1+G7.2)"},
    "LO_STL_FIXED_07": {"func": getCau7_Moi1_V30_V5,   "desc": "C·∫ßu L√¥ 07 (G5.0+G7.0)"},
    "LO_STL_FIXED_08": {"func": getCau8_Moi2_V30_V5,   "desc": "C·∫ßu L√¥ 08 (G3.0+G4.0)"},
    "LO_STL_FIXED_09": {"func": getCau9_Moi3_V30_V5,   "desc": "C·∫ßu L√¥ 09 (ƒê·∫ßu GƒêB+ƒê·∫ßu G1)"},
    "LO_STL_FIXED_10": {"func": getCau10_Moi4_V30_V5,  "desc": "C·∫ßu L√¥ 10 (G2.1+G3.2)"},
    "LO_STL_FIXED_11": {"func": getCau11_Moi5_V30_V5,  "desc": "C·∫ßu L√¥ 11 (GƒêB+G3.1)"},
    "LO_STL_FIXED_12": {"func": getCau12_Moi6_V30_V5,  "desc": "C·∫ßu L√¥ 12 (ƒêu√¥i GƒêB+G3.2)"},
    "LO_STL_FIXED_13": {"func": getCau13_G7_3_P8_V30_V5, "desc": "C·∫ßu L√¥ 13 (G7.3+8)"},
    "LO_STL_FIXED_14": {"func": getCau14_G1_P2_V30_V5,   "desc": "C·∫ßu L√¥ 14 (G1+2)"},
    "LO_STL_FIXED_15": {"func": getCau15_DE_P7_V30_V5,   "desc": "C·∫ßu L√¥ 15 (GƒêB+7)"},
}

# =========================================================================
# HELPER FUNCTIONS
# =========================================================================
def _sanitize_name_v2(name):
    """Sanitize bridge name for safe database storage."""
    return name.replace("[", "_").replace("]", "").replace("(", "_").replace(")", "").replace(".", "_").replace("+", "_").replace(" ", "")


def _ensure_core_db_columns(cursor):
    """Ensure required database columns exist."""
    try:
        cursor.execute("PRAGMA table_info(ManagedBridges)")
        columns = [info[1] for info in cursor.fetchall()]
        if "type" not in columns:
            cursor.execute("ALTER TABLE ManagedBridges ADD COLUMN type TEXT DEFAULT 'UNKNOWN'")
        if "search_rate_text" not in columns:
            cursor.execute("ALTER TABLE ManagedBridges ADD COLUMN search_rate_text TEXT DEFAULT ''")
    except:
        pass


def _get_existing_bridges_map(db_name) -> Dict:
    """Helper: L·∫•y to√†n b·ªô c·∫ßu hi·ªán c√≥ ƒë·ªÉ tra c·ª©u K1N c≈©."""
    try:
        bridges = get_all_managed_bridges(db_name)
        # Tr·∫£ v·ªÅ Set c√°c t√™n c·∫ßu ƒë·ªÉ check nhanh
        return {b['name']: b.get('win_rate_text', 'N/A') for b in bridges}
    except Exception:
        return {}


# ===================================================================================
# I. H√ÄM D√í C·∫¶U V17 SHADOW (FIXED: FORCE UPDATE OLD BRIDGES)
# ===================================================================================
def TIM_CAU_TOT_NHAT_V16(toan_bo_A_I, ky_bat_dau_kiem_tra, ky_ket_thuc_kiem_tra, db_name=DB_NAME):
    """
    D√≤ t√¨m c√°c c·∫ßu L√¥ V·ªã Tr√≠ (V17 Shadow) t·ªët nh·∫•t.
    
    Args:
        toan_bo_A_I: D·ªØ li·ªáu to√†n b·ªô k·ª≥ quay
        ky_bat_dau_kiem_tra: K·ª≥ b·∫Øt ƒë·∫ßu ki·ªÉm tra
        ky_ket_thuc_kiem_tra: K·ª≥ k·∫øt th√∫c ki·ªÉm tra
        db_name: ƒê∆∞·ªùng d·∫´n database
        
    Returns:
        List of results with bridge information
    """
    print("B·∫Øt ƒë·∫ßu D√≤ C·∫ßu L√¥ V·ªã Tr√≠ (V17 Shadow) - Ch·∫ø ƒë·ªô Force Update...")
    allData, finalEndRow, startCheckRow, offset = toan_bo_A_I, ky_ket_thuc_kiem_tra, ky_bat_dau_kiem_tra + 1, ky_bat_dau_kiem_tra
    headers = ["STT", "C·∫ßu (V17)", "V·ªã Tr√≠", "T·ª∑ L·ªá K2N (Scan)", "Chu·ªói"]
    results = [headers]

    last_row_real = allData[-1]
    try:
        last_positions = getAllPositions_V17_Shadow(last_row_real)
    except:
        return results

    # Danh s√°ch c·∫ßu ƒëang c√≥ trong DB (ƒë·ªÉ √©p c·∫≠p nh·∫≠t)
    existing_bridges_map = _get_existing_bridges_map(db_name)

    try:
        positions_shadow = getAllPositions_V17_Shadow(allData[0])
        num_positions_shadow = len(positions_shadow)
    except:
        return [["L·ªñI:", "Kh√¥ng th·ªÉ l·∫•y V·ªã Tr√≠ V17 Shadow."]]
    
    if num_positions_shadow == 0:
        return [["L·ªñI:", "Kh√¥ng th·ªÉ l·∫•y V·ªã Tr√≠ V17 Shadow."]]

    algorithms = []
    for i in range(num_positions_shadow):
        for j in range(i, num_positions_shadow):
            algorithms.append((i, j))

    processedData = []
    for k in range(startCheckRow, finalEndRow + 1):
        prevRow_idx, actualRow_idx = k - 1 - offset, k - offset
        if actualRow_idx >= len(allData) or prevRow_idx < 0:
            continue
        processedData.append({
            "prevPositions": getAllPositions_V17_Shadow(allData[prevRow_idx]),
            "actualLotoSet": set(getAllLoto_V30(allData[actualRow_idx])),
        })

    AUTO_ADD_MIN_RATE = SETTINGS.AUTO_ADD_MIN_RATE
    bridges_to_upsert = []
    bridges_to_cache = []

    for idx1, idx2 in algorithms:
        # 1. T·∫°o t√™n c·∫ßu tr∆∞·ªõc ƒë·ªÉ check t·ªìn t·∫°i
        pos1_name = getPositionName_V17_Shadow(idx1)
        pos2_name = getPositionName_V17_Shadow(idx2)
        safe_p1 = _sanitize_name_v2(pos1_name)
        safe_p2 = _sanitize_name_v2(pos2_name)
        std_id = f"LO_POS_{safe_p1}_{safe_p2}"

        # 2. T√≠nh to√°n hi·ªáu su·∫•t qu√° kh·ª©
        win_count, current_streak, max_streak = 0, 0, 0
        for dayData in processedData:
            a, b = dayData["prevPositions"][idx1], dayData["prevPositions"][idx2]
            if a is None or b is None:
                current_streak = 0
                continue
            
            if "‚úÖ" in checkHitSet_V30_K2N(taoSTL_V30_Bong(a, b), dayData["actualLotoSet"]):
                win_count += 1
                current_streak += 1
            else:
                current_streak = 0
            max_streak = max(max_streak, current_streak)

        totalTestDays = len(processedData)
        if totalTestDays > 0:
            scan_rate = (win_count / totalTestDays) * 100
            scan_rate_str = f"{scan_rate:.2f}%"

            # 3. QUY·∫æT ƒê·ªäNH C√ì L∆ØU KH√îNG?
            # L∆∞u n·∫øu: (T·ª∑ l·ªá cao) HO·∫∂C (C·∫ßu ƒë√£ c√≥ trong DB c·∫ßn update s·ªë li·ªáu m·ªõi)
            is_good_bridge = (scan_rate >= AUTO_ADD_MIN_RATE)
            is_existing_bridge = (std_id in existing_bridges_map)

            if is_good_bridge or is_existing_bridge:
                
                # T√≠nh d·ª± ƒëo√°n (Fix N/A do s·ªë 0)
                try:
                    p1_val = last_positions[idx1]
                    p2_val = last_positions[idx2]
                    
                    if p1_val is not None and p2_val is not None and str(p1_val) != "" and str(p2_val) != "":
                        next_stl = taoSTL_V30_Bong(p1_val, p2_val)
                        next_pred_str = ",".join(next_stl)
                    else:
                        next_pred_str = "N/A"
                except:
                    next_pred_str = "Error"

                # Logic K1N
                preserved_k1n = scan_rate_str
                if is_existing_bridge:
                    old_k1n = existing_bridges_map[std_id]
                    if old_k1n and old_k1n not in ['N/A', '', None]:
                         preserved_k1n = old_k1n

                # Ch·ªâ th√™m v√†o results hi·ªÉn th·ªã n·∫øu l√† c·∫ßu t·ªët (ƒë·ªÉ log ƒë·ª° r√°c)
                if is_good_bridge:
                    results.append([len(results), std_id, f"{pos1_name}+{pos2_name}", scan_rate_str, f"{current_streak}"])

                # NH∆ØNG lu√¥n ƒë·∫©y v√†o queue c·∫≠p nh·∫≠t DB
                bridge_data_dict = {
                    "pos1_idx": idx1, "pos2_idx": idx2,
                    "search_rate_text": scan_rate_str,
                    "search_period": totalTestDays,
                    "is_enabled": 1,
                    "type": "LO_POS"
                }
                bridges_to_upsert.append((std_id, f"V·ªã tr√≠: {pos1_name} + {pos2_name}", preserved_k1n, db_name, idx1, idx2, bridge_data_dict))
                bridges_to_cache.append((scan_rate_str, current_streak, next_pred_str, max_streak, std_id))

    if bridges_to_upsert:
        print(f"D√≤ c·∫ßu V17: ƒêang c·∫≠p nh·∫≠t {len(bridges_to_upsert)} c·∫ßu (bao g·ªìm c·∫ßu c≈©)...")
        try:
            [upsert_managed_bridge(n, d, r, db, i1, i2, data_dict) for n, d, r, db, i1, i2, data_dict in bridges_to_upsert]
            update_bridge_k2n_cache_batch(bridges_to_cache, db_name)
            conn = sqlite3.connect(db_name)
            conn.execute("UPDATE ManagedBridges SET type='LO_POS' WHERE name LIKE 'LO_POS_%'")
            conn.commit()
            conn.close()
        except Exception as e:
            print(f"L·ªói l∆∞u c·∫ßu V17: {e}")

    return results


# ===================================================================================
# II. H√ÄM D√í C·∫¶U B·∫†C NH·ªö (FIXED: FORCE UPDATE OLD BRIDGES)
# ===================================================================================
def TIM_CAU_BAC_NHO_TOT_NHAT(toan_bo_A_I, ky_bat_dau_kiem_tra, ky_ket_thuc_kiem_tra, db_name=DB_NAME):
    """
    D√≤ t√¨m c√°c c·∫ßu B·∫°c Nh·ªõ t·ªët nh·∫•t.
    
    Args:
        toan_bo_A_I: D·ªØ li·ªáu to√†n b·ªô k·ª≥ quay
        ky_bat_dau_kiem_tra: K·ª≥ b·∫Øt ƒë·∫ßu ki·ªÉm tra
        ky_ket_thuc_kiem_tra: K·ª≥ k·∫øt th√∫c ki·ªÉm tra
        db_name: ƒê∆∞·ªùng d·∫´n database
        
    Returns:
        List of results with bridge information
    """
    print("B·∫Øt ƒë·∫ßu D√≤ C·∫ßu B·∫°c Nh·ªõ - Ch·∫ø ƒë·ªô Force Update...")
    allData, finalEndRow, startCheckRow, offset = toan_bo_A_I, ky_ket_thuc_kiem_tra, ky_bat_dau_kiem_tra + 1, ky_bat_dau_kiem_tra
    loto_names = get_27_loto_names()
    processedData = []
    
    last_row_real = allData[-1]
    try:
        last_lotos = get_27_loto_positions(last_row_real)
    except:
        return []

    existing_bridges_map = _get_existing_bridges_map(db_name)

    for k in range(startCheckRow, finalEndRow + 1):
        prevRow_idx, actualRow_idx = k - 1 - offset, k - offset
        if actualRow_idx >= len(allData) or prevRow_idx < 0:
            continue
        processedData.append({
            "prevLotos": get_27_loto_positions(allData[prevRow_idx]),
            "actualLotoSet": set(getAllLoto_V30(allData[actualRow_idx])),
        })

    AUTO_ADD_MIN_RATE = SETTINGS.AUTO_ADD_MIN_RATE
    bridges_to_upsert = []
    bridges_to_cache = []
    results = [["STT", "C·∫ßu (B·∫°c Nh·ªõ)", "V·ªã Tr√≠", "T·ª∑ L·ªá K2N", "Chu·ªói"]]

    algorithms = []
    for i in range(len(loto_names)):
        for j in range(i, len(loto_names)):
            std_sum = f"LO_MEM_SUM_{loto_names[i]}_{loto_names[j]}"
            desc_sum = f"B·∫°c Nh·ªõ: T·ªïng({loto_names[i]} + {loto_names[j]})"
            algorithms.append((i, j, "sum", std_sum, desc_sum))
            
            std_diff = f"LO_MEM_DIFF_{loto_names[i]}_{loto_names[j]}"
            desc_diff = f"B·∫°c Nh·ªõ: Hi·ªáu(|{loto_names[i]} - {loto_names[j]}|)"
            algorithms.append((i, j, "diff", std_diff, desc_diff))

    for idx1, idx2, alg_type, std_id, desc in algorithms:
        win_count, current_streak, max_streak = 0, 0, 0
        for dayData in processedData:
            loto1, loto2 = dayData["prevLotos"][idx1], dayData["prevLotos"][idx2]
            if "‚úÖ" in checkHitSet_V30_K2N(calculate_bridge_stl(loto1, loto2, alg_type), dayData["actualLotoSet"]):
                win_count += 1
                current_streak += 1
            else:
                current_streak = 0
            max_streak = max(max_streak, current_streak)

        totalTestDays = len(processedData)
        if totalTestDays > 0:
            scan_rate = (win_count / totalTestDays) * 100
            scan_rate_str = f"{scan_rate:.2f}%"
            
            is_good = (scan_rate >= AUTO_ADD_MIN_RATE)
            is_exist = (std_id in existing_bridges_map)

            if is_good or is_exist:
                try:
                    val1 = last_lotos[idx1]
                    val2 = last_lotos[idx2]
                    if val1 is not None and val2 is not None:
                        next_stl = calculate_bridge_stl(val1, val2, alg_type)
                        next_pred_str = ",".join(next_stl)
                    else:
                        next_pred_str = "N/A"
                except:
                    next_pred_str = "Error"

                preserved_k1n = scan_rate_str 
                if is_exist:
                    old_k1n = existing_bridges_map[std_id]
                    if old_k1n and old_k1n not in ['N/A', '', None]:
                        preserved_k1n = old_k1n

                if is_good:
                    results.append([len(results), std_id, desc, scan_rate_str, f"{current_streak}"])

                bridge_data = {
                    "pos1_idx": -1, "pos2_idx": -1,
                    "search_rate_text": scan_rate_str,
                    "search_period": totalTestDays,
                    "is_enabled": 1,
                    "type": "LO_MEM"
                }
                
                bridges_to_upsert.append((std_id, desc, preserved_k1n, db_name, -1, -1, bridge_data))
                bridges_to_cache.append((scan_rate_str, current_streak, next_pred_str, max_streak, std_id))

    if bridges_to_upsert:
        print(f"D√≤ B·∫°c Nh·ªõ: ƒêang c·∫≠p nh·∫≠t {len(bridges_to_upsert)} c·∫ßu (bao g·ªìm c·∫ßu c≈©)...")
        try:
            [upsert_managed_bridge(n, d, r, db, i1, i2, data_dict) for n, d, r, db, i1, i2, data_dict in bridges_to_upsert]
            update_bridge_k2n_cache_batch(bridges_to_cache, db_name)
            conn = sqlite3.connect(db_name)
            conn.execute("UPDATE ManagedBridges SET type='LO_MEM' WHERE name LIKE 'LO_MEM_%'")
            conn.commit()
            conn.close()
        except Exception as e:
            print(f"L·ªói l∆∞u B·∫°c Nh·ªõ: {e}")

    return results


# ===================================================================================
# III. H√ÄM C·∫¨P NH·∫¨T C·∫¶U C·ªê ƒê·ªäNH
# ===================================================================================
def update_fixed_lo_bridges(all_data_ai, db_name):
    """
    C·∫≠p nh·∫≠t 15 c·∫ßu L√¥ C·ªë ƒê·ªãnh (Fixed Bridges).
    
    Args:
        all_data_ai: D·ªØ li·ªáu to√†n b·ªô k·ª≥ quay
        db_name: ƒê∆∞·ªùng d·∫´n database
        
    Returns:
        Number of bridges updated
    """
    print(">>> [LO MANAGER] ƒêang c·∫≠p nh·∫≠t 15 C·∫ßu L√¥ C·ªë ƒê·ªãnh (Phase C - Fix N/A)...")
    if not all_data_ai or len(all_data_ai) < 10:
        return 0
    
    check_days = 10 
    scan_data = all_data_ai[- (check_days + 5):]
    
    updated_count = 0
    
    conn = sqlite3.connect(db_name)
    cursor = conn.cursor()
    _ensure_core_db_columns(cursor)
    
    for bridge_id, info in LO_BRIDGE_MAP.items():
        func = info["func"]
        desc = info["desc"]
        
        wins = 0
        current_streak = 0
        
        for i in range(len(scan_data) - 1 - check_days, len(scan_data) - 1):
            if i < 0:
                continue
            row_prev = scan_data[i]
            row_next = scan_data[i+1]
            try:
                stl = func(row_prev)
                lotos_next = set(getAllLoto_V30(row_next))
                if "‚úÖ" in checkHitSet_V30_K2N(stl, lotos_next):
                    wins += 1
                    current_streak += 1
                else:
                    current_streak = 0
            except:
                pass
            
        last_row = all_data_ai[-1]
        try:
            next_stl = func(last_row)
            pred_val = f"{next_stl[0]},{next_stl[1]}"
        except: 
            pred_val = "Error"
            
        win_rate = (wins / check_days) * 100
        full_desc = f"{desc}. Phong ƒë·ªô {wins}/{check_days}."
        rate_str = f"{win_rate:.0f}%"
        
        try:
            cursor.execute("SELECT count(*) FROM ManagedBridges WHERE name=?", (bridge_id,))
            exists = cursor.fetchone()[0] > 0
            
            if not exists:
                cursor.execute("""
                    INSERT INTO ManagedBridges (name, description, win_rate_text, search_rate_text, current_streak, next_prediction_stl, is_enabled, type)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """, (bridge_id, full_desc, rate_str, rate_str, current_streak, pred_val, 1 if win_rate>=40 else 0, 'LO_STL_FIXED'))
            else:
                cursor.execute("""
                    UPDATE ManagedBridges 
                    SET description=?, win_rate_text=?, search_rate_text=?, current_streak=?, next_prediction_stl=?, is_enabled=?, type='LO_STL_FIXED'
                    WHERE name=?
                """, (full_desc, rate_str, rate_str, current_streak, pred_val, 1 if win_rate>=40 else 0, bridge_id))
            updated_count += 1
        except Exception as e: 
            print(f"L·ªói update Fixed Bridge {bridge_id}: {e}")
            
    conn.commit()
    conn.close()
    return updated_count


# ===================================================================================
# V. K1N-PRIMARY REFACTORED WRAPPERS (V11.2)
# ===================================================================================

def scan_lo_bridges_v17(
    toan_bo_A_I, 
    ky_bat_dau_kiem_tra, 
    ky_ket_thuc_kiem_tra, 
    db_name=DB_NAME
) -> Tuple[List[Candidate], Dict[str, Any]]:
    """
    V11.2 K1N-Primary: Scan LO V17 bridges and return Candidate objects (READ-ONLY).
    
    Wraps TIM_CAU_TOT_NHAT_V16 but returns Candidates instead of writing to DB.
    
    Args:
        toan_bo_A_I: Historical lottery data
        ky_bat_dau_kiem_tra: Start period for checking
        ky_ket_thuc_kiem_tra: End period for checking
        db_name: Database path (for reading existing bridges only)
        
    Returns:
        Tuple of (candidates: List[Candidate], meta: Dict):
            - candidates: List of bridge candidates with rates attached
            - meta: Dict with 'found_total', 'excluded_existing', 'returned_count'
    """
    print(">>> [LO SCANNER V11.2] Scanning V17 bridges (K1N-Primary Read-Only)...")
    
    # Get data from original scanner
    allData = toan_bo_A_I
    finalEndRow = ky_ket_thuc_kiem_tra
    startCheckRow = ky_bat_dau_kiem_tra + 1
    offset = ky_bat_dau_kiem_tra
    
    last_row_real = allData[-1]
    try:
        last_positions = getAllPositions_V17_Shadow(last_row_real)
    except:
        return [], {'found_total': 0, 'excluded_existing': 0, 'returned_count': 0}
    
    try:
        positions_shadow = getAllPositions_V17_Shadow(allData[0])
        num_positions_shadow = len(positions_shadow)
    except:
        return [], {'found_total': 0, 'excluded_existing': 0, 'returned_count': 0}
    
    if num_positions_shadow == 0:
        return [], {'found_total': 0, 'excluded_existing': 0, 'returned_count': 0}
    
    algorithms = []
    for i in range(num_positions_shadow):
        for j in range(i, num_positions_shadow):
            algorithms.append((i, j))
    
    processedData = []
    for k in range(startCheckRow, finalEndRow + 1):
        prevRow_idx, actualRow_idx = k - 1 - offset, k - offset
        if actualRow_idx >= len(allData) or prevRow_idx < 0:
            continue
        processedData.append({
            "prevPositions": getAllPositions_V17_Shadow(allData[prevRow_idx]),
            "actualLotoSet": set(getAllLoto_V30(allData[actualRow_idx])),
        })
    
    AUTO_ADD_MIN_RATE = SETTINGS.AUTO_ADD_MIN_RATE
    bridge_dicts = []
    
    for idx1, idx2 in algorithms:
        pos1_name = getPositionName_V17_Shadow(idx1)
        pos2_name = getPositionName_V17_Shadow(idx2)
        safe_p1 = _sanitize_name_v2(pos1_name)
        safe_p2 = _sanitize_name_v2(pos2_name)
        std_id = f"LO_POS_{safe_p1}_{safe_p2}"
        
        win_count, current_streak, max_streak = 0, 0, 0
        for dayData in processedData:
            a, b = dayData["prevPositions"][idx1], dayData["prevPositions"][idx2]
            if a is None or b is None:
                current_streak = 0
                continue
            
            if "‚úÖ" in checkHitSet_V30_K2N(taoSTL_V30_Bong(a, b), dayData["actualLotoSet"]):
                win_count += 1
                current_streak += 1
            else:
                current_streak = 0
            max_streak = max(max_streak, current_streak)
        
        totalTestDays = len(processedData)
        if totalTestDays > 0:
            scan_rate = (win_count / totalTestDays) * 100
            
            # Only include if meets threshold
            if scan_rate >= AUTO_ADD_MIN_RATE:
                a_pred, b_pred = last_positions[idx1], last_positions[idx2]
                if a_pred is not None and b_pred is not None:
                    next_pred_str = calculate_bridge_stl(a_pred, b_pred)
                else:
                    next_pred_str = "N/A"
                
                bridge_dicts.append({
                    'name': std_id,
                    'type': 'LO_POS',
                    'description': f"V·ªã tr√≠: {pos1_name} + {pos2_name}",
                    'win_rate': scan_rate,
                    'streak': current_streak,
                    'predicted_value': next_pred_str,
                    'pos1_idx': idx1,
                    'pos2_idx': idx2,
                    'win_count_10': win_count if totalTestDays <= 10 else int((scan_rate / 100.0) * 10)
                })
    
    found_total = len(bridge_dicts)
    
    # Load existing names and rates cache (SINGLE DB CALL EACH)
    print(f">>> [LO SCANNER] Loading existing bridges and rates cache...")
    existing_names = get_all_managed_bridge_names(db_name)
    rates_cache = load_rates_cache(db_name)
    
    # Convert to Candidates with rates and exclude existing
    candidates = _convert_lo_bridges_to_candidates(bridge_dicts, existing_names, rates_cache)
    excluded_count = found_total - len(candidates)
    
    meta = {
        'found_total': found_total,
        'excluded_existing': excluded_count,
        'returned_count': len(candidates)
    }
    
    print(f">>> [LO SCANNER] K·∫øt qu·∫£ V17: {found_total} t√¨m th·∫•y, {excluded_count} ƒë√£ t·ªìn t·∫°i, {len(candidates)} tr·∫£ v·ªÅ.")
    return candidates, meta


def _convert_lo_bridges_to_candidates(
    bridge_dicts: List[Dict[str, Any]],
    existing_names: Set[str],
    rates_cache: Dict[str, Dict[str, float]]
) -> List[Candidate]:
    """
    Convert LO bridge dicts to Candidate objects with K1N/K2N rates attached.
    
    Args:
        bridge_dicts: List of bridge dictionaries from scan
        existing_names: Set of normalized existing bridge names
        rates_cache: Dict mapping normalized names to rates
        
    Returns:
        List of Candidate objects (excluding existing bridges)
    """
    candidates = []
    
    for b in bridge_dicts:
        name = b.get('name', '')
        if not name:
            continue
        
        # Normalize name for duplicate checking
        norm_name = normalize_bridge_name(name)
        
        # Skip if already exists
        if norm_name in existing_names:
            continue
        
        # Get rates from cache
        rates = rates_cache.get(norm_name, {})
        k1n_lo = rates.get('k1n_rate_lo', 0.0)
        k1n_de = rates.get('k1n_rate_de', 0.0)
        k2n_lo = rates.get('k2n_rate_lo', 0.0)
        k2n_de = rates.get('k2n_rate_de', 0.0)
        
        # Set rate_missing flag if no rates found
        rate_missing = (k1n_lo == 0.0 and k2n_lo == 0.0)
        
        # Create Candidate object
        candidate = Candidate(
            name=name,
            normalized_name=norm_name,
            type='lo',
            kind='single',
            k1n_lo=k1n_lo,
            k1n_de=k1n_de,
            k2n_lo=k2n_lo,
            k2n_de=k2n_de,
            stl=b.get('predicted_value', 'N/A'),
            reason=b.get('type', 'LO_UNKNOWN'),
            pos1_idx=b.get('pos1_idx'),
            pos2_idx=b.get('pos2_idx'),
            description=b.get('description', ''),
            streak=b.get('streak', 0),
            win_count_10=b.get('win_count_10', 0),
            rate_missing=rate_missing,
            metadata={
                'win_rate': b.get('win_rate', 0.0)
            }
        )
        
        candidates.append(candidate)
    
    return candidates


--------------------------------------------------

=== FILE: logic\bridges\__init__.py ===


--------------------------------------------------

=== FILE: scripts\check_cau_bo_50_days.py ===
import sys
import os
import re
import inspect

# --- C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N ---
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, project_root)

try:
    from logic.bridges.bridge_manager_de import de_manager
    from logic.bridges.bridges_v16 import get_index_from_name_V16, getPositionName_V16
    from logic.db_manager import DB_NAME
    from logic.data_repository import get_all_data_ai
except ImportError as e:
    print(f"‚ùå L·ªói Import: {e}")
    sys.exit(1)

def check_source_code():
    print("="*80)
    print("üîç KI·ªÇM TRA M√É NGU·ªíN TH·ª∞C T·∫æ (SOURCE CODE INSPECTION)")
    print("="*80)
    
    try:
        # L·∫•y source code c·ªßa h√†m _map_safe_name_to_index
        source = inspect.getsource(de_manager._map_safe_name_to_index)
        print("--- Code hi·ªán t·∫°i c·ªßa h√†m _map_safe_name_to_index ---")
        print(source)
        print("-----------------------------------------------------")
        
        # Ki·ªÉm tra Regex
        if r'[\[\.]?' in source or r'[\\.]?' in source:
            print("‚úÖ Regex c√≥ v·∫ª ƒê√öNG (C√≥ ch·ª©a [\[\.]?)")
        else:
            print("‚ùå Regex c√≥ v·∫ª SAI/C≈® (Thi·∫øu [\[\.]?)")
            
    except Exception as e:
        print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ ƒë·ªçc source code: {e}")

def debug_bridge_logic(bridge_name):
    print("\n" + "="*80)
    print(f"üïµÔ∏è  DEBUG LOGIC T√çNH TO√ÅN C·∫¶U: {bridge_name}")
    print("="*80)

    # 1. Test Parse T√™n C·∫ßu
    print(f"üîπ [B∆Ø·ªöC 1] Test Parse T√™n: '{bridge_name}'")
    
    # Gi·∫£ l·∫≠p b_type d·ª±a tr√™n t√™n
    b_type = "UNKNOWN"
    if "DE_SET" in bridge_name: b_type = "DE_SET"
    elif "DE_DYN" in bridge_name: b_type = "DE_DYNAMIC_K"
    elif "DE_KILLER" in bridge_name: b_type = "DE_KILLER"
    
    print(f"   -> B_Type gi·∫£ l·∫≠p: {b_type}")
    
    try:
        parsed = de_manager._parse_bridge_id_v2(bridge_name, b_type)
        if parsed:
            idx1, idx2, k, mode = parsed
            print(f"   ‚úÖ Parse TH√ÄNH C√îNG!")
            print(f"      - Index 1: {idx1} ({getPositionName_V16(idx1)})")
            print(f"      - Index 2: {idx2} ({getPositionName_V16(idx2)})")
            print(f"      - Mode: {mode}")
        else:
            print(f"   ‚ùå Parse TH·∫§T B·∫†I (Tr·∫£ v·ªÅ None)")
            
            # Debug chi ti·∫øt t·∫°i sao th·∫•t b·∫°i
            parts = bridge_name.split("_")
            if len(parts) >= 3:
                p1 = parts[2]
                print(f"      -> Th·ª≠ map v·ªã tr√≠ 1 '{p1}':")
                idx1_try = de_manager._map_safe_name_to_index(p1)
                print(f"         K·∫øt qu·∫£: {idx1_try}")
                
                # Test logic chuy·ªÉn ƒë·ªïi th·ªß c√¥ng ƒë·ªÉ xem l·ªói ·ªü ƒë√¢u
                clean_name = p1.replace("[", "").replace("]", "").replace(".", "")
                print(f"         Clean name (logic c≈©): '{clean_name}'")
                
                # Test regex match
                # Regex mong ƒë·ª£i: r"(G\d+\.?\d*|GDB)[\[\.]?(\d+)"
                match = re.match(r"(G\d+\.?\d*|GDB)[\[\.]?(\d+)", p1)
                print(f"         Regex Match (M·ªõi): {bool(match)}")
                if match:
                    print(f"         Groups: {match.groups()}")
                    g_name, g_idx = match.groups()
                    recon = f"{g_name}[{g_idx}]"
                    print(f"         Reconstructed: '{recon}'")
                    print(f"         get_index_from_name_V16('{recon}'): {get_index_from_name_V16(recon)}")

    except Exception as e:
        print(f"   ‚ùå L·ªói Exception khi Parse: {e}")
        import traceback
        traceback.print_exc()

def main():
    check_source_code()
    
    # Test v·ªõi c·∫ßu b·ªã b√°o l·ªói trong log c·ªßa b·∫°n
    debug_bridge_logic("DE_SET_G3.2.2_G5.5.3")
    
    # Test th√™m c·∫ßu DYN c≈©ng b·ªã l·ªói
    debug_bridge_logic("DE_DYN_G1.4_G6.3.2_K3")

if __name__ == "__main__":
    main()

--------------------------------------------------

=== FILE: scripts\config.json ===
{
    "STATS_DAYS": 7,
    "GAN_DAYS": 15,
    "HIGH_WIN_THRESHOLD": 47.0,
    "AUTO_ADD_MIN_RATE": 50.0,
    "AUTO_PRUNE_MIN_RATE": 40.0,
    "K2N_RISK_START_THRESHOLD": 4,
    "K2N_RISK_PENALTY_PER_FRAME": 0.5,
    "AI_PROB_THRESHOLD": 45.0,
    "AI_MAX_DEPTH": 15,
    "AI_N_ESTIMATORS": 100,
    "AI_LEARNING_RATE": 0.1,
    "AI_OBJECTIVE": "binary:logistic",
    "AI_SCORE_WEIGHT": 0.3,
    "RECENT_FORM_PERIODS": 10,
    "RECENT_FORM_BONUS_VERY_HIGH": 4.0,
    "RECENT_FORM_BONUS_HIGH": 3.0,
    "RECENT_FORM_BONUS_MED": 2.0,
    "RECENT_FORM_BONUS_LOW": 1.0,
    "RECENT_FORM_MIN_VERY_HIGH": 9,
    "RECENT_FORM_MIN_HIGH": 7,
    "RECENT_FORM_MIN_MED": 5,
    "RECENT_FORM_MIN_LOW": 3,
    "VOTE_SCORE_WEIGHT": 0.3,
    "HIGH_WIN_SCORE_BONUS": 2.5,
    "K2N_RISK_PROGRESSIVE": true,
    "FILTER_MIN_CONFIDENCE": 0,
    "FILTER_MIN_AI_PROB": 0,
    "FILTER_ENABLED": false
}

--------------------------------------------------

=== FILE: scripts\diagnose_bridge_sync.py ===
import sys
import os
import sqlite3
import re

# --- C·∫§U H√åNH ---
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, project_root)

try:
    from logic.db_manager import DB_NAME
    from logic.data_repository import get_all_data_ai
    from logic.bridges.bridges_v16 import get_index_from_name_V16
    from logic.de_backtester_core import run_de_bridge_historical_test
except ImportError as e:
    print(f"‚ùå L·ªói Import: {e}")
    sys.exit(1)

def check_name_parsing(bridge_name):
    """M√¥ ph·ªèng logic parse c·ªßa h·ªá th·ªëng ƒë·ªÉ xem c√≥ ƒë·ªçc ƒë∆∞·ª£c t√™n kh√¥ng"""
    # Logic c≈© c·ªßa Bridge Manager (G√¢y l·ªói)
    # Regex n√†y kh√¥ng b·∫Øt ƒë∆∞·ª£c d·∫•u '[' n√™n s·∫Ω tr∆∞·ª£t c√°c c·∫ßu l·ªói t√™n
    match = re.match(r"(G\d+\.?\d*|GDB)(\d+)", bridge_name)
    
    # Logic V16 chu·∫©n
    idx = get_index_from_name_V16(bridge_name)
    
    return {
        "regex_manager_ok": bool(match),
        "v16_parser_ok": (idx is not None)
    }

def main():
    print("\n" + "="*80)
    print("üöë CH·∫®N ƒêO√ÅN ƒê·ªíNG B·ªò D·ªÆ LI·ªÜU C·∫¶U (DB SYNC DIAGNOSTIC)")
    print("="*80)

    # 1. T·∫£i d·ªØ li·ªáu
    print("‚è≥ ƒêang t·∫£i d·ªØ li·ªáu th·ª±c t·∫ø...")
    all_data = get_all_data_ai(DB_NAME)
    if not all_data:
        print("‚ùå DB r·ªóng.")
        return

    # 2. L·∫•y c·∫ßu t·ª´ DB
    conn = sqlite3.connect(DB_NAME)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    cursor.execute("SELECT id, name, current_streak, type FROM ManagedBridges WHERE is_enabled=1 AND type LIKE 'DE_%'")
    bridges = [dict(row) for row in cursor.fetchall()]
    conn.close()

    print(f"‚úÖ ƒêang ki·ªÉm tra {len(bridges)} c·∫ßu ƒê·ªÅ ƒëang ho·∫°t ƒë·ªông...")
    print("-" * 100)
    print(f"{'T√äN C·∫¶U':<25} | {'DB STREAK':<10} | {'REAL STREAK':<12} | {'TR·∫†NG TH√ÅI':<15} | {'NGUY√äN NH√ÇN'}")
    print("-" * 100)

    error_count = 0
    sync_error_count = 0

    for b in bridges:
        name = b['name']
        db_streak = b['current_streak']
        
        # A. Ki·ªÉm tra Parse T√™n
        parse_status = check_name_parsing(name)
        is_name_broken = not (parse_status['regex_manager_ok'] or parse_status['v16_parser_ok'])
        
        # B. T√≠nh to√°n Streak Th·ª±c t·∫ø (Real-time)
        # Ch·∫°y backtest 5 ng√†y g·∫ßn nh·∫•t ƒë·ªÉ l·∫•y streak hi·ªán t·∫°i
        try:
            history = run_de_bridge_historical_test(b, all_data, days=10)
            if history and not isinstance(history[0], str):
                # T√≠nh streak t·ª´ history
                real_streak = 0
                for day in reversed(history):
                    if day['is_win']: real_streak += 1
                    else: break
            else:
                real_streak = -1 # L·ªói backtest
        except:
            real_streak = -2 # Crash

        # C. So s√°nh & ƒê√°nh gi√°
        status = "‚úÖ OK"
        reason = ""
        
        if is_name_broken:
            status = "‚ùå L·ªñI T√äN"
            reason = "Sai ƒë·ªãnh d·∫°ng (Thi·∫øu ngo·∫∑c/Format l·∫°)"
            error_count += 1
        
        if real_streak >= 0 and db_streak != real_streak:
            status = "‚ö†Ô∏è L·ªÜCH S·ªê"
            reason += f" (DB treo {db_streak}, Th·ª±c {real_streak})"
            sync_error_count += 1
            
        # Ch·ªâ in ra c√°c c·∫ßu c√≥ v·∫•n ƒë·ªÅ ho·∫∑c c·∫ßu ti√™u bi·ªÉu
        if status != "‚úÖ OK":
            print(f"{name:<25} | {str(db_streak):<10} | {str(real_streak):<12} | {status:<15} | {reason}")

    print("-" * 100)
    print(f"üìä T·ªîNG K·∫æT:")
    print(f"   - T·ªïng s·ªë c·∫ßu ki·ªÉm tra: {len(bridges)}")
    print(f"   - S·ªë c·∫ßu b·ªã l·ªói t√™n (Unparsable): {error_count}")
    print(f"   - S·ªë c·∫ßu b·ªã l·ªách d·ªØ li·ªáu (Desync): {sync_error_count}")
    
    if error_count > 0:
        print("\nüëâ K·∫æT LU·∫¨N: H·ªá th·ªëng kh√¥ng th·ªÉ ƒë·ªçc t√™n c√°c c·∫ßu b·ªã l·ªói,")
        print("   d·∫´n ƒë·∫øn vi·ªác kh√¥ng th·ªÉ c·∫≠p nh·∫≠t Streak m·ªõi (DB v·∫´n gi·ªØ s·ªë c≈©).")
        print("   -> C·∫ßn x√≥a c√°c c·∫ßu n√†y v√† qu√©t l·∫°i sau khi ƒë√£ fix Scanner.")

if __name__ == "__main__":
    main()

--------------------------------------------------

=== FILE: scripts\fix_dashboard_na.py ===
import sys
import os
import sqlite3

# Th√™m ƒë∆∞·ªùng d·∫´n project v√†o sys.path ƒë·ªÉ import ƒë∆∞·ª£c c√°c module logic
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, project_root)

try:
    from logic.data_repository import get_all_data_ai
    from logic.bridges.lo_bridge_scanner import update_fixed_lo_bridges
    from logic.bridges.bridge_manager_core import find_and_auto_manage_bridges
    from logic.db_manager import DB_NAME
except ImportError as e:
    print(f"‚ùå L·ªói Import: {e}")
    print("üëâ H√£y ƒë·∫£m b·∫£o b·∫°n l∆∞u script n√†y v√†o th∆∞ m·ª•c 'scripts/'")
    sys.exit(1)

def force_update():
    print("üöÄ B·∫ÆT ƒê·∫¶U C·∫¨P NH·∫¨T D·ªÆ LI·ªÜU D·ª∞ ƒêO√ÅN (FORCE UPDATE)...")
    
    # 1. Ki·ªÉm tra Database
    if not os.path.exists(DB_NAME):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y Database t·∫°i: {DB_NAME}")
        return

    # 2. L·∫•y d·ªØ li·ªáu k·∫øt qu·∫£ x·ªï s·ªë
    print("‚è≥ ƒêang t·∫£i d·ªØ li·ªáu x·ªï s·ªë...")
    all_data = get_all_data_ai(DB_NAME)
    if not all_data or len(all_data) < 10:
        print("‚ùå D·ªØ li·ªáu x·ªï s·ªë qu√° √≠t ho·∫∑c r·ªóng. Vui l√≤ng n·∫°p file d·ªØ li·ªáu tr∆∞·ªõc.")
        return
    print(f"‚úÖ ƒê√£ t·∫£i {len(all_data)} k·ª≥ d·ªØ li·ªáu.")

    # 3. Ch·∫°y c·∫≠p nh·∫≠t 15 C·∫ßu C·ªë ƒê·ªãnh (ƒê√¢y l√† n∆°i sinh ra l·ªói N/A cho b·∫£ng Top 10)
    print("\n------------------------------------------------")
    print("üîÑ ƒêang t√≠nh to√°n l·∫°i 15 C·∫ßu C·ªë ƒê·ªãnh (Fixed Bridges)...")
    try:
        count = update_fixed_lo_bridges(all_data, DB_NAME)
        print(f"‚úÖ ƒê√£ c·∫≠p nh·∫≠t th√†nh c√¥ng {count} c·∫ßu c·ªë ƒë·ªãnh.")
    except Exception as e:
        print(f"‚ùå L·ªói khi c·∫≠p nh·∫≠t Fixed Bridges: {e}")
        import traceback
        traceback.print_exc()

    # 4. (T√πy ch·ªçn) Ch·∫°y c·∫≠p nh·∫≠t c√°c c·∫ßu kh√°c
    print("\n------------------------------------------------")
    print("üîÑ ƒêang r√† so√°t l·∫°i c√°c c·∫ßu V17 & B·∫°c Nh·ªõ (Auto Manage)...")
    try:
        msg = find_and_auto_manage_bridges(all_data, DB_NAME)
        print(f"‚úÖ K·∫øt qu·∫£: {msg}")
    except Exception as e:
        print(f"‚ö†Ô∏è C√≥ l·ªói nh·ªè khi r√† so√°t c·∫ßu ƒë·ªông (c√≥ th·ªÉ b·ªè qua): {e}")

    # 5. Ki·ªÉm tra l·∫°i k·∫øt qu·∫£ trong DB
    print("\n------------------------------------------------")
    print("üìä KI·ªÇM TRA D·ªÆ LI·ªÜU SAU C·∫¨P NH·∫¨T:")
    conn = sqlite3.connect(DB_NAME)
    cursor = conn.cursor()
    
    # L·∫•y th·ª≠ 5 c·∫ßu c√≥ ƒëi·ªÉm cao nh·∫•t
    cursor.execute("""
        SELECT name, win_rate_text, next_prediction_stl 
        FROM ManagedBridges 
        WHERE is_enabled=1 
        ORDER BY recent_win_count_10 DESC 
        LIMIT 5
    """)
    rows = cursor.fetchall()
    
    print(f"{'T√äN C·∫¶U':<25} | {'WIN RATE':<10} | {'D·ª∞ ƒêO√ÅN (PRED)'}")
    print("-" * 60)
    has_na = False
    for row in rows:
        name, rate, pred = row
        print(f"{name:<25} | {rate:<10} | {pred}")
        if pred == 'N/A' or pred is None:
            has_na = True
            
    conn.close()
    
    print("-" * 60)
    if not has_na and len(rows) > 0:
        print("üéâ TH√ÄNH C√îNG! H·∫øt l·ªói N/A. B·∫°n c√≥ th·ªÉ m·ªü App ngay.")
    else:
        print("‚ö†Ô∏è V·∫´n c√≤n N/A. H√£y ki·ªÉm tra l·∫°i log l·ªói ph√≠a tr√™n.")

if __name__ == "__main__":
    force_update()

--------------------------------------------------

=== FILE: scripts\fix_v38_all.py ===
# T√™n file: code6/scripts/generate_digest.py
import os

# C·∫•u h√¨nh: C√°c th∆∞ m·ª•c v√† file c·∫ßn qu√©t
TARGET_DIRS = ['logic', 'services', 'ui', 'scripts']
TARGET_FILES = ['main_app.py', 'app_controller.py', 'config.json', 'README.md']
SKIP_DIRS = ['__pycache__', 'ml_model_files', 'DOC'] # DOC b·ªè qua ƒë·ªÉ gi·∫£m dung l∆∞·ª£ng th·ª´a
OUTPUT_FILE = 'PROJECT_FULL_CONTEXT.txt'

def generate_digest():
    root_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
    output_path = os.path.join(root_dir, OUTPUT_FILE)
    
    print(f"üöÄ ƒêang t·∫°o h·ªì s∆° d·ª± √°n t·∫°i: {output_path}")
    
    with open(output_path, 'w', encoding='utf-8') as outfile:
        # 1. Ghi c·∫•u tr√∫c th∆∞ m·ª•c
        outfile.write("=== PROJECT STRUCTURE ===\n")
        for root, dirs, files in os.walk(root_dir):
            # L·ªçc th∆∞ m·ª•c ·∫©n/b·ªè qua
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in SKIP_DIRS]
            level = root.replace(root_dir, '').count(os.sep)
            indent = ' ' * 4 * (level)
            outfile.write(f"{indent}{os.path.basename(root)}/\n")
            subindent = ' ' * 4 * (level + 1)
            for f in files:
                if not f.startswith('.') and not f.endswith('.pyc'):
                    outfile.write(f"{subindent}{f}\n")
        
        outfile.write("\n" + "="*50 + "\n\n")

        # 2. Ghi n·ªôi dung file code quan tr·ªçng
        for root, dirs, files in os.walk(root_dir):
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in SKIP_DIRS]
            
            # Ch·ªâ l·∫•y c√°c th∆∞ m·ª•c m·ª•c ti√™u ho·∫∑c file g·ªëc
            rel_dir = os.path.relpath(root, root_dir)
            if rel_dir == '.' or any(rel_dir.startswith(d) for d in TARGET_DIRS):
                for file in files:
                    if file.endswith('.py') or file in TARGET_FILES:
                        file_path = os.path.join(root, file)
                        rel_path = os.path.relpath(file_path, root_dir)
                        
                        outfile.write(f"=== FILE: {rel_path} ===\n")
                        try:
                            with open(file_path, 'r', encoding='utf-8') as infile:
                                content = infile.read()
                                outfile.write(content)
                        except Exception as e:
                            outfile.write(f"[Error reading file: {e}]")
                        outfile.write("\n\n" + "-"*50 + "\n\n")

    print(f"‚úÖ Ho√†n t·∫•t! File '{OUTPUT_FILE}' ƒë√£ s·∫µn s√†ng.")
    print("üëâ B·∫°n h√£y upload file n√†y l√™n Gemini ƒë·ªÉ AI hi·ªÉu to√†n b·ªô d·ª± √°n ngay l·∫≠p t·ª©c.")

if __name__ == "__main__":
    generate_digest()

--------------------------------------------------

=== FILE: scripts\force_update_predictions.py ===
import sys
import os
import sqlite3

# Th√™m ƒë∆∞·ªùng d·∫´n project v√†o sys.path ƒë·ªÉ import ƒë∆∞·ª£c c√°c module logic
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, project_root)

try:
    from logic.data_repository import get_all_data_ai
    from logic.bridges.lo_bridge_scanner import update_fixed_lo_bridges
    from logic.bridges.bridge_manager_core import find_and_auto_manage_bridges
    from logic.db_manager import DB_NAME
except ImportError as e:
    print(f"‚ùå L·ªói Import: {e}")
    print("üëâ H√£y ƒë·∫£m b·∫£o b·∫°n l∆∞u script n√†y v√†o th∆∞ m·ª•c 'scripts/'")
    sys.exit(1)

def force_update():
    print("üöÄ B·∫ÆT ƒê·∫¶U C·∫¨P NH·∫¨T D·ªÆ LI·ªÜU D·ª∞ ƒêO√ÅN (FORCE UPDATE)...")
    
    # 1. Ki·ªÉm tra Database
    if not os.path.exists(DB_NAME):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y Database t·∫°i: {DB_NAME}")
        return

    # 2. L·∫•y d·ªØ li·ªáu k·∫øt qu·∫£ x·ªï s·ªë
    print("‚è≥ ƒêang t·∫£i d·ªØ li·ªáu x·ªï s·ªë...")
    all_data = get_all_data_ai(DB_NAME)
    if not all_data or len(all_data) < 10:
        print("‚ùå D·ªØ li·ªáu x·ªï s·ªë qu√° √≠t ho·∫∑c r·ªóng. Vui l√≤ng n·∫°p file d·ªØ li·ªáu tr∆∞·ªõc.")
        return
    print(f"‚úÖ ƒê√£ t·∫£i {len(all_data)} k·ª≥ d·ªØ li·ªáu.")

    # 3. Ch·∫°y c·∫≠p nh·∫≠t 15 C·∫ßu C·ªë ƒê·ªãnh (ƒê√¢y l√† n∆°i sinh ra l·ªói N/A cho b·∫£ng Top 10)
    print("\n------------------------------------------------")
    print("üîÑ ƒêang t√≠nh to√°n l·∫°i 15 C·∫ßu C·ªë ƒê·ªãnh (Fixed Bridges)...")
    try:
        count = update_fixed_lo_bridges(all_data, DB_NAME)
        print(f"‚úÖ ƒê√£ c·∫≠p nh·∫≠t th√†nh c√¥ng {count} c·∫ßu c·ªë ƒë·ªãnh.")
    except Exception as e:
        print(f"‚ùå L·ªói khi c·∫≠p nh·∫≠t Fixed Bridges: {e}")
        import traceback
        traceback.print_exc()

    # 4. (T√πy ch·ªçn) Ch·∫°y c·∫≠p nh·∫≠t c√°c c·∫ßu kh√°c
    print("\n------------------------------------------------")
    print("üîÑ ƒêang r√† so√°t l·∫°i c√°c c·∫ßu V17 & B·∫°c Nh·ªõ (Auto Manage)...")
    try:
        msg = find_and_auto_manage_bridges(all_data, DB_NAME)
        print(f"‚úÖ K·∫øt qu·∫£: {msg}")
    except Exception as e:
        print(f"‚ö†Ô∏è C√≥ l·ªói nh·ªè khi r√† so√°t c·∫ßu ƒë·ªông (c√≥ th·ªÉ b·ªè qua): {e}")

    # 5. Ki·ªÉm tra l·∫°i k·∫øt qu·∫£ trong DB
    print("\n------------------------------------------------")
    print("üìä KI·ªÇM TRA D·ªÆ LI·ªÜU SAU C·∫¨P NH·∫¨T:")
    conn = sqlite3.connect(DB_NAME)
    cursor = conn.cursor()
    
    # L·∫•y th·ª≠ 5 c·∫ßu c√≥ ƒëi·ªÉm cao nh·∫•t
    cursor.execute("""
        SELECT name, win_rate_text, next_prediction_stl 
        FROM ManagedBridges 
        WHERE is_enabled=1 
        ORDER BY recent_win_count_10 DESC 
        LIMIT 5
    """)
    rows = cursor.fetchall()
    
    print(f"{'T√äN C·∫¶U':<25} | {'WIN RATE':<10} | {'D·ª∞ ƒêO√ÅN (PRED)'}")
    print("-" * 60)
    has_na = False
    for row in rows:
        name, rate, pred = row
        print(f"{name:<25} | {rate:<10} | {pred}")
        if pred == 'N/A' or pred is None:
            has_na = True
            
    conn.close()
    
    print("-" * 60)
    if not has_na and len(rows) > 0:
        print("üéâ TH√ÄNH C√îNG! H·∫øt l·ªói N/A. B·∫°n c√≥ th·ªÉ m·ªü App ngay.")
    else:
        print("‚ö†Ô∏è V·∫´n c√≤n N/A. H√£y ki·ªÉm tra l·∫°i log l·ªói ph√≠a tr√™n.")

if __name__ == "__main__":
    force_update()

--------------------------------------------------

=== FILE: scripts\generate_digest.py ===
# T√™n file: code6/scripts/generate_digest.py
import os

# C·∫•u h√¨nh: C√°c th∆∞ m·ª•c v√† file c·∫ßn qu√©t
TARGET_DIRS = ['logic', 'services', 'ui', 'scripts']
TARGET_FILES = ['main_app.py', 'app_controller.py', 'config.json', 'README.md']
SKIP_DIRS = ['__pycache__', 'ml_model_files', 'DOC'] # DOC b·ªè qua ƒë·ªÉ gi·∫£m dung l∆∞·ª£ng th·ª´a
OUTPUT_FILE = 'PROJECT_FULL_CONTEXT.txt'

def generate_digest():
    root_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
    output_path = os.path.join(root_dir, OUTPUT_FILE)
    
    print(f"üöÄ ƒêang t·∫°o h·ªì s∆° d·ª± √°n t·∫°i: {output_path}")
    
    with open(output_path, 'w', encoding='utf-8') as outfile:
        # 1. Ghi c·∫•u tr√∫c th∆∞ m·ª•c
        outfile.write("=== PROJECT STRUCTURE ===\n")
        for root, dirs, files in os.walk(root_dir):
            # L·ªçc th∆∞ m·ª•c ·∫©n/b·ªè qua
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in SKIP_DIRS]
            level = root.replace(root_dir, '').count(os.sep)
            indent = ' ' * 4 * (level)
            outfile.write(f"{indent}{os.path.basename(root)}/\n")
            subindent = ' ' * 4 * (level + 1)
            for f in files:
                if not f.startswith('.') and not f.endswith('.pyc'):
                    outfile.write(f"{subindent}{f}\n")
        
        outfile.write("\n" + "="*50 + "\n\n")

        # 2. Ghi n·ªôi dung file code quan tr·ªçng
        for root, dirs, files in os.walk(root_dir):
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in SKIP_DIRS]
            
            # Ch·ªâ l·∫•y c√°c th∆∞ m·ª•c m·ª•c ti√™u ho·∫∑c file g·ªëc
            rel_dir = os.path.relpath(root, root_dir)
            if rel_dir == '.' or any(rel_dir.startswith(d) for d in TARGET_DIRS):
                for file in files:
                    if file.endswith('.py') or file in TARGET_FILES:
                        file_path = os.path.join(root, file)
                        rel_path = os.path.relpath(file_path, root_dir)
                        
                        outfile.write(f"=== FILE: {rel_path} ===\n")
                        try:
                            with open(file_path, 'r', encoding='utf-8') as infile:
                                content = infile.read()
                                outfile.write(content)
                        except Exception as e:
                            outfile.write(f"[Error reading file: {e}]")
                        outfile.write("\n\n" + "-"*50 + "\n\n")

    print(f"‚úÖ Ho√†n t·∫•t! File '{OUTPUT_FILE}' ƒë√£ s·∫µn s√†ng.")
    print("üëâ B·∫°n h√£y upload file n√†y l√™n Gemini ƒë·ªÉ AI hi·ªÉu to√†n b·ªô d·ª± √°n ngay l·∫≠p t·ª©c.")

if __name__ == "__main__":
    generate_digest()

--------------------------------------------------

=== FILE: scripts\inspect_last_row.py ===
import sys
import os
import sqlite3

# Setup ƒë∆∞·ªùng d·∫´n
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, project_root)

try:
    # [FIX] Import DB_NAME t·ª´ db_manager v√† get_all_data_ai t·ª´ data_repository
    from logic.db_manager import DB_NAME
    from logic.data_repository import get_all_data_ai
    from logic.bridges.bridges_v16 import getAllPositions_V17_Shadow, getPositionName_V17_Shadow
except ImportError as e:
    print(f"‚ùå L·ªói Import: {e}")
    sys.exit(1)

def inspect_data():
    print("üîç B·∫ÆT ƒê·∫¶U KI·ªÇM TRA D·ªÆ LI·ªÜU K·ª≤ M·ªöI NH·∫§T...")
    
    if not os.path.exists(DB_NAME):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y DB: {DB_NAME}")
        return

    # 1. L·∫•y d·ªØ li·ªáu th√¥
    conn = sqlite3.connect(DB_NAME)
    cursor = conn.cursor()
    cursor.execute("SELECT * FROM DuLieu_AI ORDER BY MaSoKy DESC LIMIT 1")
    row = cursor.fetchone()
    conn.close()

    if not row:
        print("‚ùå Database r·ªóng!")
        return

    # Row structure: MaSoKy, Ky, GDB, G1, G2, G3, G4, G5, G6, G7
    print(f"\nüìÖ K·ª≤ M·ªöI NH·∫§T: {row[1]}")
    print("-" * 50)
    
    columns = ["MaSoKy", "Ky", "GDB", "G1", "G2", "G3", "G4", "G5", "G6", "G7"]
    raw_values = list(row)
    
    # In d·ªØ li·ªáu th√¥ ƒë·ªÉ m·∫Øt th∆∞·ªùng nh√¨n
    for i, val in enumerate(raw_values):
        col_name = columns[i] if i < len(columns) else f"Col_{i}"
        print(f"{col_name:<10}: {val}")
        
        # C·∫£nh b√°o n·∫øu chu·ªói qu√° ng·∫Øn (D·ªØ li·ªáu b·ªã thi·∫øu)
        if i >= 2 and isinstance(val, str): # B·ªè qua MaSoKy, Ky
            clean_val = val.replace("-", "").replace(" ", "").replace(",", "")
            # G3 th∆∞·ªùng c√≥ 6 gi·∫£i x 5 s·ªë = 30 s·ªë. N·∫øu √≠t h∆°n nhi·ªÅu l√† l·ªói.
            if col_name == "G3" and len(clean_val) < 25:
                print(f"   ‚ö†Ô∏è C·∫¢NH B√ÅO: G3 qu√° ng·∫Øn ({len(clean_val)} k√Ω t·ª±). C√≥ th·ªÉ thi·∫øu gi·∫£i.")
            if col_name == "G4" and len(clean_val) < 15: # 4 gi·∫£i x 4 s·ªë = 16
                print(f"   ‚ö†Ô∏è C·∫¢NH B√ÅO: G4 qu√° ng·∫Øn ({len(clean_val)} k√Ω t·ª±).")

    print("-" * 50)
    
    # 2. Ki·ªÉm tra vi·ªác ph√¢n t√°ch V·ªã Tr√≠ (Parsing)
    print("‚öôÔ∏è TEST PH√ÇN T√ÅCH V·ªä TR√ç (V17):")
    try:
        # Gi·∫£ l·∫≠p row cho h√†m V17 (H√†m n√†y th∆∞·ªùng c·∫ßn list values)
        positions = getAllPositions_V17_Shadow(raw_values)
        
        # ƒê·∫øm s·ªë l∆∞·ª£ng v·ªã tr√≠ l·∫•y ƒë∆∞·ª£c
        valid_count = sum(1 for p in positions if p is not None and p != "")
        total_count = len(positions)
        
        print(f"‚úÖ ƒê√£ t√°ch ƒë∆∞·ª£c: {valid_count}/{total_count} v·ªã tr√≠.")
        
        if valid_count < total_count:
            print("\n‚ùå C√ÅC V·ªä TR√ç B·ªä L·ªñI (NULL/EMPTY) - G√ÇY RA N/A:")
            error_count = 0
            for idx, val in enumerate(positions):
                if not val:
                    name = getPositionName_V17_Shadow(idx)
                    print(f"   - Index {idx} ({name}): TR·ªêNG")
                    error_count += 1
                    if error_count >= 10:
                        print("   ... (v√† nhi·ªÅu v·ªã tr√≠ kh√°c)")
                        break
            
            print("\nüëâ NGUY√äN NH√ÇN: Do d·ªØ li·ªáu th√¥ (G3, G4...) nh·∫≠p v√†o b·ªã sai ƒë·ªãnh d·∫°ng (thi·∫øu d·∫•u ngƒÉn c√°ch '-' ho·∫∑c thi·∫øu s·ªë).")
            print("üëâ GI·∫¢I PH√ÅP: X√≥a k·ª≥ n√†y ƒëi v√† n·∫°p l·∫°i chu·∫©n x√°c.")
        else:
            print("\n‚úÖ T·∫•t c·∫£ v·ªã tr√≠ ƒë·ªÅu h·ª£p l·ªá. H·ªá th·ªëng l·∫Ω ra ph·∫£i d·ª± ƒëo√°n ƒë∆∞·ª£c.")

    except Exception as e:
        print(f"‚ùå L·ªói khi ch·∫°y parser V17: {e}")

if __name__ == "__main__":
    inspect_data()

--------------------------------------------------

=== FILE: scripts\README.md ===
# V7.7 Upgrade Scripts

This directory contains scripts to help execute the V7.7 upgrade plan.

## Available Scripts

### 1. v77_phase2_finalize.py

**Purpose**: Complete Phase 2 by retraining the AI model with 14 features and preparing for Phase 3.

**What it does:**
1. Creates Phase 3 database tables (`meta_learning_history`, `model_performance_log`)
2. Retrains the AI model with all 14 features (F1-F14)
3. Verifies the model is correctly saved
4. Logs training results to database

**Usage:**

```bash
# Basic retraining (faster, uses default parameters)
python scripts/v77_phase2_finalize.py

# With hyperparameter tuning (recommended for best results, but slower)
python scripts/v77_phase2_finalize.py --hyperparameter-tuning

# Skip database setup if already done
python scripts/v77_phase2_finalize.py --skip-db-setup
```

**Requirements:**
- Database must be accessible with lottery data
- Minimum 50 periods of data required for training
- For hyperparameter tuning: Recommended 100+ periods for better results

**Expected Duration:**
- Without tuning: 2-10 minutes (depending on data size)
- With tuning: 10-30 minutes (performs grid search)

**Output:**
- Updates model files: `logic/ml_model_files/loto_model.joblib` and `ai_scaler.joblib`
- Creates/updates Phase 3 database tables
- Logs training results to `model_performance_log` table

---

### 2. v77_phase3_check_progress.py

**Purpose**: Check Phase 3 data collection progress and readiness for Meta-Learner training.

**What it does:**
1. Checks database tables for Phase 3 exist
2. Reports data collection statistics
3. Shows progress toward 100-period minimum
4. Provides integration guide for data collection
5. Indicates when ready for Phase 3 implementation

**Usage:**

```bash
# Check current progress
python scripts/v77_phase3_check_progress.py
```

**Output Example:**
```
üìä Collection Statistics:
   Total Predictions Logged: 5,000
   Predictions with Outcomes: 4,500
   Unique Periods Collected: 45

üìà Progress to Phase 3 Readiness:
   Required Periods: 100
   Current Periods: 45
   Remaining: 55
[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 45.0%

‚è≥ NOT YET READY
   Need 55 more periods of data collection
   Estimated time: 55 days (if collecting daily)
```

**When to run:**
- After Phase 2 completion
- Periodically during data collection (weekly/monthly)
- Before attempting Phase 3 implementation

---

### 3. v77_phase3_implement.py

**Purpose**: Implement Phase 3 components - Meta-Learner, Adaptive Trainer, and Performance Monitor.

**What it does:**
1. Checks if 100+ periods of data collected (prerequisite)
2. Trains Meta-Learner on historical predictions and outcomes
3. Sets up Adaptive Trainer for automatic retraining
4. Configures Performance Monitor for model health tracking
5. Provides usage guide for all Phase 3 components

**Usage:**

```bash
# Check prerequisites only (doesn't train/enable anything)
python scripts/v77_phase3_implement.py

# Train Meta-Learner and enable Adaptive Trainer
python scripts/v77_phase3_implement.py --train-meta-learner --enable-adaptive

# Train Meta-Learner only
python scripts/v77_phase3_implement.py --train-meta-learner

# Skip prerequisite checks
python scripts/v77_phase3_implement.py --skip-checks
```

**Prerequisites:**
- Phase 2 completed (14-feature model trained)
- 100+ periods of prediction data collected in `meta_learning_history` table
- Database accessible with collected data

**Expected Duration:**
- Prerequisite check: <1 minute
- Meta-Learner training: 1-5 minutes (depends on data size)
- Full setup: 2-10 minutes

**Output:**
- Creates `logic/ml_model_files/meta_learner.joblib` and `meta_scaler.joblib`
- Configures Adaptive Trainer (can enable/disable auto-retrain)
- Initializes Performance Monitor
- Provides detailed usage guide

**When to run:**
- After collecting 100+ periods of data
- When ready to activate Phase 3 features
- To retrain Meta-Learner with new data

---

## After Running Scripts

### Phase 2 Completion Checklist
- [ ] Run `v77_phase2_finalize.py` successfully
- [ ] Verify model files exist in `logic/ml_model_files/`
- [ ] Test predictions to ensure 14 features work correctly
- [ ] Begin collecting prediction data for Phase 3

### Phase 3 Completion Checklist
- [ ] Collect 100+ periods of data (check with `v77_phase3_check_progress.py`)
- [ ] Run `v77_phase3_implement.py --train-meta-learner`
- [ ] Verify Meta-Learner files exist in `logic/ml_model_files/`
- [ ] Optionally enable Adaptive Trainer with `--enable-adaptive`
- [ ] Integrate Meta-Learner into dashboard for enhanced decisions

### Next Steps: Phase 3 Usage
1. **Use Meta-Learner** for better decisions
   ```python
   from logic.meta_learner import load_meta_learner
   meta_learner = load_meta_learner()
   final_prob, decision = meta_learner.predict_final_decision(...)
   ```

2. **Monitor Performance** continuously
   ```python
   from logic.performance_monitor import get_performance_monitor
   monitor = get_performance_monitor()
   monitor.record_performance(date, predictions, actuals)
   ```

3. **Let Adaptive Trainer** handle retraining automatically
   ```python
   from logic.adaptive_trainer import get_adaptive_trainer
   trainer = get_adaptive_trainer()
   success, msg, type = trainer.auto_retrain(all_data_ai)
   ```

## Troubleshooting

### Database Connection Errors
```
Error: Could not connect to database
```
**Solution**: Ensure `config.json` has correct database path and the database file exists.

### Import Errors
```
Error: No module named 'logic'
```
**Solution**: Run script from repository root: `python scripts/v77_phase2_finalize.py`

### Insufficient Data Error
```
Error: Need at least 50 periods of data
```
**Solution**: Add more lottery result data to the database before training.

### Out of Memory Errors
```
Error: MemoryError during training
```
**Solution**: 
- Close other applications to free memory
- Try without hyperparameter tuning first
- Consider using a subset of data for testing

## Documentation References

- **Phase 2 Implementation**: `DOC/V77_PHASE2_IMPLEMENTATION.md`
- **Phase 3 Design**: `DOC/V77_PHASE3_DESIGN.md`
- **Feasibility Assessment** (Vietnamese): `DOC/V77_FEASIBILITY_ASSESSMENT_VI.md`
- **Quick Reference**: `V77_UPGRADE_SUMMARY.md`

## Support

For issues or questions:
1. Check the documentation in `DOC/` directory
2. Review error messages and traceback carefully
3. Ensure all prerequisites are met (data, dependencies, etc.)


--------------------------------------------------

=== FILE: scripts\test_de_memory_pipeline.py ===
#!/usr/bin/env python3
"""
Test script for DE_MEMORY bridge scanning, storage, and filtering pipeline.
Usage: python scripts/test_de_memory_pipeline.py
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

import sqlite3
from logic.data_repository import load_data_ai_from_db
from logic.bridges.de_bridge_scanner import run_de_scanner

def test_de_memory_pipeline():
    """Test the complete DE_MEMORY bridge pipeline."""
    print("=" * 80)
    print("TESTING DE_MEMORY BRIDGE PIPELINE")
    print("=" * 80)
    
    db_name = "lottery.db"
    
    # Step 1: Load data
    print("\n[STEP 1] Loading lottery data...")
    all_data, _ = load_data_ai_from_db(db_name)
    if not all_data:
        print("‚ùå No data found in database")
        return False
    print(f"‚úÖ Loaded {len(all_data)} lottery periods")
    
    # Step 2: Run DE scanner
    print("\n[STEP 2] Running DE bridge scanner...")
    count, found_bridges = run_de_scanner(all_data)
    print(f"‚úÖ Scanner completed: {count} bridges found")
    
    # Step 3: Analyze results by type
    print("\n[STEP 3] Analyzing bridge types...")
    type_counts = {}
    memory_bridges = []
    
    for bridge in found_bridges:
        bridge_type = bridge.get('type', 'UNKNOWN')
        type_counts[bridge_type] = type_counts.get(bridge_type, 0) + 1
        
        if bridge_type == 'DE_MEMORY':
            memory_bridges.append(bridge)
    
    print("\nüìä Bridge Type Distribution:")
    for btype, count in sorted(type_counts.items()):
        icon = "üß†" if btype == 'DE_MEMORY' else "üì¶" if btype == 'DE_SET' else "üîç"
        print(f"  {icon} {btype}: {count}")
    
    # Step 4: Verify DE_MEMORY bridges
    print(f"\n[STEP 4] Verifying DE_MEMORY bridges ({len(memory_bridges)})...")
    if memory_bridges:
        print("\nüß† Sample DE_MEMORY bridges:")
        for i, bridge in enumerate(memory_bridges[:5], 1):
            name = bridge.get('name', 'N/A')
            desc = bridge.get('display_desc', bridge.get('description', 'N/A'))
            confidence = bridge.get('win_rate', 0)
            print(f"  {i}. {name}")
            print(f"     Confidence: {confidence:.1f}%")
            print(f"     {desc[:100]}...")
    else:
        print("‚ö†Ô∏è  No DE_MEMORY bridges found (may need more historical data)")
    
    # Step 5: Verify database storage
    print("\n[STEP 5] Checking database storage...")
    conn = sqlite3.connect(db_name)
    cursor = conn.cursor()
    
    # Check if DE_MEMORY bridges are saved
    cursor.execute("SELECT COUNT(*) FROM ManagedBridges WHERE type = 'DE_MEMORY'")
    db_memory_count = cursor.fetchone()[0]
    
    print(f"  Scanner found: {len(memory_bridges)} DE_MEMORY bridges")
    print(f"  Database stored: {db_memory_count} DE_MEMORY bridges")
    
    if db_memory_count == len(memory_bridges):
        print("  ‚úÖ All DE_MEMORY bridges saved correctly")
    elif db_memory_count > 0:
        print(f"  ‚ö†Ô∏è  Partial storage: {db_memory_count}/{len(memory_bridges)}")
    else:
        print("  ‚ùå No DE_MEMORY bridges in database")
    
    # Show sample from DB
    cursor.execute("""
        SELECT id, name, type, description, is_enabled 
        FROM ManagedBridges 
        WHERE type = 'DE_MEMORY' 
        LIMIT 3
    """)
    db_samples = cursor.fetchall()
    
    if db_samples:
        print("\n  üìù Sample from database:")
        for row in db_samples:
            bridge_id, name, btype, desc, enabled = row
            status = "üü¢ Enabled" if enabled else "üî¥ Disabled"
            print(f"    ID {bridge_id}: {name} ({btype}) - {status}")
            print(f"    {desc[:80]}...")
    
    # Step 6: Verify DE filter coverage
    print("\n[STEP 6] Testing DE bridge filtering...")
    cursor.execute("""
        SELECT type, COUNT(*) 
        FROM ManagedBridges 
        WHERE type LIKE 'DE_%' OR type LIKE 'CAU_DE%'
        GROUP BY type
        ORDER BY COUNT(*) DESC
    """)
    de_types = cursor.fetchall()
    
    print("\n  üî¥ DE bridge types in database:")
    total_de = 0
    for btype, count in de_types:
        total_de += count
        icon = "üß†" if btype == 'DE_MEMORY' else "üì¶" if btype == 'DE_SET' else "üîç"
        print(f"    {icon} {btype}: {count}")
    
    print(f"\n  Total DE bridges: {total_de}")
    
    # Step 7: Test filter query
    print("\n[STEP 7] Testing management filter query...")
    valid_de_types = ['DE_DYNAMIC_K', 'DE_POS_SUM', 'DE_SET', 'DE_PASCAL', 'DE_KILLER', 'DE_MEMORY', 'CAU_DE']
    
    filter_query = "SELECT COUNT(*) FROM ManagedBridges WHERE ("
    conditions = []
    for t in valid_de_types:
        conditions.append(f"type LIKE '{t}%' OR type = '{t}'")
    filter_query += " OR ".join(conditions) + ")"
    
    cursor.execute(filter_query)
    filter_count = cursor.fetchone()[0]
    
    print(f"  Filter query matches: {filter_count} bridges")
    print(f"  Direct DE count: {total_de} bridges")
    
    if filter_count == total_de:
        print("  ‚úÖ Filter query working correctly")
    else:
        print(f"  ‚ö†Ô∏è  Filter mismatch: {filter_count} vs {total_de}")
    
    conn.close()
    
    # Step 8: Summary
    print("\n" + "=" * 80)
    print("PIPELINE TEST SUMMARY")
    print("=" * 80)
    
    issues = []
    if len(memory_bridges) == 0:
        issues.append("‚ö†Ô∏è  No memory bridges found (may need more data)")
    elif db_memory_count == 0:
        issues.append("‚ùå Memory bridges not saved to database")
    elif db_memory_count != len(memory_bridges):
        issues.append(f"‚ö†Ô∏è  Storage mismatch: {db_memory_count}/{len(memory_bridges)}")
    
    if not issues:
        print("‚úÖ ALL TESTS PASSED")
        print(f"  - {len(memory_bridges)} DE_MEMORY bridges scanned")
        print(f"  - {db_memory_count} DE_MEMORY bridges stored")
        print(f"  - {total_de} total DE bridges in database")
        print(f"  - Filter query working correctly")
        return True
    else:
        print("‚ö†Ô∏è  TESTS COMPLETED WITH WARNINGS")
        for issue in issues:
            print(f"  {issue}")
        return False

if __name__ == "__main__":
    try:
        success = test_de_memory_pipeline()
        sys.exit(0 if success else 1)
    except Exception as e:
        print(f"\n‚ùå ERROR: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


--------------------------------------------------

=== FILE: scripts\v77_phase2_finalize.py ===
#!/usr/bin/env python3
"""
V7.7 Phase 2 Finalization Script

This script completes Phase 2 by:
1. Retraining the AI model with 14 features (F1-F14)
2. Creating the database table for Phase 3 data collection
3. Validating the model training

Usage:
    python scripts/v77_phase2_finalize.py [--hyperparameter-tuning]

Options:
    --hyperparameter-tuning    Enable hyperparameter tuning during retraining (recommended)
                               This will take longer but optimize the model parameters.
"""

import sys
import os
import argparse
from datetime import datetime
# Add parent directory to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

def create_phase3_database_table():
    """
    Create the meta_learning_history table for Phase 3 data collection.
    This table will store predictions alongside actual outcomes for training the meta-learner.
    """
    print("\n" + "=" * 80)
    print("Step 1: Creating Phase 3 Database Table")
    print("=" * 80)
    
    try:
        import sqlite3
        from logic.db_manager import DB_NAME
        
        conn = sqlite3.connect(DB_NAME)
        cursor = conn.cursor()
        
        # Create meta_learning_history table
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS meta_learning_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                ky TEXT NOT NULL,
                loto TEXT NOT NULL,
                ai_probability REAL,
                manual_score REAL,
                confidence INTEGER,
                vote_count INTEGER,
                recent_form_score REAL,
                actual_outcome INTEGER,
                decision_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(ky, loto)
            )
        """)
        
        # Create model_performance_log table
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS model_performance_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                log_date DATE NOT NULL,
                model_version TEXT,
                f1_score REAL,
                accuracy REAL,
                training_type TEXT,
                training_duration_seconds INTEGER,
                notes TEXT
            )
        """)
        
        conn.commit()
        conn.close()
        
        print("‚úÖ Phase 3 database tables created successfully!")
        print("   - meta_learning_history: For storing predictions and outcomes")
        print("   - model_performance_log: For tracking model performance over time")
        return True
        
    except Exception as e:
        print(f"‚ùå Error creating Phase 3 tables: {e}")
        import traceback
        traceback.print_exc()
        return False


def retrain_model_with_14_features(use_hyperparameter_tuning=False):
    """
    Retrain the AI model with all 14 features (including new F13 and F14).
    
    Args:
        use_hyperparameter_tuning: If True, performs grid search for optimal hyperparameters
    """
    print("\n" + "=" * 80)
    print("Step 2: Retraining AI Model with 14 Features")
    print("=" * 80)
    print(f"Hyperparameter Tuning: {'ENABLED' if use_hyperparameter_tuning else 'DISABLED'}")
    print()
    
    try:
        from logic.data_repository import load_data_ai_from_db
        from logic.ai_feature_extractor import _get_daily_bridge_predictions
        from logic.ml_model import train_ai_model
        
        # Load data
        print("Loading lottery data from database...")
        all_data_ai, msg = load_data_ai_from_db()
        if all_data_ai is None:
            print(f"‚ùå Error loading data: {msg}")
            return False
        print(f"‚úÖ Loaded {len(all_data_ai)} periods of data")
        
        # Extract features
        print("\nExtracting features for all periods (including F13 and F14)...")
        print("This may take several minutes for large datasets...")
        daily_bridge_predictions = _get_daily_bridge_predictions(all_data_ai)
        print(f"‚úÖ Feature extraction complete for {len(daily_bridge_predictions)} periods")
        
        # Train model
        print("\nTraining AI model with 14 features...")
        if use_hyperparameter_tuning:
            print("‚ö†Ô∏è  Hyperparameter tuning is enabled - this will take longer but find optimal parameters")
        
        start_time = datetime.now()
        success, result_msg = train_ai_model(
            all_data_ai,
            daily_bridge_predictions,
            use_hyperparameter_tuning=use_hyperparameter_tuning
        )
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        if success:
            print(f"\n‚úÖ {result_msg}")
            print(f"‚è±Ô∏è  Training completed in {duration:.1f} seconds ({duration / 60:.1f} minutes)")
            
            # Log to database
            try:
                from logic.db_manager import get_db_connection
                conn = get_db_connection()
                cursor = conn.cursor()

                cursor.execute("""
                    INSERT INTO model_performance_log
                    (log_date, model_version, training_type, training_duration_seconds, notes)
                    VALUES (?, ?, ?, ?, ?)
                """, (
                    datetime.now().date(),
                    'V7.7-Phase2-14Features',
                    'full_with_tuning' if use_hyperparameter_tuning else 'full',
                    int(duration),
                    result_msg
                ))
                conn.commit()
                conn.close()
                print("‚úÖ Training log saved to database")
            except Exception as log_error:
                print(f"‚ö†Ô∏è  Could not log training to database: {log_error}")
            
            return True
        else:
            print(f"\n‚ùå Training failed: {result_msg}")
            return False
            
    except Exception as e:
        print(f"\n‚ùå Error during model training: {e}")
        import traceback
        traceback.print_exc()
        return False


def verify_model():
    """
    Verify that the model is correctly saved and can be loaded.
    """
    print("\n" + "=" * 80)
    print("Step 3: Verifying Model")
    print("=" * 80)
    
    try:
        import os
        from logic.ml_model import MODEL_FILE_PATH, SCALER_FILE_PATH
        
        # Check if model files exist
        if not os.path.exists(MODEL_FILE_PATH):
            print(f"‚ùå Model file not found: {MODEL_FILE_PATH}")
            return False
        
        if not os.path.exists(SCALER_FILE_PATH):
            print(f"‚ùå Scaler file not found: {SCALER_FILE_PATH}")
            return False
        
        print(f"‚úÖ Model file exists: {MODEL_FILE_PATH}")
        print(f"‚úÖ Scaler file exists: {SCALER_FILE_PATH}")
        
        # Try to load the model
        import joblib
        joblib.load(MODEL_FILE_PATH)  # Verify model can be loaded
        scaler = joblib.load(SCALER_FILE_PATH)
        
        # Check feature count
        if hasattr(scaler, 'n_features_in_'):
            n_features = scaler.n_features_in_
            print(f"‚úÖ Model expects {n_features} features")
            if n_features == 14:
                print("‚úÖ Correct! Model is configured for 14 features (F1-F14)")
            else:
                print(f"‚ö†Ô∏è  Warning: Expected 14 features but model has {n_features}")
        
        print("\n‚úÖ Model verification successful!")
        return True
        
    except Exception as e:
        print(f"\n‚ùå Error verifying model: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    parser = argparse.ArgumentParser(
        description='V7.7 Phase 2 Finalization - Retrain model with 14 features',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Basic retraining (faster, uses default parameters)
  python scripts/v77_phase2_finalize.py
  
  # With hyperparameter tuning (recommended, but slower)
  python scripts/v77_phase2_finalize.py --hyperparameter-tuning
        """
    )
    parser.add_argument(
        '--hyperparameter-tuning',
        action='store_true',
        help='Enable hyperparameter tuning (recommended for best results)'
    )
    parser.add_argument(
        '--skip-db-setup',
        action='store_true',
        help='Skip database table creation (if already done)'
    )
    
    args = parser.parse_args()

    print("=" * 80)
    print("V7.7 PHASE 2 FINALIZATION")
    print("=" * 80)
    print("This script will:")
    print("1. Create Phase 3 database tables (if not skipped)")
    print("2. Retrain AI model with 14 features (F1-F14)")
    print("3. Verify the model is correctly saved")
    print("=" * 80)
    
    # Step 1: Create Phase 3 database tables
    if not args.skip_db_setup:
        if not create_phase3_database_table():
            print("\n‚ö†Ô∏è  Database setup failed, but continuing with training...")
    else:
        print("\n‚è≠Ô∏è  Skipping database setup (--skip-db-setup)")
    
    # Step 2: Retrain model
    if not retrain_model_with_14_features(use_hyperparameter_tuning=args.hyperparameter_tuning):
        print("\n‚ùå Phase 2 finalization FAILED")
        print("Please check the error messages above and try again.")
        return 1
    
    # Step 3: Verify model
    if not verify_model():
        print("\n‚ö†Ô∏è  Model verification failed, but training completed")
        print("Please manually verify the model files exist and are correct.")
    
    print("\n" + "=" * 80)
    print("‚úÖ PHASE 2 FINALIZATION COMPLETE!")
    print("=" * 80)
    print("\nNext Steps:")
    print("1. Test the model with predictions to ensure 14 features work correctly")
    print("2. Begin collecting prediction data for Phase 3 Meta-Learner")
    print("3. After collecting 100+ periods, proceed with Phase 3 implementation")
    print("\nFor Phase 3 details, see: DOC/V77_PHASE3_DESIGN.md")
    print("=" * 80)
    
    return 0


if __name__ == '__main__':
    try:
        exit_code = main()
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Script interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\n\n‚ùå Unexpected error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


--------------------------------------------------

=== FILE: scripts\v77_phase3_check_progress.py ===
#!/usr/bin/env python3
"""
V7.7 Phase 3 Data Collection Progress Checker

This script checks the progress of data collection for Phase 3 and provides
status updates on when the system will be ready for Meta-Learner training.

Usage:
    python scripts/v77_phase3_check_progress.py
"""

import sys
import os
from datetime import datetime
# Add parent directory to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))


def print_header(text):
    """Print a formatted header."""
    print("\n" + "=" * 80)
    print(text)
    print("=" * 80)


def print_progress_bar(percentage, width=50):
    """Print a progress bar."""
    filled = int(width * percentage / 100)
    bar = "‚ñà" * filled + "‚ñë" * (width - filled)
    print(f"[{bar}] {percentage:.1f}%")


def check_data_collection_progress():
    """Check and display Phase 3 data collection progress."""
    print_header("V7.7 PHASE 3 DATA COLLECTION PROGRESS")
    
    try:
        from logic.phase3_data_collector import get_collector
        
        collector = get_collector()
        stats = collector.get_collection_stats()
        
        print("\nüìä Collection Statistics:")
        print("   Total Predictions Logged: {:,}".format(stats['total_predictions']))
        print("   Predictions with Outcomes: {:,}".format(stats['predictions_with_outcomes']))
        print("   Unique Periods Collected: {}".format(stats['unique_periods']))
        
        if stats['oldest_period'] and stats['newest_period']:
            print("   Oldest Period: {}".format(stats['oldest_period']))
            print("   Newest Period: {}".format(stats['newest_period']))
        
        print("\nüìà Progress to Phase 3 Readiness:")
        print("   Required Periods: 100")
        print("   Current Periods: {}".format(stats['unique_periods']))
        print("   Remaining: {}".format(max(0, 100 - stats['unique_periods'])))
        print()
        print_progress_bar(stats['progress_percentage'])
        
        if stats['ready_for_training']:
            print("\n‚úÖ READY FOR PHASE 3!")
            print("   You have collected enough data to train the Meta-Learner.")
            print("   Next step: Run Phase 3 implementation")
            print("   Command: python scripts/v77_phase3_implement.py")
        else:
            remaining = 100 - stats['unique_periods']
            print("\n‚è≥ NOT YET READY")
            print("   Need {} more periods of data collection".format(remaining))
            print("   Estimated time: {} days (if collecting daily)".format(remaining))
            print("\nüí° What to do:")
            print("   1. Continue running the system normally")
            print("   2. Predictions will be logged automatically")
            print("   3. Check progress periodically with this script")
            print("   4. Once ready, proceed to Phase 3 implementation")
        
        collector.close()
        
    except Exception as e:
        print(f"\n‚ùå Error checking progress: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True


def check_database_tables():
    """Check if Phase 3 database tables exist."""
    print_header("DATABASE TABLE STATUS")
    
    try:
        import sqlite3
        from logic.db_manager import DB_NAME
        
        conn = sqlite3.connect(DB_NAME)
        cursor = conn.cursor()
        
        # Check meta_learning_history table
        cursor.execute("""
            SELECT name FROM sqlite_master
            WHERE type='table' AND name='meta_learning_history'
        """)
        meta_table_exists = cursor.fetchone() is not None

        # Check model_performance_log table
        cursor.execute("""
            SELECT name FROM sqlite_master
            WHERE type='table' AND name='model_performance_log'
        """)
        perf_table_exists = cursor.fetchone() is not None
        
        print("\nPhase 3 Database Tables:")
        print("   meta_learning_history: {}".format('‚úÖ Exists' if meta_table_exists else '‚ùå Missing'))
        print("   model_performance_log: {}".format('‚úÖ Exists' if perf_table_exists else '‚ùå Missing'))
        
        if not meta_table_exists or not perf_table_exists:
            print("\n‚ö†Ô∏è  Warning: Phase 3 tables are missing!")
            print("   Run this command to create them:")
            print("   python scripts/v77_phase2_finalize.py --skip-db-setup")
            return False
        
        conn.close()
        return True
        
    except Exception as e:
        print(f"\n‚ùå Error checking database: {e}")
        import traceback
        traceback.print_exc()
        return False


def show_integration_guide():
    """Show guide for integrating data collection."""
    print_header("INTEGRATION GUIDE")
    
    print("""
üìù How to Integrate Data Collection:

The Phase 3 data collector is ready to use. Integrate it into your dashboard
or prediction workflow:

1. After making predictions:

    from logic.phase3_data_collector import log_prediction
    
    for loto in range(100):
        log_prediction(
            ky=current_ky,
            loto=str(loto).zfill(2),
            ai_probability=ai_probs[loto],
            manual_score=manual_scores[loto],
            confidence=confidence_levels[loto],
            vote_count=vote_counts[loto],
            recent_form_score=recent_form_scores.get(loto, 0.0)
        )

2. After actual results are known:

    from logic.phase3_data_collector import log_outcome
    from logic.bridges.bridges_classic import getAllLoto_V30
    
    # Get actual results
    lotos_appeared = getAllLoto_V30(result_row)
    
    # Log outcomes
    for loto in range(100):
        loto_str = str(loto).zfill(2)
        outcome = 1 if loto_str in lotos_appeared else 0
        log_outcome(ky=current_ky, loto=loto_str, actual_outcome=outcome)

3. Or use batch methods:

    from logic.phase3_data_collector import get_collector
    
    collector = get_collector()
    
    # Log batch of predictions
    predictions = [
        {'loto': '00', 'ai_probability': 45.2, 'manual_score': 7.5, ...},
        {'loto': '01', 'ai_probability': 32.1, 'manual_score': 5.0, ...},
        # ...
    ]
    collector.log_batch_predictions(ky=current_ky, predictions_list=predictions)
    
    # Log batch of outcomes
    lotos_appeared = ['00', '15', '27', ...]
    collector.log_batch_outcomes(ky=current_ky, lotos_appeared=lotos_appeared)

For more details, see: logic/phase3_data_collector.py
    """)


def main():
    """Main function."""
    print("=" * 80)
    print("V7.7 PHASE 3 PREPARATION")
    print("Data Collection Progress Checker")
    print("=" * 80)
    print(f"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Check database tables
    if not check_database_tables():
        print("\n‚ö†Ô∏è  Setup incomplete. Please fix database issues first.")
        return 1
    
    # Check data collection progress
    if not check_data_collection_progress():
        print("\n‚ö†Ô∏è  Could not check progress. Please verify setup.")
        return 1
    
    # Show integration guide
    show_integration_guide()
    
    print("\n" + "=" * 80)
    print("For more information:")
    print("   Phase 3 Design: DOC/V77_PHASE3_DESIGN.md")
    print("   Data Collector: logic/phase3_data_collector.py")
    print("=" * 80)
    
    return 0


if __name__ == '__main__':
    try:
        exit_code = main()
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Script interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\n\n‚ùå Unexpected error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


--------------------------------------------------

=== FILE: scripts\v77_phase3_implement.py ===
#!/usr/bin/env python3
"""
V7.7 Phase 3 Implementation Script

This script implements Phase 3 by training and activating:
1. Meta-Learner - Second-level AI combining predictions
2. Adaptive Trainer - Automatic retraining system
3. Performance Monitor - Performance tracking and alerts

Prerequisites:
- Phase 2 completed (14 features model trained)
- 100+ periods of prediction data collected

Usage:
    python scripts/v77_phase3_implement.py [--train-meta-learner] [--enable-adaptive]
"""

import sys
import os
from datetime import datetime
# Add parent directory to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))


def print_header(text):
    """Print formatted header."""
    print("\n" + "=" * 80)
    print(text)
    print("=" * 80)


def check_prerequisites():
    """Check if prerequisites are met."""
    print_header("CHECKING PREREQUISITES")

    try:
        from logic.phase3_data_collector import get_collector

        collector = get_collector()
        stats = collector.get_collection_stats()

        print("\nüìä Data Collection Status:")
        print("   Periods Collected: {}".format(stats['unique_periods']))
        print("   Ready for Phase 3: {}".format('‚úÖ YES' if stats['ready_for_training'] else '‚ùå NO'))

        if not stats['ready_for_training']:
            print("\n‚ö†Ô∏è  WARNING: Only {} periods collected".format(stats['unique_periods']))
            print("   Recommended: 100+ periods for reliable Meta-Learner training")
            print("   Continue anyway? (y/N): ", end='')
            response = input().strip().lower()
            if response != 'y':
                print("\n‚ùå Phase 3 implementation cancelled")
                return False

        collector.close()
        return True

    except Exception as e:
        print(f"\n‚ùå Error checking prerequisites: {e}")
        return False


def train_meta_learner():
    """Train the Meta-Learner on collected data."""
    print_header("TRAINING META-LEARNER")

    try:
        from logic.meta_learner import train_meta_learner_from_db

        print("\nTraining Meta-Learner from collected data...")
        print("This may take a few minutes...\n")

        success, message, meta_learner = train_meta_learner_from_db()

        if success:
            print(f"\n‚úÖ {message}")

            # Show feature importance
            if meta_learner:
                print("\nüìä Feature Importance:")
                importance = meta_learner.get_feature_importance()
                sorted_features = sorted(importance.items(), key=lambda x: abs(x[1]), reverse=True)
                for i, (feature, coef) in enumerate(sorted_features[:5], 1):
                    print(f"   {i}. {feature}: {coef:+.4f}")

            return True
        else:
            print(f"\n‚ùå {message}")
            return False

    except Exception as e:
        print(f"\n‚ùå Error training Meta-Learner: {e}")
        import traceback
        traceback.print_exc()
        return False


def setup_adaptive_trainer(enable=False):
    """Setup Adaptive Trainer."""
    print_header("SETTING UP ADAPTIVE TRAINER")

    try:
        from logic.adaptive_trainer import get_adaptive_trainer

        config = {
            'ROLLING_WINDOW_SIZE': 400,
            'MIN_RETRAINING_GAP_DAYS': 7,
            'F1_DEGRADATION_THRESHOLD': 0.02,
            'FULL_RETRAIN_INTERVAL_DAYS': 30,
            'ENABLE_AUTO_RETRAIN': enable
        }

        trainer = get_adaptive_trainer(config)
        status = trainer.get_status()

        print("\n‚öôÔ∏è  Adaptive Trainer Configuration:")
        print("   Auto-Retrain: {}".format('‚úÖ ENABLED' if status['enabled'] else '‚ùå DISABLED'))
        print("   Rolling Window: {} periods".format(status['rolling_window_size']))
        print("   Min Gap: {} days".format(status['min_gap_days']))
        print("   F1 Threshold: {:.2%}".format(status['f1_threshold']))
        print("   Full Retrain Interval: {} days".format(status['full_retrain_interval']))

        if enable:
            print("\n‚úÖ Adaptive Trainer is ACTIVE")
            print("   The system will automatically retrain when needed")
        else:
            print("\n‚ö†Ô∏è  Adaptive Trainer is INACTIVE")
            print("   Use --enable-adaptive flag to activate")

        return True

    except Exception as e:
        print(f"\n‚ùå Error setting up Adaptive Trainer: {e}")
        import traceback
        traceback.print_exc()
        return False


def setup_performance_monitor():
    """Setup Performance Monitor."""
    print_header("SETTING UP PERFORMANCE MONITOR")

    try:
        from logic.performance_monitor import get_performance_monitor

        monitor = get_performance_monitor()

        # Try to load historical data
        success, msg = monitor.load_from_database(days=30)
        if success:
            print(f"\n‚úÖ {msg}")
        else:
            print(f"\n‚ö†Ô∏è  {msg}")

        # Get summary
        summary = monitor.get_performance_summary()

        if summary['count'] > 0:
            print("\nüìà Performance Summary:")
            print("   Records: {}".format(summary['count']))
            print("   F1-Score Mean: {:.4f}".format(summary['f1_score']['mean']))
            print("   F1-Score Current: {:.4f}".format(summary['f1_score']['current']))
            print("   Trend: {}".format(summary['trend']))
            print("   Alerts: {}".format(summary['alerts_count']))
        else:
            print("\nüìà Performance Monitor ready (no historical data yet)")

        print("\n‚úÖ Performance Monitor is ACTIVE")
        print("   System will track model performance and detect degradation")

        return True

    except Exception as e:
        print(f"\n‚ùå Error setting up Performance Monitor: {e}")
        import traceback
        traceback.print_exc()
        return False


def show_usage_guide():
    """Show guide for using Phase 3 components."""
    print_header("PHASE 3 USAGE GUIDE")

    print("""
üéØ How to Use Phase 3 Components:

1. META-LEARNER - Enhanced Decision Making
   
   from logic.meta_learner import load_meta_learner
   
   meta_learner = load_meta_learner()
   if meta_learner:
       final_prob, decision = meta_learner.predict_final_decision(
           ai_prob=45.2,
           manual_score=7.5,
           confidence=5,
           vote_count=8,
           recent_form_score=2.0
       )
       print(f"Decision: {decision} (Probability: {final_prob:.1f}%)")

2. ADAPTIVE TRAINER - Automatic Retraining
   
   from logic.adaptive_trainer import get_adaptive_trainer
   from logic.data_repository import load_data_ai_from_db
   
   trainer = get_adaptive_trainer()
   all_data_ai, _ = load_data_ai_from_db()
   
   # Check if retrain needed and execute
   should_retrain, reason = trainer.should_retrain_incremental()
   if should_retrain:
       success, msg = trainer.incremental_retrain(all_data_ai)

3. PERFORMANCE MONITOR - Track Model Health
   
   from logic.performance_monitor import get_performance_monitor
   
   monitor = get_performance_monitor()
   
   # Record performance after predictions
   metrics = monitor.record_performance(
       date='2025-01-15',
       predictions=[1, 0, 1, ...],
       actuals=[1, 1, 0, ...]
   )
   
   # Get summary
   summary = monitor.get_performance_summary()
   print(f"F1-Score Trend: {summary['trend']}")

4. INTEGRATION - Combine All Components
   
   # In your dashboard/prediction code:
   
   # Step 1: Make predictions with Meta-Learner
   meta_learner = load_meta_learner()
   final_prob, decision = meta_learner.predict_final_decision(...)
   
   # Step 2: Check if adaptive retrain needed
   trainer = get_adaptive_trainer()
   success, msg, retrain_type = trainer.auto_retrain(all_data_ai)
   
   # Step 3: Monitor performance
   monitor = get_performance_monitor()
   monitor.record_performance(date, predictions, actuals)

For detailed documentation, see:
- DOC/V77_PHASE3_DESIGN.md - Complete architecture
- logic/meta_learner.py - Meta-Learner implementation
- logic/adaptive_trainer.py - Adaptive Trainer implementation
- logic/performance_monitor.py - Performance Monitor implementation
    """)


def main():
    """Main function."""
    import argparse

    parser = argparse.ArgumentParser(
        description='V7.7 Phase 3 Implementation - Meta-Learner and Adaptive Training',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument(
        '--train-meta-learner',
        action='store_true',
        help='Train the Meta-Learner on collected data'
    )
    parser.add_argument(
        '--enable-adaptive',
        action='store_true',
        help='Enable Adaptive Trainer for automatic retraining'
    )
    parser.add_argument(
        '--skip-checks',
        action='store_true',
        help='Skip prerequisite checks'
    )

    args = parser.parse_args()

    print("=" * 80)
    print("V7.7 PHASE 3 IMPLEMENTATION")
    print("Meta-Learner & Adaptive Training System")
    print("=" * 80)
    print(f"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

    # Check prerequisites
    if not args.skip_checks:
        if not check_prerequisites():
            return 1

    success_count = 0
    total_steps = 3

    # Step 1: Train Meta-Learner (if requested)
    if args.train_meta_learner:
        if train_meta_learner():
            success_count += 1
    else:
        print_header("META-LEARNER TRAINING")
        print("\n‚è≠Ô∏è  Skipped (use --train-meta-learner to train)")
        print("   If already trained, Meta-Learner is ready to use")

    # Step 2: Setup Adaptive Trainer
    if setup_adaptive_trainer(enable=args.enable_adaptive):
        success_count += 1

    # Step 3: Setup Performance Monitor
    if setup_performance_monitor():
        success_count += 1

    # Show usage guide
    show_usage_guide()

    # Summary
    print("\n" + "=" * 80)
    if success_count == total_steps:
        print("‚úÖ PHASE 3 IMPLEMENTATION COMPLETE!")
    else:
        print(f"‚ö†Ô∏è  PHASE 3 PARTIALLY COMPLETE ({success_count}/{total_steps} steps)")
    print("=" * 80)

    print("\nNext Steps:")
    print("1. Integrate Meta-Learner into your dashboard for better decisions")
    print("2. Monitor system performance regularly")
    print("3. Let Adaptive Trainer handle retraining automatically")
    print("\nFor help, see: DOC/V77_PHASE3_DESIGN.md")
    print("=" * 80)

    return 0 if success_count == total_steps else 1


if __name__ == '__main__':
    try:
        exit_code = main()
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Script interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\n\n‚ùå Unexpected error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


--------------------------------------------------

=== FILE: scripts\validate_bo_scoring.py ===
#!/usr/bin/env python3
"""
Script to validate Set (B·ªô) scoring against historical database.

This script analyzes historical lottery data to:
1. Identify duplicate sets (b·ªô k√©p) and their performance
2. Calculate trending patterns for all sets
3. Validate scoring bonuses match actual historical patterns
4. Generate statistics on recently appeared sets

Usage:
    python scripts/validate_bo_scoring.py [--days N] [--output FILE]
"""

import sys
import os
import argparse
from datetime import datetime, timedelta

# Add parent directory to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from logic.db_manager import get_results_recent_n_ky
from logic.de_utils import BO_SO_DE, get_gdb_last_2


def is_duplicate_set(bo_name):
    """Check if a set is a duplicate set (b·ªô k√©p)."""
    return bo_name in {"00", "11", "22", "33", "44"}


def get_bo_for_number(number_str):
    """Find which set a number belongs to."""
    for bo_name, numbers in BO_SO_DE.items():
        if number_str in numbers:
            return bo_name
    return None


def analyze_historical_data(days=90):
    """
    Analyze historical data to validate scoring bonuses.
    
    Returns:
        dict: Statistics for each set including:
            - frequency: How many times appeared
            - last_appearance: Days since last appearance (gan)
            - is_duplicate: Whether it's a duplicate set
            - trending_score: Frequency in last 30 days
    """
    print(f"\n{'='*70}")
    print(f"üìä VALIDATING SET (B·ªò) SCORING AGAINST HISTORICAL DATA")
    print(f"{'='*70}\n")
    
    # Get historical data
    print(f"üîç Fetching last {days} lottery results...")
    recent_data = get_results_recent_n_ky(days)
    
    if not recent_data:
        print("‚ùå No historical data found!")
        return None
    
    print(f"‚úÖ Loaded {len(recent_data)} lottery results\n")
    
    # Initialize statistics
    bo_stats = {}
    for bo_name in BO_SO_DE.keys():
        bo_stats[bo_name] = {
            "name": bo_name,
            "is_duplicate": is_duplicate_set(bo_name),
            "appearances": [],  # List of (ky, date, days_ago)
            "frequency_30d": 0,
            "frequency_60d": 0,
            "frequency_90d": 0,
            "last_gan": days,  # Default to max if never appeared
        }
    
    # Analyze each result
    today = datetime.now()
    for idx, row in enumerate(recent_data):
        # Extract the winning number (last 2 digits of special prize)
        winning_number = get_gdb_last_2(row)
        if not winning_number:
            continue
        
        # Find which set this number belongs to
        bo_name = get_bo_for_number(winning_number)
        if not bo_name:
            continue
        
        # Calculate days ago
        try:
            date_str = str(row[0])  # Assuming first column is date
            # Try parsing date (may need adjustment based on actual format)
            result_date = datetime.strptime(date_str.split()[0], "%Y-%m-%d")
            days_ago = (today - result_date).days
        except:
            days_ago = idx  # Fallback: use index as approximation
        
        # Record appearance
        bo_stats[bo_name]["appearances"].append({
            "ky": row[1] if len(row) > 1 else "N/A",
            "number": winning_number,
            "days_ago": days_ago
        })
        
        # Count frequencies
        if days_ago <= 30:
            bo_stats[bo_name]["frequency_30d"] += 1
        if days_ago <= 60:
            bo_stats[bo_name]["frequency_60d"] += 1
        if days_ago <= 90:
            bo_stats[bo_name]["frequency_90d"] += 1
    
    # Calculate last gan (days since last appearance)
    for bo_name, stats in bo_stats.items():
        if stats["appearances"]:
            stats["last_gan"] = min(app["days_ago"] for app in stats["appearances"])
        else:
            stats["last_gan"] = days
    
    return bo_stats


def print_validation_report(bo_stats):
    """Print a comprehensive validation report."""
    if not bo_stats:
        print("‚ùå No statistics to report")
        return
    
    print(f"\n{'='*70}")
    print("üìà SET (B·ªò) PERFORMANCE ANALYSIS")
    print(f"{'='*70}\n")
    
    # Separate duplicate and regular sets
    duplicate_sets = {k: v for k, v in bo_stats.items() if v["is_duplicate"]}
    regular_sets = {k: v for k, v in bo_stats.items() if not v["is_duplicate"]}
    
    # === DUPLICATE SETS (B·ªò K√âP) ===
    print("üîµ DUPLICATE SETS (B·ªò K√âP) - 4 numbers each")
    print(f"{'‚îÄ'*70}")
    print(f"{'Set':<6} {'Freq30':<8} {'Freq60':<8} {'Freq90':<8} {'Last Gan':<10} {'Bonus Valid?':<12}")
    print(f"{'‚îÄ'*70}")
    
    for bo_name in sorted(duplicate_sets.keys()):
        stats = duplicate_sets[bo_name]
        bonus_valid = "‚úÖ YES" if stats["frequency_30d"] > 0 or stats["last_gan"] < 15 else "‚ö†Ô∏è  LOW"
        print(f"{bo_name:<6} {stats['frequency_30d']:<8} {stats['frequency_60d']:<8} "
              f"{stats['frequency_90d']:<8} {stats['last_gan']:<10} {bonus_valid:<12}")
    
    # === REGULAR SETS ===
    print(f"\nüîµ REGULAR SETS (B·ªò TH∆Ø·ªúNG) - 8 numbers each")
    print(f"{'‚îÄ'*70}")
    print(f"{'Set':<6} {'Freq30':<8} {'Freq60':<8} {'Freq90':<8} {'Last Gan':<10} {'Trending?':<12}")
    print(f"{'‚îÄ'*70}")
    
    for bo_name in sorted(regular_sets.keys()):
        stats = regular_sets[bo_name]
        is_trending = "‚úÖ YES" if stats["frequency_30d"] >= 3 else "‚îÄ"
        print(f"{bo_name:<6} {stats['frequency_30d']:<8} {stats['frequency_60d']:<8} "
              f"{stats['frequency_90d']:<8} {stats['last_gan']:<10} {is_trending:<12}")
    
    # === SCORING VALIDATION ===
    print(f"\n{'='*70}")
    print("üéØ SCORING BONUS VALIDATION")
    print(f"{'='*70}\n")
    
    # Check duplicate set bonus
    dup_avg_freq = sum(s["frequency_30d"] for s in duplicate_sets.values()) / len(duplicate_sets)
    reg_avg_freq = sum(s["frequency_30d"] for s in regular_sets.values()) / len(regular_sets)
    
    print(f"1. DUPLICATE SET BONUS (+2.0 points):")
    print(f"   - Duplicate sets avg frequency: {dup_avg_freq:.2f} times/30d")
    print(f"   - Regular sets avg frequency: {reg_avg_freq:.2f} times/30d")
    print(f"   - Bonus justified: {'‚úÖ YES' if dup_avg_freq >= reg_avg_freq * 0.8 else '‚ö†Ô∏è  REVIEW'}")
    print(f"   - Rationale: Duplicate sets have 4 numbers vs 8, but should appear often enough")
    
    # Check recent appearance bonus
    recent_count = sum(1 for s in bo_stats.values() if s["last_gan"] < 7)
    print(f"\n2. RECENT APPEARANCE BONUS (+1.5 points for gan < 7 days):")
    print(f"   - Sets with gan < 7 days: {recent_count}/{len(bo_stats)}")
    print(f"   - Bonus justified: ‚úÖ YES (Recent patterns indicate near-term likelihood)")
    
    # Check trending bonus
    trending_count = sum(1 for s in bo_stats.values() if s["frequency_30d"] >= 3)
    print(f"\n3. TRENDING BONUS (+1.0 points for freq ‚â• 3 in 30 days):")
    print(f"   - Trending sets (freq ‚â• 3): {trending_count}/{len(bo_stats)}")
    print(f"   - Bonus justified: ‚úÖ YES (High frequency indicates hot pattern)")
    
    # Check gan penalty reduction
    print(f"\n4. GAN PENALTY REDUCTION (0.5 ‚Üí 0.3):")
    print(f"   - Old penalty: Heavily penalized long-absent sets")
    print(f"   - New penalty: Reduced by 40% (0.5 ‚Üí 0.3)")
    print(f"   - Rationale: ‚úÖ JUSTIFIED - Sets can return after long absence")
    
    # === TOP PERFORMERS ===
    print(f"\n{'='*70}")
    print("üèÜ TOP PERFORMING SETS")
    print(f"{'='*70}\n")
    
    # Calculate scores using new formula
    scored_sets = []
    for bo_name, stats in bo_stats.items():
        f = stats["frequency_30d"]
        g = stats["last_gan"]
        
        # New scoring formula
        base_score = f * 1.5
        gan_penalty = float(g) * 0.3
        kep_bonus = 2.0 if stats["is_duplicate"] else 0.0
        recent_bonus = 1.5 if g < 7 else 0.0
        trending_bonus = 1.0 if f >= 3 else 0.0
        
        score = base_score - gan_penalty + kep_bonus + recent_bonus + trending_bonus
        
        scored_sets.append({
            "name": bo_name,
            "score": score,
            "freq": f,
            "gan": g,
            "is_kep": stats["is_duplicate"]
        })
    
    scored_sets.sort(key=lambda x: x["score"], reverse=True)
    
    print(f"{'Rank':<6} {'Set':<6} {'Type':<10} {'Score':<8} {'Freq30':<8} {'Gan':<8}")
    print(f"{'‚îÄ'*70}")
    for rank, s in enumerate(scored_sets[:10], 1):
        bo_type = "K√©p" if s["is_kep"] else "Th∆∞·ªùng"
        print(f"{rank:<6} {s['name']:<6} {bo_type:<10} {s['score']:<8.1f} {s['freq']:<8} {s['gan']:<8}")
    
    print(f"\n{'='*70}\n")


def main():
    parser = argparse.ArgumentParser(description="Validate Set (B·ªô) scoring against historical data")
    parser.add_argument("--days", type=int, default=90, help="Number of days to analyze (default: 90)")
    parser.add_argument("--output", type=str, help="Output file for detailed results (optional)")
    
    args = parser.parse_args()
    
    # Analyze data
    bo_stats = analyze_historical_data(days=args.days)
    
    if bo_stats:
        # Print report
        print_validation_report(bo_stats)
        
        # Save to file if requested
        if args.output:
            print(f"üíæ Saving detailed results to {args.output}...")
            # Implementation for file output can be added here
            print(f"‚úÖ Results saved\n")
    else:
        print("‚ùå Failed to analyze data")
        sys.exit(1)


if __name__ == "__main__":
    main()


--------------------------------------------------

=== FILE: scripts\verify_analysis_data.py ===
# T√™n file: scripts/verify_real_scoring.py
# (PHI√äN B·∫¢N V3.8.3 - FIX IMPORT PATH)

import sys
import os
import sqlite3
import time

# Th√™m ƒë∆∞·ªùng d·∫´n project root
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

try:
    from logic.db_manager import DB_NAME
    from logic.data_repository import load_data_ai_from_db
    
    # [QUAN TR·ªåNG] Fix ƒë∆∞·ªùng d·∫´n import dashboard_scorer
    try:
        from logic.analytics.dashboard_scorer import prepare_daily_features, get_top_scored_pairs
    except ImportError:
        from logic.dashboard_analytics import prepare_daily_features, get_top_scored_pairs

    # [QUAN TR·ªåNG] Fix ƒë∆∞·ªùng d·∫´n import de_bridge_scanner (n·∫±m trong bridges)
    from logic.bridges.de_bridge_scanner import run_de_scanner
    
    from logic.de_analytics import calculate_number_scores, analyze_market_trends
except ImportError as e:
    print(f"‚ùå L·ªói Import Ban ƒê·∫ßu: {e}")
    sys.exit(1)

def verify_real_lo_scoring():
    print("\n" + "="*50)
    print("üöÄ KI·ªÇM TRA SCORING L√î V3.8 (REAL DATA)")
    print("="*50)
    
    # 1. T·∫£i d·ªØ li·ªáu
    print("... ƒêang t·∫£i d·ªØ li·ªáu t·ª´ DB...")
    all_data, msg = load_data_ai_from_db(DB_NAME)
    if not all_data:
        print("‚ùå L·ªñI: Kh√¥ng c√≥ d·ªØ li·ªáu A:I trong DB.")
        return

    # L·∫•y 500 k·ª≥ g·∫ßn nh·∫•t ƒë·ªÉ x·ª≠ l√Ω nhanh
    data_slice = all_data[-500:]
    last_ky = data_slice[-1][0]
    print(f"‚úÖ ƒê√£ t·∫£i {len(data_slice)} k·ª≥. K·ª≥ cu·ªëi: {last_ky}")

    # 2. Chu·∫©n b·ªã Features (M√¥ ph·ªèng Dashboard)
    print("... ƒêang t√≠nh to√°n Features (Stats, Consensus, K2N)...")
    t0 = time.time()
    try:
        # G·ªçi h√†m chu·∫©n b·ªã d·ªØ li·ªáu (gi·ªëng h·ªát UI)
        features = prepare_daily_features(data_slice, len(data_slice)-1)
        
        if not features:
            print("‚ö†Ô∏è C·∫£nh b√°o: Kh√¥ng t·∫°o ƒë∆∞·ª£c features (C√≥ th·ªÉ thi·∫øu d·ªØ li·ªáu c·∫ßu).")
            return

        # 3. T√≠nh ƒëi·ªÉm
        print("... ƒêang ch·∫°y Scoring Engine...")
        scores = get_top_scored_pairs(
            features["stats_n_day"],
            features["consensus"],
            features["high_win"],
            features["pending_k2n"],
            features["gan_stats"],
            features["top_memory"],
            features.get("ai_predictions"),
            features.get("recent_data")
        )
        t1 = time.time()
        print(f"‚úÖ T√≠nh to√°n xong trong {t1-t0:.2f}s.")

        # 4. Hi·ªÉn th·ªã k·∫øt qu·∫£
        print("\nüèÜ TOP 5 L√î ƒêI·ªÇM CAO NH·∫§T:")
        print(f"{'C·∫∑p S·ªë':<10} | {'ƒêi·ªÉm':<8} | {'L√Ω do ch√≠nh'}")
        print("-" * 60)
        
        if scores:
            for item in scores[:5]:
                # R√∫t g·ªçn l√Ω do ƒë·ªÉ hi·ªÉn th·ªã
                reasons = str(item.get('reasons', ''))
                reason_short = reasons[:50] + "..." if len(reasons) > 50 else reasons
                print(f"{item.get('pair', '??'):<10} | {item.get('score', 0):<8.1f} | {reason_short}")
        else:
            print("(Kh√¥ng c√≥ d·ªØ li·ªáu ƒëi·ªÉm - C√≥ th·ªÉ ch∆∞a 'D√≤ C·∫ßu' ho·∫∑c ch∆∞a 'L√†m M·ªõi Cache')")

    except Exception as e:
        print(f"‚ùå L·ªñI LOGIC L√î: {e}")
        import traceback
        traceback.print_exc()

def verify_real_de_scoring():
    print("\n" + "="*50)
    print("üöÄ KI·ªÇM TRA SCORING ƒê·ªÄ V3.8 (REAL DATA)")
    print("="*50)
    
    # 1. T·∫£i d·ªØ li·ªáu
    all_data, _ = load_data_ai_from_db(DB_NAME)
    if not all_data: return
    data_slice = all_data[-100:] # L·∫•y 100 k·ª≥ cho ƒê·ªÅ
    
    # 2. Qu√©t c·∫ßu & Th·ªëng k√™
    print("... ƒêang qu√©t c·∫ßu ƒê·ªÅ & Ph√¢n t√≠ch th·ªã tr∆∞·ªùng...")
    try:
        # Qu√©t c·∫ßu
        count, bridges = run_de_scanner(data_slice)
        print(f"‚úÖ T√¨m th·∫•y {len(bridges)} c·∫ßu ƒê·ªÅ (Scanner V3.3).")
        
        # Th·ªëng k√™ th·ªã tr∆∞·ªùng
        market_stats = analyze_market_trends(data_slice)
        
        # 3. T√≠nh ƒëi·ªÉm
        print("... ƒêang ch·∫°y Scoring Engine ƒê·ªÅ...")
        scores = calculate_number_scores(bridges, market_stats)
        
        # 4. Hi·ªÉn th·ªã k·∫øt qu·∫£
        print("\nüèÜ TOP 5 S·ªê ƒê·ªÄ ƒêI·ªÇM CAO NH·∫§T:")
        print(f"{'S·ªë':<6} | {'ƒêi·ªÉm':<8} | {'Ghi ch√∫'}")
        print("-" * 40)
        
        if scores:
            for item in scores[:5]:
                # Item l√† tuple (s·ªë, ƒëi·ªÉm) do h√†m sort tr·∫£ v·ªÅ
                num = item[0]
                score = item[1]
                print(f"{num:<6} | {score:<8.1f} |")
        else:
            print("(Kh√¥ng c√≥ d·ªØ li·ªáu ƒëi·ªÉm)")
            
    except Exception as e:
        print(f"‚ùå L·ªñI LOGIC ƒê·ªÄ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    verify_real_lo_scoring()
    verify_real_de_scoring()
    print("\n" + "="*50)
    print("üëâ N·∫æU K·∫æT QU·∫¢ HI·ªÜN RA ƒê·∫¶Y ƒê·ª¶ -> H·ªÜ TH·ªêNG ƒê√É S·∫¥N S√ÄNG 100%.")

--------------------------------------------------

=== FILE: scripts\verify_fix.py ===
# T√™n file: scripts/verify_fix.py
import sys
import os

# --- C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N ---
# L·∫•y ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c hi·ªán t·∫°i (scripts)
current_dir = os.path.dirname(os.path.abspath(__file__))
# L·∫•y ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c g·ªëc d·ª± √°n (th∆∞ m·ª•c cha c·ªßa scripts)
project_root = os.path.dirname(current_dir)
# Th√™m th∆∞ m·ª•c g·ªëc v√†o sys.path ƒë·ªÉ Python t√¨m th·∫•y 'logic'
sys.path.append(project_root)
# ---------------------------

try:
    from logic.bridges.de_bridge_scanner import DeBridgeScanner
except ImportError as e:
    print(f"L·ªñI IMPORT: {e}")
    print("H√£y ch·∫Øc ch·∫Øn b·∫°n ƒëang ch·∫°y t·ª´ th∆∞ m·ª•c g·ªëc d·ª± √°n.")
    sys.exit()

def test_logic():
    print(f">>> ƒêANG KI·ªÇM TRA T·ª™ TH∆Ø M·ª§C: {current_dir}")
    scanner = DeBridgeScanner()
    
    # Mock data: [Th·∫Øng, Th·∫Øng, Thua, Th·∫Øng, Th·∫Øng] (M·ªõi -> C≈©)
    mock_results = [True, True, False, True, True]
    print(f"D·ªØ li·ªáu gi·∫£ l·∫≠p (M·ªõi -> C≈©): {mock_results}")
    
    try:
        # G·ªçi h√†m t√≠nh to√°n (L∆∞u √Ω: N·∫øu b·∫°n ƒë√£ t√°ch h√†m n√†y ra common_utils th√¨ s·ª≠a d√≤ng n√†y)
        metrics = scanner._calculate_performance_metrics(mock_results)
        
        streak = metrics['streak']
        total_wins = metrics['total_wins']
        
        print("-" * 40)
        print(f"K·∫øt qu·∫£ Streak:     {streak} (Mong ƒë·ª£i: 2)")
        print(f"T·ªïng s·ªë ng√†y th·∫Øng: {total_wins} (Mong ƒë·ª£i: 4)")
        print("-" * 40)
        
        if streak == 2 and total_wins == 4:
            print("‚úÖ K·∫æT QU·∫¢: CH√çNH X√ÅC (Strict Mode OK)")
        else:
            print("‚ùå K·∫æT QU·∫¢: SAI (V·∫´n t√≠nh c·ªông d·ªìn)")
            
    except AttributeError:
        print("‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y h√†m '_calculate_performance_metrics' trong DeBridgeScanner.")

if __name__ == "__main__":
    test_logic()

--------------------------------------------------

=== FILE: scripts\verify_v10_optimization.py ===
# T√™n file: scripts/verify_v10_optimization.py
# M·ª•c ti√™u: Ki·ªÉm tra logic On-Demand Analysis (L√¥/ƒê·ªÅ t√°ch bi·ªát) v√† ƒëo l∆∞·ªùng hi·ªáu nƒÉng.

import sys
import os
import time
import pandas as pd

# Th√™m ƒë∆∞·ªùng d·∫´n project root ƒë·ªÉ import modules
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, project_root)

try:
    from logic.db_manager import DB_NAME
    from logic.data_repository import load_data_ai_from_db
    from services.analysis_service import AnalysisService
    
    # Gi·∫£ l·∫≠p Logger ƒë·ªÉ kh√¥ng b·ªã l·ªói khi kh·ªüi t·∫°o Service
    class MockLogger:
        def log(self, msg):
            print(f"[LOG] {msg}")

except ImportError as e:
    print(f"‚ùå L·ªói Import: {e}")
    sys.exit(1)

def measure_execution(service, all_data, lo_mode, de_mode, label):
    print(f"\n{'='*60}")
    print(f"üöÄ TEST CASE: {label}")
    print(f"   C·∫•u h√¨nh: L√¥={lo_mode}, ƒê·ªÅ={de_mode}")
    print(f"{'-'*60}")
    
    start_time = time.time()
    
    # G·ªçi h√†m ph√¢n t√≠ch
    result = service.prepare_dashboard_data(
        all_data, 
        data_limit=500, # Test v·ªõi 500 k·ª≥ ƒë·ªÉ gi·∫£ l·∫≠p th·ª±c t·∫ø
        lo_mode=lo_mode, 
        de_mode=de_mode
    )
    
    end_time = time.time()
    duration = end_time - start_time
    
    print(f"‚è±Ô∏è Th·ªùi gian th·ª±c thi: {duration:.4f} gi√¢y")
    
    # Ki·ªÉm tra d·ªØ li·ªáu tr·∫£ v·ªÅ
    verify_data(result, lo_mode, de_mode)
    
    return duration

def verify_data(result, expect_lo, expect_de):
    if not result:
        print("‚ùå L·ªñI: Kh√¥ng nh·∫≠n ƒë∆∞·ª£c k·∫øt qu·∫£ tr·∫£ v·ªÅ!")
        return

    # 1. Ki·ªÉm tra D·ªØ li·ªáu L√¥
    has_lo_data = False
    # Ki·ªÉm tra m·ªôt s·ªë key ƒë·∫∑c tr∆∞ng c·ªßa L√¥
    if result.get('stats_n_day') and result.get('top_scores'):
        has_lo_data = True
    
    # 2. Ki·ªÉm tra D·ªØ li·ªáu ƒê·ªÅ
    has_de_data = False
    if result.get('df_de') is not None and not result.get('df_de').empty:
        has_de_data = True
        
    # ƒê√°nh gi√°
    print("üìä K·∫øt qu·∫£ ki·ªÉm tra d·ªØ li·ªáu:")
    
    # Check L√¥
    if expect_lo:
        if has_lo_data: print("   ‚úÖ [L√î] C√≥ d·ªØ li·ªáu (ƒê√∫ng)")
        else: print("   ‚ùå [L√î] Thi·∫øu d·ªØ li·ªáu (Sai)")
    else:
        if not has_lo_data: print("   ‚úÖ [L√î] Kh√¥ng c√≥ d·ªØ li·ªáu (ƒê√∫ng - ƒê√£ b·ªè qua)")
        else: 
            # C√≥ th·ªÉ list r·ªóng v·∫´n ƒë∆∞·ª£c kh·ªüi t·∫°o, ki·ªÉm tra k·ªπ h∆°n ƒë·ªô d√†i
            if len(result.get('top_scores', [])) == 0:
                 print("   ‚úÖ [L√î] D·ªØ li·ªáu r·ªóng (ƒê√∫ng - ƒê√£ b·ªè qua)")
            else:
                 print("   ‚ö†Ô∏è [L√î] V·∫´n t√≠nh to√°n d·ªØ li·ªáu? (C·∫ßn ki·ªÉm tra l·∫°i)")

    # Check ƒê·ªÅ
    if expect_de:
        if has_de_data: print("   ‚úÖ [ƒê·ªÄ] C√≥ d·ªØ li·ªáu DataFrame (ƒê√∫ng)")
        else: print("   ‚ùå [ƒê·ªÄ] Thi·∫øu d·ªØ li·ªáu DataFrame (Sai)")
    else:
        if not has_de_data: print("   ‚úÖ [ƒê·ªÄ] Kh√¥ng c√≥ d·ªØ li·ªáu (ƒê√∫ng - ƒê√£ b·ªè qua)")
        else: print("   ‚ùå [ƒê·ªÄ] V·∫´n t√≠nh to√°n d·ªØ li·ªáu? (Sai)")

def main():
    print("üõ†Ô∏è B·∫ÆT ƒê·∫¶U KI·ªÇM TH·ª¨ T√çNH NƒÇNG ON-DEMAND ANALYSIS (V10.0)")
    
    # 1. Setup m√¥i tr∆∞·ªùng
    if not os.path.exists(DB_NAME):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y DB t·∫°i {DB_NAME}")
        return

    print("... ƒêang t·∫£i d·ªØ li·ªáu t·ª´ DB...")
    all_data, msg = load_data_ai_from_db(DB_NAME)
    if not all_data:
        print("‚ùå DB r·ªóng ho·∫∑c l·ªói t·∫£i.")
        return
    print(f"‚úÖ ƒê√£ t·∫£i {len(all_data)} d√≤ng d·ªØ li·ªáu.")
    
    # Kh·ªüi t·∫°o Service
    service = AnalysisService(DB_NAME, logger=MockLogger())
    
    # 2. Ch·∫°y c√°c Test Case
    
    # Case 1: Ch·∫°y C·∫£ Hai (Baseline)
    t_full = measure_execution(service, all_data, True, True, "FULL ANALYSIS")
    
    # Case 2: Ch·ªâ Ch·∫°y L√¥
    t_lo = measure_execution(service, all_data, True, False, "ONLY LO MODE")
    
    # Case 3: Ch·ªâ Ch·∫°y ƒê·ªÅ
    t_de = measure_execution(service, all_data, False, True, "ONLY DE MODE")
    
    # 3. T·ªïng k·∫øt hi·ªáu nƒÉng
    print(f"\n{'='*60}")
    print("üìà T·ªîNG K·∫æT HI·ªÜU NƒÇNG")
    print(f"{'='*60}")
    print(f"1. Full Mode: {t_full:.4f}s")
    print(f"2. L√¥ Only  : {t_lo:.4f}s (Ti·∫øt ki·ªám: {t_full - t_lo:.4f}s)")
    print(f"3. ƒê·ªÅ Only  : {t_de:.4f}s (Ti·∫øt ki·ªám: {t_full - t_de:.4f}s)")
    
    if t_de < 1.0:
        print("\n‚úÖ ƒê√ÅNH GI√Å: Ch·∫ø ƒë·ªô ƒê·ªÅ ch·∫°y R·∫§T NHANH (<1s). T·ªëi ∆∞u th√†nh c√¥ng!")
    else:
        print("\n‚ö†Ô∏è ƒê√ÅNH GI√Å: Ch·∫ø ƒë·ªô ƒê·ªÅ c√≤n ch·∫≠m, c·∫ßn ki·ªÉm tra th√™m.")

if __name__ == "__main__":
    main()

--------------------------------------------------

=== FILE: scripts\verify_v39_upgrade.py ===
# T√™n file: code6/scripts/verify_v39_upgrade.py
import sys
import os
import pandas as pd

# Th√™m ƒë∆∞·ªùng d·∫´n project v√†o sys.path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

try:
    from logic.de_analytics import run_intersection_matrix_analysis, BO_SO_DICT
    print("‚úÖ Import th√†nh c√¥ng logic module.")
except ImportError as e:
    print(f"‚ùå L·ªói Import: {e}")
    sys.exit(1)

def verify_logic():
    print("--- B·∫ÆT ƒê·∫¶U KI·ªÇM TRA LOGIC V3.8 ---")
    
    # 1. Mock Dataframe
    data = {
        'Ngay': pd.date_range(start='2023-01-01', periods=20),
        'De': [10, 20, 30, 40, 50, 60, 70, 80, 90, 11, 22, 33, 44, 55, 66, 77, 88, 99, 15, 25]
    }
    df = pd.DataFrame(data)
    print(f"1. T·∫°o DataFrame gi·∫£ l·∫≠p: {len(df)} d√≤ng.")

    # 2. Run Analysis
    try:
        result = run_intersection_matrix_analysis(df)
        print("2. Ch·∫°y h√†m ph√¢n t√≠ch: OK")
        
        ranked = result.get('ranked', [])
        print(f"3. K·∫øt qu·∫£ tr·∫£ v·ªÅ: {len(ranked)} s·ªë ƒë∆∞·ª£c ch·∫•m ƒëi·ªÉm.")
        
        if ranked:
            top_1 = ranked[0]
            print(f"   -> Top 1: S·ªë {top_1['so']} ({top_1['diem']} ƒëi·ªÉm) - Rank: {top_1['rank']}")
            print(f"   -> L√Ω do: {top_1['note']}")
        else:
            print("‚ùå Kh√¥ng c√≥ k·∫øt qu·∫£ x·∫øp h·∫°ng.")
            
    except Exception as e:
        print(f"‚ùå L·ªói khi ch·∫°y ph√¢n t√≠ch: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    verify_logic()

--------------------------------------------------

=== FILE: scripts\v√° l·ªói.py ===
import os

# N·ªôi dung chu·∫©n c·ªßa file bridge_manager_de.py (ƒê√£ fix l·ªói Regex v√† Logic)
FULL_CONTENT = r'''# T√™n file: logic/bridges/bridge_manager_de.py
# (PHI√äN B·∫¢N V8.0 - RESTORED & FIXED INDENTATION)

import os
import sys
import sqlite3
import re

# Import c√°c t√†i nguy√™n chung
from logic.de_utils import get_touches_by_offset, generate_dan_de_from_touches, get_bo_name_by_pair, BO_SO_DE, get_gdb_last_2, get_set_name_of_number
try:
    from logic.config_manager import SETTINGS
    from logic.db_manager import DB_NAME, upsert_managed_bridge
    from logic.bridges.bridges_v16 import (
        getAllPositions_V17_Shadow,
        getPositionName_V17_Shadow,
        taoSTL_V30_Bong,
        get_index_from_name_V16,
    )
except ImportError as e:
    print(f"L·ªói Import trong bridge_manager_de: {e}")
    SETTINGS = None
    # Fallback path
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(os.path.dirname(current_dir))
    DB_NAME = os.path.join(project_root, "data", "xo_so_prizes_all_logic.db")

# ===================================================================================
# HELPER FUNCTIONS
# ===================================================================================
def _ensure_db_columns(cursor):
    """[SELF-HEALING] Ki·ªÉm tra v√† t·ª± ƒë·ªông th√™m c√°c c·ªôt thi·∫øu trong DB."""
    try:
        cursor.execute("PRAGMA table_info(ManagedBridges)")
        columns = [info[1] for info in cursor.fetchall()]

        if "recent_win_count_10" not in columns:
            cursor.execute("ALTER TABLE ManagedBridges ADD COLUMN recent_win_count_10 INTEGER DEFAULT 0")
        
        if "type" not in columns:
            cursor.execute("ALTER TABLE ManagedBridges ADD COLUMN type TEXT DEFAULT 'UNKNOWN'")
            
        if "next_prediction_stl" not in columns:
            cursor.execute("ALTER TABLE ManagedBridges ADD COLUMN next_prediction_stl TEXT DEFAULT ''")
            
    except Exception as e:
        print(f"L·ªói Self-Healing DB: {e}")

# ===================================================================================
# V2.5: DE BRIDGE MANAGER
# ===================================================================================

class DeBridgeManager:
    """
    Tr√¨nh qu·∫£n l√Ω C·∫ßu ƒê·ªÅ (V2.5)
    """
    def __init__(self):
        self.max_health = 3
        self.lookback_window = 10

    def update_daily_stats(self, all_data_ai):
        if not all_data_ai or len(all_data_ai) < self.lookback_window + 2: return 0, []
        
        print(">>> [DE MANAGER] C·∫≠p nh·∫≠t H·ªì S∆° Phong ƒê·ªô...")
        last_row = all_data_ai[-1]; prev_row = all_data_ai[-2]
        gdb_today = get_gdb_last_2(last_row)
        pos_today = getAllPositions_V17_Shadow(last_row)
        
        conn = sqlite3.connect(DB_NAME)
        cursor = conn.cursor()

        try:
            _ensure_db_columns(cursor)
            conn.commit()
            cursor.execute("SELECT id, name, type, current_streak, recent_win_count_10, description FROM ManagedBridges WHERE is_enabled=1 AND (type LIKE 'DE_%' OR type LIKE 'CAU_DE%')")
            active_bridges = cursor.fetchall()
        except sqlite3.OperationalError as e:
            print(f"L·ªói ƒê·ªçc DB: {e}")
            conn.close()
            return 0, []
        
        updated_count = 0
        active_list_ui = []
        
        for br_id, name, b_type, streak, hp_db, desc in active_bridges:
            try:
                # PARSER V2.1: Ph√¢n t√≠ch ID C·∫ßu
                parsed_info = self._parse_bridge_id_v2(name, b_type)
                if not parsed_info:
                    parsed_info = self._parse_bridge_id_legacy(name)
                
                if not parsed_info: continue 

                idx1, idx2, k_offset, mode = parsed_info

                # 1. T√≠nh k·∫øt qu·∫£ (Streak)
                pos_prev = getAllPositions_V17_Shadow(prev_row)
                dan_today = self._calculate_dan_logic(pos_prev, idx1, idx2, k_offset, mode, return_string=False)
                
                is_win = (gdb_today in dan_today) if (gdb_today and dan_today) else False
                
                current_hp = hp_db if (hp_db is not None and 0 <= hp_db <= self.max_health) else self.max_health
                new_streak = streak + 1 if is_win else 0
                new_hp = self.max_health if is_win else current_hp - 1
                
                # 2. Backtest 10 k·ª≥
                wins_10 = 0
                recent_data = all_data_ai[-11:] if len(all_data_ai) >= 11 else all_data_ai
                
                for i in range(min(10, len(recent_data) - 1)):
                    idx_today = len(recent_data) - 1 - i
                    idx_prev = idx_today - 1
                    if idx_prev < 0: break
                    
                    row_today_k = recent_data[idx_today]
                    row_prev_k = recent_data[idx_prev]
                    g_today = get_gdb_last_2(row_today_k)
                    if not g_today: continue
                    p_prev = getAllPositions_V17_Shadow(row_prev_k)
                    d_prev = self._calculate_dan_logic(p_prev, idx1, idx2, k_offset, mode, return_string=False)
                    if g_today in d_prev:
                        wins_10 += 1

                # T√≠nh Search Rate
                search_rate_val = (wins_10 / 10.0) * 100
                new_search_rate = f"{search_rate_val:.0f}%"

                # 3. Sinh t·ªìn & X·∫øp h·∫°ng
                is_enabled = 1 if new_hp > 0 else 0
                rank_score = (new_streak * 10) + (wins_10 * 5)
                
                # 4. D·ª± ƒëo√°n ng√†y mai
                pred_display = ""
                if is_enabled:
                    pred_display = self._calculate_dan_logic(pos_today, idx1, idx2, k_offset, mode, return_string=True, display_mode=True)
                
                # 5. C·∫≠p nh·∫≠t DB
                new_desc = desc.split(".")[0] if desc and "." in desc else (desc or name)
                new_desc += f". HP:{new_hp}/{self.max_health} | Win10:{wins_10}"
                
                cursor.execute("""
                    UPDATE ManagedBridges 
                    SET current_streak=?, recent_win_count_10=?, is_enabled=?, next_prediction_stl=?, description=?, search_rate_text=? 
                    WHERE id=?""", 
                    (new_streak, wins_10, is_enabled, pred_display, new_desc, new_search_rate, br_id))
                
                if is_enabled:
                    active_list_ui.append({
                        "name": name, 
                        "type": b_type, 
                        "streak": new_streak, 
                        "recent_win_count_10": wins_10,
                        "wins_10": wins_10,
                        "rank_score": rank_score, 
                        "predicted_value": pred_display,
                        "next_prediction_stl": pred_display,
                        "prediction": pred_display,
                        "hp": new_hp, 
                        "description": new_desc
                    })
                    updated_count += 1
            except Exception as e: 
                # print(f"L·ªói x·ª≠ l√Ω c·∫ßu {name}: {e}")
                continue
                
        conn.commit(); conn.close()
        return updated_count, sorted(active_list_ui, key=lambda x: x['rank_score'], reverse=True)

    def _parse_bridge_id_v2(self, name, b_type):
        """
        [FIXED] Parser h·ªó tr·ª£ c·∫£ t√™n c≈© v√† t√™n m·ªõi (d·∫•u ch·∫•m/ngo·∫∑c).
        S·ª≠ d·ª•ng _map_safe_name_to_index ƒë·ªÉ ƒë·∫£m b·∫£o ƒë·ªçc ƒë∆∞·ª£c m·ªçi ƒë·ªãnh d·∫°ng.
        """
        try:
            if "DE_DYN" in name or b_type == "DE_DYNAMIC_K":
                parts = name.split("_")
                k_str = "0"
                for p in parts:
                    if p.startswith("K") and p[1:].isdigit():
                        k_str = p[1:]
                        break
                
                match = re.search(r"DE_DYN_(.+)_([^_]+)_K(\d+)", name)
                if match:
                    p1_str, p2_str, _ = match.groups()
                    idx1 = self._map_safe_name_to_index(p1_str) 
                    idx2 = self._map_safe_name_to_index(p2_str)
                    if idx1 is not None and idx2 is not None:
                        return idx1, idx2, int(k_str), "DYNAMIC"

            elif "DE_POS" in name or b_type == "DE_POS_SUM":
                match = re.search(r"DE_POS_(.+)_([^_]+)", name)
                if match:
                    p1_str, p2_str = match.groups()
                    idx1 = self._map_safe_name_to_index(p1_str)
                    idx2 = self._map_safe_name_to_index(p2_str)
                    if idx1 is not None and idx2 is not None:
                        return idx1, idx2, 0, "POS_SUM"
            
            elif "DE_SET" in name or b_type == "DE_SET":
                match = re.search(r"DE_SET_(.+)_([^_]+)", name)
                if match:
                    p1_str, p2_str = match.groups()
                    idx1 = self._map_safe_name_to_index(p1_str)
                    idx2 = self._map_safe_name_to_index(p2_str)
                    
                    if idx1 is None: idx1 = self._map_std_name_to_index(p1_str)
                    if idx2 is None: idx2 = self._map_std_name_to_index(p2_str)
                    
                    if idx1 is not None and idx2 is not None:
                        return idx1, idx2, 0, "SET"
                    
        except: return None
        return None

    def _parse_bridge_id_legacy(self, name):
        try:
            match = re.match(r"(.+)\+(.+) \((.+)\)", name)
            if match:
                p1, p2, suffix = match.groups()
                idx1 = get_index_from_name_V16(p1.strip())
                idx2 = get_index_from_name_V16(p2.strip())
                return idx1, idx2, 0, "LEGACY_V17"
        except: pass
        return None

    def _map_std_name_to_index(self, std_name):
        mapping = {
            "GDB": 4, "G1": 9, "G2": 19, "G3": 49, 
            "G4": 65, "G5": 89, "G6": 98, "G7": 106
        }
        return mapping.get(std_name, None)

    def _map_safe_name_to_index(self, safe_name):
        """
        [FIXED] Ph√¢n t√≠ch t√™n v·ªã tr√≠ linh ho·∫°t.
        H·ªó tr·ª£: G2.1[0], G2.1.0, G2.1[0
        """
        try:
            # Regex m·ªõi ch·∫•p nh·∫≠n d·∫•u . v√† [
            match = re.match(r"(G\d+\.?\d*|GDB)[\[\.]?(\d+)", safe_name)
            
            if match:
                g_name, g_idx = match.groups()
                # T√°i t·∫°o v·ªÅ format chu·∫©n m√† th∆∞ vi·ªán V16 hi·ªÉu
                reconstructed = f"{g_name}[{g_idx}]"
                return get_index_from_name_V16(reconstructed)
            return None
        except: return None

    def _calculate_dan_logic(self, positions, idx1, idx2, k_offset, mode, return_string=False, display_mode=False):
        try:
            if idx1 is None or idx2 is None: return [] if not return_string else ""
            
            # Ki·ªÉm tra bounds
            if idx1 >= len(positions) or idx2 >= len(positions):
                 return [] if not return_string else ""

            v1_raw = positions[idx1]
            v2_raw = positions[idx2]
            
            if v1_raw is None or v2_raw is None:
                return [] if not return_string else ""

            v1 = int(v1_raw)
            v2 = int(v2_raw)

            base_sum = 0
            if mode == "DYNAMIC":
                base_sum = (v1 + v2) % 10
            elif mode == "POS_SUM" or mode == "LEGACY_V17":
                base_sum = (v1 + v2) % 10
            elif mode == "SET":
                combined_number = f"{v1}{v2}"
                set_name = get_set_name_of_number(combined_number)
                if set_name:
                    set_numbers = BO_SO_DE.get(set_name, [])
                    if display_mode:
                        return f"B·ªô {set_name}"
                    if return_string:
                        return ",".join(set_numbers)
                    else:
                        return set_numbers
                else:
                    return [] if not return_string else ""
            
            # T√≠nh c√°c ch·∫°m
            touches = []
            if mode == "DYNAMIC":
                 touches = get_touches_by_offset(base_sum, k_offset) 
            else:
                 touches = [base_sum, (base_sum+5)%10]
            
            if display_mode:
                t_str = ", ".join(map(str, sorted(list(set(touches)))))
                return t_str
            
            final_dan = generate_dan_de_from_touches(touches)
            return ",".join(final_dan) if return_string else final_dan

        except: return [] if not return_string else ""

de_manager = DeBridgeManager()

def find_and_auto_manage_bridges_de(all_data_ai, db_name=DB_NAME):
    from logic.bridges.de_bridge_scanner import run_de_scanner
    count, _ = run_de_scanner(all_data_ai)
    return f"ƒê√£ c·∫≠p nh·∫≠t {count} c·∫ßu ƒê·ªÅ."
'''

def restore_file():
    # 1. X√°c ƒë·ªãnh v·ªã tr√≠ file
    target_path = None
    potential_paths = [
        'logic/bridges/bridge_manager_de.py',
        'code6/logic/bridges/bridge_manager_de.py',
        '../logic/bridges/bridge_manager_de.py',
        os.path.join(os.getcwd(), 'logic/bridges/bridge_manager_de.py')
    ]
    
    for path in potential_paths:
        dir_path = os.path.dirname(path)
        # N·∫øu th∆∞ m·ª•c t·ªìn t·∫°i th√¨ ƒë√¢y l√† ƒë∆∞·ªùng d·∫´n ƒë√∫ng (k·ªÉ c·∫£ file ch∆∞a c√≥)
        if os.path.exists(dir_path):
            target_path = path
            break
            
    if not target_path:
        print("‚ùå KH√îNG T√åM TH·∫§Y th∆∞ m·ª•c logic/bridges! Vui l√≤ng ki·ªÉm tra c·∫•u tr√∫c d·ª± √°n.")
        return

    print(f"üîÑ ƒêang kh√¥i ph·ª•c file: {target_path}")
    
    try:
        with open(target_path, 'w', encoding='utf-8') as f:
            f.write(FULL_CONTENT)
        print("‚úÖ KH√îI PH·ª§C TH√ÄNH C√îNG! File ƒë√£ ƒë∆∞·ª£c ghi ƒë√® b·∫±ng phi√™n b·∫£n chu·∫©n.")
        print("üëâ B·∫°n h√£y m·ªü App l·∫°i ƒë·ªÉ ki·ªÉm tra.")
    except Exception as e:
        print(f"‚ùå L·ªói ghi file: {e}")

if __name__ == "__main__":
    restore_file()

--------------------------------------------------

=== FILE: scripts\jobs\db_schema_detector.py ===
"""
Database Schema Auto-Detection Utilities

Automatically detects table and column names in SQLite databases
to handle different naming conventions (ManagedBridges vs managed_bridges, etc.)
"""

import sqlite3
import re


def detect_bridge_table(conn):
    """
    Auto-detect the bridge management table name.
    
    Tries common variants:
    - ManagedBridges
    - managed_bridges
    - bridge_management
    - bridges
    
    Returns:
        str or None: Table name if found, None otherwise
    """
    cursor = conn.cursor()
    
    # Possible table names (ordered by likelihood)
    possible_names = [
        'ManagedBridges',
        'managed_bridges',
        'bridge_management',
        'bridges',
        'Bridge',
        'BRIDGES'
    ]
    
    for table_name in possible_names:
        cursor.execute(
            "SELECT name FROM sqlite_master WHERE type='table' AND name=? COLLATE NOCASE",
            (table_name,)
        )
        if cursor.fetchone():
            return table_name
    
    return None


def detect_history_table(conn):
    """
    Auto-detect the bridge history/results table name.
    
    Tries common variants:
    - bridge_history
    - bridge_results  
    - DuLieu_AI
    - results_A_I
    - history
    
    Returns:
        str or None: Table name if found, None otherwise
    """
    cursor = conn.cursor()
    
    possible_names = [
        'bridge_history',
        'bridge_results',
        'DuLieu_AI',
        'results_A_I',
        'history',
        'results'
    ]
    
    for table_name in possible_names:
        cursor.execute(
            "SELECT name FROM sqlite_master WHERE type='table' AND name=? COLLATE NOCASE",
            (table_name,)
        )
        if cursor.fetchone():
            return table_name
    
    return None


def detect_audit_table(conn):
    """
    Auto-detect the audit table name.
    
    Returns:
        str or None: Table name if found, None otherwise
    """
    cursor = conn.cursor()
    
    possible_names = [
        'bridge_audit',
        'audit',
        'audit_log',
        'bridge_audit_log'
    ]
    
    for table_name in possible_names:
        cursor.execute(
            "SELECT name FROM sqlite_master WHERE type='table' AND name=? COLLATE NOCASE",
            (table_name,)
        )
        if cursor.fetchone():
            return table_name
    
    return None


def is_dynamic_bridge_type(bridge_type):
    """
    Check if a bridge type is a dynamic variant.
    
    Matches patterns like:
    - DE_DYN
    - DE_DYNAMIC
    - DE_DYNAMIC_K
    - DE_DYNAMIC-*
    - etc.
    
    Args:
        bridge_type: String bridge type (case-insensitive)
    
    Returns:
        bool: True if dynamic type, False otherwise
    """
    if not bridge_type:
        return False
    
    bridge_type_upper = bridge_type.upper()
    
    # Match DE_DYN* or DE_DYNAMIC*
    return (
        bridge_type_upper.startswith('DE_DYN') or
        bridge_type_upper.startswith('DE_DYNAMIC')
    )


def get_table_schema(conn, table_name):
    """
    Get schema information for a table.
    
    Returns:
        list: List of column info dicts with 'name', 'type', etc.
    """
    if not table_name:
        return []
    
    cursor = conn.cursor()
    cursor.execute(f"PRAGMA table_info({table_name})")
    
    columns = []
    for row in cursor.fetchall():
        columns.append({
            'cid': row[0],
            'name': row[1],
            'type': row[2],
            'notnull': row[3],
            'dflt_value': row[4],
            'pk': row[5]
        })
    
    return columns


def detect_schema_info(conn):
    """
    Detect all relevant schema information from the database.
    
    Returns:
        dict: Schema information including table names and columns
    """
    schema_info = {
        'bridge_table': None,
        'history_table': None,
        'audit_table': None,
        'warnings': [],
        'bridge_columns': [],
        'has_de_metrics': False
    }
    
    # Detect tables
    schema_info['bridge_table'] = detect_bridge_table(conn)
    schema_info['history_table'] = detect_history_table(conn)
    schema_info['audit_table'] = detect_audit_table(conn)
    
    # Add warnings for missing tables
    if not schema_info['bridge_table']:
        schema_info['warnings'].append("‚ö† Bridge management table not found (tried: ManagedBridges, managed_bridges, etc.)")
    
    if not schema_info['history_table']:
        schema_info['warnings'].append("‚ö† Bridge history table not found (tried: bridge_history, DuLieu_AI, etc.)")
    
    if not schema_info['audit_table']:
        schema_info['warnings'].append("‚ö† Audit table not found (tried: bridge_audit, audit, etc.)")
    
    # Get column info for bridge table
    if schema_info['bridge_table']:
        schema_info['bridge_columns'] = get_table_schema(conn, schema_info['bridge_table'])
        
        # Check for DE metrics columns
        column_names = [col['name'] for col in schema_info['bridge_columns']]
        de_metric_columns = [
            'de_win_count_last30',
            'de_win_rate_last30',
            'de_current_streak',
            'de_score',
            'de_auto_enabled'
        ]
        
        has_all = all(col in column_names for col in de_metric_columns)
        schema_info['has_de_metrics'] = has_all
        
        if not has_all:
            missing = [col for col in de_metric_columns if col not in column_names]
            schema_info['warnings'].append(f"‚ö† Missing DE metric columns: {', '.join(missing)}")
    
    return schema_info


__all__ = [
    'detect_bridge_table',
    'detect_history_table',
    'detect_audit_table',
    'is_dynamic_bridge_type',
    'get_table_schema',
    'detect_schema_info'
]


--------------------------------------------------

=== FILE: scripts\jobs\update_de_bridge_performance.py ===
#!/usr/bin/env python3
"""
Job: Update DE Bridge Performance Metrics (Auto-Detection Enhanced)

Computes and persists DE metrics for all DE_* bridges:
- de_win_count_last30: Win count in last 30 periods
- de_win_rate_last30: Win rate percentage
- de_current_streak: Current winning/losing streak
- de_score: Calculated bridge score
- de_auto_enabled: Auto-enable flag with hysteresis
- de_last_evaluated: Last evaluation timestamp

Creates audit entries when de_auto_enabled changes.

Features:
- Auto-detects dynamic bridge variants (DE_DYN, DE_DYNAMIC, etc.)
- Auto-detects table names (ManagedBridges vs managed_bridges, etc.)
- Generates dry-run report (JSON/text)
- Requires --apply flag to write to DB (backup mandatory)
- Clear logging with reasons

Usage:
  # Dry-run (default, generates report)
  python scripts/jobs/update_de_bridge_performance.py [--db path] [--limit N]
  
  # Apply changes (requires backup confirmation)
  python scripts/jobs/update_de_bridge_performance.py --apply [--db path]
"""

import argparse
import json
import os
import sqlite3
import sys
from datetime import datetime
from pathlib import Path

# Add project root to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "../..")))

# Import schema detector
from db_schema_detector import (
    detect_schema_info,
    is_dynamic_bridge_type
)


def load_config():
    """Load configuration from constants or use defaults."""
    try:
        from logic.constants import DEFAULT_SETTINGS
        window_kys = DEFAULT_SETTINGS.get("DE_WINDOW_KYS", 30)
        enable_threshold = DEFAULT_SETTINGS.get("DE_DYN_ENABLE_RAW", 28)
        disable_threshold = DEFAULT_SETTINGS.get("DE_DYN_DISABLE_RAW", 26)
    except ImportError:
        # Fallback defaults
        window_kys = 30
        enable_threshold = 28
        disable_threshold = 26
    
    return {
        "window_kys": window_kys,
        "enable_threshold": enable_threshold,
        "disable_threshold": disable_threshold
    }


def get_db_connection(db_path):
    """Get database connection."""
    if not os.path.exists(db_path):
        raise FileNotFoundError(f"Database not found: {db_path}")
    
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row
    return conn


def get_de_bridges(conn, schema_info, limit=None):
    """
    Get all DE_* bridges using auto-detected table name.
    
    Args:
        conn: Database connection
        schema_info: Schema information from detect_schema_info()
        limit: Optional limit on number of bridges
    
    Returns:
        list: List of bridge dicts
    """
    cursor = conn.cursor()
    
    table_name = schema_info.get('bridge_table')
    if not table_name:
        print("‚ùå ERROR: Bridge table not found")
        return []
    
    # Get all DE_* bridges
    query = f"SELECT * FROM {table_name} WHERE type LIKE 'DE_%'"
    if limit:
        query += f" LIMIT {limit}"
    
    cursor.execute(query)
    bridges = [dict(row) for row in cursor.fetchall()]
    
    # Filter to only dynamic bridge types if processing DE_DYN logic
    # (other types like DE_SET, DE_MEMORY don't use auto_enabled)
    return bridges


def get_bridge_history(conn, bridge, window_kys):
    """
    Get bridge win/loss history for the last N periods.
    
    TODO: Adapt to your actual history table structure.
    Expected columns: ky (period), result (1=win, 0=loss)
    
    Returns:
        list of dicts with 'ky' and 'result' keys
    """
    cursor = conn.cursor()
    
    # TODO: Replace with actual history table query
    # For now, use a safe fallback that checks for common table names
    possible_tables = ['bridge_history', 'bridge_results', 'DuLieu_AI', 'results_A_I']
    
    for table_name in possible_tables:
        cursor.execute(f"SELECT name FROM sqlite_master WHERE type='table' AND name='{table_name}'")
        if cursor.fetchone():
            print(f"  [INFO] Using table: {table_name}")
            # TODO: Implement actual query based on your schema
            # This is a placeholder - adapt to your schema
            break
    else:
        print(f"  [WARNING] No history table found for bridge {bridge.get('name', '?')}")
        return []
    
    # Placeholder - return empty for now
    # TODO: Implement actual history query
    return []


def compute_metrics(bridge, history, config):
    """
    Compute performance metrics for a bridge.
    
    Args:
        bridge: Bridge dict from DB
        history: List of win/loss records
        config: Configuration dict with thresholds
    
    Returns:
        dict with computed metrics
    """
    window_kys = config["window_kys"]
    
    # Compute wins in window
    wins_count = sum(1 for record in history[-window_kys:] if record.get("result") == 1)
    total_count = min(len(history), window_kys)
    
    # Win rate
    win_rate = (wins_count / total_count * 100) if total_count > 0 else 0.0
    
    # Current streak (consecutive wins from most recent)
    current_streak = 0
    for record in reversed(history):
        if record.get("result") == 1:
            current_streak += 1
        else:
            break
    
    # Simple score (can be enhanced)
    score = win_rate / 100.0 * 10.0  # Scale 0-10
    
    return {
        "de_win_count_last30": wins_count,
        "de_win_rate_last30": round(win_rate, 2),
        "de_current_streak": current_streak,
        "de_score": round(score, 2)
    }


def determine_auto_enabled(bridge, metrics, config):
    """
    Determine de_auto_enabled flag using hysteresis.
    
    Args:
        bridge: Bridge dict with current state
        metrics: Computed metrics dict
        config: Configuration dict with thresholds
    
    Returns:
        (new_auto_enabled: int, reason: str)
    """
    enable_threshold = config["enable_threshold"]
    disable_threshold = config["disable_threshold"]
    
    wins_count = metrics["de_win_count_last30"]
    current_auto_enabled = bridge.get("de_auto_enabled", 0)
    
    # Apply hysteresis
    if wins_count >= enable_threshold:
        return 1, f"wins={wins_count} >= enable_threshold={enable_threshold}"
    elif wins_count <= disable_threshold:
        return 0, f"wins={wins_count} <= disable_threshold={disable_threshold}"
    else:
        # In hysteresis zone - maintain current state
        return current_auto_enabled, f"wins={wins_count} in hysteresis zone, maintaining state={current_auto_enabled}"


def update_bridge_metrics(conn, bridge_id, metrics, new_auto_enabled, schema_info, dry_run=False):
    """Update bridge metrics in database."""
    if dry_run:
        print(f"    [DRY-RUN] Would update bridge {bridge_id} with metrics: {metrics}")
        print(f"    [DRY-RUN] Would set de_auto_enabled={new_auto_enabled}")
        return
    
    cursor = conn.cursor()
    table_name = schema_info.get('bridge_table')
    
    if not table_name:
        print(f"    ‚ùå ERROR: Bridge table not found, cannot update")
        return
    
    # Update metrics
    cursor.execute(f"""
        UPDATE {table_name}
        SET de_win_count_last30 = ?,
            de_win_rate_last30 = ?,
            de_current_streak = ?,
            de_score = ?,
            de_auto_enabled = ?,
            de_last_evaluated = ?
        WHERE id = ?
    """, (
        metrics["de_win_count_last30"],
        metrics["de_win_rate_last30"],
        metrics["de_current_streak"],
        metrics["de_score"],
        new_auto_enabled,
        datetime.now().isoformat(),
        bridge_id
    ))
    
    print(f"    ‚úì Updated bridge {bridge_id}")


def create_audit_entry(conn, bridge_id, old_value, new_value, reason, schema_info, dry_run=False):
    """Create audit entry when de_auto_enabled changes."""
    if old_value == new_value:
        return  # No change
    
    if dry_run:
        print(f"    [DRY-RUN] Would create audit entry: {old_value} -> {new_value}")
        return
    
    audit_table = schema_info.get('audit_table')
    if not audit_table:
        print("    ‚ö† Audit table not found, skipping audit entry")
        return
    
    cursor = conn.cursor()
    action = "auto_enable" if new_value == 1 else "auto_disable"
    
    cursor.execute(f"""
        INSERT INTO {audit_table} (bridge_id, action, old_value, new_value, reason, actor, created_at)
        VALUES (?, ?, ?, ?, ?, 'system', datetime('now'))
    """, (bridge_id, action, str(old_value), str(new_value), reason))
    
    print(f"    ‚úì Created audit entry: {action}")


def process_bridge(conn, bridge, config, schema_info, dry_run=False):
    """Process a single bridge: compute metrics and update DB."""
    bridge_id = bridge.get("id")
    bridge_name = bridge.get("name", "N/A")
    bridge_type = (bridge.get("type", "") or "")
    
    print(f"\n  Processing: {bridge_name} (ID={bridge_id}, Type={bridge_type})")
    
    # Auto-detect if this is a dynamic bridge variant
    if not is_dynamic_bridge_type(bridge_type):
        print(f"    ‚äô Skipping non-dynamic bridge (type: {bridge_type})")
        return
    
    # Get history
    history = get_bridge_history(conn, bridge, config["window_kys"])
    
    if not history:
        print(f"    ‚ö† No history data available, using legacy current_streak if available")
        # Fallback: use existing current_streak if available
        current_streak = bridge.get("current_streak", 0)
        if current_streak:
            # Estimate wins from streak (very rough approximation)
            metrics = {
                "de_win_count_last30": current_streak,
                "de_win_rate_last30": round(current_streak / 30 * 100, 2),
                "de_current_streak": current_streak,
                "de_score": round(current_streak / 30 * 10, 2)
            }
        else:
            print(f"    ‚ö† No legacy data either, skipping")
            return
    else:
        # Compute metrics from history
        metrics = compute_metrics(bridge, history, config)
    
    # Determine auto_enabled with hysteresis
    old_auto_enabled = bridge.get("de_auto_enabled", 0)
    new_auto_enabled, reason = determine_auto_enabled(bridge, metrics, config)
    
    print(f"    Metrics: wins={metrics['de_win_count_last30']}, rate={metrics['de_win_rate_last30']}%, streak={metrics['de_current_streak']}, score={metrics['de_score']}")
    print(f"    Auto-enabled: {old_auto_enabled} -> {new_auto_enabled} ({reason})")
    
    # Update database
    update_bridge_metrics(conn, bridge_id, metrics, new_auto_enabled, schema_info, dry_run)
    
    # Create audit entry if changed
    if old_auto_enabled != new_auto_enabled:
        create_audit_entry(conn, bridge_id, old_auto_enabled, new_auto_enabled, reason, schema_info, dry_run)
    
    # Return summary for reporting
    return {
        'bridge_id': bridge_id,
        'bridge_name': bridge_name,
        'bridge_type': bridge_type,
        'old_auto_enabled': old_auto_enabled,
        'new_auto_enabled': new_auto_enabled,
        'reason': reason,
        'metrics': metrics
    }


def generate_report(report_data, output_format='json'):
    """Generate dry-run report in specified format."""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    if output_format == 'json':
        filename = f"de_performance_report_{timestamp}.json"
        with open(filename, 'w') as f:
            json.dump(report_data, f, indent=2)
        return filename
    else:
        filename = f"de_performance_report_{timestamp}.txt"
        with open(filename, 'w') as f:
            f.write("=" * 70 + "\n")
            f.write("DE BRIDGE PERFORMANCE REPORT\n")
            f.write("=" * 70 + "\n\n")
            f.write(f"Generated: {report_data['timestamp']}\n")
            f.write(f"Database: {report_data['database']}\n\n")
            
            f.write("Schema Detection:\n")
            for key, value in report_data['schema'].items():
                if key != 'warnings' and key != 'bridge_columns':
                    f.write(f"  {key}: {value}\n")
            
            if report_data['schema']['warnings']:
                f.write("\nWarnings:\n")
                for warning in report_data['schema']['warnings']:
                    f.write(f"  {warning}\n")
            
            f.write(f"\nBridges Processed: {report_data['summary']['processed']}/{report_data['summary']['total']}\n")
            f.write(f"Would Enable: {report_data['summary']['would_enable']}\n")
            f.write(f"Would Disable: {report_data['summary']['would_disable']}\n")
            f.write(f"No Change: {report_data['summary']['no_change']}\n")
            
            if report_data['changes']:
                f.write("\nDetailed Changes:\n")
                for change in report_data['changes']:
                    f.write(f"\n  Bridge: {change['bridge_name']} (ID={change['bridge_id']})\n")
                    f.write(f"    Type: {change['bridge_type']}\n")
                    f.write(f"    Auto-enabled: {change['old_auto_enabled']} -> {change['new_auto_enabled']}\n")
                    f.write(f"    Reason: {change['reason']}\n")
                    f.write(f"    Metrics: {change['metrics']}\n")
        
        return filename


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description="Update DE bridge performance metrics (Auto-Detection Enhanced)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Dry-run (default, generates report)
  python scripts/jobs/update_de_bridge_performance.py
  
  # Dry-run with limit
  python scripts/jobs/update_de_bridge_performance.py --limit 10
  
  # Apply changes (REQUIRES --apply flag and backup!)
  python scripts/jobs/update_de_bridge_performance.py --apply
  
  # Custom database path
  python scripts/jobs/update_de_bridge_performance.py --db path/to/db.sqlite --apply
        """
    )
    
    parser.add_argument(
        '--db',
        default='data/xo_so_prizes_all_logic.db',
        help='Path to SQLite database (default: data/xo_so_prizes_all_logic.db)'
    )
    
    parser.add_argument(
        '--apply',
        action='store_true',
        help='Apply changes to database (default is dry-run)'
    )
    
    parser.add_argument(
        '--limit',
        type=int,
        help='Limit number of bridges to process (for testing)'
    )
    
    parser.add_argument(
        '--report-format',
        choices=['json', 'text'],
        default='json',
        help='Report format (default: json)'
    )
    
    args = parser.parse_args()
    
    # Determine dry-run mode (inverse of --apply)
    dry_run = not args.apply
    
    print("=" * 70)
    print("DE BRIDGE PERFORMANCE UPDATE JOB (AUTO-DETECTION)")
    print("=" * 70)
    
    if dry_run:
        print("üîç MODE: DRY-RUN (no database writes, generates report)\n")
    else:
        print("‚ö†Ô∏è  MODE: APPLY (will update database)\n")
        print("üí° IMPORTANT: Ensure you have backed up the database!\n")
    
    # Load config
    config = load_config()
    print(f"Configuration:")
    print(f"  - Window: {config['window_kys']} periods")
    print(f"  - Enable threshold: {config['enable_threshold']}")
    print(f"  - Disable threshold: {config['disable_threshold']}\n")
    
    # Connect to database
    try:
        conn = get_db_connection(args.db)
        print(f"‚úì Connected to: {args.db}")
    except Exception as e:
        print(f"‚ùå ERROR: Failed to connect to database: {e}")
        return 1
    
    try:
        # Auto-detect schema
        print("\nüîç Auto-detecting database schema...")
        schema_info = detect_schema_info(conn)
        
        print(f"  Bridge table: {schema_info['bridge_table'] or 'NOT FOUND'}")
        print(f"  History table: {schema_info['history_table'] or 'NOT FOUND'}")
        print(f"  Audit table: {schema_info['audit_table'] or 'NOT FOUND'}")
        print(f"  Has DE metrics: {schema_info['has_de_metrics']}")
        
        if schema_info['warnings']:
            print("\n‚ö†Ô∏è  Warnings:")
            for warning in schema_info['warnings']:
                print(f"  {warning}")
        
        if not schema_info['bridge_table']:
            print("\n‚ùå ERROR: Cannot proceed without bridge table")
            return 1
        
        # Get DE bridges
        bridges = get_de_bridges(conn, schema_info, args.limit)
        print(f"\nFound {len(bridges)} DE_* bridges to process")
        
        if args.limit:
            print(f"(Limited to {args.limit} bridges for testing)")
        
        # Prepare report data
        report_data = {
            'timestamp': datetime.now().isoformat(),
            'database': args.db,
            'mode': 'apply' if not dry_run else 'dry-run',
            'schema': schema_info,
            'config': config,
            'summary': {
                'total': len(bridges),
                'processed': 0,
                'would_enable': 0,
                'would_disable': 0,
                'no_change': 0
            },
            'changes': []
        }
        
        # Process each bridge
        processed = 0
        for bridge in bridges:
            try:
                result = process_bridge(conn, bridge, config, schema_info, dry_run)
                processed += 1
                
                if result:
                    report_data['changes'].append(result)
                    
                    # Update summary counts
                    if result['old_auto_enabled'] != result['new_auto_enabled']:
                        if result['new_auto_enabled'] == 1:
                            report_data['summary']['would_enable'] += 1
                        else:
                            report_data['summary']['would_disable'] += 1
                    else:
                        report_data['summary']['no_change'] += 1
                        
            except Exception as e:
                print(f"  ‚ùå ERROR processing bridge {bridge.get('id')}: {e}")
        
        report_data['summary']['processed'] = processed
        
        # Commit if not dry-run
        if not dry_run:
            conn.commit()
            print(f"\n‚úì Committed changes to database")
        else:
            # Generate report
            print(f"\nüìÑ Generating report...")
            report_file = generate_report(report_data, args.report_format)
            print(f"‚úì Report saved to: {report_file}")
        
        print(f"\n{'=' * 70}")
        print(f"SUMMARY:")
        print(f"  Processed: {processed}/{len(bridges)} bridges")
        print(f"  Would enable: {report_data['summary']['would_enable']}")
        print(f"  Would disable: {report_data['summary']['would_disable']}")
        print(f"  No change: {report_data['summary']['no_change']}")
        
        if dry_run:
            print(f"\nüí° To apply changes, run with --apply flag (backup DB first!)")
        else:
            print(f"\n‚úì Database updated successfully")
        
        print(f"{'=' * 70}")
        
        return 0
        
    except Exception as e:
        print(f"\n‚ùå ERROR: Job failed: {e}")
        import traceback
        traceback.print_exc()
        conn.rollback()
        return 1
        
    finally:
        conn.close()


if __name__ == "__main__":
    sys.exit(main())


--------------------------------------------------

=== FILE: scripts\migrations\add_de_metrics.py ===
#!/usr/bin/env python3
"""
Safe migration script to add DE metrics columns and bridge_audit table.
Usage: python scripts/migrations/add_de_metrics.py [--db path/to/db.sqlite]
"""

import argparse
import os
import sqlite3
import sys
from pathlib import Path


def validate_db_path(db_path):
    """Validate that the database file exists."""
    if not os.path.exists(db_path):
        print(f"‚ùå ERROR: Database file not found: {db_path}")
        return False
    
    if not os.path.isfile(db_path):
        print(f"‚ùå ERROR: Path is not a file: {db_path}")
        return False
    
    print(f"‚úì Database file found: {db_path}")
    return True


def check_table_exists(cursor, table_name):
    """Check if a table exists in the database."""
    cursor.execute(
        "SELECT name FROM sqlite_master WHERE type='table' AND name=?",
        (table_name,)
    )
    exists = cursor.fetchone() is not None
    if exists:
        print(f"‚úì Table '{table_name}' exists")
    else:
        print(f"‚ö† Table '{table_name}' not found")
    return exists


def check_column_exists(cursor, table_name, column_name):
    """Check if a column exists in a table."""
    cursor.execute(f"PRAGMA table_info({table_name})")
    columns = [row[1] for row in cursor.fetchall()]
    return column_name in columns


def add_column_if_missing(cursor, table_name, column_def):
    """Add a column to a table if it doesn't exist."""
    # Parse column definition to get column name
    column_name = column_def.split()[0]
    
    if check_column_exists(cursor, table_name, column_name):
        print(f"  ‚äô Column '{column_name}' already exists, skipping")
        return False
    
    try:
        cursor.execute(f"ALTER TABLE {table_name} ADD COLUMN {column_def}")
        print(f"  ‚úì Added column '{column_name}'")
        return True
    except sqlite3.OperationalError as e:
        # Column might already exist (race condition or previous partial migration)
        if "duplicate column name" in str(e).lower():
            print(f"  ‚äô Column '{column_name}' already exists (caught exception)")
            return False
        raise


def create_bridge_audit_table(cursor):
    """Create the bridge_audit table if it doesn't exist."""
    if check_table_exists(cursor, 'bridge_audit'):
        print("  ‚äô Table 'bridge_audit' already exists, skipping")
        return False
    
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS bridge_audit (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            bridge_id INTEGER,
            action TEXT NOT NULL,
            old_value TEXT,
            new_value TEXT,
            reason TEXT,
            actor TEXT,
            created_at TEXT DEFAULT (datetime('now'))
        )
    """)
    print("  ‚úì Created table 'bridge_audit'")
    return True


def create_index_if_missing(cursor, index_name, table_name, column_name):
    """Create an index if it doesn't exist."""
    cursor.execute(
        "SELECT name FROM sqlite_master WHERE type='index' AND name=?",
        (index_name,)
    )
    
    if cursor.fetchone() is not None:
        print(f"  ‚äô Index '{index_name}' already exists, skipping")
        return False
    
    cursor.execute(f"CREATE INDEX IF NOT EXISTS {index_name} ON {table_name}({column_name})")
    print(f"  ‚úì Created index '{index_name}'")
    return True


def run_migration(db_path):
    """Run the migration on the specified database."""
    print("\n" + "="*60)
    print("DE METRICS MIGRATION - SAFE EXECUTION")
    print("="*60 + "\n")
    
    # Validate database
    if not validate_db_path(db_path):
        return False
    
    # Connect to database
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        print(f"‚úì Connected to database\n")
    except Exception as e:
        print(f"‚ùå ERROR: Failed to connect to database: {e}")
        return False
    
    try:
        # Check if ManagedBridges table exists
        print("Step 1: Validate ManagedBridges table")
        if not check_table_exists(cursor, 'ManagedBridges'):
            print("‚ùå ERROR: 'ManagedBridges' table not found!")
            print("   This migration requires the ManagedBridges table to exist.")
            return False
        print()
        
        # Add DE metric columns
        print("Step 2: Add DE metric columns to ManagedBridges")
        columns_to_add = [
            "de_win_count_last30 INTEGER DEFAULT 0",
            "de_win_rate_last30 REAL DEFAULT 0.0",
            "de_current_streak INTEGER DEFAULT 0",
            "de_score REAL DEFAULT 0.0",
            "de_auto_enabled INTEGER DEFAULT 0",
            "de_manual_override INTEGER DEFAULT 0",
            "de_manual_override_value INTEGER DEFAULT NULL",
            "de_last_evaluated TEXT DEFAULT NULL"
        ]
        
        added_count = 0
        for column_def in columns_to_add:
            if add_column_if_missing(cursor, 'ManagedBridges', column_def):
                added_count += 1
        
        print(f"  ‚Üí Added {added_count} new column(s)\n")
        
        # Create bridge_audit table
        print("Step 3: Create bridge_audit table")
        if create_bridge_audit_table(cursor):
            print("  ‚Üí Created bridge_audit table\n")
        else:
            print("  ‚Üí No action needed\n")
        
        # Create indexes
        print("Step 4: Create indexes")
        idx_added = 0
        if create_index_if_missing(cursor, 'idx_managed_bridges_type', 'ManagedBridges', 'type'):
            idx_added += 1
        if create_index_if_missing(cursor, 'idx_managed_bridges_de_auto', 'ManagedBridges', 'de_auto_enabled'):
            idx_added += 1
        print(f"  ‚Üí Created {idx_added} new index(es)\n")
        
        # Commit changes
        conn.commit()
        print("‚úì Migration completed successfully!")
        print("\n" + "="*60 + "\n")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå ERROR: Migration failed: {e}")
        conn.rollback()
        print("   Changes have been rolled back.")
        return False
        
    finally:
        conn.close()


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description='Add DE metrics columns and bridge_audit table to the database',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python scripts/migrations/add_de_metrics.py
  python scripts/migrations/add_de_metrics.py --db data/xo_so_prizes_all_logic.db
  
IMPORTANT: Back up your database before running this migration!
        """
    )
    
    parser.add_argument(
        '--db',
        default='data/xo_so_prizes_all_logic.db',
        help='Path to SQLite database file (default: data/xo_so_prizes_all_logic.db)'
    )
    
    args = parser.parse_args()
    
    # Run migration
    success = run_migration(args.db)
    
    # Exit with appropriate code
    sys.exit(0 if success else 1)


if __name__ == '__main__':
    main()


--------------------------------------------------

=== FILE: services\analysis_service.py ===
# T√™n file: services/analysis_service.py
# Service layer: Logic ph√¢n t√≠ch, backtest v√† AI

import itertools
import json
import pandas as pd
import traceback

class AnalysisService:
    """Service ph√¢n t√≠ch v√† backtest"""
    
    def __init__(self, db_name, logger=None):
        self.db_name = db_name
        self.logger = logger
        
        # Import c√°c h√†m backtest t·ª´ lottery_service
        try:
            from lottery_service import (
                BACKTEST_15_CAU_K2N_V30_AI_V8,
                BACKTEST_15_CAU_N1_V31_AI_V8,
                BACKTEST_CUSTOM_CAU_V16,
                BACKTEST_MANAGED_BRIDGES_K2N,
                BACKTEST_MANAGED_BRIDGES_N1,
                BACKTEST_MEMORY_BRIDGES,
                getAllLoto_V30,
                run_ai_prediction_for_dashboard,
                run_ai_training_threaded,
                run_and_update_all_bridge_K2N_cache,
                run_and_update_all_bridge_rates,
            )
            self.BACKTEST_15_CAU_K2N = BACKTEST_15_CAU_K2N_V30_AI_V8
            self.BACKTEST_15_CAU_N1 = BACKTEST_15_CAU_N1_V31_AI_V8
            self.BACKTEST_CUSTOM = BACKTEST_CUSTOM_CAU_V16
            self.BACKTEST_MANAGED_K2N = BACKTEST_MANAGED_BRIDGES_K2N
            self.BACKTEST_MANAGED_N1 = BACKTEST_MANAGED_BRIDGES_N1
            self.BACKTEST_MEMORY = BACKTEST_MEMORY_BRIDGES
            self.getAllLoto_V30 = getAllLoto_V30
            self.run_ai_prediction_for_dashboard = run_ai_prediction_for_dashboard
            self.run_ai_training_threaded = run_ai_training_threaded
            self.run_and_update_all_bridge_K2N_cache = run_and_update_all_bridge_K2N_cache
            self.run_and_update_all_bridge_rates = run_and_update_all_bridge_rates
        except ImportError as e:
            self._log(f"L·ªói import backtest functions: {e}")
        
        # Import c√°c h√†m dashboard analytics TR·ª∞C TI·∫æP t·ª´ module m·ªõi (FIX REGRESSION BUG)
        try:
            # Th·ª≠ import tuy·ªát ƒë·ªëi tr∆∞·ªõc
            try:
                from logic.analytics.dashboard_scorer import (
                    get_loto_gan_stats,
                    get_loto_stats_last_n_days,
                    get_prediction_consensus,
                    get_high_win_rate_predictions,
                    get_top_memory_bridge_predictions,
                    get_top_scored_pairs,
                )
            except ImportError:
                # Fallback: th·ª≠ import t∆∞∆°ng ƒë·ªëi
                from logic.dashboard_analytics import (
                    get_loto_gan_stats,
                    get_loto_stats_last_n_days,
                    get_prediction_consensus,
                    get_high_win_rate_predictions,
                    get_top_memory_bridge_predictions,
                    get_top_scored_pairs,
                )
            
            self.get_loto_gan_stats = get_loto_gan_stats
            self.get_loto_stats_last_n_days = get_loto_stats_last_n_days
            self.get_prediction_consensus = get_prediction_consensus
            self.get_high_win_rate_predictions = get_high_win_rate_predictions
            self.get_top_memory_bridge_predictions = get_top_memory_bridge_predictions
            self.get_top_scored_pairs = get_top_scored_pairs
        except ImportError as e:
            self._log(f"L·ªñI NGHI√äM TR·ªåNG: Kh√¥ng th·ªÉ import dashboard analytics functions: {e}")
            # T·∫°o dummy functions ƒë·ªÉ tr√°nh crash
            def dummy_func(*args, **kwargs):
                return []
            self.get_loto_gan_stats = dummy_func
            self.get_loto_stats_last_n_days = dummy_func
            self.get_prediction_consensus = dummy_func
            self.get_high_win_rate_predictions = dummy_func
            self.get_top_memory_bridge_predictions = dummy_func
            self.get_top_scored_pairs = dummy_func
    
    def _log(self, message):
        """Helper ƒë·ªÉ log messages"""
        if self.logger:
            self.logger.log(message)
    
    def run_backtest(self, all_data_ai, mode, title):
        """
        Ch·∫°y backtest d·ª±a tr√™n mode v√† title.
        
        Args:
            all_data_ai: D·ªØ li·ªáu A:I
            mode: "N1" ho·∫∑c "K2N"
            title: Ti√™u ƒë·ªÅ backtest (ƒë·ªÉ ph√¢n lo·∫°i)
        
        Returns:
            list: K·∫øt qu·∫£ backtest ho·∫∑c None n·∫øu l·ªói
        """
        if not all_data_ai:
            return None
        
        ky_bat_dau = 2
        ky_ket_thuc = len(all_data_ai) + (ky_bat_dau - 1)
        self._log(f"ƒêang ch·∫°y backtest tr√™n {len(all_data_ai)} h√†ng d·ªØ li·ªáu...")
        
        func_to_call = None
        
        if "15" in title:
            func_to_call = self.BACKTEST_15_CAU_N1 if mode == "N1" else self.BACKTEST_15_CAU_K2N
        else:
            if mode == "N1":
                func_to_call = self.BACKTEST_MANAGED_N1
            else:
                func_to_call = lambda a, b, c: self.BACKTEST_MANAGED_K2N(a, b, c, history=True)
        
        if not func_to_call:
            return None
        
        try:
            results = func_to_call(all_data_ai, ky_bat_dau, ky_ket_thuc)
            self._log("Backtest ho√†n t·∫•t.")
            return results
        except Exception as e:
            self._log(f"L·ªói backtest: {e}")
            return None
    
    def run_custom_backtest(self, all_data_ai, mode, custom_bridge_name):
        """
        Ch·∫°y backtest cho c·∫ßu t√πy ch·ªânh.
        
        Args:
            all_data_ai: D·ªØ li·ªáu A:I
            mode: "N1" ho·∫∑c "K2N"
            custom_bridge_name: T√™n c·∫ßu t√πy ch·ªânh
        
        Returns:
            tuple: (results, adjusted_mode, adjusted_title)
        """
        if not all_data_ai:
            return None, mode, None
        
        ky_bat_dau = 2
        ky_ket_thuc = len(all_data_ai) + (ky_bat_dau - 1)
        
        adjusted_mode = mode
        adjusted_title = f"Test C·∫ßu {mode}: {custom_bridge_name}"
        
        if ("T·ªïng(" in custom_bridge_name or "Hi·ªáu(" in custom_bridge_name) and mode == "K2N":
            self._log("L·ªói: C·∫ßu B·∫°c Nh·ªõ ch·ªâ h·ªó tr·ª£ Backtest N1. ƒêang ch·∫°y N1...")
            adjusted_mode = "N1"
            adjusted_title = f"Test C·∫ßu N1: {custom_bridge_name}"
        
        if "T·ªïng(" in custom_bridge_name or "Hi·ªáu(" in custom_bridge_name:
            self._log("L·ªói: Ch·ª©c nƒÉng test c·∫ßu B·∫°c Nh·ªõ t√πy ch·ªânh ch∆∞a ƒë∆∞·ª£c h·ªó tr·ª£.")
            return None, adjusted_mode, adjusted_title
        
        try:
            results = self.BACKTEST_CUSTOM(all_data_ai, ky_bat_dau, ky_ket_thuc, custom_bridge_name, adjusted_mode)
            return results, adjusted_mode, adjusted_title
        except Exception as e:
            self._log(f"L·ªói custom backtest: {e}")
            return None, adjusted_mode, adjusted_title
    
    def run_backtest_memory(self, all_data_ai):
        """Ch·∫°y backtest c·∫ßu B·∫°c Nh·ªõ"""
        if not all_data_ai:
            return None
        
        ky_bat_dau = 2
        ky_ket_thuc = len(all_data_ai) + (ky_bat_dau - 1)
        
        try:
            results = self.BACKTEST_MEMORY(all_data_ai, ky_bat_dau, ky_ket_thuc)
            return results
        except Exception as e:
            self._log(f"L·ªói backtest memory: {e}")
            return None
    
    def run_backtest_managed_n1(self, all_data_ai):
        """Ch·∫°y backtest c·∫ßu ƒë√£ l∆∞u N1"""
        if not all_data_ai:
            return None
        
        ky_bat_dau = 2
        ky_ket_thuc = len(all_data_ai) + (ky_bat_dau - 1)
        
        try:
            results = self.BACKTEST_MANAGED_N1(all_data_ai, ky_bat_dau, ky_ket_thuc)
            return results
        except Exception as e:
            self._log(f"L·ªói backtest managed N1: {e}")
            return None
    
    def run_backtest_managed_k2n(self, all_data_ai):
        """Ch·∫°y backtest c·∫ßu ƒë√£ l∆∞u K2N"""
        if not all_data_ai:
            return None
        
        ky_bat_dau = 2
        ky_ket_thuc = len(all_data_ai) + (ky_bat_dau - 1)
        
        try:
            results = self.BACKTEST_MANAGED_K2N(all_data_ai, ky_bat_dau, ky_ket_thuc, history=True)
            return results
        except Exception as e:
            self._log(f"L·ªói backtest managed K2N: {e}")
            return None
    
    def train_ai(self, callback=None):
        """
        Hu·∫•n luy·ªán AI model.
        
        Args:
            callback: H√†m callback(success, message)
        
        Returns:
            tuple: (success: bool, message: str)
        """
        def train_callback_wrapper(success, message):
            if callback:
                callback(success, message)
            if success:
                self._log(f">>> Hu·∫•n luy·ªán AI HO√ÄN T·∫§T: {message}")
            else:
                self._log(f"L·ªñI hu·∫•n luy·ªán AI: {message}")
        
        try:
            success, message = self.run_ai_training_threaded(callback=train_callback_wrapper)
            if not success:
                self._log(f"L·ªñI KH·ªûI CH·∫†Y LU·ªíNG: {message}")
            return success, message
        except Exception as e:
            error_msg = f"L·ªói train AI: {e}"
            self._log(error_msg)
            return False, error_msg
    
    def prepare_dashboard_data(self, all_data_ai, data_limit=None, lo_mode=True, de_mode=True):
        """
        Chu·∫©n b·ªã d·ªØ li·ªáu dashboard (ph√¢n t√≠ch to√†n di·ªán) theo ch·∫ø ƒë·ªô (On-Demand).

        Args:
            all_data_ai: D·ªØ li·ªáu A:I
            data_limit: Gi·ªõi h·∫°n s·ªë k·ª≥
            lo_mode: C√≥ ph√¢n t√≠ch L√¥ hay kh√¥ng
            de_mode: C√≥ ph√¢n t√≠ch ƒê·ªÅ hay kh√¥ng

        Returns:
            dict: D·ªØ li·ªáu ƒë√£ ph√¢n t√≠ch
        """
        if not all_data_ai or len(all_data_ai) < 2:
            return None

        # Load settings V√Ä x√°c ƒë·ªãnh gi·ªõi h·∫°n d·ªØ li·ªáu
        data_limit_dashboard = 0 # Default (no limit)
        try:
            from logic.config_manager import SETTINGS
            SETTINGS.load_settings()
            n_days_stats = SETTINGS.STATS_DAYS
            n_days_gan = SETTINGS.GAN_DAYS
            high_win_thresh = SETTINGS.HIGH_WIN_THRESHOLD
            data_limit_dashboard = SETTINGS.DATA_LIMIT_DASHBOARD
        except:
            n_days_stats = 7
            n_days_gan = 15
            high_win_thresh = 47.0

        # X√°c ƒë·ªãnh gi·ªõi h·∫°n cu·ªëi c√πng
        final_data_limit = data_limit if data_limit is not None else data_limit_dashboard

        # ‚ö° √ÅP D·ª§NG GI·ªöI H·∫†N D·ªÆ LI·ªÜU T·ª™ CONFIG
        if final_data_limit > 0 and len(all_data_ai) > final_data_limit:
            all_data_ai = all_data_ai[-final_data_limit:]
            self._log(f"‚ö° HI·ªÜU NƒÇNG: ƒêang ph√¢n t√≠ch {final_data_limit} k·ª≥ g·∫ßn nh·∫•t.")
        else:
            final_data_limit = len(all_data_ai)
            self._log(f"‚ö° Ch·∫ø ƒë·ªô Full Data: ƒêang ph√¢n t√≠ch to√†n b·ªô {final_data_limit} k·ª≥.")
            
        last_row = all_data_ai[-1]
        
        # T√≠nh next_ky (Chung)
        try:
            ky_int = int(last_row[0])
            next_ky = f"K·ª≥ {ky_int + 1}"
        except (ValueError, TypeError):
            next_ky = f"K·ª≥ {last_row[0]} (Next)"
        
        # Kh·ªüi t·∫°o result dict c∆° b·∫£n
        result = {
        "next_ky": next_ky,
        "n_days_stats": n_days_stats,
        "stats_n_day": [],
        "consensus": [],
        "high_win": [],
        "pending_k2n_data": {},
        "gan_stats": [],
        "top_scores": [],
        "top_memory_bridges": [],
        "ai_predictions": [],
        "df_de": None
        }

        # =======================================================================
        # üü¢ PH√ÇN T√çCH L√î (N·∫∑ng nh·∫•t - T√°ch bi·ªát)
        # =======================================================================
        if lo_mode:
            self._log("‚ö° [L√î] B·∫Øt ƒë·∫ßu t√≠nh to√°n ph√¢n h·ªá L√¥...")

            # 1. Th·ªëng k√™
            self._log(f"... (1/6) ƒêang th·ªëng k√™ Loto V·ªÅ Nhi·ªÅu ({n_days_stats} ng√†y)...")
            try:
                stats_n_day = self.get_loto_stats_last_n_days(all_data_ai, n=n_days_stats) or []
                self._log(f"... (Stats) ƒê√£ t√≠nh ƒë∆∞·ª£c {len(stats_n_day)} loto hot")
                result["stats_n_day"] = stats_n_day
            except Exception as e:
                self._log(f"L·ªói th·ªëng k√™ Loto: {e}")
                result["stats_n_day"] = []

            # 2. K2N Cache
            self._log("... (2/6) ƒêang ch·∫°y h√†m C·∫≠p nh·∫≠t K2N Cache...")
            try:
                pending_k2n_data, _, cache_message = self.run_and_update_all_bridge_K2N_cache(all_data_ai, self.db_name)
                result["pending_k2n_data"] = pending_k2n_data or {}
                self._log(f"... (Cache K2N) {cache_message}")
            except Exception as e:
                self._log(f"L·ªói Cache K2N: {e}")
                result["pending_k2n_data"] = {}

            # 3. K1N Rates
            self._log("... (2.5/6) ƒêang c·∫≠p nh·∫≠t T·ª∑ L·ªá v√† Phong ƒê·ªô 10 K·ª≥ t·ª´ K1N...")
            try:
                count, rate_message = self.run_and_update_all_bridge_rates(all_data_ai, self.db_name)
                self._log(f"... (K1N Rates) {rate_message}")
            except Exception as e:
                self._log(f"L·ªói c·∫≠p nh·∫≠t K1N Rates: {e}")

            # 4. Consensus & High Win
            self._log("... (3/6) ƒêang ƒë·ªçc Consensus v√† C·∫ßu T·ª∑ l·ªá Cao t·ª´ cache...")
            try:
                consensus = self.get_prediction_consensus(last_row=last_row, db_name=self.db_name) or []
                result["consensus"] = consensus
                self._log(f"... (Consensus) ƒê√£ ƒë·ªçc ƒë∆∞·ª£c {len(consensus)} c·∫∑p c√≥ vote")
            except Exception: 
                result["consensus"] = []
            
            try:
                high_win = self.get_high_win_rate_predictions(threshold=high_win_thresh) or []
                result["high_win"] = high_win
            except Exception: 
                result["high_win"] = []

            # 5. Gan stats
            self._log(f"... (4/6) ƒêang t√¨m L√¥ Gan (tr√™n {n_days_gan} k·ª≥)...")
            try:
                gan_stats = self.get_loto_gan_stats(all_data_ai, n_days=n_days_gan) or []
                result["gan_stats"] = gan_stats
            except Exception: 
                result["gan_stats"] = []

            # 6. AI predictions
            self._log("... (5/6) ƒêang ch·∫°y d·ª± ƒëo√°n AI...")
            try:
                ai_res = self.run_ai_prediction_for_dashboard()
                if ai_res and isinstance(ai_res, tuple) and len(ai_res) >= 2:
                    result["ai_predictions"] = ai_res[0]
                    self._log(f"... (AI) {ai_res[1]}")
                else:
                    result["ai_predictions"] = []
            except Exception as e:
                self._log(f"L·ªói d·ª± ƒëo√°n AI: {e}")
                result["ai_predictions"] = []

            # 7. Top memory & Top Score
            try:
                top_memory_bridges = self.get_top_memory_bridge_predictions(all_data_ai, last_row, top_n=5) or []
                result["top_memory_bridges"] = top_memory_bridges

                self._log("... (6/6) T√≠nh ƒëi·ªÉm t·ªïng l·ª±c...")
                top_scores = self.get_top_scored_pairs(
                    result.get("stats_n_day"), result.get("consensus"), result.get("high_win"), 
                    result.get("pending_k2n_data"), result.get("gan_stats"), top_memory_bridges, 
                    result.get("ai_predictions")
                )
                result["top_scores"] = top_scores or []
                self._log(f"... (Top Scores) ƒê√£ t√≠nh ƒë∆∞·ª£c {len(result['top_scores'])} c·∫∑p c√≥ ƒëi·ªÉm")
            except Exception as e:
                self._log(f"L·ªói t√≠nh ƒêi·ªÉm T·ªïng L·ª±c: {e}")
                result["top_scores"] = []

        else:
            self._log("‚è© [L√î] B·ªè qua ph√¢n t√≠ch L√¥.")

        # =======================================================================
        # üî¥ PH√ÇN T√çCH ƒê·ªÄ (T√°ch bi·ªát)
        # =======================================================================
        if de_mode:
            self._log("‚ö° [ƒê·ªÄ] B·∫Øt ƒë·∫ßu t√≠nh to√°n ph√¢n h·ªá ƒê·ªÅ...")
            try:
                cols = ["NB", "NGAY", "GDB", "G1", "G2", "G3", "G4", "G5", "G6", "G7"]
                data_for_df = [r[:10] for r in all_data_ai if r and len(r) >= 10]
                result["df_de"] = pd.DataFrame(data_for_df, columns=cols)
            except Exception as e:
                self._log(f"C·∫£nh b√°o: L·ªói t·∫°o DataFrame cho DE: {e}")
                result["df_de"] = None
        else:
            self._log("‚è© [ƒê·ªÄ] B·ªè qua ph√¢n t√≠ch ƒê·ªÅ.")
            
        return result

        
    
    def train_ai(self, callback=None):
        """
        Hu·∫•n luy·ªán AI model.
        
        Args:
            callback: H√†m callback(success, message)
        
        Returns:
            tuple: (success: bool, message: str)
        """
        def train_callback_wrapper(success, message):
            if callback:
                callback(success, message)
            if success:
                self._log(f">>> Hu·∫•n luy·ªán AI HO√ÄN T·∫§T: {message}")
            else:
                self._log(f"L·ªñI hu·∫•n luy·ªán AI: {message}")
        
        try:
            success, message = self.run_ai_training_threaded(callback=train_callback_wrapper)
            if not success:
                self._log(f"L·ªñI KH·ªûI CH·∫†Y LU·ªíNG: {message}")
            return success, message
        except Exception as e:
            error_msg = f"L·ªói train AI: {e}"
            self._log(error_msg)
            return False, error_msg
    
    def run_parameter_tuning(self, all_data_ai, param_key, val_from, val_to, val_step, log_callback):
        """
        Ch·∫°y parameter tuning cho m·ªôt tham s·ªë c·ª• th·ªÉ.
        
        Args:
            all_data_ai: D·ªØ li·ªáu A:I
            param_key: T√™n tham s·ªë c·∫ßn tune
            val_from, val_to, val_step: Ph·∫°m vi v√† b∆∞·ªõc nh·∫£y
            log_callback: H√†m callback ƒë·ªÉ log (nh·∫≠n message string)
        
        Returns:
            None (k·∫øt qu·∫£ ƒë∆∞·ª£c log qua callback)
        """
        try:
            from logic.config_manager import SETTINGS
            from logic.data_repository import get_all_managed_bridges
            from lottery_service import TIM_CAU_TOT_NHAT_V16, TIM_CAU_BAC_NHO_TOT_NHAT
            
            if not all_data_ai or len(all_data_ai) < 2:
                log_callback("L·ªñI: Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu A:I.")
                return
            
            last_row = all_data_ai[-1]
            log_callback(f"...T·∫£i th√†nh c√¥ng {len(all_data_ai)} k·ª≥.")
            
            def float_range(start, stop, step):
                if step == 0:
                    yield start
                    return
                n = start
                while n < (stop + (step * 0.5)):
                    yield n
                    n += step
            
            def test_gan_days(p_key, v_from, v_to, v_step):
                log_callback(f"--- B·∫Øt ƒë·∫ßu ki·ªÉm th·ª≠: {p_key} ---")
                for i in float_range(v_from, v_to, v_step):
                    n = int(i)
                    if n <= 0:
                        continue
                    gan_stats = self.get_loto_gan_stats(all_data_ai, n_days=n)
                    log_callback(f"Ki·ªÉm th·ª≠ {p_key} = {n}: T√¨m th·∫•y {len(gan_stats)} loto gan.")
                log_callback(f"--- Ho√†n t·∫•t ki·ªÉm th·ª≠ {p_key} ---")
            
            def test_high_win_threshold(p_key, v_from, v_to, v_step):
                log_callback(f"--- B·∫Øt ƒë·∫ßu ki·ªÉm th·ª≠: {p_key} ---")
                log_callback("... (Ch·∫°y Cache K2N m·ªôt l·∫ßn ƒë·ªÉ l·∫•y d·ªØ li·ªáu m·ªõi nh·∫•t)...")
                self.run_and_update_all_bridge_K2N_cache(all_data_ai, self.db_name)
                log_callback("... (Cache K2N ho√†n t·∫•t. B·∫Øt ƒë·∫ßu l·∫∑p)...")
                for i in float_range(v_from, v_to, v_step):
                    high_win_bridges = self.get_high_win_rate_predictions(threshold=i)
                    log_callback(f"Ki·ªÉm th·ª≠ {p_key} >= {i:.1f}%: T√¨m th·∫•y {len(high_win_bridges)} c·∫ßu ƒë·∫°t chu·∫©n.")
                log_callback(f"--- Ho√†n t·∫•t ki·ªÉm th·ª≠ {p_key} ---")
            
            def test_auto_add_rate(p_key, v_from, v_to, v_step):
                log_callback(f"--- B·∫Øt ƒë·∫ßu ki·ªÉm th·ª≠: {p_key} ---")
                log_callback("... (Ch·∫°y D√≤ C·∫ßu V17... R·∫•t n·∫∑ng, vui l√≤ng ch·ªù)...")
                ky_bat_dau = 2
                ky_ket_thuc = len(all_data_ai) + (ky_bat_dau - 1)
                results_v17 = TIM_CAU_TOT_NHAT_V16(all_data_ai, ky_bat_dau, ky_ket_thuc, self.db_name)
                log_callback("... (Ch·∫°y D√≤ C·∫ßu B·∫°c Nh·ªõ...)...")
                results_memory = TIM_CAU_BAC_NHO_TOT_NHAT(all_data_ai, ky_bat_dau, ky_ket_thuc)
                combined_results = []
                if results_v17 and len(results_v17) > 1:
                    combined_results.extend([row for row in results_v17[1:] if "---" not in str(row[0])])
                if results_memory and len(results_memory) > 1:
                    combined_results.extend([row for row in results_memory[1:] if "---" not in str(row[0])])
                if not combined_results:
                    log_callback("L·ªñI: Kh√¥ng d√≤ ƒë∆∞·ª£c c·∫ßu n√†o.")
                    return
                log_callback(f"... (D√≤ c·∫ßu ho√†n t·∫•t. T·ªïng c·ªông {len(combined_results)} c·∫ßu. B·∫Øt ƒë·∫ßu l·∫∑p)...")
                for i in float_range(v_from, v_to, v_step):
                    count = 0
                    for row in combined_results:
                        try:
                            rate = float(str(row[3]).replace("%", ""))
                            if rate >= i:
                                count += 1
                        except (ValueError, IndexError):
                            continue
                    log_callback(f"Ki·ªÉm th·ª≠ {p_key} >= {i:.1f}%: S·∫Ω th√™m/c·∫≠p nh·∫≠t {count} c·∫ßu.")
                log_callback(f"--- Ho√†n t·∫•t ki·ªÉm th·ª≠ {p_key} ---")
            
            def test_auto_prune_rate(p_key, v_from, v_to, v_step):
                log_callback(f"--- B·∫Øt ƒë·∫ßu ki·ªÉm th·ª≠: {p_key} ---")
                log_callback("... (Ch·∫°y Cache K2N m·ªôt l·∫ßn ƒë·ªÉ l·∫•y d·ªØ li·ªáu m·ªõi nh·∫•t)...")
                self.run_and_update_all_bridge_K2N_cache(all_data_ai, self.db_name)
                log_callback("... (Cache K2N ho√†n t·∫•t. B·∫Øt ƒë·∫ßu l·∫∑p)...")
                enabled_bridges = get_all_managed_bridges(self.db_name, only_enabled=True)
                if not enabled_bridges:
                    log_callback("L·ªñI: Kh√¥ng c√≥ c·∫ßu n√†o ƒëang B·∫≠t ƒë·ªÉ ki·ªÉm th·ª≠.")
                    return
                for i in float_range(v_from, v_to, v_step):
                    count = 0
                    for bridge in enabled_bridges:
                        try:
                            rate_str = str(bridge.get("win_rate_text", "100%")).replace("%", "")
                            if not rate_str or rate_str == "N/A":
                                continue
                            rate = float(rate_str)
                            if rate < i:
                                count += 1
                        except ValueError:
                            continue
                    log_callback(f"Ki·ªÉm th·ª≠ {p_key} < {i:.1f}%: S·∫Ω T·∫ÆT {count} c·∫ßu.")
                log_callback(f"--- Ho√†n t·∫•t ki·ªÉm th·ª≠ {p_key} ---")
            
            def test_k2n_risk_logic(p_key, v_from, v_to, v_step):
                log_callback(f"--- B·∫Øt ƒë·∫ßu ki·ªÉm th·ª≠: {p_key} ---")
                log_callback("... (Ch·∫°y Cache K2N m·ªôt l·∫ßn ƒë·ªÉ l·∫•y d·ªØ li·ªáu n·ªÅn)...")
                pending_k2n, _, _ = self.run_and_update_all_bridge_K2N_cache(all_data_ai, self.db_name)
                stats_n_day = self.get_loto_stats_last_n_days(all_data_ai)
                # Truy·ªÅn last_row n·∫øu c√≥ ƒë·ªÉ t√≠nh to√°n tr·ª±c ti·∫øp
                test_last_row = all_data_ai[-1] if all_data_ai else None
                consensus = self.get_prediction_consensus(last_row=test_last_row, db_name=self.db_name)
                high_win = self.get_high_win_rate_predictions()
                gan_stats = self.get_loto_gan_stats(all_data_ai)
                top_memory = self.get_top_memory_bridge_predictions(all_data_ai, last_row)
                ai_preds, _ = self.run_ai_prediction_for_dashboard()
                log_callback("... (D·ªØ li·ªáu n·ªÅn ho√†n t·∫•t. B·∫Øt ƒë·∫ßu l·∫∑p)...")
                original_value = SETTINGS.get_all_settings().get(p_key)
                for i in float_range(v_from, v_to, v_step):
                    val = i
                    if p_key == "K2N_RISK_START_THRESHOLD":
                        val = int(i)
                    setattr(SETTINGS, p_key, val)
                    top_scores = self.get_top_scored_pairs(stats_n_day, consensus, high_win, pending_k2n, gan_stats, top_memory, ai_preds)
                    if not top_scores:
                        log_callback(f"Ki·ªÉm th·ª≠ {p_key} = {val}: Kh√¥ng c√≥ c·∫∑p n√†o ƒë·∫°t ƒëi·ªÉm.")
                    else:
                        top_score_item = top_scores[0]
                        log_callback(f"Ki·ªÉm th·ª≠ {p_key} = {val}: Top 1 l√† {top_score_item['pair']} (ƒêi·ªÉm: {top_score_item['score']})")
                if original_value is not None:
                    setattr(SETTINGS, p_key, original_value)
                log_callback(f"--- Ho√†n t·∫•t ki·ªÉm th·ª≠ {p_key} ---")
            
            # Dispatch
            if param_key == "GAN_DAYS":
                test_gan_days(param_key, val_from, val_to, val_step)
            elif param_key == "HIGH_WIN_THRESHOLD":
                test_high_win_threshold(param_key, val_from, val_to, val_step)
            elif param_key == "AUTO_ADD_MIN_RATE":
                test_auto_add_rate(param_key, val_from, val_to, val_step)
            elif param_key == "AUTO_PRUNE_MIN_RATE":
                test_auto_prune_rate(param_key, val_from, val_to, val_step)
            elif param_key in ["K2N_RISK_START_THRESHOLD", "K2N_RISK_PENALTY_PER_FRAME"]:
                test_k2n_risk_logic(param_key, val_from, val_to, val_step)
            else:
                log_callback(f"L·ªói: Ch∆∞a ƒë·ªãnh nghƒ©a logic ki·ªÉm th·ª≠ cho {param_key}")
        except Exception as e:
            log_callback(f"L·ªñI: {e}")
            import traceback
            log_callback(traceback.format_exc())
    
    def run_strategy_optimization(self, all_data_ai, days_to_test, param_ranges, log_callback, update_results_callback):
        """
        Ch·∫°y t·ªëi ∆∞u h√≥a chi·∫øn l∆∞·ª£c (strategy optimization).
        
        Args:
            all_data_ai: D·ªØ li·ªáu A:I
            days_to_test: S·ªë ng√†y ƒë·ªÉ test
            param_ranges: Dict c√°c tham s·ªë c·∫ßn optimize {param: (from, to, step)}
            log_callback: H√†m callback ƒë·ªÉ log (nh·∫≠n message string)
            update_results_callback: H√†m callback ƒë·ªÉ update k·∫øt qu·∫£ (nh·∫≠n results_list)
        
        Returns:
            None (k·∫øt qu·∫£ ƒë∆∞·ª£c g·ªçi qua callbacks)
        """
        try:
            from logic.config_manager import SETTINGS
            from logic.dashboard_analytics import prepare_daily_features, calculate_score_from_features
            
            if not all_data_ai or len(all_data_ai) < days_to_test + 50:
                log_callback(f"L·ªñI: C·∫ßn √≠t nh·∫•t {days_to_test + 50} k·ª≥ d·ªØ li·ªáu ƒë·ªÉ ki·ªÉm th·ª≠.")
                return
            
            log_callback(f"...T·∫£i d·ªØ li·ªáu th√†nh c√¥ng ({len(all_data_ai)} k·ª≥).")
            
            # Data limit
            try:
                limit = getattr(SETTINGS, "DATA_LIMIT_RESEARCH", 0)
            except:
                limit = 0
            if limit > 0 and len(all_data_ai) > limit:
                data_processing = all_data_ai[-limit:]
                log_callback(f"‚ö° HI·ªÜU NƒÇNG: T·ªëi ∆∞u h√≥a tr√™n {limit} k·ª≥ g·∫ßn nh·∫•t.")
            else:
                data_processing = all_data_ai
                log_callback(f"‚ö° Ch·∫ø ƒë·ªô Full Data: T·ªëi ∆∞u h√≥a tr√™n to√†n b·ªô {len(all_data_ai)} k·ª≥.")
            
            def float_range(start, stop, step):
                if step == 0:
                    yield start
                    return
                n = start
                while n < (stop + (step * 0.5)):
                    yield n
                    n += step
            
            def generate_combinations(param_ranges, original_settings):
                param_lists = []
                config_keys = list(param_ranges.keys())
                static_keys = [k for k in original_settings.keys() if k not in config_keys]
                for key in config_keys:
                    v_from, v_to, v_step = param_ranges[key]
                    if isinstance(original_settings[key], int):
                        param_lists.append([(key, int(i)) for i in float_range(v_from, v_to, v_step) if i >= 0])
                    else:
                        param_lists.append([(key, round(i, 2)) for i in float_range(v_from, v_to, v_step) if i >= 0])
                if not param_lists:
                    return []
                combinations = []
                for combo in itertools.product(*param_lists):
                    temp_config = {}
                    for static_key in static_keys:
                        temp_config[static_key] = original_settings[static_key]
                    for key, value in combo:
                        temp_config[key] = value
                    combinations.append(temp_config)
                return combinations
            
            original_settings = SETTINGS.get_all_settings()
            combinations = generate_combinations(param_ranges, original_settings)
            total_combos = len(combinations)
            if total_combos == 0:
                log_callback("L·ªói: Kh√¥ng t·∫°o ƒë∆∞·ª£c t·ªï h·ª£p ki·ªÉm th·ª≠.")
                return
            
            log_callback(f"ƒê√£ t·∫°o {total_combos} t·ªï h·ª£p. B·∫Øt ƒë·∫ßu chu·∫©n b·ªã features cache...")
            
            # Precompute features
            cached_features = []
            offset = len(data_processing) - days_to_test
            for i in range(days_to_test):
                day_index = offset + i
                log_callback(f"ƒêang chu·∫©n b·ªã d·ªØ li·ªáu ng√†y {day_index + 1 - offset}/{days_to_test} ...")
                try:
                    features = prepare_daily_features(data_processing, day_index)
                    cached_features.append(features)
                except Exception as e:
                    log_callback(f"L·ªói khi prepare features ng√†y {i+1}: {e}")
                    cached_features.append(None)
            
            results_list = []
            log_callback(f"Chu·∫©n b·ªã xong features. B·∫Øt ƒë·∫ßu Loop t·ªëi ∆∞u ({total_combos} t·ªï h·ª£p)...")
            for ci, config in enumerate(combinations):
                log_callback(f"--- ƒêang ki·ªÉm th·ª≠ [{ci + 1}/{total_combos}]: {config} ---")
                total_hits = 0
                days_tested = 0
                for fidx, features in enumerate(cached_features):
                    if not features:
                        continue
                    try:
                        top_scores = calculate_score_from_features(features, config)
                    except Exception as e:
                        log_callback(f"L·ªói t√≠nh score ng√†y {fidx+1}: {e}")
                        continue
                    days_tested += 1
                    if not top_scores:
                        continue
                    top1 = top_scores[0]
                    last_row = features['recent_data'][-1] if 'recent_data' in features else None
                    if last_row:
                        actual_lotos = set(self.getAllLoto_V30(last_row))
                        loto1, loto2 = top1['pair'].split('-')
                        if loto1 in actual_lotos or loto2 in actual_lotos:
                            total_hits += 1
                rate = total_hits / days_tested if days_tested > 0 else 0
                hits_str = f"{total_hits}/{days_tested}"
                config_str_json = json.dumps(config)
                params_str_display = ", ".join([f"{key}: {value}" for key, value in config.items() if key in param_ranges])
                results_list.append((rate, hits_str, params_str_display, config_str_json))
                log_callback(f"-> K·∫øt qu·∫£: {hits_str} ({rate * 100:.1f}%)")
            
            log_callback("ƒêang s·∫Øp x·∫øp k·∫øt qu·∫£...")
            results_list.sort(key=lambda x: x[0], reverse=True)
            if update_results_callback:
                update_results_callback(results_list)
            log_callback("--- HO√ÄN T·∫§T T·ªêI ∆ØU H√ìA ---")
        except Exception as e:
            log_callback(f"L·ªñI: {e}")
            import traceback
            log_callback(traceback.format_exc())
    
    def run_lo_backtest_30_days(self, bridge_name, all_data_ai):
        """
        Ch·∫°y backtest 30 ng√†y cho m·ªôt c·∫ßu L√¥ c·ª• th·ªÉ.
        
        Args:
            bridge_name: T√™n c·∫ßu
            all_data_ai: To√†n b·ªô d·ªØ li·ªáu A:I
        
        Returns:
            list: List c√°c dict v·ªõi k·∫øt qu·∫£ backtest ho·∫∑c None n·∫øu l·ªói
        """
        if not all_data_ai:
            return None
        
        try:
            from logic.data_repository import get_bridge_by_name
            from logic.backtester import run_backtest_lo_30_days
            
            # L·∫•y bridge config t·ª´ DB b·∫±ng h√†m m·ªõi (ƒë·∫£m b·∫£o c√≥ pos1_idx)
            bridge_config = get_bridge_by_name(bridge_name, self.db_name)
            if not bridge_config:
                self._log(f"Kh√¥ng t√¨m th·∫•y c·∫ßu '{bridge_name}' trong database.")
                return None
            
            # [DEBUG] Ki·ªÉm tra xem config c√≥ v·ªã tr√≠ kh√¥ng ƒë·ªÉ log c·∫£nh b√°o
            if bridge_config.get('pos1_idx') is None and "LO_STL_FIXED" not in bridge_name:
                 self._log(f"C·∫£nh b√°o: C·∫ßu '{bridge_name}' thi·∫øu th√¥ng tin v·ªã tr√≠ (pos1_idx). K·∫øt qu·∫£ c√≥ th·ªÉ r·ªóng.")

            # Ch·∫°y backtest
            results = run_backtest_lo_30_days(bridge_config, all_data_ai)
            return results
    
        except Exception as e:
            self._log(f"L·ªói ch·∫°y backtest 30 ng√†y: {e}")
            import traceback
            self._log(traceback.format_exc())
            return None
    
    def run_de_backtest_30_days(self, bridge_name, all_data_ai):
        """
        Ch·∫°y backtest 30 ng√†y cho c·∫ßu ƒê·ªÅ.
        [FIX SHADOW] ∆Øu ti√™n c·∫•u h√¨nh Managed Bridge t·ª´ DB ƒë·ªÉ ƒë·ªìng b·ªô v·ªõi Dashboard.
        """
        if not all_data_ai:
            return None
        
        try:
            from services.bridge_service import BridgeService
            from logic.de_backtester_core import run_de_bridge_historical_test
            
            # --- 1. ∆ØU TI√äN: KI·ªÇM TRA TRONG DB TR∆Ø·ªöC (Managed Bridge) ---
            # ƒê·ªÉ ƒë·∫£m b·∫£o logic ƒë·ªìng nh·∫•t v·ªõi B·∫£ng C·∫ßu ƒê·ªông (d√πng Index V16)
            bridge_service = BridgeService(self.db_name, logger=self.logger)
            bridge_config = bridge_service.get_de_bridge_config_by_name(bridge_name)
            
            if bridge_config:
                # N·∫øu t√¨m th·∫•y trong DB, ch·∫°y ngay v·ªõi config ƒë√≥ (s·∫Ω d√πng pos1_idx chu·∫©n)
                self._log(f"-> Ch·∫°y Backtest Managed Bridge: {bridge_name}")
                return run_de_bridge_historical_test(bridge_config, all_data_ai, days=30)

            # --- 2. N·∫æU KH√îNG C√ì TRONG DB -> CH·∫†Y LOGIC SCANNER T·ª™ T√äN ---
            is_scanner = False
            def_string = bridge_name
            b_type = "UNKNOWN"
            k_offset = 0

            # CASE A: C·∫ßu Scanner chu·∫©n m·ªõi (VD: GDB.0-G1.0)
            if "G" in bridge_name and "-" in bridge_name and any(c.isdigit() for c in bridge_name):
                is_scanner = True
                if "B·ªô" in bridge_name or "DE_SET" in bridge_name: b_type = "DE_SET"
                elif "DE_POS" in bridge_name: b_type = "DE_POS_SUM"
                else: b_type = "DE_DYNAMIC_K"
            
            # CASE B: C·∫ßu Dynamic c≈© / Killer / B·ªô / Pos / C·∫ßu B√≥ng (D·∫°ng chu·ªói nh∆∞ng kh√¥ng c√≥ trong DB)
            elif any(x in bridge_name for x in ["DE_DYN_", "DE_KILLER_", "DE_SET_", "DE_POS_"]):
                try:
                    parts = bridge_name.split('_')
                    
                    # [FIX QUAN TR·ªåNG] Nh·∫≠n di·ªán c·∫£ 'G...' V√Ä 'Bong(...)'
                    pos_parts = []
                    for p in parts:
                        if any(c.isdigit() for c in p) and (p.startswith("G") or p.lower().startswith("bong") or "ong(" in p):
                            pos_parts.append(p)
                    
                    if len(pos_parts) >= 2:
                        p1 = pos_parts[0].replace('[', '.').replace(']', '') 
                        p2 = pos_parts[1].replace('[', '.').replace(']', '')
                        
                        def_string = f"{p1}-{p2}"
                        is_scanner = True
                        
                        if "DE_SET_" in bridge_name: b_type = "DE_SET"
                        elif "DE_POS_" in bridge_name: b_type = "DE_POS_SUM"
                        elif "DE_KILLER_" in bridge_name: b_type = "DE_DYNAMIC_K"
                        else: b_type = "DE_DYNAMIC_K"
                            
                        if parts[-1].startswith("K") and parts[-1][1:].isdigit():
                            k_offset = int(parts[-1][1:])
                            
                        self._log(f"-> Converted '{bridge_name}' to Scanner format: '{def_string}'")
                except: pass 

            # --- 3. G·ªåI BACKTEST SCANNER ---
            if is_scanner:
                scanner_config = {
                    "name": bridge_name,
                    "type": b_type,
                    "is_scanner_result": True, 
                    "def_string": def_string,
                    "k_offset": k_offset
                }
                return run_de_bridge_historical_test(scanner_config, all_data_ai, days=30)
            
            return None
                
        except Exception as e:
            self._log(f"L·ªói Backtest ƒê·ªÅ: {e}")
            import traceback
            self._log(traceback.format_exc())
            return None

    def calculate_lo_scoring_engine(self, all_data_ai):
        """
        [NEW V3.8 - ROBUST] Ch·∫°y Scoring Engine cho L√¥.
        S·ª≠ d·ª•ng k·∫øt n·ªëi SQL tr·ª±c ti·∫øp ƒë·ªÉ tr√°nh l·ªói import v√≤ng (Circular Import).
        """
        try:
            # Import logic t√≠nh ƒëi·ªÉm
            from logic.lo_analytics import calculate_lo_scores
            import sqlite3
            
            self._log("--- B·∫Øt ƒë·∫ßu Scoring Engine L√¥ (Direct SQL Mode) ---")

            # 1. L·∫•y d·ªØ li·ªáu C·∫ßu (Managed Bridges) - QUAN TR·ªåNG: D√πng SQL tr·ª±c ti·∫øp
            bridges = []
            try:
                # K·∫øt n·ªëi tr·ª±c ti·∫øp DB ƒë·ªÉ l·∫•y c·∫ßu active
                conn = sqlite3.connect(self.db_name)
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute("SELECT * FROM ManagedBridges WHERE is_enabled = 1")
                rows = cursor.fetchall()
                # Convert row object to dict
                bridges = [dict(row) for row in rows]
                conn.close()
                self._log(f"-> [SQL] ƒê√£ t·∫£i {len(bridges)} c·∫ßu ho·∫°t ƒë·ªông.")
            except Exception as e:
                self._log(f"‚ö†Ô∏è L·ªói k·∫øt n·ªëi DB l·∫•y c·∫ßu: {e}")
                bridges = []
            
            # 2. L·∫•y d·ªØ li·ªáu Th·ªëng k√™ (Gan & T·∫ßn su·∫•t)
            gan_stats = self.get_loto_gan_stats(all_data_ai, n_days=10) or []
            freq_stats = self.get_loto_stats_last_n_days(all_data_ai, n=30) or []
            
            # 3. L·∫•y B·∫°c nh·ªõ
            last_row = all_data_ai[-1] if all_data_ai else None
            top_memory = self.get_top_memory_bridge_predictions(all_data_ai, last_row, top_n=5) or []
            
            # 4. T√≠nh ƒëi·ªÉm
            scores = calculate_lo_scores(bridges, gan_stats, freq_stats, top_memory)
            self._log(f"-> T√≠nh ƒëi·ªÉm xong. Top 1: {scores[0] if scores else 'None'}")
            
            return scores, gan_stats
            
        except Exception as e:
            self._log(f"‚ùå L·ªñI CRITICAL Scoring Engine: {e}")
            import traceback
            self._log(traceback.format_exc())
            return [], []


--------------------------------------------------

=== FILE: services\bridge_service.py ===
# T√™n file: services/bridge_service.py
# Service layer: Logic qu·∫£n l√Ω c·∫ßu

import traceback

# Import c√°c h√†m Data Repository v·ªõi alias ƒë·ªÉ h·ªó tr·ª£ testing v√† mocking
try:
    from logic.data_repository import get_all_managed_bridges as data_repo_get_all_managed_bridges
    from logic.data_repository import get_bridge_by_name as data_repo_get_bridge_by_name
except ImportError:
    # Fallback n·∫øu kh√¥ng import ƒë∆∞·ª£c
    data_repo_get_all_managed_bridges = None
    data_repo_get_bridge_by_name = None

# Import c√°c h√†m DB Manager v·ªõi alias n·∫øu c·∫ßn
try:
    from logic.db_manager import update_managed_bridge as db_manager_update_managed_bridge
    from logic.db_manager import toggle_pin_bridge as db_manager_toggle_pin_bridge
    # Alias cho update_bridge_status (c√≥ th·ªÉ l√† wrapper ho·∫∑c t√™n kh√°c c·ªßa update_managed_bridge)
    # N·∫øu h√†m update_bridge_status kh√¥ng t·ªìn t·∫°i, s·ª≠ d·ª•ng update_managed_bridge l√†m alias
    try:
        from logic.db_manager import update_bridge_status as db_manager_update_bridge_status
    except ImportError:
        # Fallback: S·ª≠ d·ª•ng update_managed_bridge l√†m alias cho update_bridge_status
        from logic.db_manager import update_managed_bridge as db_manager_update_bridge_status
except ImportError:
    # Fallback n·∫øu kh√¥ng import ƒë∆∞·ª£c
    db_manager_update_managed_bridge = None
    db_manager_toggle_pin_bridge = None
    db_manager_update_bridge_status = None

class BridgeService:
    """Service qu·∫£n l√Ω c·∫ßu (L√¥ & ƒê·ªÅ)"""
    
    def __init__(self, db_name, logger=None):
        self.db_name = db_name
        self.logger = logger
    
    def _log(self, message):
        """Helper ƒë·ªÉ log messages"""
        if self.logger:
            self.logger.log(message)
    
    def find_and_scan_bridges(self, all_data_ai, scan_limit=None):
        """
        Qu√©t v√† t√¨m c·∫ßu L√¥ & ƒê·ªÅ t·ª± ƒë·ªông.
        
        Args:
            all_data_ai: D·ªØ li·ªáu A:I
            scan_limit: Gi·ªõi h·∫°n s·ªë k·ª≥ ƒë·ªÉ qu√©t (None = to√†n b·ªô)
        
        Returns:
            dict: K·∫øt qu·∫£ qu√©t v·ªõi keys 'lo' v√† 'de'
        """
        if not all_data_ai:
            return {"lo": None, "de": None}
        
        # √Åp d·ª•ng scan limit n·∫øu c√≥
        if scan_limit and scan_limit > 0 and len(all_data_ai) > scan_limit:
            self._log(f"‚ö° T·ª∞ ƒê·ªòNG T·ªêI ∆ØU: H·ªá th·ªëng ch·ªâ qu√©t tr√™n {scan_limit} k·ª≥ g·∫ßn nh·∫•t ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô.")
            scan_data = all_data_ai[-scan_limit:]
        else:
            scan_data = all_data_ai
        
        result = {"lo": None, "de": None}
        
        # 1. Qu√©t c·∫ßu L√¥
        try:
            self._log(">>> ƒêang qu√©t c·∫ßu L√¥ (V17 & B·∫°c Nh·ªõ)...")
            from lottery_service import find_and_auto_manage_bridges
            msg_lo = find_and_auto_manage_bridges(scan_data, self.db_name)
            result["lo"] = msg_lo
            self._log(f"L√¥: {msg_lo}")
        except Exception as e:
            self._log(f"L·ªói qu√©t L√¥: {e}")
        
        # 2. Qu√©t c·∫ßu ƒê·ªÅ
        try:
            self._log(">>> ƒêang qu√©t c·∫ßu ƒê·ªÅ (Ch·∫°m/T·ªïng/B·ªô)...")
            from logic.bridges.de_bridge_scanner import run_de_scanner
            count, bridges = run_de_scanner(scan_data)
            result["de"] = f"ƒê√£ t√¨m th·∫•y v√† l∆∞u {count} c·∫ßu ƒê·ªÅ ƒëang th√¥ng."
            self._log(result["de"])
        except Exception as e:
            self._log(f"L·ªói qu√©t ƒê·ªÅ: {e}")
        
        return result
    
    def prune_bad_bridges(self, all_data_ai):
        """
        X√≥a c√°c c·∫ßu c√≥ t·ª∑ l·ªá th·∫•p.
        
        Args:
            all_data_ai: D·ªØ li·ªáu A:I
        
        Returns:
            str: Th√¥ng b√°o k·∫øt qu·∫£
        """
        if not all_data_ai:
            return "L·ªói: Kh√¥ng c√≥ d·ªØ li·ªáu"
        
        try:
            from lottery_service import prune_bad_bridges
            return prune_bad_bridges(all_data_ai, self.db_name)
        except ImportError:
            try:
                from services.bridge_service import prune_bad_bridges as _prune
                return _prune(all_data_ai, self.db_name)
            except:
                return "L·ªói: Kh√¥ng th·ªÉ import prune_bad_bridges"
    
    def auto_manage_bridges(self, all_data_ai):
        """
        T·ª± ƒë·ªông B·∫¨T/T·∫ÆT c·∫ßu d·ª±a tr√™n t·ª∑ l·ªá K2N.
        
        Args:
            all_data_ai: D·ªØ li·ªáu A:I
        
        Returns:
            str: Th√¥ng b√°o k·∫øt qu·∫£
        """
        if not all_data_ai:
            return "L·ªói: Kh√¥ng c√≥ d·ªØ li·ªáu"
        
        try:
            from lottery_service import auto_manage_bridges
            return auto_manage_bridges(all_data_ai, self.db_name)
        except ImportError:
            return "L·ªói: Kh√¥ng th·ªÉ import auto_manage_bridges"
    
    def smart_optimization(self, all_data_ai):
        """
        G·ªôp ch·ª©c nƒÉng: L·ªçc c·∫ßu y·∫øu + Qu·∫£n l√Ω t·ª± ƒë·ªông.
        
        Args:
            all_data_ai: D·ªØ li·ªáu A:I
        
        Returns:
            tuple: (prune_message: str, manage_message: str)
        """
        if not all_data_ai:
            return None, None
        
        self._log("\n--- ‚ö° B·∫ÆT ƒê·∫¶U: T·ªëi ∆Øu H√≥a C·∫ßu ---")
        
        # B∆∞·ªõc 1: Prune
        self._log("(1/2) ƒêang qu√©t v√† T·∫ÆT c√°c c·∫ßu hi·ªáu qu·∫£ k√©m...")
        msg_prune = self.prune_bad_bridges(all_data_ai)
        self._log(f"-> K·∫øt qu·∫£ l·ªçc: {msg_prune}")
        
        # B∆∞·ªõc 2: Auto Manage
        self._log("(2/2) ƒêang ki·ªÉm tra v√† B·∫¨T l·∫°i c√°c c·∫ßu ti·ªÅm nƒÉng...")
        msg_manage = self.auto_manage_bridges(all_data_ai)
        self._log(f"-> K·∫øt qu·∫£ qu·∫£n l√Ω: {msg_manage}")
        
        self._log("‚úÖ T·ªêI ∆ØU H√ìA HO√ÄN T·∫§T!")
        
        return msg_prune, msg_manage
    
    def update_k2n_cache(self, all_data_ai):
        """
        C·∫≠p nh·∫≠t cache K2N cho c√°c c·∫ßu.
        
        Args:
            all_data_ai: D·ªØ li·ªáu A:I
        
        Returns:
            tuple: (pending_dict, cache_count, message)
        """
        if not all_data_ai:
            return {}, 0, "L·ªói: Kh√¥ng c√≥ d·ªØ li·ªáu"
        
        try:
            from lottery_service import run_and_update_all_bridge_K2N_cache
            pending_dict, cache_count, message = run_and_update_all_bridge_K2N_cache(all_data_ai, self.db_name)
            self._log(message)
            return pending_dict, cache_count, message
        except Exception as e:
            error_msg = f"L·ªói c·∫≠p nh·∫≠t K2N cache: {e}"
            self._log(error_msg)
            return {}, 0, error_msg
    
    def should_refresh_bridge_manager(self):
        """
        Ki·ªÉm tra xem c√≥ c·∫ßn refresh bridge manager window kh√¥ng.
        
        Returns:
            bool: True n·∫øu c·∫ßn refresh
        """
        # Logic n√†y s·∫Ω ƒë∆∞·ª£c controller x·ª≠ l√Ω v√¨ c·∫ßn truy c·∫≠p app.bridge_manager_window
        return True
    
    def get_de_bridge_config_by_name(self, bridge_name):
        """
        L·∫•y c·∫•u h√¨nh c·∫ßu ƒê·ªÅ t·ª´ DB b·∫±ng t√™n.
        
        Args:
            bridge_name: T√™n c·∫ßu
        
        Returns:
            dict: C·∫•u h√¨nh c·∫ßu (bao g·ªìm pos1_idx, pos2_idx, type, v.v.) ho·∫∑c None n·∫øu kh√¥ng t√¨m th·∫•y
        """
        try:
            # S·ª≠ d·ª•ng alias ƒë√£ import ·ªü c·∫•p module (global)
            if data_repo_get_bridge_by_name is None:
                from logic.data_repository import get_bridge_by_name
                bridge_config = get_bridge_by_name(bridge_name, self.db_name)
            else:
                # S·ª≠ d·ª•ng alias ƒë√£ ƒë∆∞·ª£c patch trong test
                bridge_config = data_repo_get_bridge_by_name(bridge_name, self.db_name)
            if not bridge_config:
                self._log(f"Kh√¥ng t√¨m th·∫•y c·∫ßu '{bridge_name}' trong database.")
                return None
            
            # Ki·ªÉm tra xem c√≥ ph·∫£i c·∫ßu ƒê·ªÅ kh√¥ng
            bridge_type = bridge_config.get("type", "")
            if not (bridge_type.startswith("DE_") or "DE_" in bridge_name):
                # Kh√¥ng ph·∫£i c·∫ßu ƒê·ªÅ, tr·∫£ v·ªÅ None
                return None
            
            return bridge_config
        except Exception as e:
            self._log(f"L·ªói l·∫•y c·∫•u h√¨nh c·∫ßu ƒê·ªÅ '{bridge_name}': {e}")
            import traceback
            self._log(traceback.format_exc())
            return None
    
    def toggle_pin_bridge(self, bridge_name):
        """
        ƒê·∫£o ng∆∞·ª£c tr·∫°ng th√°i ghim c·ªßa c·∫ßu (Phase 4 - Pinning).
        
        Args:
            bridge_name: T√™n c·∫ßu
        
        Returns:
            tuple: (success: bool, message: str, new_pin_state: bool or None)
        """
        try:
            # S·ª≠ d·ª•ng alias ƒë√£ import ·ªü c·∫•p module (global)
            # N·∫øu alias l√† None, import l·∫°i
            if db_manager_toggle_pin_bridge is None:
                from logic.db_manager import toggle_pin_bridge
                success, message, new_pin_state = toggle_pin_bridge(bridge_name, self.db_name)
            else:
                # S·ª≠ d·ª•ng alias ƒë√£ ƒë∆∞·ª£c patch trong test
                success, message, new_pin_state = db_manager_toggle_pin_bridge(bridge_name, self.db_name)
            
            if success:
                pin_status = "ƒë√£ ghim" if new_pin_state else "ƒë√£ b·ªè ghim"
                self._log(f">>> [PIN] C·∫ßu '{bridge_name}' {pin_status}.")
            else:
                self._log(f">>> [PIN] L·ªói: {message}")
            
            return success, message, new_pin_state
        
        except Exception as e:
            error_msg = f"L·ªói khi ghim/b·ªè ghim c·∫ßu '{bridge_name}': {e}"
            self._log(error_msg)
            import traceback
            self._log(traceback.format_exc())
            return False, error_msg, None
    
    def prune_bad_de_bridges(self, all_data):
        """
        T·ª± ƒë·ªông lo·∫°i b·ªè c·∫ßu ƒê·ªÅ c√≥ chu·ªói G√£y l√¢u nh·∫•t v∆∞·ª£t qu√° ng∆∞·ª°ng.
        
        Args:
            all_data: To√†n b·ªô d·ªØ li·ªáu A:I
        
        Returns:
            str: Th√¥ng b√°o k·∫øt qu·∫£ (s·ªë c·∫ßu b·ªã v√¥ hi·ªáu h√≥a)
        """
        if not all_data or len(all_data) < 2:
            return "L·ªói: Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ki·ªÉm tra."
        
        try:
            # S·ª≠ d·ª•ng alias ƒë√£ import ·ªü c·∫•p module (global)
            if data_repo_get_all_managed_bridges is None:
                from logic.data_repository import get_all_managed_bridges
                all_bridges = get_all_managed_bridges(self.db_name, only_enabled=False)
            else:
                # S·ª≠ d·ª•ng alias ƒë√£ ƒë∆∞·ª£c patch trong test
                all_bridges = data_repo_get_all_managed_bridges(self.db_name, only_enabled=False)
            
            from logic.de_backtester_core import calculate_de_bridge_max_lose_history
            from logic.config_manager import SETTINGS
            
            # X·ª≠ l√Ω all_bridges
            if not all_bridges:
                return "Kh√¥ng c√≥ c·∫ßu n√†o trong database."
            
            # L·∫•y ng∆∞·ª°ng t·ª´ SETTINGS
            threshold = 20  # M·∫∑c ƒë·ªãnh
            try:
                if SETTINGS and hasattr(SETTINGS, 'DE_MAX_LOSE_THRESHOLD'):
                    threshold = int(SETTINGS.DE_MAX_LOSE_THRESHOLD)
                elif SETTINGS and hasattr(SETTINGS, 'get'):
                    threshold = int(SETTINGS.get('DE_MAX_LOSE_THRESHOLD', 20))
            except (ValueError, TypeError, AttributeError):
                threshold = 20  # Fallback
            
            self._log(f">>> [DE PRUNING] B·∫Øt ƒë·∫ßu ki·ªÉm tra c·∫ßu ƒê·ªÅ (Ng∆∞·ª°ng: {threshold} ng√†y)...")
            
            # L·ªçc ch·ªâ c·∫ßu ƒê·ªÅ (DE_POS, DE_DYN)
            de_bridges = []
            for bridge in all_bridges:
                bridge_type = bridge.get("type", "")
                bridge_name = bridge.get("name", "")
                
                # Ki·ªÉm tra xem c√≥ ph·∫£i c·∫ßu ƒê·ªÅ kh√¥ng
                if bridge_type.startswith("DE_") or "DE_" in bridge_name:
                    de_bridges.append(bridge)
            
            if not de_bridges:
                return "Kh√¥ng c√≥ c·∫ßu ƒê·ªÅ n√†o trong database."
            
            self._log(f">>> [DE PRUNING] T√¨m th·∫•y {len(de_bridges)} c·∫ßu ƒê·ªÅ. ƒêang ki·ªÉm tra...")
            
            # Duy·ªát qua t·ª´ng c·∫ßu v√† t√≠nh to√°n Max Lose History
            pruned_count = 0
            error_count = 0
            
            for bridge in de_bridges:
                try:
                    bridge_name = bridge.get("name", "")
                    bridge_id = bridge.get("id")
                    
                    if not bridge_name or not bridge_id:
                        continue
                    
                    # [PHASE 4 - PINNING] B·ªè qua c·∫ßu ƒë√£ ghim
                    is_pinned = bridge.get("is_pinned", 0)
                    if is_pinned:
                        self._log(f"  üìå B·ªè qua c·∫ßu '{bridge_name}' (ƒë√£ ghim).")
                        continue
                    
                    # T√≠nh to√°n Max Lose History
                    max_lose = calculate_de_bridge_max_lose_history(bridge, all_data)
                    
                    if max_lose == -1:
                        # L·ªói t√≠nh to√°n, b·ªè qua
                        error_count += 1
                        continue
                    
                    # Ki·ªÉm tra ng∆∞·ª°ng
                    if max_lose > threshold:
                        # V∆∞·ª£t qu√° ng∆∞·ª°ng: V√¥ hi·ªáu h√≥a c·∫ßu
                        try:
                            # L·∫•y description hi·ªán t·∫°i
                            current_desc = bridge.get("description", "")
                            
                            # C·∫≠p nh·∫≠t is_enabled = 0 (s·ª≠ d·ª•ng alias t·ª´ c·∫•p module)
                            if db_manager_update_managed_bridge is None:
                                from logic.db_manager import update_managed_bridge
                                success, msg = update_managed_bridge(
                                    bridge_id, 
                                    current_desc, 
                                    0,  # is_enabled = 0 (Disabled)
                                    self.db_name
                                )
                            else:
                                # S·ª≠ d·ª•ng alias ƒë√£ ƒë∆∞·ª£c patch trong test
                                success, msg = db_manager_update_managed_bridge(
                                    bridge_id, 
                                    current_desc, 
                                    0,  # is_enabled = 0 (Disabled)
                                    self.db_name
                                )
                            
                            if success:
                                pruned_count += 1
                                self._log(f"  ‚úÇÔ∏è ƒê√£ v√¥ hi·ªáu h√≥a c·∫ßu '{bridge_name}' (Max Lose: {max_lose} > {threshold})")
                            else:
                                self._log(f"  ‚ö†Ô∏è L·ªói khi v√¥ hi·ªáu h√≥a c·∫ßu '{bridge_name}': {msg}")
                        except Exception as e:
                            self._log(f"  ‚ö†Ô∏è L·ªói khi c·∫≠p nh·∫≠t c·∫ßu '{bridge_name}': {e}")
                            error_count += 1
                    else:
                        # Kh√¥ng v∆∞·ª£t ng∆∞·ª°ng: Gi·ªØ nguy√™n
                        pass
                
                except Exception as e:
                    self._log(f"  ‚ö†Ô∏è L·ªói khi x·ª≠ l√Ω c·∫ßu '{bridge.get('name', 'Unknown')}': {e}")
                    error_count += 1
                    continue
            
            # T·ªïng k·∫øt
            result_msg = f"ƒê√£ v√¥ hi·ªáu h√≥a {pruned_count} c·∫ßu ƒê·ªÅ (Max Lose > {threshold} ng√†y)"
            if error_count > 0:
                result_msg += f". {error_count} c·∫ßu g·∫∑p l·ªói."
            
            self._log(f">>> [DE PRUNING] Ho√†n t·∫•t: {result_msg}")
            return result_msg
        
        except Exception as e:
            error_msg = f"L·ªói khi lo·∫°i b·ªè c·∫ßu ƒê·ªÅ y·∫øu: {e}"
            self._log(error_msg)
            import traceback
            self._log(traceback.format_exc())
            return error_msg

--------------------------------------------------

=== FILE: services\data_service.py ===
# T√™n file: services/data_service.py
# Service layer: Logic t·∫£i v√† x·ª≠ l√Ω d·ªØ li·ªáu x·ªï s·ªë

import os
import traceback

class DataService:
    """Service x·ª≠ l√Ω d·ªØ li·ªáu x·ªï s·ªë"""
    
    def __init__(self, db_name, logger=None):
        self.db_name = db_name
        self.logger = logger
    
    def _log(self, message):
        """Helper ƒë·ªÉ log messages"""
        if self.logger:
            self.logger.log(message)
    
    def load_data(self):
        """
        T·∫£i d·ªØ li·ªáu A:I t·ª´ database.
        
        Returns:
            list ho·∫∑c None: D·ªØ li·ªáu A:I ho·∫∑c None n·∫øu l·ªói
        """
        try:
            from lottery_service import load_data_ai_from_db
            rows_of_lists, message = load_data_ai_from_db(self.db_name)
            self._log(message)
            return rows_of_lists
        except ImportError:
            try:
                from logic.data_repository import load_data_ai_from_db
                rows_of_lists, message = load_data_ai_from_db(self.db_name)
                self._log(message)
                return rows_of_lists
            except ImportError as e:
                self._log(f"L·ªói: Kh√¥ng th·ªÉ import load_data_ai_from_db: {e}")
                return None
    
    def import_data_from_file(self, input_file, callback_on_success=None):
        """
        Import d·ªØ li·ªáu t·ª´ file, x√≥a database c≈© v√† ch√®n d·ªØ li·ªáu m·ªõi.
        
        Args:
            input_file: ƒê∆∞·ªùng d·∫´n file input
            callback_on_success: H√†m callback khi th√†nh c√¥ng
        
        Returns:
            tuple: (success: bool, message: str)
        """
        conn = None
        try:
            with open(input_file, "r", encoding="utf-8-sig") as f:
                raw_data = f.read()
            self._log(f"ƒê√£ ƒë·ªçc t·ªáp tin '{input_file}' th√†nh c√¥ng.")

            if os.path.exists(self.db_name):
                os.remove(self.db_name)
                self._log(f"ƒê√£ x√≥a database c≈©: {self.db_name}")

            from lottery_service import setup_database, parse_and_insert_data
            conn, cursor = setup_database()
            total_records_ai = parse_and_insert_data(raw_data, conn, cursor)

            if total_records_ai == 0:
                return False, "Kh√¥ng th·ªÉ ph√¢n t√≠ch d·ªØ li·ªáu. File c√≥ th·ªÉ kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng."
            else:
                self._log("Ph√¢n t√≠ch v√† ch√®n d·ªØ li·ªáu ho√†n t·∫•t.")
                self._log(f"- ƒê√£ ch√®n {total_records_ai} h√†ng A:I (backtest).")
                self._log("- ƒê√£ x√≥a m·ªçi C·∫ßu ƒê√£ L∆∞u (do n·∫°p l·∫°i).")
                self._log(">>> S·∫µn s√†ng cho Ch·ª©c NƒÉng Soi C·∫ßu.")
                if callback_on_success:
                    callback_on_success()
                return True, f"ƒê√£ ch√®n {total_records_ai} h√†ng A:I"

        except Exception as e:
            error_msg = f"L·ªñI trong import data: {e}"
            self._log(error_msg)
            self._log(traceback.format_exc())
            return False, error_msg
        finally:
            if conn:
                conn.close()
                self._log("ƒê√£ ƒë√≥ng k·∫øt n·ªëi database.")
    
    def append_data_from_file(self, input_file, callback_on_success=None):
        """
        Th√™m d·ªØ li·ªáu m·ªõi t·ª´ file v√†o database hi·ªán c√≥.
        
        Args:
            input_file: ƒê∆∞·ªùng d·∫´n file input
            callback_on_success: H√†m callback khi th√†nh c√¥ng
        
        Returns:
            tuple: (success: bool, message: str)
        """
        conn = None
        try:
            with open(input_file, "r", encoding="utf-8-sig") as f:
                raw_data = f.read()
            self._log(f"ƒê√£ ƒë·ªçc t·ªáp tin '{input_file}' th√†nh c√¥ng.")

            from lottery_service import setup_database, parse_and_APPEND_data
            conn, cursor = setup_database()
            total_keys_added = parse_and_APPEND_data(raw_data, conn, cursor)

            if total_keys_added == 0:
                return False, "Kh√¥ng c√≥ k·ª≥ n√†o ƒë∆∞·ª£c th√™m (c√≥ th·ªÉ do tr√πng l·∫∑p ho·∫∑c file r·ªóng)."
            else:
                self._log("Th√™m d·ªØ li·ªáu ho√†n t·∫•t.")
                self._log(f"- ƒê√£ th√™m {total_keys_added} k·ª≥ m·ªõi v√†o DB.")
                self._log(">>> S·∫µn s√†ng cho Ch·ª©c NƒÉng Soi C·∫ßu.")
                if callback_on_success:
                    callback_on_success()
                return True, f"ƒê√£ th√™m {total_keys_added} k·ª≥ m·ªõi"

        except Exception as e:
            error_msg = f"L·ªñI trong append data: {e}"
            self._log(error_msg)
            self._log(traceback.format_exc())
            return False, error_msg
        finally:
            if conn:
                conn.close()
                self._log("ƒê√£ ƒë√≥ng k·∫øt n·ªëi database.")
    
    def update_from_text(self, raw_data, callback_on_success=None):
        """
        C·∫≠p nh·∫≠t d·ªØ li·ªáu t·ª´ text input.
        
        Args:
            raw_data: D·ªØ li·ªáu d·∫°ng text
            callback_on_success: H√†m callback khi th√†nh c√¥ng
        
        Returns:
            tuple: (success: bool, message: str)
        """
        try:
            from logic.data_parser import run_and_update_from_text
            success, message = run_and_update_from_text(raw_data)
            self._log(message)
            
            if success and callback_on_success:
                callback_on_success()
            
            return success, message
        except Exception as e:
            error_msg = f"L·ªñI khi c·∫≠p nh·∫≠t t·ª´ text: {e}"
            self._log(error_msg)
            self._log(traceback.format_exc())
            return False, error_msg


--------------------------------------------------

=== FILE: services\__init__.py ===
# Services layer - Business logic separated from controllers

from .data_service import DataService
from .bridge_service import BridgeService
from .analysis_service import AnalysisService

__all__ = ['DataService', 'BridgeService', 'AnalysisService']


--------------------------------------------------

=== FILE: ui\ui_bridge_management.py ===
# T√™n file: ui/ui_bridge_management.py
# (PHI√äN B·∫¢N V1.0 - TAB QU·∫¢N L√ù C·∫¶U - MANAGEMENT ONLY)
#
# M·ª•c ƒë√≠ch: Tab chuy√™n d·ª•ng cho QU·∫¢N L√ù C·∫¶U ƒë√£ c√≥.
#           KH√îNG c√≥ ch·ª©c nƒÉng qu√©t/d√≤ t√¨m c·∫ßu m·ªõi.

import tkinter as tk
from tkinter import messagebox, ttk
import threading

# Import management functions ONLY
try:
    from logic.data_repository import get_managed_bridges_with_prediction
    from logic.bridges.bridge_manager_core import (
        prune_bad_bridges,
        auto_manage_bridges,
    )
    from lottery_service import (
        add_managed_bridge,
        delete_managed_bridge,
        update_managed_bridge,
        DB_NAME,
    )
except ImportError as e:
    print(f"L·ªñI IMPORT t·∫°i ui_bridge_management: {e}")
    def get_managed_bridges_with_prediction(*args, **kwargs): return []
    def prune_bad_bridges(*args, **kwargs): return "L·ªói Import"
    def auto_manage_bridges(*args, **kwargs): return "L·ªói Import"
    def add_managed_bridge(*args, **kwargs): return False, "L·ªói Import"
    def update_managed_bridge(*args, **kwargs): return False, "L·ªói Import"
    def delete_managed_bridge(*args, **kwargs): return False, "L·ªói Import"
    DB_NAME = "data/xo_so_prizes_all_logic.db"


class BridgeManagementTab(ttk.Frame):
    """
    Tab chuy√™n d·ª•ng cho QU·∫¢N L√ù C·∫¶U.
    
    Ch·ª©c nƒÉng:
    - Hi·ªÉn th·ªã danh s√°ch c·∫ßu ƒëang qu·∫£n l√Ω
    - B·∫≠t/t·∫Øt c·∫ßu
    - Ch·ªânh s·ª≠a th√¥ng tin c·∫ßu
    - X√≥a c·∫ßu
    - Ghim/B·ªè ghim c·∫ßu
    - T·ªëi ∆∞u th√¥ng minh (prune bad bridges)
    - Auto-manage bridges
    
    KH√îNG c√≥:
    - Qu√©t c·∫ßu m·ªõi
    - D√≤ t√¨m c·∫ßu
    - C√°c ch·ª©c nƒÉng scanning
    """
    
    def __init__(self, parent, app):
        super().__init__(parent)
        self.app = app
        self.db_name = DB_NAME
        self.all_bridges_cache = []
        
        self.columnconfigure(0, weight=1)
        self.rowconfigure(1, weight=1)
        
        self._create_edit_form()
        self._create_bridge_table()
        self._create_toolbar()
        
        # Auto-refresh on init
        self.after(100, self.refresh_bridge_list)
    
    def _create_edit_form(self):
        """T·∫°o form ch·ªânh s·ª≠a c·∫ßu."""
        frame = ttk.LabelFrame(self, text="‚úèÔ∏è Ch·ªânh S·ª≠a C·∫ßu", padding="10")
        frame.grid(row=0, column=0, sticky="ew", padx=10, pady=10)
        frame.columnconfigure(1, weight=1)
        
        ttk.Label(frame, text="T√™n C·∫ßu:").grid(row=0, column=0, sticky="w", padx=5)
        self.name_entry = ttk.Entry(frame, width=30)
        self.name_entry.grid(row=0, column=1, sticky="ew", padx=5)
        
        self.enabled_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(
            frame, 
            text="üü¢ ƒêang B·∫≠t (S·ª≠ d·ª•ng)", 
            variable=self.enabled_var
        ).grid(row=0, column=2, padx=10)
        
        ttk.Label(frame, text="M√¥ t·∫£:").grid(row=1, column=0, sticky="w", padx=5, pady=5)
        self.desc_entry = ttk.Entry(frame)
        self.desc_entry.grid(row=1, column=1, columnspan=2, sticky="ew", padx=5, pady=5)
    
    def _create_bridge_table(self):
        """T·∫°o b·∫£ng hi·ªÉn th·ªã danh s√°ch c·∫ßu ƒëang qu·∫£n l√Ω."""
        frame = ttk.LabelFrame(self, text="üìã Danh S√°ch C·∫ßu ƒêang Qu·∫£n L√Ω", padding="10")
        frame.grid(row=1, column=0, sticky="nsew", padx=10, pady=10)
        frame.columnconfigure(0, weight=1)
        frame.rowconfigure(1, weight=1)
        
        # Add filter controls
        filter_frame = ttk.Frame(frame)
        filter_frame.grid(row=0, column=0, sticky="ew", pady=(0, 5))
        
        ttk.Label(filter_frame, text="L·ªçc theo lo·∫°i:", font=("Helvetica", 9, "bold")).pack(side=tk.LEFT, padx=(0, 10))
        
        self.filter_var = tk.StringVar(value="ALL")
        filter_options = [
            ("T·∫•t c·∫£", "ALL"),
            ("Ch·ªâ C·∫ßu L√¥", "LO"),
            ("Ch·ªâ C·∫ßu ƒê·ªÅ", "DE"),
        ]
        
        for text, value in filter_options:
            ttk.Radiobutton(
                filter_frame,
                text=text,
                variable=self.filter_var,
                value=value,
                command=self.refresh_bridge_list
            ).pack(side=tk.LEFT, padx=5)
        
        columns = ("id", "type", "name", "desc", "win_rate_k1n", "win_rate_scan", "status", "pinned", "created_at")
        self.tree = ttk.Treeview(frame, columns=columns, show="headings", selectmode="extended")
        
        self.tree.heading("id", text="ID")
        self.tree.column("id", width=40, anchor="center")
        
        self.tree.heading("type", text="Lo·∫°i")
        self.tree.column("type", width=60, anchor="center")
        
        self.tree.heading("name", text="T√™n C·∫ßu")
        self.tree.column("name", width=140, anchor=tk.W)
        
        self.tree.heading("desc", text="M√¥ T·∫£")
        self.tree.column("desc", width=200, anchor=tk.W)
        
        self.tree.heading("win_rate_k1n", text="K1N (Th·ª±c T·∫ø)")
        self.tree.column("win_rate_k1n", width=110, anchor="center")
        
        self.tree.heading("win_rate_scan", text="K2N (L√∫c D√≤)")
        self.tree.column("win_rate_scan", width=110, anchor="center")
        
        self.tree.heading("status", text="Tr·∫°ng Th√°i")
        self.tree.column("status", width=90, anchor="center")
        
        self.tree.heading("pinned", text="üìå Ghim")
        self.tree.column("pinned", width=70, anchor="center")
        
        self.tree.heading("created_at", text="Ng√†y T·∫°o")
        self.tree.column("created_at", width=110, anchor="center")
        
        scrollbar = ttk.Scrollbar(frame, orient=tk.VERTICAL, command=self.tree.yview)
        self.tree.configure(yscrollcommand=scrollbar.set)
        
        self.tree.grid(row=1, column=0, sticky="nsew")
        scrollbar.grid(row=1, column=1, sticky="ns")
        
        self.tree.bind("<<TreeviewSelect>>", self._on_bridge_select)
        
        # Context menu
        self.context_menu = tk.Menu(self, tearoff=0)
        self.context_menu.add_command(label="üìå Ghim/B·ªè Ghim", command=self._toggle_pin)
        self.context_menu.add_separator()
        self.context_menu.add_command(label="üîç Xem Backtest 30 Ng√†y", command=self._run_backtest)
        self.tree.bind("<Button-3>", self._show_context_menu)
    
    def _create_toolbar(self):
        """T·∫°o toolbar v·ªõi c√°c n√∫t qu·∫£n l√Ω."""
        frame = ttk.Frame(self, padding="10")
        frame.grid(row=2, column=0, sticky="ew", padx=10, pady=5)
        
        # Left side: CRUD operations
        left_frame = ttk.Frame(frame)
        left_frame.pack(side=tk.LEFT, fill=tk.X, expand=True)
        
        ttk.Button(
            left_frame, 
            text="‚ûï Th√™m M·ªõi", 
            command=self._add_bridge
        ).pack(side=tk.LEFT, padx=2)
        
        ttk.Button(
            left_frame, 
            text="üíæ C·∫≠p Nh·∫≠t", 
            command=self._update_bridge
        ).pack(side=tk.LEFT, padx=2)
        
        ttk.Button(
            left_frame, 
            text="üóëÔ∏è X√≥a", 
            command=self._delete_bridge
        ).pack(side=tk.LEFT, padx=2)
        
        ttk.Button(
            left_frame, 
            text="üìå Ghim/B·ªè Ghim", 
            command=self._toggle_pin
        ).pack(side=tk.LEFT, padx=2)
        
        ttk.Separator(left_frame, orient=tk.VERTICAL).pack(side=tk.LEFT, fill=tk.Y, padx=10)
        
        ttk.Button(
            left_frame, 
            text="üîÑ L√†m M·ªõi", 
            command=self.refresh_bridge_list
        ).pack(side=tk.LEFT, padx=2)
        
        # Right side: Smart operations
        right_frame = ttk.Frame(frame)
        right_frame.pack(side=tk.RIGHT)
        
        style = ttk.Style()
        style.configure("Smart.TButton", foreground="blue", font=("Helvetica", 10, "bold"))
        
        ttk.Button(
            right_frame, 
            text="‚ö° T·ªëi ∆Øu Th√¥ng Minh", 
            style="Smart.TButton",
            command=self._smart_optimize
        ).pack(side=tk.LEFT, padx=5)
        
        ttk.Button(
            right_frame, 
            text="üîç Test C·∫ßu", 
            command=self._run_backtest
        ).pack(side=tk.LEFT, padx=5)
    
    # ==================== DISPLAY FUNCTIONS ====================
    
    def refresh_bridge_list(self):
        """T·∫£i l·∫°i danh s√°ch c·∫ßu ƒëang qu·∫£n l√Ω."""
        try:
            # Clear old items
            for item in self.tree.get_children():
                self.tree.delete(item)
            
            # Get current data
            current_data = getattr(self.app, 'all_data_ai', [])
            if not current_data and hasattr(self.app, 'controller'):
                current_data = getattr(self.app.controller, 'all_data_ai', [])
            
            # Fallback to loading from DB
            if not current_data:
                try:
                    from logic.data_repository import load_data_ai_from_db
                    rows, _ = load_data_ai_from_db(self.db_name)
                    if rows:
                        current_data = rows
                except:
                    pass
            
            # Get managed bridges with prediction
            self.all_bridges_cache = get_managed_bridges_with_prediction(
                self.db_name,
                current_data=current_data,
                only_enabled=False
            )
            
            # Get filter selection
            filter_type = getattr(self, 'filter_var', None)
            filter_value = filter_type.get() if filter_type else "ALL"
            
            # Display in table with filter
            for b in self.all_bridges_cache:
                # Get bridge type
                bridge_type = b.get('type', 'UNKNOWN')
                
                # Apply filter
                if filter_value == "LO":
                    # Show only LO bridges
                    if not bridge_type.startswith(('LO_', 'LO')):
                        continue
                elif filter_value == "DE":
                    # Show only DE bridges (including DE_MEMORY)
                    valid_de_types = ['DE_DYNAMIC_K', 'DE_POS_SUM', 'DE_SET', 'DE_PASCAL', 'DE_KILLER', 'DE_MEMORY', 'CAU_DE']
                    is_de = any(bridge_type.startswith(t) or bridge_type == t for t in valid_de_types)
                    if not is_de:
                        continue
                # If "ALL", show everything
                
                # Determine display type
                if bridge_type.startswith('LO_'):
                    display_type = "üîµ L√¥"
                elif bridge_type.startswith('DE_') or bridge_type.startswith('CAU_DE') or bridge_type == 'DE_MEMORY':
                    display_type = "üî¥ ƒê·ªÅ"
                else:
                    display_type = bridge_type[:8]  # Truncate if too long
                status_text = "üü¢ ƒêang B·∫≠t" if b['is_enabled'] else "üî¥ ƒê√£ T·∫Øt"
                is_pinned = b.get('is_pinned', 0)
                pinned_text = "üìå C√≥" if is_pinned else "‚ùå Kh√¥ng"
                
                tags = []
                if not b['is_enabled']:
                    tags.append("disabled")
                if is_pinned:
                    tags.append("pinned")
                
                created_date = b.get('created_at') or b.get('date_added', 'N/A')
                
                # K1N rate
                k1n_rate = str(b.get('win_rate_text', ''))
                if not k1n_rate or 'N/A' in k1n_rate:
                    pred = str(b.get('next_prediction_stl', ''))
                    if not pred or 'N/A' in pred:
                        k1n_rate = "Ch·ªù d·ªØ li·ªáu..." if not current_data else "Kh√¥ng x√°c ƒë·ªãnh"
                    else:
                        k1n_rate = f"D·ª±: {pred}"
                
                # K2N scan rate
                search_rate = b.get("search_rate_text", "")
                search_period = b.get("search_period", 0)
                if search_rate and search_rate != "0.00%":
                    k2n_display = f"{search_rate}"
                    if search_period > 0:
                        k2n_display += f" ({search_period}k·ª≥)"
                else:
                    k2n_display = "-"
                
                self.tree.insert(
                    "", tk.END,
                    values=(
                        b['id'], display_type, b['name'], b['description'],
                        k1n_rate,
                        k2n_display,
                        status_text, pinned_text, created_date
                    ),
                    tags=tuple(tags) if tags else ()
                )
            
            self.tree.tag_configure("disabled", foreground="gray")
            self.tree.tag_configure("pinned", background="#fff9c4")
            
        except Exception as e:
            print(f"L·ªói refresh_bridge_list: {e}")
            messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ t·∫£i danh s√°ch c·∫ßu:\n{e}")
    
    def _on_bridge_select(self, event):
        """X·ª≠ l√Ω khi ch·ªçn m·ªôt c·∫ßu trong b·∫£ng."""
        selected = self.tree.focus()
        if not selected:
            return
        
        values = self.tree.item(selected, "values")
        if not values:
            return
        
        # Fill form (updated for new column structure: id, type, name, desc, ...)
        self.name_entry.delete(0, tk.END)
        self.name_entry.insert(0, values[2])  # name is now at index 2
        
        self.desc_entry.delete(0, tk.END)
        self.desc_entry.insert(0, values[3])  # desc is now at index 3
        
        # Status is now at index 6
        is_enabled = ("üü¢" in values[6])
        self.enabled_var.set(is_enabled)
    
    def _show_context_menu(self, event):
        """Hi·ªÉn th·ªã context menu."""
        item = self.tree.identify_row(event.y)
        if item:
            self.tree.selection_set(item)
            self.context_menu.post(event.x_root, event.y_root)
    
    # ==================== CRUD OPERATIONS ====================
    
    def _add_bridge(self):
        """Th√™m c·∫ßu m·ªõi."""
        name = self.name_entry.get().strip()
        desc = self.desc_entry.get().strip()
        
        if not name:
            messagebox.showwarning("Thi·∫øu Th√¥ng Tin", "Vui l√≤ng nh·∫≠p t√™n c·∫ßu.")
            return
        
        is_enabled = 1 if self.enabled_var.get() else 0
        
        success, msg = add_managed_bridge(name, desc, "N/A")
        
        if success:
            messagebox.showinfo("Th√†nh C√¥ng", f"ƒê√£ th√™m c·∫ßu: {name}")
            self.refresh_bridge_list()
            self.name_entry.delete(0, tk.END)
            self.desc_entry.delete(0, tk.END)
        else:
            messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ th√™m c·∫ßu:\n{msg}")
    
    def _update_bridge(self):
        """C·∫≠p nh·∫≠t th√¥ng tin c·∫ßu ƒë√£ ch·ªçn."""
        selected = self.tree.focus()
        if not selected:
            messagebox.showwarning("Ch∆∞a Ch·ªçn", "Vui l√≤ng ch·ªçn m·ªôt c·∫ßu ƒë·ªÉ c·∫≠p nh·∫≠t.")
            return
        
        values = self.tree.item(selected, "values")
        bridge_id = values[0]
        
        new_desc = self.desc_entry.get().strip()
        is_enabled = 1 if self.enabled_var.get() else 0
        
        success, msg = update_managed_bridge(bridge_id, new_desc, is_enabled, self.db_name)
        
        if success:
            messagebox.showinfo("Th√†nh C√¥ng", "ƒê√£ c·∫≠p nh·∫≠t c·∫ßu.")
            self.refresh_bridge_list()
        else:
            messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ c·∫≠p nh·∫≠t:\n{msg}")
    
    def _delete_bridge(self):
        """X√≥a c√°c c·∫ßu ƒë√£ ch·ªçn (H·ªó tr·ª£ x√≥a nhi·ªÅu d√≤ng)."""
        # 1. L·∫•y danh s√°ch ID c√°c d√≤ng ƒëang ch·ªçn
        selected_items = self.tree.selection()
        
        if not selected_items:
            messagebox.showwarning("Ch∆∞a Ch·ªçn", "Vui l√≤ng ch·ªçn √≠t nh·∫•t m·ªôt c·∫ßu ƒë·ªÉ x√≥a.")
            return
        
        # 2. X√°c nh·∫≠n x√≥a
        count = len(selected_items)
        if count == 1:
            # Logic c≈©: L·∫•y t√™n c·∫ßu ƒë·ªÉ h·ªèi cho chi ti·∫øt
            item = selected_items[0]
            values = self.tree.item(item, "values")
            # L∆∞u √Ω: C·ªôt name trong file n√†y n·∫±m ·ªü index 2 (id, type, name...)
            bridge_name = values[2] 
            msg = f"B·∫°n c√≥ ch·∫Øc mu·ªën x√≥a c·∫ßu '{bridge_name}'?"
        else:
            msg = f"B·∫°n c√≥ ch·∫Øc mu·ªën x√≥a {count} c·∫ßu ƒë√£ ch·ªçn?"

        if not messagebox.askyesno("X√°c Nh·∫≠n", msg):
            return
        
        # 3. Th·ª±c hi·ªán x√≥a
        deleted_count = 0
        errors = []
        
        for item_id in selected_items:
            # L·∫•y ID c·∫ßu t·ª´ c·ªôt ƒë·∫ßu ti√™n
            values = self.tree.item(item_id, "values")
            bridge_id = values[0]
            
            # G·ªçi h√†m x√≥a
            success, err_msg = delete_managed_bridge(bridge_id)
            if success:
                deleted_count += 1
            else:
                errors.append(f"{bridge_id}: {err_msg}")
        
        # 4. Th√¥ng b√°o k·∫øt qu·∫£ v√† l√†m m·ªõi
        if deleted_count > 0:
            if errors:
                messagebox.showwarning("K·∫øt Qu·∫£", f"ƒê√£ x√≥a {deleted_count} c·∫ßu.\nL·ªói {len(errors)} c·∫ßu: {errors[0]}...")
            else:
                messagebox.showinfo("Th√†nh C√¥ng", f"ƒê√£ x√≥a th√†nh c√¥ng {deleted_count} c·∫ßu.")
            
            # Reset form v√† reload b·∫£ng
            self.name_entry.delete(0, tk.END)
            self.desc_entry.delete(0, tk.END)
            self.refresh_bridge_list()
        elif errors:
            messagebox.showerror("L·ªói", f"Kh√¥ng x√≥a ƒë∆∞·ª£c c·∫ßu n√†o.\nL·ªói: {errors[0]}")
    
    def _toggle_pin(self):
        """Ghim/B·ªè ghim c·∫ßu."""
        selected = self.tree.focus()
        if not selected:
            messagebox.showwarning("Ch∆∞a Ch·ªçn", "Vui l√≤ng ch·ªçn m·ªôt c·∫ßu.")
            return
        
        values = self.tree.item(selected, "values")
        bridge_id = values[0]
        
        # Find bridge in cache
        bridge = next((b for b in self.all_bridges_cache if b['id'] == bridge_id), None)
        if not bridge:
            return
        
        new_pinned = 0 if bridge.get('is_pinned', 0) else 1
        
        # Update in DB
        try:
            import sqlite3
            conn = sqlite3.connect(self.db_name)
            conn.execute("UPDATE ManagedBridges SET is_pinned=? WHERE id=?", (new_pinned, bridge_id))
            conn.commit()
            conn.close()
            
            self.refresh_bridge_list()
            messagebox.showinfo("Th√†nh C√¥ng", "ƒê√£ c·∫≠p nh·∫≠t tr·∫°ng th√°i ghim.")
        except Exception as e:
            messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ c·∫≠p nh·∫≠t:\n{e}")
    
    # ==================== MANAGEMENT OPERATIONS ====================
    
    def _smart_optimize(self):
        """T·ªëi ∆∞u th√¥ng minh - Prune bad bridges."""
        if not messagebox.askyesno(
            "X√°c Nh·∫≠n", 
            "T·ªëi ∆∞u th√¥ng minh s·∫Ω T·∫ÆT c√°c c·∫ßu y·∫øu (K1N & K2N < 40%).\n\nTi·∫øp t·ª•c?"
        ):
            return
        
        def worker():
            try:
                # Get data
                current_data = getattr(self.app, 'all_data_ai', [])
                if not current_data and hasattr(self.app, 'controller'):
                    current_data = getattr(self.app.controller, 'all_data_ai', [])
                
                if not current_data:
                    from logic.data_repository import load_data_ai_from_db
                    rows, _ = load_data_ai_from_db(self.db_name)
                    if rows:
                        current_data = rows
                
                # Run optimization
                result = prune_bad_bridges(current_data, self.db_name)
                
                self.after(0, lambda: messagebox.showinfo("K·∫øt Qu·∫£ T·ªëi ∆Øu", result))
                self.after(0, self.refresh_bridge_list)
            except Exception as e:
                self.after(0, lambda: messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ t·ªëi ∆∞u:\n{e}"))
        
        thread = threading.Thread(target=worker, daemon=True)
        thread.start()
    
    def _run_backtest(self):
        """Ch·∫°y backtest cho c·∫ßu ƒë√£ ch·ªçn."""
        selected = self.tree.focus()
        if not selected:
            messagebox.showwarning("Ch∆∞a Ch·ªçn", "Vui l√≤ng ch·ªçn m·ªôt c·∫ßu ƒë·ªÉ test.")
            return
        
        values = self.tree.item(selected, "values")
        bridge_name = values[2]  # name is now at index 2 (id, type, name, ...)
        
        messagebox.showinfo(
            "Backtest", 
            f"Ch·ª©c nƒÉng backtest cho c·∫ßu '{bridge_name}' s·∫Ω ƒë∆∞·ª£c tri·ªÉn khai sau.\n\n"
            "Hi·ªán t·∫°i b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng ch·ª©c nƒÉng Backtest trong tab T·ªëi ∆Øu H√≥a."
        )


--------------------------------------------------

=== FILE: ui\ui_bridge_manager.py ===
# T√™n file: code6/ui/ui_bridge_manager.py
# (PHI√äN B·∫¢N V3.9.21 - FIX: T√çNH TO√ÅN D·ª∞ ƒêO√ÅN REAL-TIME ƒê·ªÇ KH·∫ÆC PH·ª§C L·ªñI N/A)

import tkinter as tk
from tkinter import messagebox, ttk
import threading

# Import Config
from logic.config_manager import SETTINGS

# Import Logic
try:
    # [FIX IMPORT] Th√™m get_managed_bridges_with_prediction ƒë·ªÉ t√≠nh to√°n n√≥ng
    from logic.data_repository import get_managed_bridges_with_prediction 
    from lottery_service import (
        add_managed_bridge,
        delete_managed_bridge,
        # get_all_managed_bridges, # Kh√¥ng d√πng h√†m th√¥ n√†y n·ªØa
        update_managed_bridge,
    )
except ImportError as e:
    print(f"L·ªñI IMPORT NGHI√äM TR·ªåNG t·∫°i ui_bridge_manager: {e}")
    def get_managed_bridges_with_prediction(db, current_data=None, only_enabled=False): return []
    def add_managed_bridge(n, d, w): return False, "L·ªói Import"
    def update_managed_bridge(i, d, s): return False, "L·ªói Import"
    def delete_managed_bridge(i): return False, "L·ªói Import"


class BridgeManagerWindow:
    """Qu·∫£n l√Ω c·ª≠a s·ªï Toplevel Qu·∫£n l√Ω C·∫ßu."""

    def __init__(self, app):
        self.app = app
        self.root = app.root
        self.all_bridges_cache = []
        
        if (
            hasattr(self.app, "bridge_manager_window")
            and self.app.bridge_manager_window
            and self.app.bridge_manager_window.winfo_exists()
        ):
            self.app.bridge_manager_window.lift()
            return

        self.window = tk.Toplevel(self.root)
        self.window.title("Qu·∫£n L√Ω C·∫ßu (Bridge Manager) - K1N & Scan Check")
        self.window.geometry("1150x650") 
        
        self.app.bridge_manager_window = self.window
        self.app.bridge_manager_window_instance = self

        self.window.columnconfigure(0, weight=1)
        self.window.rowconfigure(1, weight=1)

        self.create_input_form()
        self.create_bridge_list()
        self.create_toolbar()

        self.refresh_bridge_list()

    def create_input_form(self):
        frame = ttk.LabelFrame(self.window, text="Th√¥ng tin C·∫ßu", padding="10")
        frame.grid(row=0, column=0, sticky="ew", padx=10, pady=5)
        frame.columnconfigure(1, weight=1)

        ttk.Label(frame, text="T√™n C·∫ßu (VD: C·∫ßu 1, Bong(0,1)):").grid(row=0, column=0, sticky="w")
        self.name_entry = ttk.Entry(frame)
        self.name_entry.grid(row=0, column=1, sticky="ew", padx=5)

        self.enabled_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(frame, text="ƒêang B·∫≠t (S·ª≠ d·ª•ng)", variable=self.enabled_var).grid(row=0, column=2, padx=5)

        ttk.Label(frame, text="M√¥ t·∫£:").grid(row=1, column=0, sticky="w")
        self.desc_entry = ttk.Entry(frame)
        self.desc_entry.grid(row=1, column=1, columnspan=2, sticky="ew", padx=5, pady=5)

    def _setup_treeview_columns(self):
        self.tree.heading("id", text="ID")
        self.tree.column("id", width=40, anchor="center")
        
        self.tree.heading("name", text="T√™n C·∫ßu")
        self.tree.column("name", width=140, anchor=tk.W)
        
        self.tree.heading("desc", text="M√¥ T·∫£")
        self.tree.column("desc", width=180, anchor=tk.W)
        
        self.tree.heading("win_rate_k1n", text="K1N (Th·ª±c T·∫ø)")
        self.tree.column("win_rate_k1n", width=100, anchor="center")
        
        self.tree.heading("win_rate_scan", text="K2N (L√∫c D√≤)")
        self.tree.column("win_rate_scan", width=100, anchor="center")
        
        self.tree.heading("status", text="Tr·∫°ng Th√°i")
        self.tree.column("status", width=80, anchor="center")
        
        self.tree.heading("pinned", text="üìå Ghim")
        self.tree.column("pinned", width=60, anchor="center")
        
        self.tree.heading("created_at", text="Ng√†y T·∫°o")
        self.tree.column("created_at", width=100, anchor="center")

    def create_bridge_list(self):
        frame = ttk.Frame(self.window)
        frame.grid(row=1, column=0, sticky="nsew", padx=10)
        frame.columnconfigure(0, weight=1)
        frame.rowconfigure(0, weight=1)

        columns = ("id", "name", "desc", "win_rate_k1n", "win_rate_scan", "status", "pinned", "created_at")
        self.tree = ttk.Treeview(frame, columns=columns, show="headings", selectmode="extended")
        self._setup_treeview_columns()

        scrollbar = ttk.Scrollbar(frame, orient=tk.VERTICAL, command=self.tree.yview)
        self.tree.configure(yscrollcommand=scrollbar.set)
        
        self.tree.grid(row=0, column=0, sticky="nsew")
        scrollbar.grid(row=0, column=1, sticky="ns")

        self.tree.bind("<<TreeviewSelect>>", self.on_bridge_select)
        
        # Add controls frame for bulk operations
        controls_frame = ttk.Frame(frame)
        controls_frame.grid(row=1, column=0, sticky="ew", pady=(5, 0))
        self.delete_selected_btn = ttk.Button(controls_frame, text="Delete selected", command=self._on_delete_selected)
        self.delete_selected_btn.pack(side=tk.LEFT, padx=(0, 5))
        self.delete_selected_btn.state(['disabled'])
        
        self.context_menu = tk.Menu(self.window, tearoff=0)
        self.context_menu.add_command(label="üìå Ghim/B·ªè Ghim", command=self.toggle_pin_selected_bridge)
        self.context_menu.add_separator()
        self.context_menu.add_command(label="üîç Xem Backtest 30 Ng√†y", command=self.run_quick_backtest)
        self.tree.bind("<Button-3>", self.show_context_menu)

    def create_toolbar(self):
        frame = ttk.Frame(self.window, padding="10")
        frame.grid(row=2, column=0, sticky="ew")
        
        style = ttk.Style()
        style.configure("Smart.TButton", foreground="blue", font=("Helvetica", 10, "bold"))

        ttk.Button(frame, text="Th√™m M·ªõi", command=self.add_bridge).pack(side=tk.LEFT, padx=2)
        ttk.Button(frame, text="C·∫≠p Nh·∫≠t", command=self.update_selected_bridge).pack(side=tk.LEFT, padx=2)
        ttk.Button(frame, text="X√≥a", command=self.delete_selected_bridge).pack(side=tk.LEFT, padx=2)
        ttk.Button(frame, text="üìå Ghim/B·ªè Ghim", command=self.toggle_pin_selected_bridge).pack(side=tk.LEFT, padx=2)
        ttk.Button(frame, text="L√†m M·ªõi List", command=self.refresh_bridge_list).pack(side=tk.LEFT, padx=2)

        ttk.Separator(frame, orient=tk.VERTICAL).pack(side=tk.LEFT, fill=tk.Y, padx=10)
        
        self.btn_smart_opt = ttk.Button(
            frame, 
            text="‚ö° T·ªëi ∆Øu C·∫ßu Th√¥ng Minh", 
            style="Smart.TButton",
            command=self.run_smart_optimization
        )
        self.btn_smart_opt.pack(side=tk.LEFT, padx=2)
        
        ttk.Button(frame, text="Test C·∫ßu N√†y", command=self.run_quick_backtest).pack(side=tk.RIGHT, padx=2)

    # --- LOGIC HANDLERS ---

    def refresh_bridge_list(self):
        """
        T·∫£i l·∫°i danh s√°ch c·∫ßu.
        [FIX V3.9.22] C·∫£i thi·ªán logic ki·ªÉm tra N/A v√† l·∫•y d·ªØ li·ªáu ngu·ªìn.
        """
        try:
            if not hasattr(self, 'window') or not self.window.winfo_exists(): return
            
            # X√≥a c≈©
            for item in self.tree.get_children(): self.tree.delete(item)
            
            # 1. L·∫•y d·ªØ li·ªáu x·ªï s·ªë: Th·ª≠ nhi·ªÅu ngu·ªìn kh√°c nhau ƒë·ªÉ ch·∫Øc ch·∫Øn c√≥ d·ªØ li·ªáu
            current_data = getattr(self.app, 'all_data_ai', [])
            if not current_data and hasattr(self.app, 'controller'):
                current_data = getattr(self.app.controller, 'all_data_ai', [])
            
            # [FALLBACK] N·∫øu v·∫´n kh√¥ng c√≥, th·ª≠ load tr·ª±c ti·∫øp t·ª´ DB (Ch·∫≠m h∆°n ch√∫t nh∆∞ng ch·∫Øc ch·∫Øn c√≥)
            if not current_data:
                try:
                    from logic.data_repository import load_data_ai_from_db
                    rows, _ = load_data_ai_from_db(self.app.db_name)
                    if rows: current_data = rows
                except: pass

            # 2. G·ªçi h√†m t√≠nh to√°n
            self.all_bridges_cache = get_managed_bridges_with_prediction(
                self.app.db_name, 
                current_data=current_data, 
                only_enabled=False
            )
            
            for b in self.all_bridges_cache:
                status_text = "ƒêang B·∫≠t" if b['is_enabled'] else "ƒê√£ T·∫Øt"
                is_pinned = b.get('is_pinned', 0)
                pinned_text = "üìå C√≥" if is_pinned else "‚ùå Kh√¥ng"
                
                tags = []
                if not b['is_enabled']: tags.append("disabled")
                if is_pinned: tags.append("pinned")
                
                created_date = b.get('created_at') or b.get('date_added', 'N/A')
                
                # --- [FIX LOGIC HI·ªÇN TH·ªä] ---
                k1n_rate = str(b.get('win_rate_text', ''))
                
                # ƒêi·ªÅu ki·ªán l·ªèng h∆°n: Ch·∫•p nh·∫≠n 'N/A', 'N/A ', None, r·ªóng
                if not k1n_rate or 'N/A' in k1n_rate:
                    pred = str(b.get('next_prediction_stl', ''))
                    
                    if not pred or 'N/A' in pred:
                        # N·∫øu kh√¥ng c√≥ c·∫£ d·ª± ƒëo√°n -> C√≥ th·ªÉ do ch∆∞a c√≥ d·ªØ li·ªáu x·ªï s·ªë
                        k1n_rate = "Ch·ªù d·ªØ li·ªáu..." if not current_data else "Kh√¥ng x√°c ƒë·ªãnh"
                    else:
                        k1n_rate = f"D·ª±: {pred}"
                
                # --- SCAN RATE ---
                search_rate = b.get("search_rate_text", "")
                search_period = b.get("search_period", 0)
                if search_rate and search_rate != "0.00%":
                    k2n_display = f"{search_rate}"
                    if search_period > 0: k2n_display += f" ({search_period}k·ª≥)"
                else:
                    k2n_display = "-"
                
                self.tree.insert(
                    "", tk.END, 
                    values=(
                        b['id'], b['name'], b['description'], 
                        k1n_rate,      
                        k2n_display,   
                        status_text, pinned_text, created_date
                    ),
                    tags=tuple(tags) if tags else ()
                )
            
            self.tree.tag_configure("disabled", foreground="gray")
            self.tree.tag_configure("pinned", background="#fff9c4")
            
        except Exception as e:
            print(f"L·ªói refresh_bridge_list (Ignored): {e}")

    def on_bridge_select(self, event):
        selected_items = self.tree.selection()
        
        # Enable/disable bulk delete button based on selection
        if hasattr(self, 'delete_selected_btn'):
            if selected_items:
                self.delete_selected_btn.state(['!disabled'])
            else:
                self.delete_selected_btn.state(['disabled'])
        
        # For single selection, populate the form fields
        selected = self.tree.focus()
        if not selected: return
        values = self.tree.item(selected, "values")
        if not values: return
        
        self.name_entry.delete(0, tk.END)
        self.name_entry.insert(0, values[1])
        self.desc_entry.delete(0, tk.END)
        self.desc_entry.insert(0, values[2])
        
        # Status l√† c·ªôt index 5
        is_enabled = (values[5] == "ƒêang B·∫≠t")
        self.enabled_var.set(is_enabled)

    def add_bridge(self):
        name = self.name_entry.get().strip()
        desc = self.desc_entry.get().strip()
        if not name:
            messagebox.showwarning("L·ªói", "T√™n c·∫ßu kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng!", parent=self.window)
            return 
        success, msg = add_managed_bridge(name, desc)
        if success:
            self.app.logger.log(f"Th√™m c·∫ßu th√†nh c√¥ng: {name}")
            self.refresh_bridge_list()
            self.reset_form()
        else:
            messagebox.showerror("L·ªói", msg, parent=self.window)

    def update_selected_bridge(self):
        selected = self.tree.focus()
        if not selected: return
        bridge_id = self.tree.item(selected, "values")[0]
        desc = self.desc_entry.get().strip()
        status = 1 if self.enabled_var.get() else 0
        success, msg = update_managed_bridge(bridge_id, desc, status)
        if success:
            self.app.logger.log(f"C·∫≠p nh·∫≠t c·∫ßu {bridge_id}: {msg}")
            self.refresh_bridge_list()
        else:
            messagebox.showerror("L·ªói", msg, parent=self.window)

    def delete_selected_bridge(self):
        """
        [FIX V3] C·∫≠p nh·∫≠t ƒë·ªÉ h·ªó tr·ª£ x√≥a nhi·ªÅu d√≤ng b·∫±ng c√°ch l·∫∑p qua self.tree.selection().
        ƒê·ªìng th·ªùi, ƒë·∫£m b·∫£o l·∫•y ƒë√∫ng bridge_id (index 0) v√† hi·ªÉn th·ªã th√¥ng b√°o k·∫øt qu·∫£ chi ti·∫øt.
        """
        # 1. L·∫•y t·∫•t c·∫£ ID c·ªßa c√°c d√≤ng ƒëang ch·ªçn
        selected_items = self.tree.selection()
        
        if not selected_items:
            messagebox.showwarning("Ch∆∞a ch·ªçn", "Vui l√≤ng ch·ªçn √≠t nh·∫•t m·ªôt c·∫ßu ƒë·ªÉ x√≥a.", parent=self.window)
            return

        num_selected = len(selected_items)
        
        # T·∫°o th√¥ng b√°o x√°c nh·∫≠n d·ª±a tr√™n s·ªë l∆∞·ª£ng d√≤ng ƒë∆∞·ª£c ch·ªçn
        try:
            # Bridge name n·∫±m ·ªü c·ªôt th·ª© 2 (index 1)
            first_bridge_name = self.tree.item(selected_items[0], "values")[1] 
        except IndexError:
            first_bridge_name = "ƒë√£ ch·ªçn"

        if num_selected == 1:
            confirm_msg = f"B·∫°n c√≥ ch·∫Øc mu·ªën x√≥a c·∫ßu '{first_bridge_name}'?"
        else:
            confirm_msg = f"B·∫°n c√≥ ch·∫Øc mu·ªën x√≥a {num_selected} c·∫ßu ƒë√£ ch·ªçn?"

        if not messagebox.askyesno("X√°c nh·∫≠n X√≥a", confirm_msg, parent=self.window):
            return
        
        deleted_count = 0
        failed_names = []
        
        # 2. L·∫∂P QUA T·∫§T C·∫¢ C√ÅC D√íNG ƒê∆Ø·ª¢C CH·ªåN V√Ä TH·ª∞C HI·ªÜN X√ìA
        for selected_item_id in selected_items:
            try:
                # Bridge ID n·∫±m ·ªü c·ªôt ƒë·∫ßu ti√™n (index 0)
                values = self.tree.item(selected_item_id, "values")
                bridge_id = values[0]
                bridge_name = values[1]

                # G·ªçi h√†m x√≥a t·ª´ service
                success, msg = delete_managed_bridge(bridge_id)
                
                if success:
                    deleted_count += 1
                else:
                    failed_names.append((bridge_name, msg))
                    
            except Exception as e:
                # Ghi l·∫°i l·ªói n·∫øu kh√¥ng ƒë·ªçc ƒë∆∞·ª£c d·ªØ li·ªáu d√≤ng
                failed_names.append((f"L·ªói ƒë·ªçc d·ªØ li·ªáu d√≤ng {selected_item_id}", str(e)))
                
        # 3. C·∫≠p nh·∫≠t giao di·ªán v√† th√¥ng b√°o k·∫øt qu·∫£
        if deleted_count > 0:
            self.refresh_bridge_list()
            self.reset_form()
            
        if deleted_count == num_selected:
            messagebox.showinfo("Th√†nh c√¥ng", f"ƒê√£ x√≥a th√†nh c√¥ng {deleted_count} c·∫ßu.", parent=self.window)
        elif deleted_count > 0:
            error_details = "\n".join([f"- {name}: {msg}" for name, msg in failed_names])
            messagebox.showwarning("Ho√†n th√†nh c√≥ l·ªói", 
                                  f"ƒê√£ x√≥a th√†nh c√¥ng {deleted_count}/{num_selected} c·∫ßu. "
                                  f"C√≥ {len(failed_names)} c·∫ßu kh√¥ng th·ªÉ x√≥a:\n{error_details}", 
                                  parent=self.window)
        elif num_selected > 0:
             error_details = "\n".join([f"- {name}: {msg}" for name, msg in failed_names])
             messagebox.showerror("L·ªói X√≥a", f"Kh√¥ng th·ªÉ x√≥a b·∫•t k·ª≥ c·∫ßu n√†o ({num_selected} c·∫ßu). Chi ti·∫øt:\n{error_details}", parent=self.window)

    def _on_delete_selected(self):
        """Handle bulk delete of selected bridges"""
        selected_items = self.tree.selection()
        if not selected_items:
            return
        
        # Collect names - name is in column index 1
        names = []
        for iid in selected_items:
            row = self.tree.item(iid)
            values = row.get('values') or []
            if values:
                bridge_name = values[1]  # name column
            else:
                bridge_name = iid
            names.append(bridge_name)

        confirm = messagebox.askyesno(
            "Confirm bulk delete",
            f"B·∫°n s·∫Øp x√≥a {len(names)} c·∫ßu. H√†nh ƒë·ªông kh√¥ng th·ªÉ ho√†n t√°c. Ti·∫øp t·ª•c?",
            parent=self.window
        )
        if not confirm:
            return

        try:
            from lottery_service import delete_managed_bridges_batch
        except Exception:
            from logic.data_repository import delete_managed_bridges_batch

        result = delete_managed_bridges_batch(names, transactional=False)

        # Remove successfully deleted rows from tree
        deleted_set = set(result.get("deleted", []))
        for iid in list(selected_items):
            row = self.tree.item(iid)
            vals = row.get('values') or []
            name = vals[1] if len(vals) > 1 else iid
            if name in deleted_set:
                try:
                    self.tree.delete(iid)
                except Exception:
                    pass

        # Show summary to user
        deleted_count = len(result.get("deleted", []))
        missing_count = len(result.get("missing", []))
        failed = result.get("failed", [])
        summary = f"Deleted: {deleted_count}. Missing: {missing_count}."
        if failed:
            summary += f" Failed: {len(failed)} (see logs)."
        messagebox.showinfo("Bulk delete result", summary, parent=self.window)

        # Audit append to file
        try:
            import json
            import time
            import os
            log_dir = "logs"
            os.makedirs(log_dir, exist_ok=True)
            entry = {
                "ts": int(time.time()),
                "user": getattr(self.app, 'current_user', 'unknown'),
                "names_count": len(names),
                "deleted": result.get("deleted", []),
                "missing": result.get("missing", []),
                "failed": result.get("failed", [])
            }
            with open(os.path.join(log_dir, "bulk_delete_audit.log"), "a", encoding="utf-8") as f:
                f.write(json.dumps(entry, ensure_ascii=False) + "\n")
        except Exception as e:
            print(f"Failed to write audit log: {e}")

    def reset_form(self):
        self.name_entry.delete(0, tk.END)
        self.desc_entry.delete(0, tk.END)
        self.enabled_var.set(True)

    def run_smart_optimization(self):
        if messagebox.askyesno("T·ªëi ∆Øu C·∫ßu", "H·ªá th·ªëng s·∫Ω:\n1. T·∫Øt c√°c c·∫ßu hi·ªáu qu·∫£ th·∫•p (L·ªçc)\n2. B·∫≠t l·∫°i c√°c c·∫ßu ti·ªÅm nƒÉng\n3. L√†m m·ªõi danh s√°ch\n\nTi·∫øp t·ª•c?"):
            self.app.task_manager.run_task(self.app.controller.task_run_smart_optimization, "T·ªëi ∆Øu C·∫ßu Th√¥ng Minh")

    def run_quick_backtest(self):
        selected = self.tree.focus()
        if not selected: 
            messagebox.showwarning("Ch∆∞a ch·ªçn c·∫ßu", "Vui l√≤ng ch·ªçn m·ªôt c·∫ßu t·ª´ danh s√°ch.", parent=self.window)
            return
        bridge_name = self.tree.item(selected, "values")[1]
        is_de = bridge_name.startswith("DE_") or "ƒê·ªÅ" in bridge_name
        if hasattr(self.app, 'controller') and self.app.controller:
            self.app.controller.trigger_bridge_backtest(bridge_name, is_de=is_de)
        else:
            messagebox.showerror("L·ªói", "Controller kh√¥ng kh·∫£ d·ª•ng.", parent=self.window)
    
    def toggle_pin_selected_bridge(self):
        selected = self.tree.focus()
        if not selected:
            messagebox.showwarning("Ch∆∞a ch·ªçn c·∫ßu", "Vui l√≤ng ch·ªçn m·ªôt c·∫ßu.", parent=self.window)
            return
        bridge_name = self.tree.item(selected, "values")[1]
        current_pinned = self.tree.item(selected, "values")[6]
        action_text = "b·ªè ghim" if current_pinned == "üìå C√≥" else "ghim"
        if messagebox.askyesno("X√°c nh·∫≠n", f"B·∫°n c√≥ ch·∫Øc mu·ªën {action_text} c·∫ßu '{bridge_name}'?", parent=self.window):
            if hasattr(self.app, 'controller') and self.app.controller:
                def run_toggle_pin():
                    try:
                        self.app.controller.task_run_toggle_pin(bridge_name)
                        self.window.after(500, self.refresh_bridge_list)
                    except Exception as e:
                        self.window.after(0, lambda: messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ {action_text}: {e}", parent=self.window))
                thread = threading.Thread(target=run_toggle_pin, daemon=True)
                thread.start()
            else:
                messagebox.showerror("L·ªói", "Controller kh√¥ng kh·∫£ d·ª•ng.", parent=self.window)
    
    def show_context_menu(self, event):
        item = self.tree.identify_row(event.y)
        if item:
            self.tree.selection_set(item)
            self.tree.focus(item)
            try: self.context_menu.tk_popup(event.x_root, event.y_root)
            finally: self.context_menu.grab_release()

--------------------------------------------------

=== FILE: ui\ui_bridge_scanner.py ===
# T√™n file: ui/ui_bridge_scanner.py
# (PHI√äN B·∫¢N V1.0 - TAB D√í T√åM C·∫¶U M·ªöI - SCANNING ONLY)
#
# M·ª•c ƒë√≠ch: Tab chuy√™n d·ª•ng cho vi·ªác d√≤ t√¨m/ph√°t hi·ªán c·∫ßu m·ªõi.
#           KH√îNG c√≥ ch·ª©c nƒÉng qu·∫£n l√Ω (enable/disable/delete/edit).

import tkinter as tk
from tkinter import messagebox, ttk
import threading

# Import scanning functions ONLY
try:
    from logic.bridges.lo_bridge_scanner import (
        TIM_CAU_TOT_NHAT_V16,
        TIM_CAU_BAC_NHO_TOT_NHAT,
        update_fixed_lo_bridges,
    )
    from logic.bridges.bridge_manager_de import find_and_auto_manage_bridges_de
    from logic.data_repository import load_data_ai_from_db
    from lottery_service import DB_NAME, upsert_managed_bridge
except ImportError as e:
    print(f"L·ªñI IMPORT t·∫°i ui_bridge_scanner: {e}")
    def TIM_CAU_TOT_NHAT_V16(*args, **kwargs): return []
    def TIM_CAU_BAC_NHO_TOT_NHAT(*args, **kwargs): return []
    def update_fixed_lo_bridges(*args, **kwargs): return 0
    def find_and_auto_manage_bridges_de(*args, **kwargs): return []
    def load_data_ai_from_db(*args, **kwargs): return [], 0
    def upsert_managed_bridge(*args, **kwargs): return False, "L·ªói Import"
    DB_NAME = "data/xo_so_prizes_all_logic.db"


class BridgeScannerTab(ttk.Frame):
    """
    Tab chuy√™n d·ª•ng cho D√í T√åM C·∫¶U M·ªöI.
    
    Ch·ª©c nƒÉng:
    - Qu√©t c·∫ßu L√¥ (V17 Shadow, B·∫°c Nh·ªõ, C·ªë ƒê·ªãnh)
    - Qu√©t c·∫ßu ƒê·ªÅ
    - Hi·ªÉn th·ªã k·∫øt qu·∫£ scan
    - Th√™m c·∫ßu m·ªõi v√†o h·ªá th·ªëng qu·∫£n l√Ω
    
    KH√îNG c√≥:
    - B·∫≠t/t·∫Øt c·∫ßu
    - X√≥a c·∫ßu
    - Ch·ªânh s·ª≠a c·∫ßu
    - Prune/Auto-manage
    """
    
    def __init__(self, parent, app):
        super().__init__(parent)
        self.app = app
        self.db_name = DB_NAME
        self.scan_results = []  # L∆∞u k·∫øt qu·∫£ scan t·∫°m th·ªùi (ch∆∞a qu·∫£n l√Ω)
        
        self.columnconfigure(0, weight=1)
        self.rowconfigure(1, weight=1)
        
        self._create_scan_controls()
        self._create_results_table()
        self._create_action_buttons()
        
    def _create_scan_controls(self):
        """T·∫°o khu v·ª±c ƒëi·ªÅu khi·ªÉn qu√©t c·∫ßu."""
        frame = ttk.LabelFrame(self, text="üîç ƒêi·ªÅu Khi·ªÉn Qu√©t C·∫ßu", padding="10")
        frame.grid(row=0, column=0, sticky="ew", padx=10, pady=10)
        frame.columnconfigure(1, weight=1)
        
        # D√≤ng 1: Qu√©t L√¥
        ttk.Label(frame, text="Qu√©t C·∫ßu L√¥:", font=("Helvetica", 10, "bold")).grid(
            row=0, column=0, sticky="w", pady=5
        )
        
        btn_frame_lo = ttk.Frame(frame)
        btn_frame_lo.grid(row=0, column=1, sticky="ew", pady=5)
        
        ttk.Button(
            btn_frame_lo, 
            text="üìä Qu√©t V17 Shadow", 
            command=self._scan_v17
        ).pack(side=tk.LEFT, padx=5)
        
        ttk.Button(
            btn_frame_lo, 
            text="üß† Qu√©t B·∫°c Nh·ªõ", 
            command=self._scan_memory
        ).pack(side=tk.LEFT, padx=5)
        
        ttk.Button(
            btn_frame_lo, 
            text="üìå C·∫≠p Nh·∫≠t C·∫ßu C·ªë ƒê·ªãnh", 
            command=self._scan_fixed
        ).pack(side=tk.LEFT, padx=5)
        
        ttk.Button(
            btn_frame_lo, 
            text="‚ö° QU√âT T·∫§T C·∫¢ L√î", 
            command=self._scan_all_lo,
            style="Accent.TButton"
        ).pack(side=tk.LEFT, padx=5)
        
        # D√≤ng 2: Qu√©t ƒê·ªÅ
        ttk.Label(frame, text="Qu√©t C·∫ßu ƒê·ªÅ:", font=("Helvetica", 10, "bold")).grid(
            row=1, column=0, sticky="w", pady=5
        )
        
        btn_frame_de = ttk.Frame(frame)
        btn_frame_de.grid(row=1, column=1, sticky="ew", pady=5)
        
        ttk.Button(
            btn_frame_de, 
            text="üîÆ Qu√©t C·∫ßu ƒê·ªÅ", 
            command=self._scan_de
        ).pack(side=tk.LEFT, padx=5)
        
        # D√≤ng 3: Th√¥ng tin
        self.scan_status_label = ttk.Label(
            frame, 
            text="üìå S·∫µn s√†ng qu√©t. Ch·ªçn lo·∫°i qu√©t v√† b·∫•m n√∫t ƒë·ªÉ b·∫Øt ƒë·∫ßu.", 
            foreground="blue"
        )
        self.scan_status_label.grid(row=2, column=0, columnspan=2, sticky="w", pady=10)
    
    def _create_results_table(self):
        """T·∫°o b·∫£ng hi·ªÉn th·ªã k·∫øt qu·∫£ qu√©t."""
        frame = ttk.LabelFrame(self, text="üìã K·∫øt Qu·∫£ Qu√©t (C·∫ßu M·ªõi Ph√°t Hi·ªán)", padding="10")
        frame.grid(row=1, column=0, sticky="nsew", padx=10, pady=10)
        frame.columnconfigure(0, weight=1)
        frame.rowconfigure(0, weight=1)
        
        # Columns: Lo·∫°i, T√™n C·∫ßu, V·ªã Tr√≠/M√¥ t·∫£, T·ª∑ L·ªá K2N, Chu·ªói, ƒê√£ Th√™m
        columns = ("type", "name", "description", "scan_rate", "streak", "added")
        self.results_tree = ttk.Treeview(frame, columns=columns, show="headings", selectmode="extended")
        
        self.results_tree.heading("type", text="Lo·∫°i")
        self.results_tree.column("type", width=80, anchor="center")
        
        self.results_tree.heading("name", text="T√™n C·∫ßu")
        self.results_tree.column("name", width=150, anchor=tk.W)
        
        self.results_tree.heading("description", text="M√¥ T·∫£")
        self.results_tree.column("description", width=250, anchor=tk.W)
        
        self.results_tree.heading("scan_rate", text="T·ª∑ L·ªá K2N")
        self.results_tree.column("scan_rate", width=100, anchor="center")
        
        self.results_tree.heading("streak", text="Chu·ªói")
        self.results_tree.column("streak", width=80, anchor="center")
        
        self.results_tree.heading("added", text="ƒê√£ Th√™m")
        self.results_tree.column("added", width=80, anchor="center")
        
        scrollbar = ttk.Scrollbar(frame, orient=tk.VERTICAL, command=self.results_tree.yview)
        self.results_tree.configure(yscrollcommand=scrollbar.set)
        
        self.results_tree.grid(row=0, column=0, sticky="nsew")
        scrollbar.grid(row=0, column=1, sticky="ns")
    
    def _create_action_buttons(self):
        """T·∫°o c√°c n√∫t thao t√°c v·ªõi k·∫øt qu·∫£ qu√©t."""
        frame = ttk.Frame(self, padding="10")
        frame.grid(row=2, column=0, sticky="ew", padx=10, pady=5)
        
        ttk.Label(frame, text="Thao t√°c v·ªõi k·∫øt qu·∫£:", font=("Helvetica", 9)).pack(side=tk.LEFT, padx=10)
        
        ttk.Button(
            frame, 
            text="‚ûï Th√™m C·∫ßu ƒê√£ Ch·ªçn v√†o Qu·∫£n L√Ω", 
            command=self._add_selected_to_management
        ).pack(side=tk.LEFT, padx=5)
        
        ttk.Button(
            frame, 
            text="‚ûï‚ûï Th√™m T·∫§T C·∫¢ v√†o Qu·∫£n L√Ω", 
            command=self._add_all_to_management
        ).pack(side=tk.LEFT, padx=5)
        
        ttk.Button(
            frame, 
            text="üóëÔ∏è X√≥a K·∫øt Qu·∫£ Qu√©t", 
            command=self._clear_results
        ).pack(side=tk.LEFT, padx=5)
    
    # ==================== SCANNING FUNCTIONS ====================
    
    def _scan_v17(self):
        """Qu√©t c·∫ßu V17 Shadow."""
        self._run_scan_in_thread("V17 Shadow", self._do_scan_v17)
    
    def _scan_memory(self):
        """Qu√©t c·∫ßu B·∫°c Nh·ªõ."""
        self._run_scan_in_thread("B·∫°c Nh·ªõ", self._do_scan_memory)
    
    def _scan_fixed(self):
        """C·∫≠p nh·∫≠t c·∫ßu c·ªë ƒë·ªãnh."""
        self._run_scan_in_thread("C·∫ßu C·ªë ƒê·ªãnh", self._do_scan_fixed)
    
    def _scan_de(self):
        """Qu√©t c·∫ßu ƒê·ªÅ."""
        self._run_scan_in_thread("C·∫ßu ƒê·ªÅ", self._do_scan_de)
    
    def _scan_all_lo(self):
        """Qu√©t t·∫•t c·∫£ lo·∫°i c·∫ßu L√¥."""
        self._run_scan_in_thread("T·∫§T C·∫¢ L√î", self._do_scan_all_lo)
    
    def _run_scan_in_thread(self, scan_type, scan_func):
        """Ch·∫°y scan trong thread ri√™ng ƒë·ªÉ kh√¥ng block UI."""
        self.scan_status_label.config(text=f"‚è≥ ƒêang qu√©t {scan_type}...", foreground="orange")
        self.update_idletasks()
        
        def worker():
            try:
                scan_func()
                self.after(0, lambda: self.scan_status_label.config(
                    text=f"‚úÖ Qu√©t {scan_type} ho√†n t·∫•t!", 
                    foreground="green"
                ))
            except Exception as e:
                self.after(0, lambda: self.scan_status_label.config(
                    text=f"‚ùå L·ªói qu√©t {scan_type}: {str(e)}", 
                    foreground="red"
                ))
                self.after(0, lambda: messagebox.showerror("L·ªói Qu√©t", f"Kh√¥ng th·ªÉ qu√©t {scan_type}:\n{e}"))
        
        thread = threading.Thread(target=worker, daemon=True)
        thread.start()
    
    def _do_scan_v17(self):
        """Th·ª±c hi·ªán qu√©t V17."""
        all_data, _ = load_data_ai_from_db(self.db_name)
        if not all_data:
            raise Exception("Kh√¥ng c√≥ d·ªØ li·ªáu x·ªï s·ªë")
        
        results = TIM_CAU_TOT_NHAT_V16(all_data, 2, len(all_data) + 1, self.db_name)
        self._process_scan_results(results, "L√î_V17")
    
    def _do_scan_memory(self):
        """Th·ª±c hi·ªán qu√©t B·∫°c Nh·ªõ."""
        all_data, _ = load_data_ai_from_db(self.db_name)
        if not all_data:
            raise Exception("Kh√¥ng c√≥ d·ªØ li·ªáu x·ªï s·ªë")
        
        results = TIM_CAU_BAC_NHO_TOT_NHAT(all_data, 2, len(all_data) + 1, self.db_name)
        self._process_scan_results(results, "L√î_BN")
    
    def _do_scan_fixed(self):
        """Th·ª±c hi·ªán c·∫≠p nh·∫≠t c·∫ßu c·ªë ƒë·ªãnh."""
        all_data, _ = load_data_ai_from_db(self.db_name)
        if not all_data:
            raise Exception("Kh√¥ng c√≥ d·ªØ li·ªáu x·ªï s·ªë")
        
        count = update_fixed_lo_bridges(all_data, self.db_name)
        self.after(0, lambda: messagebox.showinfo(
            "C·∫≠p Nh·∫≠t C·∫ßu C·ªë ƒê·ªãnh", 
            f"ƒê√£ c·∫≠p nh·∫≠t {count} c·∫ßu c·ªë ƒë·ªãnh.\nC√°c c·∫ßu n√†y ƒë√£ ƒë∆∞·ª£c th√™m v√†o h·ªá th·ªëng qu·∫£n l√Ω."
        ))
    
    def _do_scan_de(self):
        """Th·ª±c hi·ªán qu√©t ƒê·ªÅ."""
        all_data, _ = load_data_ai_from_db(self.db_name)
        if not all_data:
            raise Exception("Kh√¥ng c√≥ d·ªØ li·ªáu x·ªï s·ªë")
        
        # Import DE scanner directly to get full results
        try:
            from logic.bridges.de_bridge_scanner import run_de_scanner
            count, found_bridges = run_de_scanner(all_data)
            
            # Process and display results
            if found_bridges and count > 0:
                for bridge in found_bridges:
                    # Extract bridge info
                    name = bridge.get('name', 'N/A')
                    desc = bridge.get('description', 'N/A')
                    win_rate = bridge.get('win_rate', 0)
                    streak = bridge.get('streak', 0)
                    rate_str = f"{win_rate:.1f}%" if isinstance(win_rate, (int, float)) else str(win_rate)
                    
                    # Add type indicator to name for clarity
                    bridge_type = bridge.get('type', 'UNKNOWN')
                    type_display = ""
                    if 'DE_MEMORY' in bridge_type or bridge_type == 'DE_MEMORY':
                        type_display = " [B·∫†C NH·ªö]"
                    elif 'DE_SET' in bridge_type:
                        type_display = " [B·ªò]"
                    elif 'DE_PASCAL' in bridge_type:
                        type_display = " [PASCAL]"
                    elif 'DE_KILLER' in bridge_type:
                        type_display = " [LO·∫†I TR·ª™]"
                    elif 'DE_DYNAMIC' in bridge_type:
                        type_display = " [ƒê·ªòNG]"
                    
                    name_with_type = name + type_display
                    
                    # Add to results table with bridge type info
                    self.after(0, lambda n=name_with_type, d=desc, r=rate_str, s=streak, bt=bridge_type: 
                        self._add_de_result_to_table(n, d, r, s, bt))
                
                self.after(0, lambda c=count: messagebox.showinfo(
                    "Qu√©t C·∫ßu ƒê·ªÅ", 
                    f"ƒê√£ t√¨m th·∫•y {c} c·∫ßu ƒê·ªÅ. Xem k·∫øt qu·∫£ b√™n d∆∞·ªõi."
                ))
            else:
                self.after(0, lambda: messagebox.showinfo(
                    "Qu√©t C·∫ßu ƒê·ªÅ", 
                    "Kh√¥ng t√¨m th·∫•y c·∫ßu ƒê·ªÅ m·ªõi."
                ))
        except Exception as e:
            self.after(0, lambda: messagebox.showerror(
                "L·ªói Qu√©t ƒê·ªÅ",
                f"Kh√¥ng th·ªÉ qu√©t c·∫ßu ƒê·ªÅ:\n{str(e)}"
            ))
    
    def _do_scan_all_lo(self):
        """Qu√©t t·∫•t c·∫£ lo·∫°i c·∫ßu L√¥."""
        self._do_scan_v17()
        self._do_scan_memory()
        self._do_scan_fixed()
    
    def _process_scan_results(self, results, bridge_type):
        """X·ª≠ l√Ω v√† hi·ªÉn th·ªã k·∫øt qu·∫£ qu√©t."""
        if not results or len(results) <= 1:  # Ch·ªâ c√≥ header
            self.after(0, lambda: messagebox.showinfo(
                "K·∫øt Qu·∫£ Qu√©t", 
                f"Kh√¥ng t√¨m th·∫•y c·∫ßu m·ªõi lo·∫°i {bridge_type}."
            ))
            return
        
        # Skip header row
        for row in results[1:]:
            if len(row) >= 4:  # STT, T√™n, M√¥ t·∫£, T·ª∑ l·ªá, Chu·ªói
                self.after(0, lambda r=row, bt=bridge_type: self._add_result_to_table(r, bt))
    
    def _add_result_to_table(self, row, bridge_type):
        """Th√™m m·ªôt k·∫øt qu·∫£ v√†o b·∫£ng."""
        # row format: [STT, Name, Description, Rate, Streak]
        name = str(row[1]) if len(row) > 1 else "N/A"
        desc = str(row[2]) if len(row) > 2 else "N/A"
        rate = str(row[3]) if len(row) > 3 else "N/A"
        streak = str(row[4]) if len(row) > 4 else "0"
        
        self.results_tree.insert(
            "", tk.END,
            values=(bridge_type, name, desc, rate, streak, "‚ùå Ch∆∞a"),
            tags=("new",)
        )
        self.results_tree.tag_configure("new", background="#e3f2fd")
    
    def _add_de_result_to_table(self, name, desc, rate, streak, bridge_type="ƒê·ªÄ"):
        """Th√™m k·∫øt qu·∫£ c·∫ßu ƒê·ªÅ v√†o b·∫£ng v·ªõi th√¥ng tin type ch√≠nh x√°c."""
        # Store actual bridge type in hidden data
        item_id = self.results_tree.insert(
            "", tk.END,
            values=("ƒê·ªÄ", name, desc, rate, str(streak), "‚ùå Ch∆∞a"),
            tags=("new", bridge_type)  # Store bridge_type as tag for retrieval
        )
        self.results_tree.tag_configure("new", background="#e3f2fd")
    
    # ==================== ACTION FUNCTIONS ====================
    
    def _add_selected_to_management(self):
        """
        Th√™m c√°c c·∫ßu ƒë√£ ch·ªçn v√†o h·ªá th·ªëng qu·∫£n l√Ω.
        V11.1: Enhanced with detailed logging to logs/batch_add.log
        """
        import os
        import json
        from datetime import datetime
        
        selected = self.results_tree.selection()
        if not selected:
            messagebox.showwarning("Ch∆∞a Ch·ªçn", "Vui l√≤ng ch·ªçn √≠t nh·∫•t m·ªôt c·∫ßu ƒë·ªÉ th√™m.")
            return
        
        # Prepare log file
        logs_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "logs")
        if not os.path.exists(logs_dir):
            os.makedirs(logs_dir)
        log_file = os.path.join(logs_dir, "batch_add.log")
        
        added_count = 0
        skipped_count = 0
        error_list = []
        log_entries = []
        
        for item in selected:
            values = self.results_tree.item(item, "values")
            if values[5] == "‚úÖ R·ªìi":  # ƒê√£ th√™m r·ªìi
                skipped_count += 1
                continue
            
            # Extract bridge info
            display_type = values[0]  # "L√î_V17" / "L√î_BN" / "ƒê·ªÄ"
            name = values[1]
            desc = values[2]
            rate = values[3]
            
            # Get actual bridge type from tags (for DE bridges)
            tags = self.results_tree.item(item, "tags")
            actual_bridge_type = None
            for tag in tags:
                if tag.startswith('DE_') or tag in ['DE_MEMORY', 'DE_SET', 'DE_PASCAL', 'DE_KILLER', 'DE_DYNAMIC_K', 'DE_POS_SUM']:
                    actual_bridge_type = tag
                    break
            
            # Validate bridge name
            if not name or name == "N/A" or not name.strip():
                error_msg = f"- C·∫ßu '{desc[:30]}': T√™n kh√¥ng h·ª£p l·ªá"
                error_list.append(error_msg)
                log_entries.append({
                    "timestamp": datetime.now().isoformat(),
                    "bridge_name": desc[:30],
                    "action": "add",
                    "status": "failed",
                    "reason": "Invalid name"
                })
                continue
            
            # Validate bridge type
            if not display_type or display_type not in ["L√î_V17", "L√î_BN", "L√î_STL_FIXED", "ƒê·ªÄ"]:
                error_msg = f"- C·∫ßu '{name}': Lo·∫°i kh√¥ng x√°c ƒë·ªãnh ({display_type})"
                error_list.append(error_msg)
                log_entries.append({
                    "timestamp": datetime.now().isoformat(),
                    "bridge_name": name,
                    "action": "add",
                    "status": "failed",
                    "reason": f"Unknown type: {display_type}"
                })
                continue
            
            # Determine proper type for DB
            if display_type == "L√î_V17":
                db_type = "LO_POS"
            elif display_type == "L√î_BN":
                db_type = "LO_MEM"
            elif display_type == "L√î_STL_FIXED":
                db_type = "LO_STL_FIXED"
            elif display_type == "ƒê·ªÄ":
                # Use actual bridge type if available, otherwise default
                db_type = actual_bridge_type if actual_bridge_type else "DE_ALGO"
            else:
                db_type = "UNKNOWN"
            
            try:
                success, msg = upsert_managed_bridge(
                    name=name,
                    description=desc,
                    win_rate_text=rate,
                    db_name=self.db_name,
                    pos1_idx=-2,  # Special marker for scanner-added bridges
                    pos2_idx=-2,
                    bridge_data={"search_rate_text": rate, "is_enabled": 1, "type": db_type}
                )
                
                if success:
                    # Update table to mark as added
                    self.results_tree.item(item, values=(
                        values[0], values[1], values[2], values[3], values[4], "‚úÖ R·ªìi"
                    ))
                    self.results_tree.item(item, tags=("added",))
                    added_count += 1
                    log_entries.append({
                        "timestamp": datetime.now().isoformat(),
                        "bridge_name": name,
                        "bridge_type": db_type,
                        "action": "add",
                        "status": "success",
                        "message": msg
                    })
                else:
                    # Bridge already exists or other error
                    if "ƒë√£ t·ªìn t·∫°i" in msg.lower() or "already exists" in msg.lower():
                        # Mark as added anyway
                        self.results_tree.item(item, values=(
                            values[0], values[1], values[2], values[3], values[4], "‚úÖ R·ªìi"
                        ))
                        self.results_tree.item(item, tags=("added",))
                        skipped_count += 1
                        log_entries.append({
                            "timestamp": datetime.now().isoformat(),
                            "bridge_name": name,
                            "bridge_type": db_type,
                            "action": "add",
                            "status": "skipped",
                            "reason": "Already exists"
                        })
                    else:
                        error_list.append(f"- C·∫ßu '{name}': {msg}")
                        log_entries.append({
                            "timestamp": datetime.now().isoformat(),
                            "bridge_name": name,
                            "bridge_type": db_type,
                            "action": "add",
                            "status": "failed",
                            "error": msg
                        })
            except Exception as e:
                error_msg = f"- C·∫ßu '{name}': L·ªói th√™m - {str(e)}"
                error_list.append(error_msg)
                log_entries.append({
                    "timestamp": datetime.now().isoformat(),
                    "bridge_name": name,
                    "action": "add",
                    "status": "failed",
                    "exception": str(e)
                })
        
        # Write logs to file
        try:
            with open(log_file, 'a', encoding='utf-8') as f:
                for entry in log_entries:
                    f.write(json.dumps(entry, ensure_ascii=False) + "\n")
        except Exception as e:
            print(f"Warning: Could not write to log file: {e}")
        
        self.results_tree.tag_configure("added", background="#c8e6c9")
        
        # Build result message
        result_msg = []
        if added_count > 0:
            result_msg.append(f"‚úÖ ƒê√£ th√™m {added_count} c·∫ßu m·ªõi")
        if skipped_count > 0:
            result_msg.append(f"‚è≠Ô∏è B·ªè qua {skipped_count} c·∫ßu ƒë√£ t·ªìn t·∫°i")
        if error_list:
            result_msg.append(f"\n‚ùå C√≥ {len(error_list)} l·ªói:\n" + "\n".join(error_list[:5]))
            if len(error_list) > 5:
                result_msg.append(f"... v√† {len(error_list) - 5} l·ªói kh√°c")
        
        if result_msg:
            if error_list and added_count == 0:
                messagebox.showerror("L·ªói Th√™m C·∫ßu", "\n".join(result_msg))
            else:
                messagebox.showinfo("K·∫øt Qu·∫£ Th√™m C·∫ßu", "\n".join(result_msg))
        else:
            messagebox.showinfo("Th√¥ng B√°o", "Kh√¥ng c√≥ c·∫ßu n√†o ƒë∆∞·ª£c th√™m.")
        
        # Notify management tab to refresh if it exists
        if added_count > 0 and hasattr(self.app, 'bridge_management_tab'):
            self.app.bridge_management_tab.refresh_bridge_list()
    
    def _add_all_to_management(self):
        """Th√™m t·∫•t c·∫£ k·∫øt qu·∫£ qu√©t v√†o h·ªá th·ªëng qu·∫£n l√Ω."""
        all_items = self.results_tree.get_children()
        if not all_items:
            messagebox.showwarning("Kh√¥ng C√≥ K·∫øt Qu·∫£", "Kh√¥ng c√≥ k·∫øt qu·∫£ qu√©t n√†o ƒë·ªÉ th√™m.")
            return
        
        # Select all and add
        self.results_tree.selection_set(all_items)
        self._add_selected_to_management()
    
    def _clear_results(self):
        """X√≥a t·∫•t c·∫£ k·∫øt qu·∫£ qu√©t."""
        if not self.results_tree.get_children():
            return
        
        if messagebox.askyesno("X√°c Nh·∫≠n", "X√≥a t·∫•t c·∫£ k·∫øt qu·∫£ qu√©t?"):
            for item in self.results_tree.get_children():
                self.results_tree.delete(item)
            self.scan_status_label.config(text="üìå ƒê√£ x√≥a k·∫øt qu·∫£. S·∫µn s√†ng qu√©t m·ªõi.", foreground="blue")


--------------------------------------------------

=== FILE: ui\ui_dashboard.py ===
# T√™n file: code6/ui/ui_dashboard.py
# (PHI√äN B·∫¢N ƒê√É FIX: L·ªçc C·∫ßu ƒê·ªÅ kh·ªèi b·∫£ng Th√¥ng 10 K·ª≥)

import datetime
import tkinter as tk
import traceback
from tkinter import messagebox, ttk

try:
    from logic.config_manager import SETTINGS
except ImportError:
    print("L·ªñI: ui_dashboard.py kh√¥ng th·ªÉ import logic.config_manager...")
    
    class FallbackSettings:
        """Fallback settings when config_manager import fails"""
        GAN_DAYS = 15
        HIGH_WIN_THRESHOLD = 47.0
        K2N_RISK_START_THRESHOLD = 4
        FILTER_ENABLED = False
        FILTER_MIN_CONFIDENCE = 0
        FILTER_MIN_AI_PROB = 0
        
        def save_settings(self):
            """Dummy save method for fallback"""
            print("WARNING: Cannot save settings - config_manager not available")
            return True, "Fallback mode"
    
    SETTINGS = FallbackSettings()

# Enhancement 4: Filter threshold constants
# V7.6 IMPROVED: TƒÉng ng∆∞·ª°ng ƒë·ªÉ c·∫£i thi·ªán hi·ªáu qu·∫£ (gi·∫£m t·ªâ l·ªá g√£y)
FILTER_CONFIDENCE_THRESHOLD = 5  # Minimum confidence stars (tƒÉng t·ª´ 4 ‚Üí 5)
FILTER_AI_PROB_THRESHOLD = 60  # Minimum AI probability % (tƒÉng t·ª´ 50 ‚Üí 60)

# Import DB Logic ƒë·ªÉ l·∫•y d·ªØ li·ªáu c·∫ßu
try:
    from logic.db_manager import DB_NAME
    from logic.data_repository import get_managed_bridges_with_prediction
    # [QUAN TR·ªåNG: TH√äM D√íNG N√ÄY ƒê·ªÇ G·ªåI LOGIC T√çNH TO√ÅN]
    from logic.analytics import dashboard_scorer
except ImportError:
    print("L·ªñI: ui_dashboard.py kh√¥ng th·ªÉ import logic...")
    DB_NAME = "data/xo_so_prizes_all_logic.db"

    def get_managed_bridges_with_prediction(db_name, current_data=None, only_enabled=True):
        return []


class DashboardWindow(ttk.Frame):
    def __init__(self, app_instance):
        super().__init__(app_instance.notebook, padding=10)

        self.app = app_instance
        self.root = app_instance.root

        self.columnconfigure(0, weight=1)
        self.rowconfigure(1, weight=1)

        self.header_frame = ttk.Frame(self)
        self.header_frame.grid(row=0, column=0, sticky="ew", padx=10, pady=5)

        self.title_label = ttk.Label(
            self.header_frame, text="ƒêang t·∫£i...", font=("Arial", 16, "bold")
        )
        self.title_label.pack(side=tk.LEFT, padx=(0, 20))

        # Enhancement 4: Smart Filtering controls
        self._create_filter_controls()

        self.refresh_button = ttk.Button(
            self.header_frame, text="L√†m M·ªõi D·ªØ Li·ªáu", command=self.refresh_data
        )
        self.refresh_button.pack(side=tk.RIGHT)

        self.main_analysis_frame = ttk.Frame(self, padding=10)
        self.main_analysis_frame.grid(row=1, column=0, sticky="nsew", padx=10, pady=10)

        # ===================================================================
        # C·∫§U H√åNH LAYOUT (L∆Ø·ªöI 24 C·ªòT)
        # ===================================================================
        
        for i in range(24):
            self.main_analysis_frame.columnconfigure(i, weight=1)

        # H√†ng 0: C√°c b·∫£ng ch√≠nh (Cao h∆°n)
        self.main_analysis_frame.rowconfigure(0, weight=3)
        # H√†ng 1: C√°c b·∫£ng tham kh·∫£o (Th·∫•p h∆°n ch√∫t)
        self.main_analysis_frame.rowconfigure(1, weight=2)

        # ===================================================================
        # T·∫†O C√ÅC B·∫¢NG
        # ===================================================================

        # --- H√ÄNG 0: KHU V·ª∞C QUY·∫æT ƒê·ªäNH ---

        # 1. B·∫£ng Ch·∫•m ƒêi·ªÉm (Chi·∫øm 16/24 c·ªôt = 2/3)
        self._create_top_scores_ui(self.main_analysis_frame)
        self.top_scores_frame.grid(row=0, column=0, columnspan=16, sticky="nsew", padx=5, pady=5)

        # 2. C·∫ßu K2N ƒêang Ch·ªù (Chi·∫øm 8/24 c·ªôt = 1/3)
        self._create_pending_k2n_ui(self.main_analysis_frame)
        self.pending_k2n_frame.grid(row=0, column=16, columnspan=8, sticky="nsew", padx=5, pady=5)

        # --- H√ÄNG 1: KHU V·ª∞C THAM KH·∫¢O ---

        # 3. D·ª± ƒëo√°n AI (5/24 c·ªôt)
        self._create_ai_predictions_ui(self.main_analysis_frame)
        self.ai_predictions_frame.grid(row=1, column=0, columnspan=5, sticky="nsew", padx=5, pady=5)

        # 4. C·∫ßu Th√¥ng 10 K·ª≥ (9/24 c·ªôt - R·ªông nh·∫•t)
        self._create_recent_form_ui(self.main_analysis_frame)
        self.recent_form_frame.grid(row=1, column=5, columnspan=9, sticky="nsew", padx=5, pady=5)

        # 5. Loto V·ªÅ Nhi·ªÅu (5/24 c·ªôt)
        self._create_hot_loto_ui(self.main_analysis_frame)
        self.hot_loto_frame.grid(row=1, column=14, columnspan=5, sticky="nsew", padx=5, pady=5)

        # 6. Vote Statistics (5/24 c·ªôt) - REPLACED L√¥ Gan
        self._create_vote_statistics_ui(self.main_analysis_frame)
        self.vote_statistics_frame.grid(row=1, column=19, columnspan=5, sticky="nsew", padx=5, pady=5)
        
        # --- [M·ªöI] H√ÄNG 2: V√ôNG K·∫æT QU·∫¢ SCORING & C·∫¢NH B√ÅO ---
        self.main_analysis_frame.rowconfigure(2, weight=1) # C·∫•p quy·ªÅn gi√£n d√≤ng cho h√†ng 2
        
        self.result_log_frame = ttk.Labelframe(self.main_analysis_frame, text="üìù K·∫øt Qu·∫£ Ph√¢n T√≠ch & C·∫£nh B√°o (V3.8)")
        self.result_log_frame.grid(row=2, column=0, columnspan=24, sticky="nsew", padx=5, pady=8)
        
        # T·∫°o Widget Text ƒë·ªÉ hi·ªÉn th·ªã
        self.txt_result_log = tk.Text(self.result_log_frame, height=5, font=("Arial", 10))
        self.txt_result_log.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # Scrollbar cho text
        scrollbar_log = ttk.Scrollbar(self.result_log_frame, orient=tk.VERTICAL, command=self.txt_result_log.yview)
        scrollbar_log.pack(side=tk.RIGHT, fill=tk.Y)
        self.txt_result_log.configure(yscrollcommand=scrollbar_log.set)
    # ===================================================================================
    # C√ÅC H√ÄM T·∫†O UI
    # ===================================================================================

    def _create_filter_controls(self):
        """Enhancement 4: Create smart filtering controls"""
        filter_frame = ttk.Frame(self.header_frame)
        filter_frame.pack(side=tk.RIGHT, padx=(10, 10))

        # Filter enabled checkbox
        self.filter_enabled_var = tk.BooleanVar(value=SETTINGS.FILTER_ENABLED)
        filter_check = ttk.Checkbutton(
            filter_frame,
            text="L·ªçc th√¥ng minh",
            variable=self.filter_enabled_var,
            command=self._on_filter_changed
        )
        filter_check.pack(side=tk.LEFT, padx=5)

        # Min confidence filter
        conf_frame = ttk.Frame(filter_frame)
        conf_frame.pack(side=tk.LEFT, padx=5)
        
        self.filter_confidence_var = tk.BooleanVar(
            value=SETTINGS.FILTER_MIN_CONFIDENCE >= FILTER_CONFIDENCE_THRESHOLD
        )
        conf_check = ttk.Checkbutton(
            conf_frame,
            text=f"Ch·ªâ hi·ªán ‚â•{FILTER_CONFIDENCE_THRESHOLD}‚≠ê",
            variable=self.filter_confidence_var,
            command=self._on_filter_changed
        )
        conf_check.pack()

        # Min AI probability filter
        ai_frame = ttk.Frame(filter_frame)
        ai_frame.pack(side=tk.LEFT, padx=5)
        
        self.filter_ai_var = tk.BooleanVar(
            value=SETTINGS.FILTER_MIN_AI_PROB >= FILTER_AI_PROB_THRESHOLD
        )
        ai_check = ttk.Checkbutton(
            ai_frame,
            text=f"Ch·ªâ hi·ªán AI ‚â•{FILTER_AI_PROB_THRESHOLD}%",
            variable=self.filter_ai_var,
            command=self._on_filter_changed
        )
        ai_check.pack()

    def _on_filter_changed(self):
        """Handle filter checkbox changes"""
        # Update SETTINGS
        SETTINGS.FILTER_ENABLED = self.filter_enabled_var.get()
        SETTINGS.FILTER_MIN_CONFIDENCE = (
            FILTER_CONFIDENCE_THRESHOLD if self.filter_confidence_var.get() else 0
        )
        SETTINGS.FILTER_MIN_AI_PROB = (
            FILTER_AI_PROB_THRESHOLD if self.filter_ai_var.get() else 0
        )
        
        # Save preferences
        SETTINGS.save_settings()
        
        # Refresh data to apply filters
        if hasattr(self.app, 'refresh_dashboard'):
            self.app.refresh_dashboard()

    def _create_top_scores_ui(self, parent_frame):
        self.top_scores_frame = ttk.Labelframe(
            parent_frame, text="üèÜ B·∫£ng Ch·∫•m ƒêi·ªÉm T·ªïng L·ª±c (Double-click ƒë·ªÉ xem chi ti·∫øt)"
        )
        tree_frame = ttk.Frame(self.top_scores_frame)
        tree_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        cols = ("score", "ai", "confidence", "recommendation", "pair", "gan", "reasons")
        self.scores_tree = ttk.Treeview(
            tree_frame, columns=cols, show="headings", height=10
        )
        self.scores_tree.heading("score", text="ƒêi·ªÉm")
        self.scores_tree.heading("ai", text="AI")
        self.scores_tree.heading("confidence", text="‚≠ê")
        self.scores_tree.heading("recommendation", text="Khuy·∫øn Ngh·ªã")
        self.scores_tree.heading("pair", text="C·∫∑p s·ªë")
        self.scores_tree.heading("gan", text="Gan")
        self.scores_tree.heading("reasons", text="L√Ω do (T√≠ch h·ª£p AI)")
        
        self.scores_tree.column("score", width=50, minwidth=50, anchor=tk.E)
        self.scores_tree.column("ai", width=60, minwidth=60, anchor=tk.CENTER)
        self.scores_tree.column("confidence", width=50, minwidth=50, anchor=tk.CENTER)
        self.scores_tree.column("recommendation", width=80, minwidth=80, anchor=tk.CENTER)
        self.scores_tree.column("pair", width=60, minwidth=60, anchor=tk.CENTER)
        self.scores_tree.column("gan", width=50, minwidth=50, anchor=tk.CENTER)
        self.scores_tree.column("reasons", width=380, minwidth=280)
        
        # Thanh cu·ªôn D·ªçc
        v_scrollbar = ttk.Scrollbar(
            tree_frame, orient=tk.VERTICAL, command=self.scores_tree.yview
        )
        v_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)

        # Thanh cu·ªôn Ngang
        h_scrollbar = ttk.Scrollbar(
            tree_frame, orient=tk.HORIZONTAL, command=self.scores_tree.xview
        )
        h_scrollbar.pack(side=tk.BOTTOM, fill=tk.X)

        self.scores_tree.configure(
            yscrollcommand=v_scrollbar.set, 
            xscrollcommand=h_scrollbar.set
        )
        self.scores_tree.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)

        self.scores_tree.tag_configure("gan", foreground="red")
        self.scores_tree.tag_configure(
            "top1", background="#D5E8D4", font=("Arial", 10, "bold")
        )
        self.scores_tree.tag_configure("top3", background="#FFF2CC")
        
        # AI color tags
        self.scores_tree.tag_configure("ai_very_high", foreground="#006400", font=("Arial", 9, "bold"))  # Dark green >=70%
        self.scores_tree.tag_configure("ai_high", foreground="#228B22")  # Green >=50%
        self.scores_tree.tag_configure("ai_med", foreground="#DAA520")  # Goldenrod >=30%
        self.scores_tree.tag_configure("ai_low", foreground="#A9A9A9")  # Gray <30%
        
        # NEW: Enhancement 3 - Recommendation color tags
        self.scores_tree.tag_configure("rec_choi", foreground="green", font=("Arial", 9, "bold"))
        self.scores_tree.tag_configure("rec_xem_xet", foreground="#DAA520", font=("Arial", 9))
        self.scores_tree.tag_configure("rec_bo_qua", foreground="gray", font=("Arial", 9))
        
        # (M·ªöI) Bind s·ª± ki·ªán click
        self.scores_tree.bind("<Double-1>", self.on_tree_double_click)

    def _create_ai_predictions_ui(self, parent_frame):
        self.ai_predictions_frame = ttk.Labelframe(
            parent_frame, text="üß† AI (ƒê∆°n)"
        )
        tree_frame = ttk.Frame(self.ai_predictions_frame)
        tree_frame.pack(fill=tk.BOTH, expand=True, padx=2, pady=2)
        cols = ("loto", "probability")
        self.ai_tree = ttk.Treeview(
            tree_frame, columns=cols, show="headings", height=8
        )
        self.ai_tree.heading("loto", text="S·ªë")
        self.ai_tree.heading("probability", text="%")
        self.ai_tree.column("loto", width=40, anchor=tk.CENTER)
        self.ai_tree.column("probability", width=50, anchor=tk.E)
        scrollbar = ttk.Scrollbar(
            tree_frame, orient=tk.VERTICAL, command=self.ai_tree.yview
        )
        self.ai_tree.configure(yscrollcommand=scrollbar.set)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        self.ai_tree.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        self.ai_tree.tag_configure(
            "top1", background="#D5E8D4", font=("Arial", 9, "bold")
        )

    def _create_recent_form_ui(self, parent_frame):
        self.recent_form_frame = ttk.Labelframe(
            parent_frame, text="üî• Th√¥ng 10 K·ª≥ (>= 5/10)"
        )
        tree_frame = ttk.Frame(self.recent_form_frame)
        tree_frame.pack(fill=tk.BOTH, expand=True, padx=2, pady=2)

        cols = ("name", "wins", "prediction")
        self.recent_form_tree = ttk.Treeview(
            tree_frame, columns=cols, show="headings", height=8
        )

        self.recent_form_tree.heading("name", text="T√™n C·∫ßu")
        self.recent_form_tree.heading("wins", text="Th·∫Øng")
        self.recent_form_tree.heading("prediction", text="D·ª± ƒêo√°n")

        self.recent_form_tree.column("name", width=150, anchor=tk.W)
        self.recent_form_tree.column("wins", width=60, anchor=tk.CENTER)
        self.recent_form_tree.column("prediction", width=60, anchor=tk.CENTER)

        scrollbar = ttk.Scrollbar(
            tree_frame, orient=tk.VERTICAL, command=self.recent_form_tree.yview
        )
        self.recent_form_tree.configure(yscrollcommand=scrollbar.set)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        self.recent_form_tree.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)

        self.recent_form_tree.tag_configure(
            "excellent", background="#D5E8D4", font=("Arial", 9, "bold")
        )
        self.recent_form_tree.tag_configure("good", background="#FFF2CC")
        
        self.recent_form_tree.bind("<Double-1>", self.on_tree_double_click)

    def _create_hot_loto_ui(self, parent_frame):
        self.hot_loto_frame = ttk.Labelframe(
            parent_frame, text="üî• Hot (7 ng√†y)"
        )
        tree_frame = ttk.Frame(self.hot_loto_frame)
        tree_frame.pack(fill=tk.BOTH, expand=True, padx=2, pady=2)
        cols = ("loto", "hits")
        self.hot_loto_tree = ttk.Treeview(
            tree_frame, columns=cols, show="headings", height=8
        )
        self.hot_loto_tree.heading("loto", text="S·ªë")
        self.hot_loto_tree.heading("hits", text="Nh√°y")
        self.hot_loto_tree.column("loto", width=40, anchor=tk.CENTER)
        self.hot_loto_tree.column("hits", width=40, anchor=tk.CENTER)
        scrollbar = ttk.Scrollbar(
            tree_frame, orient=tk.VERTICAL, command=self.hot_loto_tree.yview
        )
        self.hot_loto_tree.configure(yscrollcommand=scrollbar.set)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        self.hot_loto_tree.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)

    def _create_vote_statistics_ui(self, parent_frame):
        """NEW: Vote Statistics table (replaces L√¥ Gan)"""
        self.vote_statistics_frame = ttk.Labelframe(
            parent_frame, text="üìä Vote (Top)"
        )
        tree_frame = ttk.Frame(self.vote_statistics_frame)
        tree_frame.pack(fill=tk.BOTH, expand=True, padx=2, pady=2)
        cols = ("pair", "votes")
        self.vote_tree = ttk.Treeview(
            tree_frame, columns=cols, show="headings", height=8
        )
        self.vote_tree.heading("pair", text="C·∫∑p")
        self.vote_tree.heading("votes", text="Vote")
        self.vote_tree.column("pair", width=50, anchor=tk.CENTER)
        self.vote_tree.column("votes", width=40, anchor=tk.CENTER)
        scrollbar = ttk.Scrollbar(
            tree_frame, orient=tk.VERTICAL, command=self.vote_tree.yview
        )
        self.vote_tree.configure(yscrollcommand=scrollbar.set)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        self.vote_tree.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        
        # Color coding
        self.vote_tree.tag_configure("high", background="#D5E8D4", font=("Arial", 9, "bold"))
        self.vote_tree.tag_configure("medium", background="#FFF2CC")

    def _create_pending_k2n_ui(self, parent_frame):
        self.pending_k2n_frame = ttk.Labelframe(
            parent_frame, text="‚è≥ C·∫ßu K2N ƒêang Ch·ªù (Ch·ªù N2)"
        )
        tree_frame = ttk.Frame(self.pending_k2n_frame)
        tree_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        cols = ("stl", "streak", "max_lose", "name")
        self.k2n_tree = ttk.Treeview(
            tree_frame, columns=cols, show="headings", height=10
        )
        self.k2n_tree.heading("stl", text="C·∫∑p s·ªë")
        self.k2n_tree.heading("streak", text="Chu·ªói")
        self.k2n_tree.heading("max_lose", text="G√£y Max")
        self.k2n_tree.heading("name", text="T√™n c·∫ßu")
        self.k2n_tree.column("stl", width=50, anchor=tk.CENTER)
        self.k2n_tree.column("streak", width=50, anchor=tk.CENTER)
        self.k2n_tree.column("max_lose", width=50, anchor=tk.CENTER)
        self.k2n_tree.column("name", width=200)
        scrollbar = ttk.Scrollbar(
            tree_frame, orient=tk.VERTICAL, command=self.k2n_tree.yview
        )
        self.k2n_tree.configure(yscrollcommand=scrollbar.set)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        self.k2n_tree.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        self.k2n_tree.tag_configure("risk", foreground="red")
        self.k2n_tree.tag_configure("safe", foreground="green")
        self.k2n_tree.bind("<Double-1>", self.on_tree_double_click)

    # --- H√ÄM N·∫†P D·ªÆ LI·ªÜU ---

    def _apply_filters(self, top_scores):
        """Enhancement 4: Apply smart filters to top scores"""
        if not top_scores:
            return top_scores
        
        # If filtering is not enabled, return all scores
        if not SETTINGS.FILTER_ENABLED:
            return top_scores
        
        filtered = []
        min_confidence = SETTINGS.FILTER_MIN_CONFIDENCE
        min_ai_prob = SETTINGS.FILTER_MIN_AI_PROB / 100.0  # Convert to 0-1 range
        
        for item in top_scores:
            # Check confidence filter (number of sources)
            sources = item.get("sources", 0)
            if min_confidence > 0 and sources < min_confidence:
                continue
            
            # Check AI probability filter
            ai_prob = item.get("ai_probability", 0.0)
            if min_ai_prob > 0 and ai_prob < min_ai_prob:
                continue
            
            filtered.append(item)
        
        return filtered

    def clear_data(self):
        self.title_label.config(text="ƒêang t·∫£i...")
        for tree in [
            self.scores_tree,
            self.hot_loto_tree,
            self.vote_tree,  # CHANGED: vote_tree instead of gan_tree
            self.k2n_tree,
            self.ai_tree,
            self.recent_form_tree,
        ]:
            try:
                for item in tree.get_children():
                    tree.delete(item)
            except Exception as e:
                print(f"L·ªói khi x√≥a tree {tree.winfo_name()}: {e}")

    def populate_data(
        self,
        next_ky,
        stats,
        n_days_stats,
        consensus,
        high_win,
        pending_k2n,
        gan_stats,
        top_scores,
        top_memory_bridges,
        ai_predictions,
    ):
        try:
            self.clear_data()

            today = datetime.datetime.now().strftime("%d/%m/%Y %H:%M")
            self.title_label.config(
                text=f"B·∫£ng Quy·∫øt ƒê·ªãnh T·ªëi ∆Øu - {next_ky} (C·∫≠p nh·∫≠t: {today})"
            )

            # Enhancement 4: Apply smart filters if enabled
            filtered_top_scores = self._apply_filters(top_scores)

            # N·∫°p B·∫£ng 1: Ch·∫•m ƒêi·ªÉm
            self._populate_top_scores(filtered_top_scores)

            # N·∫°p B·∫£ng 2: C·∫ßu K2N ƒêang Ch·ªù
            self._populate_pending_k2n(pending_k2n)

            # N·∫°p B·∫£ng 3: D·ª± ƒëo√°n AI
            self._populate_ai_predictions(ai_predictions)

            # N·∫°p B·∫£ng 4: Phong ƒê·ªô 10 K·ª≥
            try:
                # S·ª≠ d·ª•ng h√†m m·ªõi v·ªõi t√≠nh to√°n d·ª± ƒëo√°n t·ª± ƒë·ªông
                all_bridges = get_managed_bridges_with_prediction(
                    DB_NAME, 
                    current_data=self.app.all_data_ai if hasattr(self.app, 'all_data_ai') else None,
                    only_enabled=True
                )
                good_bridges = []
                for b in all_bridges:
                    # [CLEAN CODE FIX] Filter out DE bridges to avoid pollution in Loto table
                    bridge_type = str(b.get("type", "")).upper()
                    if bridge_type.startswith("DE"):
                        continue 

                    recent_wins = b.get("recent_win_count_10", 0)
                    if isinstance(recent_wins, str):
                        try:
                            recent_wins = int(recent_wins)
                        except ValueError:
                            recent_wins = 0
                    if recent_wins >= 5:
                        good_bridges.append(b)

                good_bridges.sort(key=lambda x: x.get("recent_win_count_10", 0), reverse=True)
                self._populate_recent_form(good_bridges)

            except Exception as e:
                print(f"L·ªói khi l·∫•y/l·ªçc c·∫ßu phong ƒë·ªô: {e}")

            # N·∫°p B·∫£ng 5: Loto V·ªÅ Nhi·ªÅu
            self.hot_loto_frame.config(text=f"üî• Hot ({n_days_stats} ng√†y)")
            self._populate_hot_loto(stats)

            # N·∫°p B·∫£ng 6: Vote Statistics
            self._populate_vote_statistics(consensus)

            # --- GEMINI FIX: HI·ªÇN TH·ªä TEXT BOX NGAY L·∫¨P T·ª®C ---
            # G·ªçi h√†m hi·ªÉn th·ªã text ngay khi c√≥ d·ªØ li·ªáu ƒë·∫ßu v√†o
            if hasattr(self, '_update_ui_scoring_results'):
                self._update_ui_scoring_results(top_scores, gan_stats)
            # --------------------------------------------------

        except Exception as e:
            messagebox.showerror(
                "L·ªói N·∫°p D·ªØ Li·ªáu Dashboard",
                f"L·ªói chi ti·∫øt: {e}\n{traceback.format_exc()}",
                parent=self,
            )

    # ===================================================================================
    # C√ÅC H√ÄM N·∫†P D·ªÆ LI·ªÜU CHI TI·∫æT
    # ===================================================================================

    def _populate_top_scores(self, top_scores):
        if not top_scores:
            self.scores_tree.insert(
                "", tk.END, values=("N/A", "", "", "", "N/A", "", "Kh√¥ng c√≥ c·∫∑p n√†o")
            )
            return
        for i, item in enumerate(top_scores[:40]):
            tags = ()
            if item["is_gan"]:
                tags += ("gan",)
            if i == 0:
                tags += ("top1",)
            elif i < 3:
                tags += ("top3",)
            
            # IMPROVED: Show gan loto with days (e.g., "38(8N)")
            gan_text = ""
            if item["is_gan"]:
                gan_loto = item.get("gan_loto", "")
                if gan_loto:
                    gan_text = f"{gan_loto}({item['gan_days']}N)"
                else:
                    gan_text = f"{item['gan_days']}N"
            
            # NEW: Format AI column with icon and percentage
            ai_prob = item.get("ai_probability", 0.0)
            ai_text = ""
            if ai_prob > 0:
                ai_text = f"ü§ñ{int(ai_prob * 100)}"
                # Add AI color tag based on probability
                if ai_prob >= 0.70:
                    tags += ("ai_very_high",)
                elif ai_prob >= 0.50:
                    tags += ("ai_high",)
                elif ai_prob >= 0.30:
                    tags += ("ai_med",)
                else:
                    tags += ("ai_low",)
            
            # NEW: Enhancement 3 - Confidence stars (‚≠ê)
            # IMPROVED: Compact display - show number instead of repeated stars
            sources = item.get("sources", 0)
            confidence_text = f"{sources}‚≠ê" if sources > 0 else ""
            
            # NEW: Enhancement 3 - Recommendation text and color
            recommendation = item.get("recommendation", "B·ªé QUA")
            if recommendation == "CH∆†I":
                tags += ("rec_choi",)
            elif recommendation == "XEM X√âT":
                tags += ("rec_xem_xet",)
            else:
                tags += ("rec_bo_qua",)
            
            self.scores_tree.insert(
                "",
                tk.END,
                values=(
                    item["score"],
                    ai_text,
                    confidence_text,
                    recommendation,
                    item["pair"],
                    gan_text,
                    item["reasons"],
                ),
                tags=tags,
            )

    def _populate_pending_k2n(self, pending_k2n):
        if not pending_k2n:
            self.k2n_tree.insert(
                "", tk.END, values=("(N/A)", "", "", "Kh√¥ng c√≥ c·∫ßu K2N n√†o ch·ªù")
            )
            return
        try:
            # L·ªçc: Ch·ªâ l·∫•y c·∫ßu ƒëang th·ª±c s·ª± ch·ªù N2 (is_n2 = True)
            filtered_items = [
                (name, data) for name, data in pending_k2n.items()
                if data.get("is_n2", True)
            ]

            sorted_k2n = sorted(
                filtered_items,
                key=lambda item: (
                    int(str(item[1]["streak"]).split(" ")[0]),
                    -int(item[1].get("max_lose", 99)),
                ),
                reverse=True,
            )
        except Exception:
            sorted_k2n = list(pending_k2n.items())
            
        risk_threshold = SETTINGS.K2N_RISK_START_THRESHOLD
        
        if not sorted_k2n:
             self.k2n_tree.insert(
                "", tk.END, values=("Kh√¥ng c√≥ c·∫ßu N2", "", "", "")
            )
             
        for bridge_name, data in sorted_k2n:
            stl, streak, max_lose = data["stl"], data["streak"], data.get("max_lose", 0)
            tags = ()
            if max_lose > risk_threshold:
                tags = ("risk",)
            elif max_lose < risk_threshold:
                tags = ("safe",)
            self.k2n_tree.insert(
                "",
                tk.END,
                values=(stl, streak, f"{max_lose} l·∫ßn", bridge_name),
                tags=tags,
            )

    def _populate_ai_predictions(self, ai_predictions):
        if not ai_predictions:
            self.ai_tree.insert("", tk.END, values=("(N/A)", "Vui l√≤ng Hu·∫•n luy·ªán AI"))
            return
        for i, pred in enumerate(ai_predictions[:20]):
            loto = pred["loto"]
            prob = pred["probability"]
            tags = ()
            if i == 0:
                tags = ("top1",)
            elif i < 5:
                tags = ("top5",)
            self.ai_tree.insert("", tk.END, values=(loto, f"{prob:.2f}%"), tags=tags)

    def _populate_recent_form(self, bridges):
        if not bridges:
            self.recent_form_tree.insert(
                "", tk.END, values=("Kh√¥ng c√≥ c·∫ßu n√†o >= 5/10", "", "")
            )
            return

        for b in bridges:
            wins = b.get("recent_win_count_10", 0)
            pred = b.get("prediction") or b.get("next_prediction_stl", "N/A")
            
            tags = ()
            if wins >= 8:
                tags = ("excellent",)
            elif wins >= 6:
                tags = ("good",)
                
            self.recent_form_tree.insert(
                "",
                tk.END,
                values=(
                    b["name"],
                    f"{wins}/10",
                    pred
                ),
                tags=tags
            )

    def _populate_hot_loto(self, stats):
        if not stats:
            self.hot_loto_tree.insert("", tk.END, values=("(N/A)", ""))
            return
        for loto, hits, days in stats:
            self.hot_loto_tree.insert("", tk.END, values=(loto, hits))

    def _populate_vote_statistics(self, consensus):
        """NEW: Populate vote statistics (replaces gan loto)"""
        if not consensus:
            self.vote_tree.insert("", tk.END, values=("(N/A)", ""))
            return
        # consensus is a list of tuples: (pair_key, count, sources_str)
        for pair_key, count, _ in consensus[:20]:  # Show top 20
            tags = ()
            if count >= 10:
                tags = ("high",)
            elif count >= 5:
                tags = ("medium",)
            self.vote_tree.insert("", tk.END, values=(pair_key, f"x{count}"), tags=tags)

    # ===================================================================================
    # H√ÄM T∆Ø∆†NG T√ÅC
    # ===================================================================================

    def _refresh_data_old(self):
        self.app.logger.log(
            "\n--- (L√†m M·ªõi) B·∫Øt ƒë·∫ßu ch·∫°y l·∫°i B·∫£ng Quy·∫øt ƒê·ªãnh T·ªëi ∆Øu ---"
        )
        self.app.run_decision_dashboard()

    def on_tree_double_click(self, event):
        try:
            item_id = event.widget.focus()
            if not item_id:
                return
            item = event.widget.item(item_id)
            values = item["values"]
            bridge_name = ""

            # 1. Click v√†o C·∫ßu K2N
            if event.widget == self.k2n_tree:
                bridge_name = values[3]
                if bridge_name:
                    self.app.trigger_bridge_backtest(bridge_name)

            # 2. Click v√†o Phong ƒê·ªô C·∫ßu
            elif event.widget == self.recent_form_tree:
                bridge_name = values[0]
                if bridge_name:
                    self.app.trigger_bridge_backtest(bridge_name)

            # 3. (M·ªöI) Click v√†o B·∫£ng ƒêi·ªÉm -> Hi·ªÉn th·ªã Popup Chi ti·∫øt L√Ω do
            elif event.widget == self.scores_tree:
                # values = (Score, AI, Confidence, Recommendation, Pair, Gan, Reasons)
                # After V7.7: Added AI (index 1) and Confidence (index 2) columns
                score = values[0]
                ai_text = values[1]  # Already formatted as "ü§ñ75" or empty
                confidence = values[2]
                recommendation = values[3]
                pair = values[4]
                gan_text = values[5]
                reasons_raw = values[6]

                # Format l·∫°i l√Ω do: Xu·ªëng d√≤ng m·ªói khi g·∫∑p d·∫•u ph·∫©y
                reasons_formatted = reasons_raw.replace(", ", "\n- ")
                
                # Format AI display - ai_text is already formatted with emoji and percentage
                ai_display = f"{ai_text}%" if ai_text else "N/A"
                
                info_text = (
                    f"C·∫∑p s·ªë: {pair}\n"
                    f"T·ªïng ƒëi·ªÉm: {score}\n"
                    f"AI: {ai_display}\n"
                    f"‚≠ê Confidence: {confidence}\n"
                    f"Khuy·∫øn ngh·ªã: {recommendation}\n"
                    f"T√¨nh tr·∫°ng Gan: {gan_text if gan_text else 'Kh√¥ng gan'}\n\n"
                    f"=== CHI TI·∫æT L√ù DO ===\n"
                    f"- {reasons_formatted}"
                )
                
                messagebox.showinfo("Chi Ti·∫øt ƒê√°nh Gi√°", info_text, parent=self)

        except Exception as e:
            print(f"L·ªói double-click: {e}")
    
    # [TH√äM M·ªöI HO·∫∂C THAY TH·∫æ] H√†m x·ª≠ l√Ω n√∫t Ph√¢n T√≠ch
    # L∆∞u √Ω: B·∫°n c·∫ßn t·∫°o m·ªôt n√∫t "Ph√¢n T√≠ch L√¥ Scoring" ri√™ng ho·∫∑c t√≠ch h·ª£p v√†o n√∫t "L√†m M·ªõi D·ªØ Li·ªáu"
    # N·∫øu t√≠ch h·ª£p v√†o n√∫t Refresh:
    def refresh_data(self):
        self.app.logger.log("\n--- (L√†m M·ªõi) B·∫Øt ƒë·∫ßu ch·∫°y l·∫°i B·∫£ng Quy·∫øt ƒê·ªãnh T·ªëi ∆Øu ---")
        
        # 1. K√≠ch ho·∫°t lu·ªìng n·∫°p d·ªØ li·ªáu c≈© (Ch·∫°y ng·∫ßm)
        self.app.run_decision_dashboard()
        
        # 2. [FIX] Thay v√¨ ch·∫°y ngay, ta chuy·ªÉn sang ch·∫ø ƒë·ªô "Ch·ªù d·ªØ li·ªáu"
        self.title_label.config(text="‚è≥ ƒêang ƒë·ªìng b·ªô d·ªØ li·ªáu...")
        
        # X√≥a log c≈© ƒë·ªÉ ng∆∞·ªùi d√πng bi·∫øt ƒëang x·ª≠ l√Ω
        if hasattr(self, 'txt_result_log'):
            self.txt_result_log.delete("1.0", tk.END)
            self.txt_result_log.insert("1.0", "‚è≥ ƒêang ƒë·ª£i d·ªØ li·ªáu n·∫°p t·ª´ Database...")
            
        # B·∫Øt ƒë·∫ßu ch·ªù (Check m·ªói 500ms)
        self._wait_for_data_and_run_scoring()

    # [TH√äM H√ÄM M·ªöI N√ÄY V√ÄO D∆Ø·ªöI refresh_data]
    def _wait_for_data_and_run_scoring(self, attempt=0):
        """
        C∆° ch·∫ø 'Polling': Ki·ªÉm tra li√™n t·ª•c xem d·ªØ li·ªáu ƒë√£ v·ªÅ ch∆∞a.
        Timeout: 10 gi√¢y (20 l·∫ßn x 500ms).
        """
        # Ki·ªÉm tra: App ƒë√£ c√≥ d·ªØ li·ªáu ch∆∞a?
        if hasattr(self.app, 'all_data_ai') and self.app.all_data_ai:
            # ‚úÖ D·ªØ li·ªáu ƒë√£ v·ªÅ -> K√≠ch ho·∫°t Scoring Engine ngay!
            self.run_lo_scoring_analysis()
        else:
            # ‚ùå Ch∆∞a c√≥ d·ªØ li·ªáu
            if attempt < 60: # [ƒê√É S·ª¨A] TƒÉng l√™n 30 gi√¢y (60 * 0.5s) ƒë·ªÉ ch·ªù n·∫°p DB l·ªõn
                # ƒê·ª£i 0.5 gi√¢y r·ªìi ki·ªÉm tra l·∫°i (ƒë·ªá quy)
                self.after(500, lambda: self._wait_for_data_and_run_scoring(attempt + 1))
            else:
                # Qu√° h·∫°n 10 gi√¢y m√† v·∫´n ch∆∞a c√≥ d·ªØ li·ªáu -> B√°o l·ªói th·∫≠t
                self.title_label.config(text="‚ö†Ô∏è L·ªói n·∫°p d·ªØ li·ªáu")
                if hasattr(self, 'txt_result_log'):
                    self.txt_result_log.delete("1.0", tk.END)
                    self.txt_result_log.insert("1.0", "‚ö†Ô∏è Qu√° th·ªùi gian ch·ªù (Timeout). D·ªØ li·ªáu ch∆∞a ƒë∆∞·ª£c n·∫°p.\nüëâ Vui l√≤ng ki·ªÉm tra l·∫°i File d·ªØ li·ªáu g·ªëc ho·∫∑c Database.")

    def run_lo_scoring_analysis(self):
        """Ch·∫°y Scoring Engine L√¥ V3.8 (GEMINI FIX 2 - Correct Data Path)"""

        
        # --- 1. T√åM D·ªÆ LI·ªÜU (QUAN TR·ªåNG: Qu√©t c·∫£ App v√† Controller) ---
        all_data = None
        
        # C√°ch 1: T√¨m trong App (C≈©)
        if hasattr(self.app, 'all_data_ai') and self.app.all_data_ai:
            all_data = self.app.all_data_ai
            
        # C√°ch 2: T√¨m trong Controller (Chu·∫©n MVC)
        if not all_data and hasattr(self.app, 'controller'):
            if hasattr(self.app.controller, 'all_data_ai') and self.app.controller.all_data_ai:
                all_data = self.app.controller.all_data_ai
            
        # N·∫øu qu√©t c·∫£ 2 n∆°i v·∫´n kh√¥ng th·∫•y -> B√°o l·ªói cho ng∆∞·ªùi d√πng bi·∫øt
        if not all_data:
            if hasattr(self, 'txt_result_log'):
                self.txt_result_log.delete("1.0", tk.END)
                self.txt_result_log.insert("1.0", "‚ö†Ô∏è KH√îNG T√åM TH·∫§Y D·ªÆ LI·ªÜU.\nüëâ Vui l√≤ng b·∫•m n√∫t 'L√†m M·ªõi D·ªØ Li·ªáu' (G√≥c tr√™n ph·∫£i) ƒë·ªÉ n·∫°p l·∫°i t·ª´ Database.")
                self.txt_result_log.update_idletasks()
            return



        # --- 2. C·∫¨P NH·∫¨T GIAO DI·ªÜN ---
        if hasattr(self, 'txt_result_log'):
            self.txt_result_log.delete("1.0", tk.END)
            msg = f"‚è≥ ƒêang ph√¢n t√≠ch {len(all_data)} k·ª≥ d·ªØ li·ªáu (Scoring V3.8)...\n"
            self.txt_result_log.insert("1.0", msg)
            self.txt_result_log.update_idletasks()

        self.title_label.config(text="ƒêang ch·∫°y Scoring L√¥...")
        
        # --- 3. LU·ªíNG X·ª¨ L√ù (THREAD) ---
        def run_thread():
            try:
                # L·∫•y ng√†y m·ªõi nh·∫•t
                day_index = len(all_data) - 1
                
                # G·ªåI TR·ª∞C TI·∫æP LOGIC (B·ªè qua Service ƒë·ªÉ tr√°nh l·ªói)
                features = dashboard_scorer.prepare_daily_features(all_data, day_index)
                
                if not features:
                    self.after(0, lambda: self.txt_result_log.insert(tk.END, "\n‚ùå L·ªói: Kh√¥ng t·∫°o ƒë∆∞·ª£c features (D·ªØ li·ªáu qu√° ng·∫Øn?)."))
                    return



                scores = dashboard_scorer.get_top_scored_pairs(
                    features["stats_n_day"],
                    features["consensus"],
                    features["high_win"],
                    features["pending_k2n"],
                    features["gan_stats"],
                    features["top_memory"],
                    features.get("ai_predictions"),
                    features.get("recent_data")
                )
                
                gan_stats = features["gan_stats"]
                
                # Update UI (Chuy·ªÉn v·ªÅ lu·ªìng ch√≠nh)
                self.after(0, lambda: self._update_ui_scoring_results(scores, gan_stats))
                
            except Exception as e:
                print(f"L·ªói Scoring Thread: {e}")
                import traceback
                traceback.print_exc()
                self.after(0, lambda: self.txt_result_log.insert(tk.END, f"\n‚ùå Exception: {str(e)}"))



        import threading
        threading.Thread(target=run_thread, daemon=True).start()

    def _update_ui_scoring_results(self, scores, gan_stats):
        """Hi·ªÉn th·ªã k·∫øt qu·∫£ v√†o Text Box (ƒê√£ s·ª≠a l·ªói Tuple vs Dict)"""
        if not hasattr(self, 'txt_result_log'): return



        self.txt_result_log.delete("1.0", tk.END)
        
        # 1. Hi·ªÉn th·ªã Top 10
        if scores:
            msg = "üèÜ TOP 10 L√î ƒêI·ªÇM CAO (SCORING V3.8):\n"
            # scores l√† list of dicts -> d√πng key access OK
            top_10 = scores[:10]
            
            # Format: "S·ªë (ƒêi·ªÉm)"
            row1_items = []
            for item in top_10[:5]:
                pair = item.get('pair', '??')
                score = item.get('score', 0)
                row1_items.append(f"{pair} ({score:.1f}ƒë)")
                
            row2_items = []
            for item in top_10[5:]:
                pair = item.get('pair', '??')
                score = item.get('score', 0)
                row2_items.append(f"{pair} ({score:.1f}ƒë)")
            
            msg += "   " + " | ".join(row1_items) + "\n"
            msg += "   " + " | ".join(row2_items) + "\n"
            
            self.txt_result_log.insert(tk.END, msg)
            
            # T√¥ m√†u ti√™u ƒë·ªÅ
            self.txt_result_log.tag_add("title", "1.0", "2.0")
            self.txt_result_log.tag_config("title", foreground="blue", font=("Arial", 10, "bold"))
        else:
            self.txt_result_log.insert(tk.END, "‚ö†Ô∏è Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ t√≠nh ƒëi·ªÉm.\n")



        # 2. C·∫£nh b√°o L√¥ Gan (FIX QUAN TR·ªåNG T·∫†I ƒê√ÇY)
        if gan_stats:
            # gan_stats l√† list of tuples: [('99', 20), ('00', 5)]
            # item[0] l√† s·ªë, item[1] l√† s·ªë ng√†y gan
            dangerous_gan = [item for item in gan_stats if item[1] > 15]
            
            if dangerous_gan:
                gan_msg = "\n‚õî C·∫¢NH B√ÅO L√î GAN (>15 ng√†y - N√äN TR√ÅNH):\n"
                # S·ª≠a item.get(...) th√†nh item[index] v√¨ item l√† Tuple
                gan_nums = [f"{item[0]} ({item[1]}d)" for item in dangerous_gan]
                gan_msg += "   " + ", ".join(gan_nums)
                
                # Ch√®n v√†o cu·ªëi
                self.txt_result_log.insert(tk.END, gan_msg)
                
                # T√¥ m√†u ƒë·ªè c·∫£nh b√°o
                idx = self.txt_result_log.search("‚õî", "1.0", tk.END)
                if idx:
                    self.txt_result_log.tag_add("warning", idx, tk.END)
                    self.txt_result_log.tag_config("warning", foreground="red", font=("Arial", 10, "bold"))

--------------------------------------------------

=== FILE: ui\ui_de_dashboard.py ===
# T√™n file: code6/ui/ui_de_dashboard.py
# (PHI√äN B·∫¢N V3.9.20 - FIX: HI·ªÇN TH·ªä ƒê·ª¶ 15 B·ªò S·ªê K·ªÇ C·∫¢ KHI KH√îNG V·ªÄ)

import tkinter as tk
from tkinter import ttk, messagebox, font
import threading
from datetime import datetime, timedelta

# --- 1. IMPORT UTILS ---
try:
    from logic.de_utils import get_gdb_last_2, BO_SO_DE
except ImportError as e:
    print(f"[UI ERROR] Utils Import Failed: {e}")
    def get_gdb_last_2(r): return "00"
    BO_SO_DE = {}

# --- 2. IMPORT ANALYTICS ---
try:
    from logic.de_analytics import (
        analyze_market_trends,
        calculate_number_scores,
        run_intersection_matrix_analysis,
        calculate_top_touch_combinations
    )
    HAS_ANALYTICS = True
except ImportError as e:
    print(f"[UI ERROR] Analytics Import Failed: {e}")
    HAS_ANALYTICS = False
    def analyze_market_trends(*a, **k): return {}
    def calculate_number_scores(*a, **k): return []
    def run_intersection_matrix_analysis(*a): return {"ranked": [], "message": str(e)}
    def calculate_top_touch_combinations(*a, **k): return []

# --- 3. IMPORT SCANNER (Legacy - not used in PR1) ---
try:
    from logic.bridges.de_bridge_scanner import run_de_scanner
    HAS_SCANNER = True
except ImportError as e:
    print(f"[UI ERROR] Scanner Import Failed: {e}")
    HAS_SCANNER = False
    def run_de_scanner(d): return 0, []

# --- 4. IMPORT DB LOADER (PR1: Load bridges from DB instead of scanning) ---
try:
    from logic.dashboard_analytics import get_cau_dong_for_tab_soi_cau_de
    HAS_DB_LOADER = True
except ImportError as e:
    print(f"[UI ERROR] DB Loader Import Failed: {e}")
    HAS_DB_LOADER = False
    def get_cau_dong_for_tab_soi_cau_de(*a, **k): return []

class UiDeDashboard(ttk.Frame):
    def __init__(self, parent, controller):
        super().__init__(parent)
        self.controller = controller
        # Define fonts
        self.font_vip = font.Font(family="Helvetica", size=14, weight="bold")
        self.font_label = font.Font(family="Helvetica", size=10, weight="bold")
        self.font_header = font.Font(family="Arial", size=11, weight="bold")
        self.font_normal = font.Font(family="Consolas", size=10)
        self._init_ui()

    def _init_ui(self):
        # TOOLBAR
        toolbar = ttk.Frame(self, padding=5)
        toolbar.pack(fill=tk.X)
        
        btn_scan = ttk.Button(toolbar, text="üöÄ QU√âT & PH√ÇN T√çCH (V3.9.20)", command=self.on_scan_click)
        btn_scan.pack(side=tk.LEFT, padx=5)
        
        self.lbl_status = ttk.Label(toolbar, text="S·∫µn s√†ng", foreground="blue")
        self.lbl_status.pack(side=tk.LEFT, padx=10)

        # MAIN LAYOUT
        paned = ttk.PanedWindow(self, orient=tk.HORIZONTAL)
        paned.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # --- COL 1: STATS ---
        f_stats = ttk.LabelFrame(paned, text="üìä Th·ªëng K√™ (30 ng√†y)")
        paned.add(f_stats, weight=1)
        
        self.nb_stats = ttk.Notebook(f_stats)
        self.nb_stats.pack(fill=tk.BOTH, expand=True)
        
        self.tree_hist = self._create_tab_tree(self.nb_stats, "L·ªãch S·ª≠", ["Ng√†y", "ƒê·ªÅ"])
        self.tree_cham = self._create_tab_tree(self.nb_stats, "Ch·∫°m", ["Ch·∫°m", "V·ªÅ", "Gan"])
        self.tree_bo = self._create_tab_tree(self.nb_stats, "B·ªô", ["B·ªô", "V·ªÅ", "Gan"])
        
        # --- COL 2: BRIDGES ---
        f_scan = ttk.LabelFrame(paned, text="üéØ C·∫ßu ƒê·ªông")
        paned.add(f_scan, weight=2)
        self.tree_br = self._create_tree(f_scan, ["T√™n", "Lo·∫°i", "Th√¥ng", "S·ªë"], height=15)
        # [TH√äM M·ªöI] G·∫Øn s·ª± ki·ªán Double Click v√†o b·∫£ng c·∫ßu ƒë·ªÉ g·ªçi Backtest
        self.tree_br.bind("<Double-1>", self.on_bridge_dbl_click)
       
        # --- COL 3: MATRIX & FORECAST ---
        f_res = ttk.LabelFrame(paned, text="üîÆ Ma Tr·∫≠n & Ch·ªët S·ªë")
        paned.add(f_res, weight=2)
        
        nb_res = ttk.Notebook(f_res)
        nb_res.pack(fill=tk.BOTH, expand=True)
        
        # TAB 1: CH·ªêT S·ªê VIP
        t_fc = ttk.Frame(nb_res)
        nb_res.add(t_fc, text="CH·ªêT S·ªê VIP")
        
        # [UI] Canvas & Scrollbar setup
        self.canvas = tk.Canvas(t_fc, highlightthickness=0)
        self.scrollbar = ttk.Scrollbar(t_fc, orient="vertical", command=self.canvas.yview)
        self.scroll_frame = ttk.Frame(self.canvas)
        
        self.canvas.configure(yscrollcommand=self.scrollbar.set)
        self.canvas.pack(side="left", fill="both", expand=True)
        self.scrollbar.pack(side="right", fill="y")
        
        self.canvas_window = self.canvas.create_window((0, 0), window=self.scroll_frame, anchor="nw")
        
        # Bind events
        self.scroll_frame.bind("<Configure>", self._on_frame_configure)
        self.canvas.bind("<Configure>", self._on_canvas_configure)

        # [HEADER]
        fr_header = ttk.Frame(self.scroll_frame, padding=5)
        fr_header.pack(fill="x", pady=5)
        self.lbl_ky_pred = ttk.Label(fr_header, text="K·ª≤: ---", font=self.font_header, foreground="#E65100")
        self.lbl_ky_pred.pack(side="left", padx=(0, 10))
        self.lbl_date_pred = ttk.Label(fr_header, text="NG√ÄY: ---", font=self.font_header, foreground="#2E7D32")
        self.lbl_date_pred.pack(side="left")

        # === KHU V·ª∞C 1: K·∫æT QU·∫¢ TR·ªåNG T√ÇM ===
        fr_vip = ttk.LabelFrame(self.scroll_frame, text="üî•üî• K·∫æT QU·∫¢ TR·ªåNG T√ÇM", padding=5)
        fr_vip.pack(fill="x", padx=5, pady=5)
        
        ttk.Label(fr_vip, text="T·ª® TH·ª¶ ƒê·ªÄ:", font=self.font_label, foreground="#D32F2F").pack(anchor="center")
        self.txt_4 = tk.Text(fr_vip, height=1, width=20, font=self.font_vip, bd=0, bg="#f0f0f0", fg="#D32F2F")
        self.txt_4.tag_configure("center", justify='center')
        self.txt_4.pack(fill="x", pady=(0, 5))
        
        ttk.Label(fr_vip, text="TOP 10 MA TR·∫¨N:", font=self.font_label, foreground="#1976D2").pack(anchor="center")
        self.txt_10 = tk.Text(fr_vip, height=1, width=30, font=("Helvetica", 11, "bold"), bd=0, bg="#f0f0f0", fg="#1976D2")
        self.txt_10.tag_configure("center", justify='center')
        self.txt_10.pack(fill="x", pady=(0, 5))

        # === KHU V·ª∞C 2: C·∫¶U & B·ªò ===
        fr_cau = ttk.LabelFrame(self.scroll_frame, text="‚ö° B·ªò S·ªê & C·∫¶U CH·∫†M", padding=5)
        fr_cau.pack(fill="x", padx=5, pady=5)
        
        self.txt_bo_top = self._create_info_row(fr_cau, "B·ªô S·ªë Ti·ªÅm NƒÉng:", height=2)
        
        self.txt_4c_thong = self._create_info_row(fr_cau, "4 Ch·∫°m (Th√¥ng):")
        self.txt_4c_tile = self._create_info_row(fr_cau, "4 Ch·∫°m (T·ªâ L·ªá):")

        # === KHU V·ª∞C 3: D√ÄN S·ªê ===
        fr_dan = ttk.LabelFrame(self.scroll_frame, text="üìã D√ÄN S·ªê & L·ªåC", padding=5)
        fr_dan.pack(fill="x", padx=5, pady=5)
        
        ttk.Label(fr_dan, text="D√†n 65 (TƒÉng d·∫ßn):", font=("Arial", 9, "bold")).pack(anchor="w")
        self.txt_65 = tk.Text(fr_dan, height=6, width=30, font=("Consolas", 9), wrap="word", bd=1, relief="solid")
        self.txt_65.pack(fill="x", pady=2)

        # TAB 2: CHI TI·∫æT S·ªê
        t_mx = ttk.Frame(nb_res)
        nb_res.add(t_mx, text="ƒêI·ªÇM S·ªê")
        self.tree_mx = self._create_tree(t_mx, ["H·∫°ng", "S·ªë", "ƒêi·ªÉm", "Note"])
        self.tree_mx.tag_configure("S", background="#FFCDD2") 
        self.tree_mx.tag_configure("A", background="#C8E6C9")

        # TAB 3: ƒê√ÅNH GI√Å CH·∫†M (SEPARATED)
        t_eval_cham = ttk.Frame(nb_res)
        nb_res.add(t_eval_cham, text="üéØ ƒê√ÅNH GI√Å CH·∫†M")
        
        self.tree_eval_cham = self._create_tree(t_eval_cham, ["Ch·∫°m", "V·ªÅ (30N)", "Gan", "ƒêi·ªÉm ƒêG"])
        self.tree_eval_cham.column("Ch·∫°m", width=80)
        self.tree_eval_cham.column("ƒêi·ªÉm ƒêG", width=70)
        self.tree_eval_cham.tag_configure("HOT", background="#FFF9C4", foreground="red")
        
        # TAB 4: ƒê√ÅNH GI√Å B·ªò (SEPARATED)
        t_eval_bo = ttk.Frame(nb_res)
        nb_res.add(t_eval_bo, text="üîµ ƒê√ÅNH GI√Å B·ªò")
        
        self.tree_eval_bo = self._create_tree(t_eval_bo, ["B·ªô", "V·ªÅ (30N)", "Gan", "ƒêi·ªÉm ƒêG"])
        self.tree_eval_bo.column("B·ªô", width=80)
        self.tree_eval_bo.column("ƒêi·ªÉm ƒêG", width=70)
        self.tree_eval_bo.tag_configure("HOT", background="#FFF9C4", foreground="red")
        self.tree_eval_bo.tag_configure("KEP", background="#E1F5FE", font=("Arial", 9, "bold")) 

    def update_data(self, *args):
        try:
            if self.winfo_exists():
                self.on_scan_click()
        except Exception as e:
            print(f"[UiDeDashboard] Update Data Error: {e}")

    # --- UI HELPERS ---
    def _on_frame_configure(self, event):
        self.canvas.configure(scrollregion=self.canvas.bbox("all"))

    def _on_canvas_configure(self, event):
        self.canvas.itemconfig(self.canvas_window, width=event.width)

    def _create_info_row(self, parent, label_text, height=1):
        container = ttk.Frame(parent)
        container.pack(fill="x", pady=2)
        ttk.Label(container, text=label_text, font=("Arial", 9, "bold"), width=15, anchor="w").pack(side="left")
        txt = tk.Text(container, height=height, font=("Consolas", 9), wrap="word", bd=1, relief="solid")
        txt.pack(side="left", fill="x", expand=True)
        return txt

    def _create_tree(self, parent, cols, height=None):
        tree = ttk.Treeview(parent, columns=cols, show="headings", height=height if height else 8)
        for c in cols:
            tree.heading(c, text=c)
            tree.column(c, width=50, anchor="center")
        sb = ttk.Scrollbar(parent, orient="vertical", command=tree.yview)
        tree.configure(yscrollcommand=sb.set)
        sb.pack(side="right", fill="y")
        tree.pack(side="left", fill="both", expand=True)
        return tree

    def _create_tab_tree(self, notebook, title, cols):
        f = ttk.Frame(notebook)
        notebook.add(f, text=title)
        return self._create_tree(f, cols)

    def _update_txt(self, widget, text, tag=None):
        widget.config(state='normal')
        widget.delete("1.0", tk.END)
        widget.insert("1.0", text)
        if tag: widget.tag_add(tag, "1.0", "end")
        widget.config(state='disabled')

    def on_scan_click(self):
        data = getattr(self.controller, 'all_data_ai', [])
        if not data: data = getattr(self.controller, 'df', None)
        if not data or len(data) == 0:
            print("[UiDeDashboard] No data available for scan.")
            return 
        self.lbl_status.config(text="ƒêang ph√¢n t√≠ch...", foreground="orange")
        threading.Thread(target=self._run_logic, args=(data,), daemon=True).start()

    def _run_logic(self, data):
        list_data = data
        if hasattr(data, "values"): list_data = data.values.tolist()
        
        # PR1: Load bridges from DB (Managed Bridges) instead of scanning
        bridges = []
        if HAS_DB_LOADER:
            try:
                # L·∫•y t·∫•t c·∫£ c·∫ßu (c√≥ th·ªÉ l·∫´n c·∫£ L√¥)
                all_bridges = get_cau_dong_for_tab_soi_cau_de()
                
                # [FIX] L·ªåC CH·ªà L·∫§Y C·∫¶U ƒê·ªÄ (DE)
                # Lo·∫°i b·ªè c√°c c·∫ßu b·∫Øt ƒë·∫ßu b·∫±ng LO_ ho·∫∑c kh√¥ng ph·∫£i lo·∫°i ƒê·ªÅ
                bridges = [
                    b for b in all_bridges 
                    if str(b.get('type', '')).upper().startswith(('DE_', 'CAU_DE')) 
                    or "ƒê·ªÅ" in str(b.get('name', ''))
                    or "DE" in str(b.get('name', '')).upper()
                ]
                
                print(f"[UI] Loaded {len(bridges)} DE bridges from DB (Filtered from {len(all_bridges)})")
            except Exception as e:
                print(f"[UI ERROR] Failed to load bridges from DB: {e}")
                # Fallback to scanner if DB load fails
                if HAS_SCANNER:
                    try: _, bridges = run_de_scanner(list_data)
                    except: pass
        elif HAS_SCANNER:
            # Legacy fallback: use scanner
            try: _, bridges = run_de_scanner(list_data)
            except: pass
        
        matrix_res = {"ranked": [], "message": "N/A"}
        if HAS_ANALYTICS:
            try: matrix_res = run_intersection_matrix_analysis(data)
            except Exception as e: matrix_res["message"] = str(e)
                
        stats, scores, touch_combinations = {}, [], []
        if HAS_ANALYTICS:
            try:
                stats = analyze_market_trends(list_data, n_days=30)
                scores = calculate_number_scores(bridges, stats)
                touch_combinations = calculate_top_touch_combinations(list_data, num_touches=4, days=30)
            except: pass

        self.after(0, lambda: self._update_ui(list_data, bridges, matrix_res, scores, stats, touch_combinations))

    def _update_ui(self, data, bridges, matrix_res, scores, stats, touch_combinations):
        self.lbl_status.config(text="Ho√†n t·∫•t.", foreground="green")
        
        # 1. Update Header
        next_ky_str, next_date_str = "---", "---"
        try:
            if data and len(data) > 0:
                last_row = data[-1]
                try: next_ky_str = f"#{int(last_row[0]) + 1}"
                except: pass
                # Date
                for fmt in ["%d/%m/%Y", "%Y-%m-%d", "%d-%m-%Y"]:
                    try:
                        dt = datetime.strptime(str(last_row[1]), fmt)
                        next_date_str = (dt + timedelta(days=1)).strftime("%d/%m/%Y")
                        break
                    except ValueError: continue
        except: pass
        self.lbl_ky_pred.config(text=f"K·ª≤: {next_ky_str}")
        self.lbl_date_pred.config(text=f"NG√ÄY: {next_date_str}")
        
        # 2. Update Stats (Left Tabs)
        for i in self.tree_hist.get_children(): self.tree_hist.delete(i)
        for r in reversed(data[-30:]):
            val = get_gdb_last_2(r) if isinstance(r, (list, tuple)) else str(r)
            self.tree_hist.insert("", "end", values=(r[0], val))
            
        freq_cham = stats.get('freq_cham', {})
        gan_cham = stats.get('gan_cham', {})
        freq_bo = stats.get('freq_bo', {})
        gan_bo = stats.get('gan_bo', {})

        self._fill_stat_tree(self.tree_cham, freq_cham, gan_cham)
        
        # [FIX V3.9.20] Hi·ªÉn th·ªã ƒë·ªß 15 B·ªô k·ªÉ c·∫£ khi kh√¥ng v·ªÅ
        self._fill_stat_tree_full_bo(self.tree_bo, freq_bo, gan_bo)

        # 3. Update Bridges
        for i in self.tree_br.get_children(): self.tree_br.delete(i)
        if bridges:
            bridges.sort(key=lambda x: x.get('streak',0), reverse=True)
            for b in bridges[:300]:
                self.tree_br.insert("", "end", values=(b.get('name'), b.get('type'), b.get('streak'), b.get('predicted_value')))
        
        # 4. Update Matrix (Scores Tab)
        for i in self.tree_mx.get_children(): self.tree_mx.delete(i)
        ranked = matrix_res.get('ranked', [])
        if ranked:
            for item in ranked[:30]:
                self.tree_mx.insert("", "end", values=(item['rank'], item['so'], item['diem'], item['note']), tags=(item['rank'],))
            top10 = [x['so'] for x in ranked[:10]]
            self._update_txt(self.txt_10, ", ".join(top10), "center")
            self._update_txt(self.txt_4,  " - ".join(top10[:4]), "center")
        else:
            self._update_txt(self.txt_10, f"L·ªói: {matrix_res.get('message')}")
            
        # 5. Update Dan 65 (WITH VIP/FOCUS + SET PRIORITY - V10.6)
        if scores:
            try:
                from logic.de_analytics import build_dan65_with_bo_priority
                
                # Extract VIP (top 10) and Focus (top 4) numbers from ranked matrix
                vip_numbers = []
                focus_numbers = []
                if ranked:
                    vip_numbers = [x['so'] for x in ranked[:10]]  # Top 10 VIP
                    focus_numbers = [x['so'] for x in ranked[:4]]  # Top 4 Focus (subset of VIP)
                
                # Build Dan 65 with VIP/Focus + set priority optimization
                dan65, inclusions, excluded = build_dan65_with_bo_priority(
                    all_scores=scores,
                    freq_bo=freq_bo,
                    gan_bo=gan_bo,
                    vip_numbers=vip_numbers,    # FORCE include VIP 10
                    focus_numbers=focus_numbers,  # FORCE include Focus 4
                    top_sets_count=5,            # Prioritize top 5 sets
                    dan_size=65,                 # Final Dan size
                    min_per_top_set=1            # At least 1 number per top set
                )
                
                self._update_txt(self.txt_65, ",".join(dan65))
                
                # Brief console summary
                print(f"\nüéØ DAN 65 OPTIMIZED: {len(dan65)} numbers ({len(vip_numbers)} VIP, {sum(inclusions.values())} from top sets)")
                
            except Exception as e:
                print(f"[WARNING] Dan 65 optimization failed, using simple method: {e}")
                import traceback
                traceback.print_exc()
                # Fallback to simple method
                top65 = [x[0] for x in scores[:65]]
                top65.sort()
                self._update_txt(self.txt_65, ",".join(top65))
        else: 
            self._update_txt(self.txt_65, "")

        # 6. Touch Combos
        if touch_combinations:
            top_streak = sorted(touch_combinations, key=lambda x: x['streak'], reverse=True)[:3]
            str_streak = " | ".join([f"C{','.join(map(str, x['touches']))}({x['streak']}N)" for x in top_streak])
            
            top_rate = sorted(touch_combinations, key=lambda x: x['rate_percent'], reverse=True)[:3]
            str_rate = " | ".join([f"C{','.join(map(str, x['touches']))}({x['rate_percent']:.0f}%)" for x in top_rate])
            
            self._update_txt(self.txt_4c_thong, str_streak)
            self._update_txt(self.txt_4c_tile, str_rate)
        else:
            self._update_txt(self.txt_4c_thong, "---")
            self._update_txt(self.txt_4c_tile, "---")
            
        # 7. UPDATE EVALUATION & TOP SETS
        self._update_evaluation_and_top_sets(freq_bo, gan_bo, freq_cham, gan_cham)

    def _update_evaluation_and_top_sets(self, freq_bo, gan_bo, freq_cham, gan_cham):
        """
        [V3.9.22] T√ÅCH BI·ªÜT ƒê√ÅNH GI√Å: C·∫≠p nh·∫≠t ri√™ng 2 b·∫£ng Ch·∫°m v√† B·ªô
        - B·∫£ng CH·∫†M: Thu·∫≠t to√°n scoring (freq * 2.0) - (gan * 0.5)
        - B·∫£ng B·ªò: Thu·∫≠t to√°n c·∫£i ti·∫øn v·ªõi bonus cho b·ªô k√©p, trending, v·ª´a v·ªÅ
        """
        # === 1. ƒê√ÅNH GI√Å CH·∫†M (SEPARATED) ===
        for i in self.tree_eval_cham.get_children(): 
            self.tree_eval_cham.delete(i)
        
        cham_scores = []
        for ch, freq in freq_cham.items():
            gan = gan_cham.get(ch, 0)
            # Scoring algorithm for CH·∫†M: Higher weight on frequency
            score = (freq * 2.0) - (float(gan) * 0.5)
            cham_scores.append({"val": str(ch), "f": freq, "g": gan, "s": score})
        
        # Sort by score descending
        cham_scores.sort(key=lambda x: x['s'], reverse=True)
        
        # Display in CH·∫†M table
        for item in cham_scores:
            tags = ()
            if item['s'] >= 5.0: 
                tags = ("HOT",)
            self.tree_eval_cham.insert("", "end", 
                values=(item['val'], item['f'], item['g'], f"{item['s']:.1f}"), 
                tags=tags)
        
        # === 2. ƒê√ÅNH GI√Å B·ªò (SEPARATED & IMPROVED) ===
        for i in self.tree_eval_bo.get_children(): 
            self.tree_eval_bo.delete(i)
        
        # B·ªô k√©p (duplicate sets): 00, 11, 22, 33, 44 - c√≥ 4 s·ªë/b·ªô
        KEP_SETS = {"00", "11", "22", "33", "44"}
        
        bo_scores = []
        if BO_SO_DE:
            # L·∫•y danh s√°ch t·∫•t c·∫£ c√°c b·ªô t·ª´ utils (ƒë·∫£m b·∫£o ƒë·ªß 15 b·ªô)
            all_bo_names = list(BO_SO_DE.keys())
            for bo in all_bo_names:
                f = freq_bo.get(bo, 0)
                g = gan_bo.get(bo, 30) # Default Gan 30 ng√†y n·∫øu kh√¥ng th·∫•y
                
                # === NEW SCORING FORMULA FOR B·ªò ===
                # Base score: frequency with moderate weight
                base_score = f * 1.5
                
                # Reduced penalty: Gan penalty reduced from 0.5 to 0.3
                gan_penalty = float(g) * 0.3
                
                # Bonus for duplicate sets (b·ªô k√©p): +2.0 points
                kep_bonus = 2.0 if bo in KEP_SETS else 0.0
                
                # Bonus for recently appeared (gan < 7 days): +1.5 points
                recent_bonus = 1.5 if g < 7 else 0.0
                
                # Bonus for trending (high frequency in last 30 days): +1.0 if freq >= 3
                trending_bonus = 1.0 if f >= 3 else 0.0
                
                # Final score
                score = base_score - gan_penalty + kep_bonus + recent_bonus + trending_bonus
                
                bo_scores.append({
                    "val": bo, 
                    "f": f, 
                    "g": g, 
                    "s": score,
                    "is_kep": bo in KEP_SETS
                })
        else:
            # Fallback n·∫øu BO_SO_DE r·ªóng (hi·∫øm)
            for bo, freq in freq_bo.items():
                bo_scores.append({
                    "val": bo, 
                    "f": freq, 
                    "g": 0, 
                    "s": 0,
                    "is_kep": False
                })
        
        # Sort by score descending
        bo_scores.sort(key=lambda x: x['s'], reverse=True)
        
        # Display in B·ªò table with special highlighting for b·ªô k√©p
        for item in bo_scores:
            tags = []
            
            # HOT indicator for high scores
            if item['s'] >= 5.0: 
                tags.append("HOT")
            
            # KEP indicator for duplicate sets (blue background, bold)
            if item.get('is_kep', False):
                tags.append("KEP")
            
            self.tree_eval_bo.insert("", "end", 
                values=(item['val'], item['f'], item['g'], f"{item['s']:.1f}"), 
                tags=tuple(tags) if tags else ())
        
        # === 3. TOP B·ªò SUMMARY ===
        top_bo = bo_scores[:5]  # Already sorted
        str_top_bo = " | ".join([f"B·ªô {b['val']} ({b['s']:.1f}ƒë)" for b in top_bo])
        self._update_txt(self.txt_bo_top, str_top_bo)

    def _fill_stat_tree(self, tree, freq, gan):
        for i in tree.get_children(): tree.delete(i)
        if not freq: return
        all_keys = sorted(freq.keys())
        items = []
        for k in all_keys:
            items.append((k, freq.get(k, 0), gan.get(k, 0)))
        items.sort(key=lambda x: x[2], reverse=True)
        for k, f, g in items:
            tree.insert("", "end", values=(k, f, g))

    # [NEW Helper] H√†m ƒëi·ªÅn b·∫£ng th·ªëng k√™ B·ªô ri√™ng (Full 15 b·ªô)
    def _fill_stat_tree_full_bo(self, tree, freq, gan):
        for i in tree.get_children(): tree.delete(i)
        # N·∫øu c√≥ BO_SO_DE th√¨ l·∫•y key t·ª´ ƒë√≥, n·∫øu kh√¥ng th√¨ l·∫•y t·ª´ freq
        keys_to_scan = list(BO_SO_DE.keys()) if BO_SO_DE else sorted(freq.keys())
        
        items = []
        for k in keys_to_scan:
            f = freq.get(k, 0)
            g = gan.get(k, 30)
            items.append((k, f, g))
            
        # Sort theo Gan gi·∫£m d·∫ßn ƒë·ªÉ d·ªÖ nh√¨n c√°c b·ªô l√¢u ch∆∞a v·ªÅ
        items.sort(key=lambda x: x[2], reverse=True)
        
        for k, f, g in items:
            tree.insert("", "end", values=(k, f, g))

    # [DEBUG VERSION] H√†m x·ª≠ l√Ω khi Double Click v√†o c·∫ßu ƒê·ªÅ
    def on_bridge_dbl_click(self, event):
        """X·ª≠ l√Ω s·ª± ki·ªán click ƒë√∫p v√†o danh s√°ch c·∫ßu -> Hi·ªán popup backtest"""
        print("\n" + "="*50)
        print(">>> [UI DEBUG] B·∫ÆT ƒê·∫¶U S·ª∞ KI·ªÜN DOUBLE CLICK")
        
        try:
            # 1. Ki·ªÉm tra vi·ªác ch·ªçn d√≤ng
            selected_item = self.tree_br.selection()
            print(f">>> [UI DEBUG] ID d√≤ng ƒë√£ ch·ªçn: {selected_item}")
            
            if not selected_item:
                print(">>> [UI DEBUG] C·∫£nh b√°o: Ch∆∞a ch·ªçn d√≤ng n√†o (selected_item r·ªóng).")
                return
            
            # 2. L·∫•y d·ªØ li·ªáu t·ª´ d√≤ng ƒë√≥
            item_data = self.tree_br.item(selected_item[0])
            print(f">>> [UI DEBUG] Raw Item Data: {item_data}")
            
            item_values = item_data.get("values")
            print(f">>> [UI DEBUG] Values: {item_values}")
            
            if not item_values:
                print(">>> [UI DEBUG] L·ªói: Kh√¥ng l·∫•y ƒë∆∞·ª£c values t·ª´ d√≤ng n√†y.")
                return

            # 3. B√≥c t√°ch t√™n c·∫ßu
            # L∆∞u √Ω: Treeview ƒë√¥i khi tr·∫£ v·ªÅ tuple, ƒë√¥i khi tr·∫£ v·ªÅ string t√πy config
            bridge_name = str(item_values[0]) 
            print(f">>> [UI DEBUG] T√™n c·∫ßu tr√≠ch xu·∫•t ƒë∆∞·ª£c: '{bridge_name}'")
            
            if not bridge_name or bridge_name == "None":
                print(">>> [UI DEBUG] L·ªói: T√™n c·∫ßu b·ªã r·ªóng ho·∫∑c None.")
                return

            # 4. Ki·ªÉm tra k·∫øt n·ªëi t·ªõi Controller
            print(f">>> [UI DEBUG] Controller Object: {self.controller}")
            
            if self.controller is None:
                print(">>> [UI DEBUG] L·ªñI NGHI√äM TR·ªåNG: Bi·∫øn self.controller l√† None (Ch∆∞a ƒë∆∞·ª£c li√™n k·∫øt).")
                return

            if not hasattr(self.controller, 'trigger_bridge_backtest'):
                print(">>> [UI DEBUG] L·ªñI NGHI√äM TR·ªåNG: Controller kh√¥ng c√≥ h√†m 'trigger_bridge_backtest'.")
                print(f"    Danh s√°ch h√†m hi·ªán c√≥: {dir(self.controller)}")
                return

            # 5. G·ª≠i l·ªánh ƒëi
            print(f">>> [UI DEBUG] ƒêang g·ªçi controller.trigger_bridge_backtest('{bridge_name}', is_de=True)...")
            self.controller.trigger_bridge_backtest(bridge_name, is_de=True)
            print(">>> [UI DEBUG] ƒê√£ g·ª≠i l·ªánh th√†nh c√¥ng.")

        except Exception as e:
            print(f">>> [UI DEBUG] CRASH (L·ªói vƒÉng code): {e}")
            import traceback
            traceback.print_exc()
        
        print("="*50 + "\n")

--------------------------------------------------

=== FILE: ui\ui_lookup.py ===
# T√™n file: git3/ui/ui_lookup.py
#
# (N·ªòI DUNG THAY TH·∫æ TO√ÄN B·ªò - S·ª¨A E741, E226)
#
import tkinter as tk
from tkinter import ttk

# Import c√°c h√†m logic c·∫ßn thi·∫øt
try:
    from lottery_service import (
        calculate_loto_stats,
        delete_ky_from_db,
        get_all_kys_from_db,
        get_results_by_ky,
        getAllLoto_V30,
    )
except ImportError:
    print("L·ªñI: ui_lookup.py kh√¥ng th·ªÉ import lottery_service.")

    def get_all_kys_from_db():
        return []

    def get_results_by_ky(k):
        return None

    def getAllLoto_V30(r):
        return []

    # S·ª≠a E741: ƒë·ªïi l th√†nh loto_list
    def calculate_loto_stats(loto_list):
        return {}, {}
    
    def delete_ky_from_db(k):
        return False, "Import error"


class LookupWindow(ttk.Frame):  # (S·ª¨A) K·∫ø th·ª´a t·ª´ ttk.Frame
    """Qu·∫£n l√Ω tab Tra C·ª©u K·∫øt Qu·∫£."""

    def __init__(self, app):
        # (S·ª¨A) Kh·ªüi t·∫°o Frame
        super().__init__(app.notebook, padding=10)

        self.app = app
        self.root = app.root
        self.all_ky_data_list = []  # D·ªØ li·ªáu cache

        # (S·ª¨A) G·∫Øn PanedWindow v√†o self (Frame ch√≠nh)
        paned_window = ttk.PanedWindow(self, orient=tk.HORIZONTAL)
        paned_window.pack(expand=True, fill=tk.BOTH, padx=0, pady=0)  # X√≥a padx/pady

        # --- Khung tr√°i (Listbox + Search) ---
        list_frame = ttk.Frame(paned_window, width=250)
        list_frame.pack(expand=True, fill=tk.BOTH)

        search_frame = ttk.Frame(list_frame)
        search_frame.pack(fill=tk.X, pady=(0, 5), padx=2)

        search_label = ttk.Label(search_frame, text="T√¨m ki·∫øm (K·ª≥/Ng√†y):")
        search_label.pack(anchor="w")
        self.search_entry = ttk.Entry(search_frame)
        self.search_entry.pack(side=tk.LEFT, fill=tk.X, expand=True)

        refresh_button = ttk.Button(
            search_frame, text="L√†m M·ªõi", command=self.refresh_lookup_list
        )
        refresh_button.pack(side=tk.LEFT, padx=(5, 0))

        # Add delete button
        delete_button = ttk.Button(
            search_frame, text="X√≥a K·ª≥", command=self.delete_selected_ky
        )
        delete_button.pack(side=tk.LEFT, padx=(5, 0))

        list_label = ttk.Label(list_frame, text="Danh s√°ch c√°c k·ª≥ (m·ªõi nh·∫•t ·ªü tr√™n):")
        list_label.pack(pady=(0, 5), anchor="w", padx=2)

        list_scrollbar = ttk.Scrollbar(list_frame, orient=tk.VERTICAL)
        self.list_box = tk.Listbox(
            list_frame, yscrollcommand=list_scrollbar.set, exportselection=False
        )
        list_scrollbar.config(command=self.list_box.yview)
        list_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        self.list_box.pack(expand=True, fill=tk.BOTH)

        paned_window.add(list_frame, weight=1)

        # --- Khung ph·∫£i (Chi ti·∫øt) ---
        detail_frame = ttk.Frame(paned_window, width=550)
        detail_frame.pack(expand=True, fill=tk.BOTH)
        detail_label = ttk.Label(detail_frame, text="Chi ti·∫øt k·∫øt qu·∫£:")
        detail_label.pack(pady=(0, 5))

        self.detail_text = tk.Text(
            detail_frame, wrap=tk.WORD, state=tk.DISABLED, font=("Courier New", 10)
        )
        detail_scrollbar = ttk.Scrollbar(
            detail_frame, orient=tk.VERTICAL, command=self.detail_text.yview
        )
        self.detail_text.config(yscrollcommand=detail_scrollbar.set)
        detail_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        self.detail_text.pack(expand=True, fill=tk.BOTH)

        paned_window.add(detail_frame, weight=3)

        # --- Logic L·ªçc/T√¨m ki·∫øm ---
        self.search_entry.bind("<KeyRelease>", self.on_lookup_search_change)

        # --- N·∫°p d·ªØ li·ªáu ---
        try:
            self.refresh_lookup_list()
            self.list_box.bind("<<ListboxSelect>>", self.on_ky_selected)
            if self.list_box.size() > 0:
                self.list_box.select_set(0)
                self.list_box.event_generate("<<ListboxSelect>>")
        except Exception as e:
            # (S·ª¨A) G·ªçi qua logger
            self.app.logger.log(f"L·ªói khi m·ªü c·ª≠a s·ªï tra c·ª©u: {e}")
            self.list_box.insert(tk.END, f"L·ªói: {e}")

    def refresh_lookup_list(self):
        """T·∫£i l·∫°i to√†n b·ªô d·ªØ li·ªáu cho Listbox Tra C·ª©u."""
        try:
            self.all_ky_data_list = get_all_kys_from_db()
            if not self.all_ky_data_list:
                self.list_box.delete(0, tk.END)
                self.list_box.insert(tk.END, "L·ªói: Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu.")
                return

            self.filter_lookup_list()

            if self.list_box.size() > 0:
                self.list_box.select_set(0)
                self.list_box.event_generate("<<ListboxSelect>>")

            # (S·ª¨A) G·ªçi qua logger
            self.app.logger.log("ƒê√£ l√†m m·ªõi danh s√°ch K·ª≥ trong Tra C·ª©u.")
        except Exception as e:
            self.app.logger.log(f"L·ªói refresh_lookup_list: {e}")

    def on_lookup_search_change(self, event):
        self.filter_lookup_list()

    def filter_lookup_list(self):
        """Ch·ªâ l·ªçc v√† hi·ªÉn th·ªã, kh√¥ng t·∫£i l·∫°i DB."""
        search_term = self.search_entry.get().strip().lower()
        self.list_box.delete(0, tk.END)
        self.update_detail_text("...")

        if not self.all_ky_data_list:
            return

        for ky in self.all_ky_data_list:
            # CSDL V6 (db_manager) ch·ªâ tr·∫£ v·ªÅ 2 c·ªôt: ky[0] (K·ª≥) v√† ky[1] (Ng√†y)
            display_text = f"{ky[0]}   ({ky[1]})"

            if search_term in display_text.lower():
                self.list_box.insert(tk.END, display_text)

    def on_ky_selected(self, event):
        """Hi·ªÉn th·ªã chi ti·∫øt k·ª≥ (ƒê√£ cƒÉn ch·ªânh)."""
        if not self.detail_text:
            return
        try:
            widget = event.widget
            selected_indices = widget.curselection()
            if not selected_indices:
                return

            selected_line = widget.get(selected_indices[0])
            ma_so_ky = selected_line.split()[0]

            row = get_results_by_ky(ma_so_ky)
            if not row:
                self.update_detail_text(
                    f"Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu chi ti·∫øt cho k·ª≥: {ma_so_ky}"
                )
                return

            # logic get_results_by_ky (V6) tr·∫£ v·ªÅ 38 c·ªôt (results_A_I)
            # C·ªôt 0=id, 1=ky, 2=date, 3-10=gi·∫£i, 11-37=l√¥
            if len(row) < 38:
                self.update_detail_text(
                    f"L·ªói: D·ªØ li·ªáu k·ª≥ {ma_so_ky} kh√¥ng ƒë·ªß 38 c·ªôt (ch·ªâ c√≥ {len(row)})."
                )
                return

            loto_list = getAllLoto_V30(row)
            dau_stats, duoi_stats = calculate_loto_stats(loto_list)

            output = f"K·∫æT QU·∫¢ K·ª≤: {ma_so_ky}\n"
            output += "=" * 46 + "\n\n"
            giai_ten = ["ƒê·∫∑c Bi·ªát", "Nh·∫•t", "Nh√¨", "Ba", "B·ªën", "NƒÉm", "S√°u", "B·∫£y"]
            LABEL_WIDTH, NUMBER_WIDTH = 10, 33

            for i in range(len(giai_ten)):
                giai_name = giai_ten[i].ljust(LABEL_WIDTH)
                # D·ªØ li·ªáu gi·∫£i b·∫Øt ƒë·∫ßu t·ª´ index 3 (gdb)
                giai_data_str = str(row[i + 3] or "")
                numbers = [n.strip() for n in giai_data_str.split(",") if n.strip()]
                num_count = len(numbers)

                if num_count == 0:
                    output += f"{giai_name} : {''.center(NUMBER_WIDTH)}\n"
                elif num_count <= 3:
                    line_str = " - ".join(numbers)
                    output += f"{giai_name} : {line_str.center(NUMBER_WIDTH)}\n"
                elif num_count == 4:
                    line1_str, line2_str = " - ".join(numbers[:2]), " - ".join(
                        numbers[2:]
                    )
                    output += f"{giai_name} : {line1_str.center(NUMBER_WIDTH)}\n"
                    output += (
                        f"{''.ljust(LABEL_WIDTH)} : {line2_str.center(NUMBER_WIDTH)}\n"
                    )
                elif num_count == 6:
                    line1_str, line2_str = " - ".join(numbers[:3]), " - ".join(
                        numbers[3:]
                    )
                    output += f"{giai_name} : {line1_str.center(NUMBER_WIDTH)}\n"
                    output += (
                        f"{''.ljust(LABEL_WIDTH)} : {line2_str.center(NUMBER_WIDTH)}\n"
                    )
                else:
                    output += f"{giai_name} : {" - ".join(numbers)}\n"

            output += "\n" + "=" * 46 + "\n"
            output += "TH·ªêNG K√ä LOTO (ƒê·∫ßu - ƒêu√¥i)\n"
            output += "-" * 46 + "\n"
            COL_DAU_W, COL_LOTO_W, COL_DUOI_W = 3, 12, 4
            output += f"{'ƒê·∫ßu'.ljust(COL_DAU_W)} | {'Loto'.ljust(COL_LOTO_W)} | {'ƒêu√¥i'.ljust(COL_DUOI_W)} | {'Loto'.ljust(COL_LOTO_W)}\n"
            output += f"{'-' * COL_DAU_W} | {'-' * COL_LOTO_W} | {'-' * COL_DUOI_W} | {'-' * COL_LOTO_W}\n"

            for i in range(10):
                dau_val_str = ",".join(dau_stats[i])
                duoi_val_str = ",".join(duoi_stats[i])
                # S·ª≠a E226: Th√™m kho·∫£ng tr·∫Øng
                output += f"{str(i).ljust(COL_DAU_W)} | {dau_val_str.ljust(COL_LOTO_W)} | {str(i).ljust(COL_DUOI_W)} | {duoi_val_str.ljust(COL_LOTO_W)}\n"

            self.update_detail_text(output)
        except Exception as e:
            self.app.logger.log(f"L·ªói on_ky_selected: {e}")
            self.update_detail_text(f"L·ªói: {e}")

    def update_detail_text(self, message):
        """H√†m h·ªó tr·ª£ c·∫≠p nh·∫≠t Text ·ªü c·ª≠a s·ªï tra c·ª©u"""
        if not self.detail_text:
            return
        self.detail_text.config(state=tk.NORMAL)
        self.detail_text.delete("1.0", tk.END)
        self.detail_text.insert(tk.END, message)
        self.detail_text.config(state=tk.DISABLED)

    def delete_selected_ky(self):
        """Delete the currently selected ky from the database"""
        from tkinter import messagebox
        
        try:
            selected_indices = self.list_box.curselection()
            if not selected_indices:
                messagebox.showwarning(
                    "Ch∆∞a ch·ªçn k·ª≥",
                    "Vui l√≤ng ch·ªçn m·ªôt k·ª≥ ƒë·ªÉ x√≥a.",
                    parent=self.root
                )
                return
            
            selected_line = self.list_box.get(selected_indices[0])
            ma_so_ky = selected_line.split()[0]
            
            # Confirm deletion
            confirm = messagebox.askyesno(
                "X√°c nh·∫≠n x√≥a",
                f"B·∫°n c√≥ ch·∫Øc ch·∫Øn mu·ªën x√≥a k·ª≥ {ma_so_ky}?\n\nThao t√°c n√†y kh√¥ng th·ªÉ ho√†n t√°c!",
                parent=self.root
            )
            
            if not confirm:
                return
            
            # Delete from database
            success, message = delete_ky_from_db(ma_so_ky)
            
            if success:
                messagebox.showinfo("Th√†nh c√¥ng", message, parent=self.root)
                self.app.logger.log(f"ƒê√£ x√≥a k·ª≥ {ma_so_ky}")
                # Refresh the list
                self.refresh_lookup_list()
            else:
                messagebox.showerror("L·ªói", message, parent=self.root)
                self.app.logger.log(f"L·ªói khi x√≥a k·ª≥ {ma_so_ky}: {message}")
                
        except Exception as e:
            messagebox.showerror(
                "L·ªói",
                f"ƒê√£ x·∫£y ra l·ªói khi x√≥a: {e}",
                parent=self.root
            )
            self.app.logger.log(f"L·ªói delete_selected_ky: {e}")


--------------------------------------------------

=== FILE: ui\ui_main_window.py ===
# T√™n file: CODE5/git1/ui/ui_main_window.py
#
# (PHI√äN B·∫¢N CLEAN UX V7.9 - FIXED LOGGER INITIALIZATION ORDER)
#
import json
import os
import tkinter as tk
import traceback
from tkinter import filedialog, messagebox, simpledialog, ttk

# --- IMPORTS AN TO√ÄN ---
try:
    from lottery_service import DB_NAME, upsert_managed_bridge
except ImportError:
    print("L·ªñI: Kh√¥ng t√¨m th·∫•y 'lottery_service.py'.")
    exit()

try:
    from app_controller import AppController
    from core_services import Logger, TaskManager
except ImportError:
    print("L·ªñI: Kh√¥ng t√¨m th·∫•y 'core_services.py' ho·∫∑c 'app_controller.py'.")
    exit()

try:
    from logic.config_manager import SETTINGS
except ImportError:
    SETTINGS = None

# Import UI Components
try:
    from ui.ui_dashboard import DashboardWindow
    from ui.ui_de_dashboard import UiDeDashboard
    from ui.ui_lookup import LookupWindow
    from ui.ui_optimizer import OptimizerTab
    from ui.ui_results_viewer import ResultsViewerWindow
    from ui.ui_settings import SettingsWindow
    from ui.ui_tuner import TunerWindow
    # NEW: Bridge Scanner and Management tabs
    from ui.ui_bridge_scanner import BridgeScannerTab
    from ui.ui_bridge_management import BridgeManagementTab
except ImportError as e:
    print(f"L·ªñI UI IMPORTS: {e}")
    exit()


class DataAnalysisApp:
    def __init__(self, root):
        self.root = root
        self.root.title("X·ªï S·ªë Data Analysis (v7.9 - Giao di·ªán Tinh G·ªçn)")
        self.root.columnconfigure(0, weight=1)
        self.root.rowconfigure(0, weight=1)
        # K√≠ch th∆∞·ªõc chu·∫©n HD
        self.root.geometry("1100x800")

        self.db_name = DB_NAME
        
        # --- C√ÅC BI·∫æN CONTROLLER C·∫¶N TRUY C·∫¨P (GI·ªÆ NGUY√äN T√äN) ---
        self.bridge_manager_window = None          # Controller c·∫ßn check bi·∫øn n√†y
        self.bridge_manager_window_instance = None # Controller c·∫ßn g·ªçi refresh_bridge_list() t·ª´ ƒë√¢y
        self.settings_window = None
        self.tuner_window = None

        # --- STYLE ---
        style = ttk.Style()
        # N√∫t Hero (N·ªïi b·∫≠t)
        style.configure("Hero.TButton", font=("Helvetica", 12, "bold"), padding=10)
        # N√∫t Action (M√†u xanh nh·∫•n)
        style.configure("Accent.TButton", font=("Helvetica", 10, "bold"), foreground="blue")
        # Label nh·ªè
        style.configure("Compact.TLabel", font=("Arial", 9), foreground="#555")

        # --- NOTEBOOK CH√çNH ---
        self.notebook = ttk.Notebook(root)
        self.notebook.grid(row=0, column=0, sticky="nsew", padx=5, pady=5)

        # ======================================================================
        # [QUAN TR·ªåNG] KH·ªûI T·∫†O LOGGER TR∆Ø·ªöC TI√äN
        # L√Ω do: C√°c tab con (Lookup, Dashboard...) c·∫ßn logger ngay khi init.
        # ======================================================================
        self.tab_log_frame = ttk.Frame(self.notebook, padding="10")
        self._setup_log_tab() # -> T·∫°o self.logger t·∫°i ƒë√¢y

        # 1. Kh·ªüi t·∫°o c√°c Tab Ch·ª©c NƒÉng (Sau khi ƒë√£ c√≥ Logger)
        self.tab1_frame = ttk.Frame(self.notebook, padding="10") # Tab Trang ch·ªß
        
        # B·ªçc try-except ƒë·ªÉ n·∫øu tab n√†o l·ªói th√¨ kh√¥ng s·∫≠p c·∫£ app
        try:
            self.dashboard_tab = DashboardWindow(self)
        except Exception as e:
            self.logger.log(f"L·ªói kh·ªüi t·∫°o Dashboard: {e}")
            self.dashboard_tab = ttk.Frame(self.notebook) # Placeholder

        try:
            self.de_dashboard_tab = UiDeDashboard(self.notebook, None)
        except Exception as e:
            self.logger.log(f"L·ªói kh·ªüi t·∫°o Tab ƒê·ªÅ: {e}")
            self.de_dashboard_tab = ttk.Frame(self.notebook)

        try:
            self.lookup_tab = LookupWindow(self)
        except Exception as e:
            self.logger.log(f"L·ªói kh·ªüi t·∫°o Tab Tra C·ª©u: {e}")
            self.lookup_tab = ttk.Frame(self.notebook)

        try:
            self.optimizer_tab = OptimizerTab(self.notebook, self)
        except Exception as e:
            self.logger.log(f"L·ªói kh·ªüi t·∫°o Tab Optimizer: {e}")
            self.optimizer_tab = ttk.Frame(self.notebook)

        # NEW: Bridge Scanner and Management tabs
        try:
            self.bridge_scanner_tab = BridgeScannerTab(self.notebook, self)
        except Exception as e:
            self.logger.log(f"L·ªói kh·ªüi t·∫°o Tab D√≤ T√¨m C·∫ßu: {e}")
            self.bridge_scanner_tab = ttk.Frame(self.notebook)

        try:
            self.bridge_management_tab = BridgeManagementTab(self.notebook, self)
        except Exception as e:
            self.logger.log(f"L·ªói kh·ªüi t·∫°o Tab Qu·∫£n L√Ω C·∫ßu: {e}")
            self.bridge_management_tab = ttk.Frame(self.notebook)

        # 2. Add Tabs v√†o Notebook
        self.notebook.add(self.tab1_frame, text="üè† Trang Ch·ªß")
        self.notebook.add(self.dashboard_tab, text="üìä B·∫£ng Quy·∫øt ƒê·ªãnh")
        self.notebook.add(self.de_dashboard_tab, text="üîÆ Soi C·∫ßu ƒê·ªÅ")
        self.notebook.add(self.bridge_scanner_tab, text="üîç D√≤ T√¨m C·∫ßu M·ªõi")  # NEW
        self.notebook.add(self.bridge_management_tab, text="üõ†Ô∏è Qu·∫£n L√Ω C·∫ßu")  # NEW
        self.notebook.add(self.lookup_tab, text="üìñ Tra C·ª©u")
        self.notebook.add(self.optimizer_tab, text="üöÄ T·ªëi ∆Øu H√≥a")
        self.notebook.add(self.tab_log_frame, text="üìù Log H·ªá Th·ªëng")

        # --- SETUP GIAO DI·ªÜN TRANG CH·ª¶ ---
        self._setup_home_tab()

        # --- LIST BUTTONS CHO TASK MANAGER ---
        # (ƒê·ªÉ kh√≥a n√∫t khi ƒëang ch·∫°y t√°c v·ª• n·∫∑ng)
        # NOTE: Removed btn_bridge_manager and btn_auto_find (now in dedicated tabs)
        self.all_buttons = [
            self.btn_load_file, self.btn_load_append, self.btn_quick_update,
            self.btn_open_dashboard,
            self.btn_train_ai, self.btn_vote_stats,
            self.btn_settings, self.btn_tuner, self.btn_refresh_cache,
        ]
        
        # Th√™m n√∫t t·ª´ optimizer n·∫øu kh·ªüi t·∫°o th√†nh c√¥ng
        if hasattr(self.optimizer_tab, 'run_button'):
            self.all_buttons.append(self.optimizer_tab.run_button)
        if hasattr(self.optimizer_tab, 'apply_button'):
            self.all_buttons.append(self.optimizer_tab.apply_button)

        # --- KH·ªûI T·∫†O SERVICES ---
        self.task_manager = TaskManager(self.logger, self.all_buttons, self.root)
        
        if hasattr(self.optimizer_tab, 'apply_button'):
            self.task_manager.optimizer_apply_button = self.optimizer_tab.apply_button
        
        self.controller = AppController(self)
        self.controller.logger = self.logger
        
        # Link controller v√†o tab ƒê·ªÅ (ƒë·ªÉ tab ƒê·ªÅ g·ªçi ng∆∞·ª£c l·∫°i controller)
        if hasattr(self.de_dashboard_tab, 'controller'):
            self.de_dashboard_tab.controller = self.controller
        
        self.logger.log("‚úÖ Giao di·ªán (V7.9) ƒë√£ kh·ªüi t·∫°o xong & Logger ƒë√£ s·∫µn s√†ng.")

    def _setup_home_tab(self):
        """D·ª±ng giao di·ªán Trang Ch·ªß: G·ªçn g√†ng, t·∫≠p trung."""
        self.tab1_frame.columnconfigure(0, weight=1)
        
        # === KHU V·ª∞C 1: NH·∫¨P LI·ªÜU (COMPACT) ===
        input_frame = ttk.LabelFrame(self.tab1_frame, text="1. D·ªØ Li·ªáu ƒê·∫ßu V√†o", padding="5")
        input_frame.grid(row=0, column=0, sticky="ew", pady=(0, 15))
        input_frame.columnconfigure(1, weight=1)

        # H√†ng 1: Ch·ªçn File (√çt d√πng -> Nh·ªè l·∫°i)
        ttk.Label(input_frame, text="File:", style="Compact.TLabel").grid(row=0, column=0, sticky="w", padx=5)
        self.file_path_entry = ttk.Entry(input_frame)
        self.file_path_entry.grid(row=0, column=1, sticky="ew", padx=5)
        ttk.Button(input_frame, text="...", width=4, command=self.browse_file).grid(row=0, column=2, padx=2)
        self.btn_load_file = ttk.Button(input_frame, text="N·∫°p M·ªõi (X√≥a)", command=self.run_parsing)
        self.btn_load_file.grid(row=0, column=3, padx=2)
        self.btn_load_append = ttk.Button(input_frame, text="N·∫°p Th√™m", command=self.run_parsing_append)
        self.btn_load_append.grid(row=0, column=4, padx=2)

        # H√†ng 2: Nh·∫≠p Text (D√πng nhi·ªÅu -> Text box v·ª´a ph·∫£i)
        ttk.Label(input_frame, text="Paste KQ:", style="Compact.TLabel").grid(row=1, column=0, sticky="nw", padx=5, pady=5)
        
        # [QUAN TR·ªåNG] Gi·∫£m height xu·ªëng 4 ƒë·ªÉ ti·∫øt ki·ªám di·ªán t√≠ch
        self.update_text_area = tk.Text(input_frame, height=4, width=60, font=("Consolas", 10))
        self.update_text_area.grid(row=1, column=1, columnspan=2, sticky="ew", pady=5, padx=5)
        
        # N√∫t C·∫≠p Nh·∫≠t N·ªïi B·∫≠t
        self.btn_quick_update = ttk.Button(input_frame, text="‚ö° C·∫¨P NH·∫¨T NGAY", style="Accent.TButton", command=self.run_update_from_text)
        self.btn_quick_update.grid(row=1, column=3, sticky="ew", pady=5, padx=5)

        # [V10.0 NEW] Checkbox ch·ªçn ch·∫ø ƒë·ªô ph√¢n t√≠ch
        mode_frame = ttk.Frame(input_frame)
        mode_frame.grid(row=2, column=0, columnspan=5, sticky="w", padx=5, pady=5)
        
        self.var_lo_mode = tk.BooleanVar(value=True)
        self.var_de_mode = tk.BooleanVar(value=True)
        
        ttk.Label(mode_frame, text="Ch·∫ø ƒë·ªô ch·∫°y:", font=("Arial", 9, "bold")).pack(side=tk.LEFT, padx=(0, 10))
        ttk.Checkbutton(mode_frame, text="Ph√¢n t√≠ch L√î", variable=self.var_lo_mode).pack(side=tk.LEFT, padx=10)
        ttk.Checkbutton(mode_frame, text="Ph√¢n t√≠ch ƒê·ªÄ", variable=self.var_de_mode).pack(side=tk.LEFT, padx=10)

        # === KHU V·ª∞C 2: HERO ACTION (TRUNG T√ÇM) ===
        # ƒê√¢y l√† n∆°i ng∆∞·ªùi d√πng thao t√°c 90% th·ªùi gian
        hero_frame = ttk.Frame(self.tab1_frame)
        hero_frame.grid(row=1, column=0, sticky="nsew", pady=10)
        hero_frame.columnconfigure(0, weight=2) # Dashboard to h∆°n
        hero_frame.columnconfigure(1, weight=1)

        # N√∫t TO NH·∫§T: B·∫£ng Quy·∫øt ƒê·ªãnh (ƒê√£ ƒë·ªïi t√™n cho ph√π h·ª£p ng·ªØ c·∫£nh)
        self.btn_open_dashboard = ttk.Button(
            hero_frame, 
            text="üöÄ CH·∫†Y PH√ÇN T√çCH\n(Theo ch·∫ø ƒë·ªô ƒë√£ ch·ªçn)", 
            style="Hero.TButton",
            command=self.run_decision_dashboard
        )
        self.btn_open_dashboard.grid(row=0, column=0, columnspan=2, sticky="nsew", ipady=25)
        
        # NOTE: Removed "Qu·∫£n L√Ω C·∫ßu" button - Now it's a dedicated tab "üõ†Ô∏è Qu·∫£n L√Ω C·∫ßu"


        # === KHU V·ª∞C 3: H·ªÜ TH·ªêNG & AI (ADVANCED) ===
        # Gom nh√≥m c√°c ch·ª©c nƒÉng √≠t d√πng xu·ªëng d∆∞·ªõi
        sys_frame = ttk.LabelFrame(self.tab1_frame, text="3. H·ªá Th·ªëng & Tr√≠ Tu·ªá Nh√¢n T·∫°o", padding="10")
        sys_frame.grid(row=2, column=0, sticky="ew", pady=15)
        for i in range(4): sys_frame.columnconfigure(i, weight=1)

        # D√≤ng 1
        self.btn_train_ai = ttk.Button(sys_frame, text="üß† Hu·∫•n Luy·ªán AI", command=self.run_train_ai)
        self.btn_train_ai.grid(row=0, column=0, sticky="ew", padx=5, pady=2)

        # NOTE: Removed "D√≤ T√¨m C·∫ßu M·ªõi" button - Now it's a dedicated tab "üîç D√≤ T√¨m C·∫ßu M·ªõi"

        self.btn_vote_stats = ttk.Button(sys_frame, text="üìà Th·ªëng K√™ Vote", command=self.show_vote_statistics_window)
        self.btn_vote_stats.grid(row=0, column=2, sticky="ew", padx=5, pady=2)

        self.btn_settings = ttk.Button(sys_frame, text="‚öôÔ∏è C√†i ƒê·∫∑t", command=self.show_settings_window)
        self.btn_settings.grid(row=0, column=3, sticky="ew", padx=5, pady=2)

        # D√≤ng 2
        self.btn_tuner = ttk.Button(sys_frame, text="üéõÔ∏è Tinh Ch·ªânh Tham S·ªë", command=self.show_tuner_window)
        self.btn_tuner.grid(row=1, column=0, columnspan=2, sticky="ew", padx=5, pady=(5,0))

        self.btn_refresh_cache = ttk.Button(sys_frame, text="üîÑ L√†m M·ªõi Cache K2N", command=self.run_update_all_bridge_K2N_cache_from_main)
        self.btn_refresh_cache.grid(row=1, column=2, columnspan=2, sticky="ew", padx=5, pady=(5,0))

    def _setup_log_tab(self):
        self.tab_log_frame.columnconfigure(0, weight=1)
        self.tab_log_frame.rowconfigure(0, weight=1)
        
        self.output_text = tk.Text(self.tab_log_frame, height=15, width=80, font=("Courier New", 9))
        self.output_text.grid(row=0, column=0, sticky="nsew")
        
        scroll = ttk.Scrollbar(self.tab_log_frame, orient="vertical", command=self.output_text.yview)
        scroll.grid(row=0, column=1, sticky="ns")
        self.output_text.config(yscrollcommand=scroll.set, state=tk.DISABLED)
        
        # Logger k·∫øt n·ªëi v√†o text box n√†y
        self.logger = Logger(self.output_text, self.root)

    # --- ACTION HANDLERS ---

    def browse_file(self):
        file_path = filedialog.askopenfilename(filetypes=(("Data Files", "*.json;*.txt"), ("All Files", "*.*")))
        if file_path:
            self.file_path_entry.delete(0, tk.END)
            self.file_path_entry.insert(0, file_path)

    def run_parsing(self):
        path = self.file_path_entry.get()
        if not path or not os.path.exists(path):
            messagebox.showerror("L·ªói", "ƒê∆∞·ªùng d·∫´n file kh√¥ng h·ª£p l·ªá!")
            return
        if messagebox.askyesno("X√°c nh·∫≠n", "H√†nh ƒë·ªông n√†y s·∫Ω X√ìA H·∫æT d·ªØ li·ªáu c≈© v√† n·∫°p l·∫°i. Ti·∫øp t·ª•c?"):
            self.logger.log("\n--- B·∫Øt ƒë·∫ßu N·∫°p L·∫°i D·ªØ Li·ªáu ---")
            self.task_manager.run_task(self.controller.task_run_parsing, path)

    def run_parsing_append(self):
        path = self.file_path_entry.get()
        if not path or not os.path.exists(path):
            messagebox.showerror("L·ªói", "ƒê∆∞·ªùng d·∫´n file kh√¥ng h·ª£p l·ªá!")
            return
        if messagebox.askyesno("X√°c nh·∫≠n", "B·∫°n mu·ªën N·∫†P TH√äM d·ªØ li·ªáu t·ª´ file n√†y v√†o Database hi·ªán t·∫°i?"):
            self.logger.log("\n--- B·∫Øt ƒë·∫ßu N·∫°p Th√™m D·ªØ Li·ªáu ---")
            self.task_manager.run_task(self.controller.task_run_parsing_append, path)

    def run_update_from_text(self):
        text_data = self.update_text_area.get("1.0", tk.END).strip()
        if not text_data:
            messagebox.showwarning("Ch∆∞a nh·∫≠p li·ªáu", "Vui l√≤ng d√°n k·∫øt qu·∫£ x·ªï s·ªë v√†o √¥ tr·ªëng.")
            return
        self.logger.log("\n--- B·∫Øt ƒë·∫ßu C·∫≠p Nh·∫≠t Nhanh ---")
        self.task_manager.run_task(self.controller.task_run_update_from_text, text_data)

    def run_decision_dashboard(self):
        """
        [V10.1] Ch·∫°y Ph√¢n T√≠ch & ƒêi·ªÅu H∆∞·ªõng Th√¥ng Minh.
        T·ª± ƒë·ªông chuy·ªÉn sang tab ph√π h·ª£p d·ª±a tr√™n ch·∫ø ƒë·ªô ng∆∞·ªùi d√πng ch·ªçn.
        """
        # 1. L·∫•y tr·∫°ng th√°i t·ª´ Checkbox
        lo_mode = self.var_lo_mode.get()
        de_mode = self.var_de_mode.get()
        
        # 2. Validate (Ph·∫£i ch·ªçn √≠t nh·∫•t 1)
        if not lo_mode and not de_mode:
            messagebox.showwarning("C·∫£nh b√°o", "Vui l√≤ng ch·ªçn √≠t nh·∫•t: L√î ho·∫∑c ƒê·ªÄ (ho·∫∑c c·∫£ hai)!", parent=self.root)
            return

        self.logger.log("\n--- B·∫Øt ƒë·∫ßu Ph√¢n T√≠ch ---")
        
        # 3. [SMART NAV] Chuy·ªÉn tab d·ª±a tr√™n nhu c·∫ßu
        # N·∫øu CH·ªà ch·ªçn ƒê·ªÅ -> Chuy·ªÉn ngay sang tab ƒê·ªÅ
        if de_mode and not lo_mode:
             self.notebook.select(self.de_dashboard_tab)
             self.logger.log("-> Ch·∫ø ƒë·ªô: ƒê·ªÄ (Chuy·ªÉn sang Tab Soi C·∫ßu ƒê·ªÅ)")
        
        # C√°c tr∆∞·ªùng h·ª£p kh√°c (Ch·ªâ L√¥ ho·∫∑c C·∫£ hai) -> Chuy·ªÉn sang Dashboard L√¥
        else:
             self.notebook.select(self.dashboard_tab)
             mode_str = "L√î & ƒê·ªÄ" if (lo_mode and de_mode) else "L√î"
             self.logger.log(f"-> Ch·∫ø ƒë·ªô: {mode_str} (Chuy·ªÉn sang Tab B·∫£ng Quy·∫øt ƒê·ªãnh)")

        # 4. G·ª≠i l·ªánh xu·ªëng Controller
        self.task_manager.run_task(
            self.controller.task_run_decision_dashboard, 
            "Ph√¢n T√≠ch D·ªØ Li·ªáu", 
            lo_mode, 
            de_mode
        )

    def show_bridge_manager_window(self):
        """Switch to Bridge Management tab (old method kept for compatibility)."""
        try:
            # Switch to the new Bridge Management tab
            self.notebook.select(self.bridge_management_tab)
            # Refresh the list
            if hasattr(self.bridge_management_tab, 'refresh_bridge_list'):
                self.bridge_management_tab.refresh_bridge_list()
        except Exception as e:
            self.logger.log(f"L·ªói chuy·ªÉn tab Qu·∫£n L√Ω C·∫ßu: {e}")
            messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ m·ªü tab Qu·∫£n L√Ω C·∫ßu: {e}")

    # --- C√ÅC H√ÄM M√Ä CONTROLLER C√ì TH·ªÇ G·ªåI (GI·ªÆ NGUY√äN) ---
    def clear_update_text_area(self):
        self.update_text_area.delete("1.0", tk.END)

    def _show_dashboard_window(self, next_ky, stats_n_day, n_days_stats, consensus, high_win, pending_k2n_data, gan_stats, top_scores, top_memory_bridges, ai_predictions):
        # H√†m callback t·ª´ controller ƒë·ªÉ hi·ªÉn th·ªã d·ªØ li·ªáu
        try:
            self.dashboard_tab.populate_data(
                next_ky, stats_n_day, n_days_stats, consensus, high_win, 
                pending_k2n_data, gan_stats, top_scores, top_memory_bridges, ai_predictions
            )
            
            # [FIX V10.2] ƒê√£ x√≥a d√≤ng l·ªánh t·ª± ƒë·ªông chuy·ªÉn tab.
            # L√Ω do: Vi·ªác chuy·ªÉn tab ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω th√¥ng minh ngay khi b·∫•m n√∫t ·ªü h√†m run_decision_dashboard.
            # Code c≈© g√¢y l·ªói: self.notebook.select(self.dashboard_tab) <--- ƒê√É X√ìA

        except Exception as e:
            self.logger.log(f"L·ªñI HI·ªÇN TH·ªä DASHBOARD: {e}")
            self._on_dashboard_close()

    def _on_dashboard_close(self):
        if hasattr(self.dashboard_tab, 'clear_data'):
            self.dashboard_tab.clear_data()

    # --- C√ÅC WRAPPER CHO TASK MANAGER (GI·ªÆ NGUY√äN) ---
    def run_train_ai(self):
        self.task_manager.run_task(self.controller.task_run_train_ai, "Hu·∫•n luy·ªán AI")

    def run_auto_find_bridges(self):
        """Switch to Bridge Scanner tab (old method kept for compatibility)."""
        try:
            # Switch to the new Bridge Scanner tab
            self.notebook.select(self.bridge_scanner_tab)
            self.logger.log("ƒê√£ chuy·ªÉn sang tab D√≤ T√¨m C·∫ßu M·ªõi. Vui l√≤ng ch·ªçn lo·∫°i qu√©t.")
        except Exception as e:
            self.logger.log(f"L·ªói chuy·ªÉn tab D√≤ T√¨m C·∫ßu: {e}")
            messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ m·ªü tab D√≤ T√¨m C·∫ßu: {e}")
    
    def run_auto_prune_bridges(self): # V·∫´n gi·ªØ h√†m n√†y cho backward compatibility
        self.task_manager.run_task(self.controller.task_run_auto_prune_bridges, "L·ªçc C·∫ßu")

    def run_auto_manage_bridges(self): # V·∫´n gi·ªØ h√†m n√†y
        self.task_manager.run_task(self.controller.task_run_auto_manage_bridges, "Qu·∫£n L√Ω C·∫ßu")

    def run_update_all_bridge_K2N_cache_from_main(self):
        self.task_manager.run_task(self.controller.task_run_update_all_bridge_K2N_cache, "C·∫≠p nh·∫≠t Cache")

    def show_vote_statistics_window(self):
        from ui.ui_vote_statistics import VoteStatisticsWindow
        VoteStatisticsWindow(self)

    def show_settings_window(self):
        SettingsWindow(self)

    def show_tuner_window(self):
        TunerWindow(self)
    
    def show_lookup_window(self):
        self.notebook.select(self.lookup_tab)

    # --- Optimizer Support ---
    def run_strategy_optimization(self, strategy, days, params, tab):
        self.task_manager.run_task(self.controller.task_run_strategy_optimization, strategy, days, params, tab)

    def apply_optimized_settings(self, config_dict_str, optimizer_window):
        try:
            config = json.loads(config_dict_str)
            if messagebox.askyesno("√Åp d·ª•ng", f"√Åp d·ª•ng c·∫•u h√¨nh n√†y?\n{config_dict_str}"):
                for k, v in config.items():
                    SETTINGS.update_setting(k, v)
                messagebox.showinfo("OK", "ƒê√£ l∆∞u c·∫•u h√¨nh!")
        except Exception as e:
            messagebox.showerror("L·ªói", str(e))

    # --- Backtest Support & Results Viewer (K·∫øt n·ªëi Bridge Manager) ---
    def show_backtest_results(self, title, data, show_save=False):
        ResultsViewerWindow(self, title, data, show_save)
    
    def run_backtest(self, mode):
        self.task_manager.run_task(self.controller.task_run_backtest, mode, f"Backtest {mode}")
    
    def run_custom_backtest(self, mode):
        # Placeholder n·∫øu c·∫ßn g·ªçi t·ª´ module kh√°c
        pass 

    def run_backtest_memory(self):
        self.task_manager.run_task(self.controller.task_run_backtest_memory, "Backtest B·∫°c Nh·ªõ")

    def run_backtest_managed_n1(self):
        self.task_manager.run_task(self.controller.task_run_backtest_managed_n1, "Backtest C·∫ßu L∆∞u N1")

    def run_backtest_managed_k2n(self):
        self.task_manager.run_task(self.controller.task_run_backtest_managed_k2n, "Backtest C·∫ßu L∆∞u K2N")
    
    def run_parameter_tuning(self, param_key, val_from, val_to, val_step, tuner_window):
        self.task_manager.run_task(self.controller.task_run_parameter_tuning, param_key, val_from, val_to, val_step, tuner_window)

    def trigger_bridge_backtest(self, bridge_name):
        """K√≠ch ho·∫°t backtest 30 ng√†y cho m·ªôt c·∫ßu c·ª• th·ªÉ"""
        if not bridge_name:
            return
        self.logger.log(f"ƒêang ch·∫°y backtest 30 ng√†y cho c·∫ßu: {bridge_name}")
        if self.controller:
            self.controller.trigger_bridge_backtest(bridge_name)
    
    def _save_bridge_from_treeview(self, tree):
        # H√†m h·ªó tr·ª£ l∆∞u c·∫ßu t·ª´ b·∫£ng k·∫øt qu·∫£
        try:
            selected_item = tree.focus()
            if not selected_item: return
            item_values = tree.item(selected_item, "values")
            bridge_name, win_rate = item_values[1], item_values[3]
            
            description = simpledialog.askstring("L∆∞u C·∫ßu", f"M√¥ t·∫£ cho: {bridge_name}", initialvalue=bridge_name)
            if description:
                success, msg = upsert_managed_bridge(bridge_name, description, win_rate)
                if success: messagebox.showinfo("OK", msg)
                else: messagebox.showerror("L·ªói", msg)
        except Exception as e:
            messagebox.showerror("L·ªói", str(e))

--------------------------------------------------

=== FILE: ui\ui_mini_dashboard.py ===
# File: ui/ui_mini_dashboard.py - ƒê√É B·ªä LO·∫†I B·ªé (DEPRECATED V7.0)
# Ch·ª©c nƒÉng c·ªßa Mini Dashboard ƒë√£ ƒë∆∞·ª£c thay th·∫ø ho√†n to√†n b·ªüi B·∫£ng Quy·∫øt ƒê·ªãnh T·ªëi ∆Øu trong ui/ui_dashboard.py.
# Vui l√≤ng kh√¥ng s·ª≠ d·ª•ng ho·∫∑c import file n√†y.


--------------------------------------------------

=== FILE: ui\ui_optimizer.py ===
# T√™n file: git3/ui/ui_optimizer.py
#
# (N·ªòI DUNG THAY TH·∫æ TO√ÄN B·ªò - S·ª¨A F541, W503)
#
import tkinter as tk
import traceback
from tkinter import messagebox, ttk

# (M·ªöI Gƒê 10) Import SETTINGS ƒë·ªÉ l·∫•y gi√° tr·ªã m·∫∑c ƒë·ªãnh
try:
    from logic.config_manager import SETTINGS
except ImportError:
    print("L·ªñI: ui_optimizer.py kh√¥ng th·ªÉ import logic.config_manager.")
    SETTINGS = None


class OptimizerTab(ttk.Frame):
    """
    (M·ªöI Gƒê 10) Giao di·ªán Tab "T·ªëi ∆∞u H√≥a Chi·∫øn l∆∞·ª£c".
    K·∫ø th·ª´a t·ª´ ttk.Frame v√† s·∫Ω ƒë∆∞·ª£c nh√∫ng v√†o Notebook ch√≠nh.
    """

    def __init__(self, parent_notebook, app_instance):
        super().__init__(parent_notebook, padding="10")
        self.app = app_instance
        self.root = app_instance.root

        # Bi·∫øn l∆∞u tr·ªØ c√°c widget
        self.param_vars = {}  # { "GAN_DAYS": (check_var, from_var, to_var, step_var) }

        # --- C·∫•u tr√∫c GUI ---
        self.columnconfigure(0, weight=1)  # C·ªôt c√†i ƒë·∫∑t
        self.columnconfigure(1, weight=2)  # C·ªôt k·∫øt qu·∫£
        self.rowconfigure(0, weight=1)  # C·∫£ 2 c·ªôt co gi√£n

        # --- C·ªòT 1: KHUNG C√ÄI ƒê·∫∂T ---
        settings_frame = ttk.Frame(self)
        settings_frame.grid(row=0, column=0, sticky="nsew", padx=(0, 10))
        settings_frame.columnconfigure(0, weight=1)

        # Khung Chi·∫øn l∆∞·ª£c & Ng√†y
        strategy_frame = ttk.Labelframe(
            settings_frame, text="1. C√†i ƒë·∫∑t Chi·∫øn l∆∞·ª£c", padding="10"
        )
        strategy_frame.grid(row=0, column=0, sticky="ew")
        strategy_frame.columnconfigure(1, weight=1)

        ttk.Label(strategy_frame, text="Chi·∫øn l∆∞·ª£c T·ªëi ∆∞u:").grid(
            row=0, column=0, sticky="w", padx=5, pady=5
        )
        self.strategy_var = tk.StringVar(value="T·ªëi ∆∞u Top 1 (N1)")
        strategy_dropdown = ttk.Combobox(
            strategy_frame,
            textvariable=self.strategy_var,
            values=["T·ªëi ∆∞u Top 1 (N1)", "T·ªëi ∆∞u Top 3 (N1)"],
            state="readonly",
        )
        strategy_dropdown.grid(row=0, column=1, sticky="ew", padx=5, pady=5)

        ttk.Label(strategy_frame, text="S·ªë ng√†y ki·ªÉm th·ª≠:").grid(
            row=1, column=0, sticky="w", padx=5, pady=5
        )
        self.days_to_test_var = tk.StringVar(value="30")
        days_entry = ttk.Entry(
            strategy_frame, textvariable=self.days_to_test_var, width=10
        )
        days_entry.grid(row=1, column=1, sticky="w", padx=5, pady=5)

        # Khung Tham s·ªë
        params_frame = ttk.Labelframe(
            settings_frame, text="2. Ch·ªçn Tham s·ªë ƒë·ªÉ T·ªëi ∆∞u H√≥a", padding="10"
        )
        params_frame.grid(row=1, column=0, sticky="ew", pady=10)
        params_frame.columnconfigure(1, weight=1)

        # Header
        header_frame = ttk.Frame(params_frame)
        header_frame.grid(row=0, column=0, columnspan=5, sticky="ew")
        header_frame.columnconfigure(1, weight=1)
        header_frame.columnconfigure(2, weight=1)
        header_frame.columnconfigure(3, weight=1)
        header_frame.columnconfigure(4, weight=1)
        ttk.Label(header_frame, text="Tham s·ªë", font=("TkDefaultFont", 9, "bold")).grid(
            row=0, column=1
        )
        ttk.Label(header_frame, text="T·ª´", font=("TkDefaultFont", 9, "bold")).grid(
            row=0, column=2
        )
        ttk.Label(header_frame, text="ƒê·∫øn", font=("TkDefaultFont", 9, "bold")).grid(
            row=0, column=3
        )
        ttk.Label(
            header_frame, text="B∆∞·ªõc nh·∫£y", font=("TkDefaultFont", 9, "bold")
        ).grid(row=0, column=4)

        # L·∫•y c√†i ƒë·∫∑t m·∫∑c ƒë·ªãnh
        current_settings = SETTINGS.get_all_settings() if SETTINGS else {}

        # Danh s√°ch tham s·ªë (ƒê√É C·∫¨P NH·∫¨T TH√äM THAM S·ªê AI V√Ä RECENT_FORM)
        self.param_definitions = [
            ("GAN_DAYS", "S·ªë ng√†y L√¥ Gan", current_settings.get("GAN_DAYS", 15), 1),
            (
                "HIGH_WIN_THRESHOLD",
                "Ng∆∞·ª°ng C·∫ßu T·ª∑ L·ªá Cao (%)",
                current_settings.get("HIGH_WIN_THRESHOLD", 47.0),
                1.0,
            ),
            (
                "K2N_RISK_START_THRESHOLD",
                "Ng∆∞·ª°ng ph·∫°t K2N (khung)",
                current_settings.get("K2N_RISK_START_THRESHOLD", 4),
                1,
            ),
            (
                "K2N_RISK_PENALTY_PER_FRAME",
                "ƒêi·ªÉm ph·∫°t K2N / khung",
                current_settings.get("K2N_RISK_PENALTY_PER_FRAME", 0.5),
                0.1,
            ),
            # --- START NEW AI PARAMETERS ---
            (
                "AI_MAX_DEPTH",
                "AI: ƒê·ªô S√¢u C√¢y Max",
                current_settings.get("AI_MAX_DEPTH", 6),
                1,
            ),
            (
                "AI_N_ESTIMATORS",
                "AI: S·ªë l∆∞·ª£ng C√¢y (Est.)",
                current_settings.get("AI_N_ESTIMATORS", 200),
                50,
            ),
            (
                "AI_LEARNING_RATE",
                "AI: T·ªëc ƒë·ªô h·ªçc (LR)",
                current_settings.get("AI_LEARNING_RATE", 0.05),
                0.01,
            ),
            (
                "AI_SCORE_WEIGHT",
                "AI: Tr·ªçng s·ªë ƒêi·ªÉm",
                current_settings.get("AI_SCORE_WEIGHT", 0.2),
                0.1,
            ),
            # --- END NEW AI PARAMETERS ---
            # --- START RECENT_FORM PARAMETERS ---
            (
                "RECENT_FORM_PERIODS",
                "S·ªë k·ª≥ x√©t phong ƒë·ªô",
                current_settings.get("RECENT_FORM_PERIODS", 10),
                1,
            ),
            (
                "RECENT_FORM_MIN_HIGH",
                "Ng∆∞·ª°ng phong ƒë·ªô r·∫•t cao",
                current_settings.get("RECENT_FORM_MIN_HIGH", 8),
                1,
            ),
            (
                "RECENT_FORM_BONUS_HIGH",
                "ƒêi·ªÉm th∆∞·ªüng phong ƒë·ªô r·∫•t cao",
                current_settings.get("RECENT_FORM_BONUS_HIGH", 3.0),
                0.5,
            ),
            (
                "RECENT_FORM_MIN_MED",
                "Ng∆∞·ª°ng phong ƒë·ªô t·ªët",
                current_settings.get("RECENT_FORM_MIN_MED", 6),
                1,
            ),
            (
                "RECENT_FORM_BONUS_MED",
                "ƒêi·ªÉm th∆∞·ªüng phong ƒë·ªô t·ªët",
                current_settings.get("RECENT_FORM_BONUS_MED", 2.0),
                0.5,
            ),
            (
                "RECENT_FORM_MIN_LOW",
                "Ng∆∞·ª°ng phong ƒë·ªô ·ªïn",
                current_settings.get("RECENT_FORM_MIN_LOW", 5),
                1,
            ),
            (
                "RECENT_FORM_BONUS_LOW",
                "ƒêi·ªÉm th∆∞·ªüng phong ƒë·ªô ·ªïn",
                current_settings.get("RECENT_FORM_BONUS_LOW", 1.0),
                0.5,
            ),
            # --- END RECENT_FORM PARAMETERS ---
        ]

        current_row = 1
        for key, name, default_val, default_step in self.param_definitions:
            check_var = tk.BooleanVar(value=False)
            from_var = tk.StringVar(value=str(default_val))
            to_var = tk.StringVar(value=str(default_val))
            step_var = tk.StringVar(value=str(default_step))

            check = ttk.Checkbutton(params_frame, variable=check_var)
            check.grid(row=current_row, column=0, sticky="w", padx=5)

            ttk.Label(params_frame, text=name).grid(
                row=current_row, column=1, sticky="w", padx=5
            )

            from_entry = ttk.Entry(params_frame, textvariable=from_var, width=8)
            from_entry.grid(row=current_row, column=2, sticky="ew", padx=5, pady=2)

            to_entry = ttk.Entry(params_frame, textvariable=to_var, width=8)
            to_entry.grid(row=current_row, column=3, sticky="ew", padx=5, pady=2)

            step_entry = ttk.Entry(params_frame, textvariable=step_var, width=8)
            step_entry.grid(row=current_row, column=4, sticky="ew", padx=5, pady=2)

            self.param_vars[key] = (check_var, from_var, to_var, step_var)
            current_row += 1

        # N√∫t Ch·∫°y
        self.run_button = ttk.Button(
            settings_frame,
            text="B·∫Øt ƒë·∫ßu T·ªëi ∆∞u H√≥a Chi·∫øn l∆∞·ª£c",
            command=self.run_optimization,
        )
        self.run_button.grid(row=2, column=0, sticky="ew", pady=(15, 5))

        # N√∫t √Åp d·ª•ng C·∫•u h√¨nh T·ªët nh·∫•t
        self.apply_button = ttk.Button(
            settings_frame,
            text="√Åp d·ª•ng C·∫•u h√¨nh T·ªët nh·∫•t",
            command=self.apply_best_settings,
            state=tk.DISABLED,
        )
        self.apply_button.grid(row=3, column=0, sticky="ew", pady=(5, 5))

        # --- C·ªòT 2: KHUNG K·∫æT QU·∫¢ ---
        results_frame = ttk.Frame(self)
        results_frame.grid(row=0, column=1, sticky="nsew")
        results_frame.rowconfigure(0, weight=1)  # B·∫£ng k·∫øt qu·∫£
        results_frame.rowconfigure(1, weight=1)  # Log chi ti·∫øt
        results_frame.columnconfigure(0, weight=1)

        # B·∫£ng K·∫øt qu·∫£ X·∫øp h·∫°ng
        tree_frame = ttk.Labelframe(
            results_frame,
            text="3. K·∫øt qu·∫£ T·ªëi ∆∞u (X·∫øp h·∫°ng theo T·ª∑ l·ªá th·∫Øng)",
            padding="10",
        )
        tree_frame.grid(row=0, column=0, sticky="nsew", pady=(0, 5))
        tree_frame.rowconfigure(0, weight=1)
        tree_frame.columnconfigure(0, weight=1)

        self.tree = self._create_treeview(tree_frame)
        self.tree.tag_configure(
            "best", background="#FFFFE0", font=("TkDefaultFont", 9, "bold")
        )
        self.tree.bind("<Double-1>", self.on_result_double_click)

        # Log Chi ti·∫øt
        log_frame = ttk.Labelframe(results_frame, text="Log Chi ti·∫øt", padding="10")
        log_frame.grid(row=1, column=0, sticky="nsew", pady=(5, 0))
        log_frame.rowconfigure(0, weight=1)
        log_frame.columnconfigure(0, weight=1)

        log_scrollbar = ttk.Scrollbar(log_frame, orient=tk.VERTICAL)
        log_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)

        self.log_text = tk.Text(
            log_frame,
            height=10,
            width=80,
            font=("Courier New", 9),
            yscrollcommand=log_scrollbar.set,
        )
        self.log_text.pack(expand=True, fill=tk.BOTH)
        log_scrollbar.config(command=self.log_text.yview)
        self.log_text.config(state=tk.DISABLED)

    def _create_treeview(self, parent):
        """T·∫°o Treeview cho b·∫£ng k·∫øt qu·∫£."""
        tree_scroll_y = ttk.Scrollbar(parent, orient=tk.VERTICAL)
        tree_scroll_y.pack(side=tk.RIGHT, fill=tk.Y)

        cols = ("rate", "hits", "params")
        tree = ttk.Treeview(
            parent, columns=cols, show="headings", yscrollcommand=tree_scroll_y.set
        )
        tree_scroll_y.config(command=tree.yview)

        tree.heading("rate", text="T·ª∑ l·ªá Th·∫Øng")
        tree.column("rate", width=80, anchor=tk.W)
        tree.heading("hits", text="Tr√∫ng/Tr∆∞·ª£t")
        tree.column("hits", width=80, anchor=tk.W)
        tree.heading("params", text="C·∫•u h√¨nh Tham s·ªë")
        tree.column("params", width=300, anchor=tk.W)

        tree.pack(expand=True, fill=tk.BOTH)
        return tree

    def log(self, message):
        """Ghi log an to√†n v√†o Text box."""
        self.log_text.config(state=tk.NORMAL)
        self.log_text.insert(tk.END, message + "\n")
        self.log_text.see(tk.END)
        self.log_text.config(state=tk.DISABLED)
        self.root.update_idletasks()  # C·∫≠p nh·∫≠t UI ngay

    def clear_log(self):
        self.log_text.config(state=tk.NORMAL)
        self.log_text.delete("1.0", tk.END)
        self.log_text.config(state=tk.DISABLED)

    def clear_results_tree(self):
        for item in self.tree.get_children():
            self.tree.delete(item)

    def run_optimization(self):
        """L·∫•y t·∫•t c·∫£ c√†i ƒë·∫∑t v√† g·ªçi h√†m logic trong app ch√≠nh."""
        try:
            # 1. L·∫•y c√†i ƒë·∫∑t chi·∫øn l∆∞·ª£c
            strategy = self.strategy_var.get()
            days_to_test = int(self.days_to_test_var.get())

            if days_to_test <= 0:
                messagebox.showerror(
                    "L·ªói", "S·ªë ng√†y ki·ªÉm th·ª≠ ph·∫£i l·ªõn h∆°n 0.", parent=self
                )
                return

            # 2. L·∫•y c√°c tham s·ªë c·∫ßn ki·ªÉm th·ª≠
            param_ranges = {}
            for key, (check_var, from_var, to_var, step_var) in self.param_vars.items():
                if check_var.get():  # N·∫øu ƒë∆∞·ª£c ch·ªçn
                    val_from = float(from_var.get())
                    val_to = float(to_var.get())
                    val_step = float(step_var.get())

                    if val_step <= 0 or val_from > val_to:
                        messagebox.showerror(
                            "L·ªói Gi√° tr·ªã",
                            f"Kho·∫£ng gi√° tr·ªã cho '{key}' kh√¥ng h·ª£p l·ªá.",
                            parent=self,
                        )
                        return

                    # Chuy·ªÉn ƒë·ªïi tham s·ªë s·ªë nguy√™n sang int (v√≠ d·ª•: MAX_DEPTH, N_ESTIMATORS, RECENT_FORM)
                    if key in [
                        "GAN_DAYS",
                        "K2N_RISK_START_THRESHOLD",
                        "AI_MAX_DEPTH",
                        "AI_N_ESTIMATORS",
                        "RECENT_FORM_PERIODS",
                        "RECENT_FORM_MIN_HIGH",
                        "RECENT_FORM_MIN_MED",
                        "RECENT_FORM_MIN_LOW",
                    ]:
                        # Ki·ªÉm tra n·∫øu gi√° tr·ªã l√† s·ªë nguy√™n
                        if (
                            val_from != int(val_from)
                            or val_to != int(val_to)
                            or val_step != int(val_step)
                        ):
                            messagebox.showerror(
                                "L·ªói Gi√° tr·ªã",
                                f"'{key}' ph·∫£i l√† s·ªë nguy√™n.",
                                parent=self,
                            )
                            return
                        val_from = int(val_from)
                        val_to = int(val_to)
                        val_step = int(val_step)

                    param_ranges[key] = (val_from, val_to, val_step)

            if not param_ranges:
                messagebox.showwarning(
                    "Ch∆∞a ch·ªçn",
                    "Vui l√≤ng ch·ªçn √≠t nh·∫•t m·ªôt tham s·ªë ƒë·ªÉ t·ªëi ∆∞u h√≥a.",
                    parent=self,
                )
                return

            # 3. X√≥a log c≈© v√† chu·∫©n b·ªã
            self.clear_log()
            self.clear_results_tree()
            self.apply_button.config(state=tk.DISABLED)
            # S·ª≠a F541: X√≥a ti·ªÅn t·ªë 'f' kh√¥ng c·∫ßn thi·∫øt
            self.log("--- B·∫ÆT ƒê·∫¶U T·ªêI ∆ØU H√ìA CHI·∫æN L∆Ø·ª¢C ---")
            self.log(f"Chi·∫øn l∆∞·ª£c: {strategy}")
            self.log(f"S·ªë ng√†y ki·ªÉm th·ª≠: {days_to_test} ng√†y (t√≠nh t·ª´ ng√†y g·∫ßn nh·∫•t)")
            self.log("C√°c tham s·ªë ki·ªÉm th·ª≠:")
            for key, (f, t, s) in param_ranges.items():
                self.log(f" - {key}: T·ª´ {f} ƒë·∫øn {t} (b∆∞·ªõc {s})")
            # S·ª≠a F541: X√≥a ti·ªÅn t·ªë 'f' kh√¥ng c·∫ßn thi·∫øt
            self.log("C·∫¢NH B√ÅO: T√°c v·ª• n√†y r·∫•t n·∫∑ng v√† s·∫Ω m·∫•t nhi·ªÅu th·ªùi gian...")

            # 4. T·∫Øt n√∫t
            self.run_button.config(state=tk.DISABLED)

            # 5. G·ªçi h√†m logic trong app ch√≠nh (s·∫Ω ƒë∆∞·ª£c t·∫°o ·ªü B∆∞·ªõc 4)
            self.app.run_strategy_optimization(
                strategy, days_to_test, param_ranges, self
            )

        except ValueError:
            messagebox.showerror(
                "L·ªói Gi√° tr·ªã",
                "Gi√° tr·ªã 'S·ªë ng√†y', 'T·ª´', 'ƒê·∫øn', 'B∆∞·ªõc nh·∫£y' ph·∫£i l√† s·ªë.",
                parent=self,
            )
        except Exception as e:
            messagebox.showerror("L·ªói", f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}", parent=self)
            self.log(traceback.format_exc())

    def on_result_double_click(self, event):
        """(M·ªöI Gƒê 10) Khi double-click, h·ªèi ng∆∞·ªùi d√πng c√≥ mu·ªën √°p d·ª•ng c·∫•u h√¨nh n√†y kh√¥ng."""
        try:
            item_id = self.tree.focus()
            if not item_id:
                return

            # L·∫•y dict c·∫•u h√¨nh ƒë√£ l∆∞u
            config_dict = self.tree.item(item_id, "tags")[0]
            if not config_dict or not isinstance(config_dict, str):
                return

            # (H√†m n√†y s·∫Ω ƒë∆∞·ª£c t·∫°o ·ªü B∆∞·ªõc 4)
            self.app.apply_optimized_settings(
                config_dict_str=config_dict, optimizer_window=self
            )

        except Exception as e:
            self.log(f"L·ªói khi ch·ªçn k·∫øt qu·∫£: {e}")
            self.log(traceback.format_exc())

    def apply_best_settings(self):
        """√Åp d·ª•ng c·∫•u h√¨nh t·ªët nh·∫•t (d√≤ng ƒë·∫ßu ti√™n)."""
        try:
            children = self.tree.get_children()
            if not children:
                self.log("L·ªói: Kh√¥ng c√≥ k·∫øt qu·∫£ n√†o ƒë·ªÉ √°p d·ª•ng.")
                return

            item_id = children[0]  # L·∫•y d√≤ng ƒë·∫ßu ti√™n
            config_dict_str = self.tree.item(item_id, "tags")[0]
            if not config_dict_str or not isinstance(config_dict_str, str):
                self.log("L·ªói: Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu c·∫•u h√¨nh trong k·∫øt qu·∫£ t·ªët nh·∫•t.")
                return

            # (H√†m n√†y s·∫Ω ƒë∆∞·ª£c t·∫°o ·ªü B∆∞·ªõc 4)
            self.app.apply_optimized_settings(
                config_dict_str=config_dict_str, optimizer_window=self
            )

        except Exception as e:
            self.log(f"L·ªói khi √°p d·ª•ng k·∫øt qu·∫£ t·ªët nh·∫•t: {e}")
            self.log(traceback.format_exc())


--------------------------------------------------

=== FILE: ui\ui_results_viewer.py ===
import tkinter as tk
from tkinter import ttk


class ResultsViewerWindow:
    """Qu·∫£n l√Ω c·ª≠a s·ªï Toplevel hi·ªÉn th·ªã k·∫øt qu·∫£ backtest (Treeview)."""

    def __init__(self, app, title, results_data, show_save_button=False):
        self.app = app  # Tham chi·∫øu ƒë·∫øn DataAnalysisApp ch√≠nh
        self.root = app.root

        if not results_data:
            self.app.update_output(f"L·ªói: Kh√¥ng c√≥ k·∫øt qu·∫£ ƒë·ªÉ hi·ªÉn th·ªã cho {title}.")
            return

        self.window = tk.Toplevel(self.root)
        self.window.title(title)
        self.window.geometry("1000x600")

        frame = ttk.Frame(self.window, padding="5")
        frame.pack(expand=True, fill=tk.BOTH)

        headers = results_data[0]
        num_cols = len(headers)

        self.tree = ttk.Treeview(frame, columns=headers, show="headings")

        yscroll = ttk.Scrollbar(frame, orient=tk.VERTICAL, command=self.tree.yview)
        yscroll.pack(side=tk.RIGHT, fill=tk.Y)
        xscroll = ttk.Scrollbar(frame, orient=tk.HORIZONTAL, command=self.tree.xview)
        xscroll.pack(side=tk.BOTTOM, fill=tk.X)

        button_frame = ttk.Frame(frame)
        button_frame.pack(side=tk.BOTTOM, fill=tk.X, pady=5)

        copy_button = ttk.Button(
            button_frame,
            text="Copy To√†n B·ªô B·∫£ng (d√°n v√†o Excel)",
            command=lambda: self.copy_all_to_clipboard(results_data),
        )
        copy_button.pack(side=tk.LEFT, fill=tk.X, expand=True)

        if show_save_button:
            save_button = ttk.Button(
                button_frame,
                text="L∆∞u C·∫ßu ƒê√£ Ch·ªçn...",
                command=self.save_selected_bridge,
            )
            save_button.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=(10, 0))

        self.tree.configure(yscrollcommand=yscroll.set, xscrollcommand=xscroll.set)

        for col in headers:
            self.tree.heading(col, text=col)
            if col == headers[0]:
                self.tree.column(col, width=150, anchor=tk.W)
            elif "Chu·ªói K2N" in col:
                self.tree.column(col, width=150, anchor=tk.W)
            else:
                self.tree.column(col, width=120, anchor=tk.W)

        self.context_menu = tk.Menu(self.window, tearoff=0)
        self.show_save_button = show_save_button

        self.tree.bind("<Button-3>", self.on_right_click)
        self.tree.bind("<Button-2>", self.on_right_click)

        self.tree.tag_configure(
            "rate_row", background="lightyellow", font=("TkDefaultFont", 9, "bold")
        )
        self.tree.tag_configure(
            "streak_row", background="#E8F0E0", font=("TkDefaultFont", 9, "bold")
        )
        self.tree.tag_configure(
            "header_row", background="lightgray", font=("TkDefaultFont", 9, "bold")
        )
        self.tree.tag_configure(
            "final_row", background="#E0E8F0", font=("TkDefaultFont", 9, "bold")
        )

        for i, row in enumerate(results_data[1:]):
            if len(row) < num_cols:
                row.extend([""] * (num_cols - len(row)))
            elif len(row) > num_cols:
                row = row[:num_cols]

            tags_to_apply = ()
            if i == 0 and ("T·ª∑ L·ªá %" in str(row[0])):
                tags_to_apply = ("rate_row",)
            elif i == 1 and ("Chu·ªói K2N" in str(row[0])):
                tags_to_apply = ("streak_row",)
            elif i == 0 and "H·∫°ng" in str(row[0]):
                tags_to_apply = ("header_row",)
            elif i == 2 and (
                str(row[0]).startswith("K·ª≥") or str(row[0]).startswith("(Ch·ªù K·ª≥)")
            ):
                tags_to_apply = ("final_row",)

            self.tree.insert("", tk.END, values=row, tags=tags_to_apply)

        self.tree.pack(expand=True, fill=tk.BOTH)

    def copy_all_to_clipboard(self, data):
        try:
            tsv_string = ""
            for row in data:
                tsv_string += "\t".join(map(str, row)) + "\n"
            self.root.clipboard_clear()
            self.root.clipboard_append(tsv_string)
            self.app.update_output(
                f"ƒê√£ copy {len(data)} h√†ng v√†o clipboard (d·∫°ng TSV)."
            )
        except Exception as e:
            self.app.update_output(f"L·ªói khi copy to√†n b·ªô: {e}")

    def on_right_click(self, event):
        try:
            item_id = self.tree.identify_row(event.y)
            column_id = self.tree.identify_column(event.x)
            if not item_id:
                return
            col_index = int(column_id.replace("#", "")) - 1
            if col_index < 0:
                return
            cell_value = self.tree.item(item_id, "values")[col_index]

            self.context_menu.delete(0, "end")

            def copy_cell_to_clipboard():
                self.root.clipboard_clear()
                self.root.clipboard_append(cell_value)
                self.app.update_output(f"ƒê√£ copy: {cell_value}")

            self.context_menu.add_command(
                label=f"Copy '{cell_value}'", command=copy_cell_to_clipboard
            )

            if self.show_save_button:
                self.context_menu.add_separator()
                self.context_menu.add_command(
                    label="L∆∞u c·∫ßu n√†y...", command=self.save_selected_bridge
                )

            self.context_menu.tk_popup(event.x_root, event.y_root)
        except Exception as e:
            self.app.update_output(f"L·ªói menu chu·ªôt ph·∫£i: {e}")

    def save_selected_bridge(self):
        # G·ªçi l·∫°i h√†m _save_bridge_from_treeview c·ªßa app ch√≠nh
        self.app._save_bridge_from_treeview(self.tree)


--------------------------------------------------

=== FILE: ui\ui_settings.py ===
# T√™n file: git3/ui/ui_settings.py
#
# (N·ªòI DUNG THAY TH·∫æ TO√ÄN B·ªò - C·∫¨P NH·∫¨T NH√ÉN HI·ªÇN TH·ªä CHO ƒê√öNG LOGIC M·ªöI)
#
import tkinter as tk
import traceback
import threading
from tkinter import messagebox, ttk

# Import SETTINGS t·ª´ file config_manager
try:
    from logic.config_manager import SETTINGS
except ImportError:
    print("L·ªñI: ui_settings.py kh√¥ng th·ªÉ import logic.config_manager.")
    # T·∫°o ƒë·ªëi t∆∞·ª£ng gi·∫£ ƒë·ªÉ UI c√≥ th·ªÉ render
    SETTINGS = type(
        "obj",
        (object,),
        {
            "get_all_settings": lambda: {
                "STATS_DAYS": 7,
                "GAN_DAYS": 15,
                "HIGH_WIN_THRESHOLD": 47.0,
                "AUTO_ADD_MIN_RATE": 50.0,
                "AUTO_PRUNE_MIN_RATE": 40.0,
                "K2N_RISK_START_THRESHOLD": 6,
                "K2N_RISK_PENALTY_PER_FRAME": 1.0,
                "AI_PROB_THRESHOLD": 45.0,
                "AI_MAX_DEPTH": 6,
                "AI_N_ESTIMATORS": 200,
                "AI_LEARNING_RATE": 0.05,
                "AI_SCORE_WEIGHT": 0.2,
            },
            "update_setting": lambda k, v: (
                False,
                "L·ªói: Kh√¥ng t√¨m th·∫•y config_manager",
            ),
        },
    )


class SettingsWindow:
    """
    C·ª≠a s·ªï Toplevel ƒë·ªÉ qu·∫£n l√Ω file config.json.
    """

    def __init__(self, app):
        self.app = app
        self.root = app.root

        # NgƒÉn vi·ªác m·ªü nhi·ªÅu c·ª≠a s·ªï
        if (
            hasattr(self.app, "settings_window")
            and self.app.settings_window
            and self.app.settings_window.window.winfo_exists()
        ):
            self.app.settings_window.window.lift()
            return

        self.app.logger.log("ƒêang m·ªü c·ª≠a s·ªï C√†i ƒë·∫∑t...")

        self.window = tk.Toplevel(self.root)
        self.app.settings_window = self  # G√°n l·∫°i v√†o app ch√≠nh
        self.window.title("C√†i ƒë·∫∑t H·ªá th·ªëng")
        self.window.geometry("550x500")  # TƒÉng chi·ªÅu cao m·ªôt ch√∫t

        main_frame = ttk.Frame(self.window, padding="10")
        main_frame.pack(expand=True, fill=tk.BOTH)
        main_frame.columnconfigure(1, weight=1)

        # Dictionary ƒë·ªÉ gi·ªØ c√°c bi·∫øn Entry
        self.entries = {}

        # --- ƒê·ªãnh nghƒ©a c√°c c√†i ƒë·∫∑t ---
        # (T√™n key trong SETTINGS, T√™n hi·ªÉn th·ªã, Tooltip/Gi·∫£i th√≠ch)
        self.setting_definitions = [
            (
                "B·∫£ng T·ªïng H·ª£p",
                [
                    (
                        "STATS_DAYS",
                        "S·ªë ng√†y Th·ªëng k√™ Loto Hot",
                        "S·ªë ng√†y (v√≠ d·ª•: 7) d√πng ƒë·ªÉ t√≠nh loto v·ªÅ nhi·ªÅu.",
                    ),
                    (
                        "GAN_DAYS",
                        "S·ªë ng√†y t√≠nh L√¥ Gan",
                        "Loto kh√¥ng v·ªÅ trong s·ªë ng√†y n√†y s·∫Ω b·ªã coi l√† Gan (v√≠ d·ª•: 15).",
                    ),
                    (
                        "HIGH_WIN_THRESHOLD",
                        "Ng∆∞·ª°ng C·∫ßu T·ª∑ L·ªá Cao (%)",
                        "T·ª∑ l·ªá K2N t·ªëi thi·ªÉu ƒë·ªÉ m·ªôt c·∫ßu ƒë∆∞·ª£c coi l√† 'T·ª∑ L·ªá Cao' (v√≠ d·ª•: 47.0).",
                    ),
                    (
                        "AI_PROB_THRESHOLD",
                        "Ng∆∞·ª°ng K√≠ch Ho·∫°t AI (%)",
                        "X√°c su·∫•t t·ªëi thi·ªÉu ƒë·ªÉ d·ª± ƒëo√°n AI ƒë∆∞·ª£c t√≠nh ƒëi·ªÉm th∆∞·ªüng (v√≠ d·ª•: 45.0).",
                    ),
                ],
            ),
            (
                "C√†i ƒë·∫∑t M√¥ h√¨nh AI (XGBoost V7.1)",
                [
                    (
                        "AI_MAX_DEPTH",
                        "ƒê·ªô S√¢u C√¢y Max",
                        "ƒê·ªô s√¢u t·ªëi ƒëa c·ªßa c√¢y (v√≠ d·ª•: 6) - C·∫ßn Hu·∫•n luy·ªán l·∫°i.",
                    ),
                    (
                        "AI_N_ESTIMATORS",
                        "S·ªë l∆∞·ª£ng C√¢y (Estimators)",
                        "S·ªë l∆∞·ª£ng c√¢y trong r·ª´ng (v√≠ d·ª•: 200) - C·∫ßn Hu·∫•n luy·ªán l·∫°i.",
                    ),
                    (
                        "AI_LEARNING_RATE",
                        "T·ªëc ƒë·ªô h·ªçc (Learning Rate)",
                        "T·ªëc ƒë·ªô h·ªçc c·ªßa m√¥ h√¨nh GBM (v√≠ d·ª•: 0.05) - C·∫ßn Hu·∫•n luy·ªán l·∫°i.",
                    ),
                    (
                        "AI_SCORE_WEIGHT",
                        "Tr·ªçng s·ªë ƒêi·ªÉm AI",
                        "M·ª©c ƒë·ªô ·∫£nh h∆∞·ªüng c·ªßa x√°c su·∫•t AI l√™n ƒëi·ªÉm t·ªïng l·ª±c (v√≠ d·ª•: 0.2).",
                    ),
                ],
            ),
            (
                "T·ª± ƒë·ªông D√≤ C·∫ßu",
                [
                    (
                        "AUTO_ADD_MIN_RATE",
                        "Ng∆∞·ª°ng Th√™m C·∫ßu M·ªõi (%)",
                        "Khi d√≤ c·∫ßu (V17+BN), t·ª± ƒë·ªông th√™m n·∫øu t·ª∑ l·ªá N1 > X (v√≠ d·ª•: 50.0).",
                    ),
                    (
                        "AUTO_PRUNE_MIN_RATE",
                        "Ng∆∞·ª°ng L·ªçc C·∫ßu Y·∫øu (%)",
                        "Khi l·ªçc c·∫ßu, t·ª± ƒë·ªông T·∫ÆT n·∫øu t·ª∑ l·ªá K2N < X (v√≠ d·ª•: 40.0).",
                    ),
                ],
            ),
            (
                "Qu·∫£n l√Ω R·ªßi ro K2N",
                [
                    (
                        "K2N_RISK_START_THRESHOLD",
                        "Ng∆∞·ª°ng b·∫Øt ƒë·∫ßu ph·∫°t (khung)",
                        "B·∫Øt ƒë·∫ßu tr·ª´ ƒëi·ªÉm n·∫øu Chu·ªói Thua Max > X (v√≠ d·ª•: 6).",
                    ),
                    # (S·ª¨A ƒê·ªîI NH√ÉN HI·ªÇN TH·ªä CHO ƒê√öNG LOGIC M·ªöI)
                    (
                        "K2N_RISK_PENALTY_PER_FRAME",
                        "ƒêi·ªÉm ph·∫°t C·ªê ƒê·ªäNH",
                        "Tr·ª´ X ƒëi·ªÉm c·ªë ƒë·ªãnh 1 l·∫ßn n·∫øu c·∫ßu v∆∞·ª£t ng∆∞·ª°ng r·ªßi ro (v√≠ d·ª•: 1.0).",
                    ),
                ],
            ),
            (
                "Ch·∫•m ƒêi·ªÉm Phong ƒê·ªô",
                [
                    (
                        "RECENT_FORM_PERIODS",
                        "S·ªë k·ª≥ x√©t phong ƒë·ªô",
                        "X√©t phong ƒë·ªô trong X k·ª≥ g·∫ßn nh·∫•t (v√≠ d·ª•: 10).",
                    ),
                    (
                        "RECENT_FORM_MIN_HIGH",
                        "Ng∆∞·ª°ng phong ƒë·ªô r·∫•t cao",
                        "S·ªë l·∫ßn ƒÉn t·ªëi thi·ªÉu cho phong ƒë·ªô r·∫•t cao (v√≠ d·ª•: 8).",
                    ),
                    (
                        "RECENT_FORM_BONUS_HIGH",
                        "ƒêi·ªÉm th∆∞·ªüng phong ƒë·ªô r·∫•t cao",
                        "ƒêi·ªÉm c·ªông cho phong ƒë·ªô r·∫•t cao (v√≠ d·ª•: 3.0).",
                    ),
                    (
                        "RECENT_FORM_MIN_MED",
                        "Ng∆∞·ª°ng phong ƒë·ªô t·ªët",
                        "S·ªë l·∫ßn ƒÉn t·ªëi thi·ªÉu cho phong ƒë·ªô t·ªët (v√≠ d·ª•: 6).",
                    ),
                    (
                        "RECENT_FORM_BONUS_MED",
                        "ƒêi·ªÉm th∆∞·ªüng phong ƒë·ªô t·ªët",
                        "ƒêi·ªÉm c·ªông cho phong ƒë·ªô t·ªët (v√≠ d·ª•: 2.0).",
                    ),
                    (
                        "RECENT_FORM_MIN_LOW",
                        "Ng∆∞·ª°ng phong ƒë·ªô ·ªïn",
                        "S·ªë l·∫ßn ƒÉn t·ªëi thi·ªÉu cho phong ƒë·ªô ·ªïn (v√≠ d·ª•: 5).",
                    ),
                    (
                        "RECENT_FORM_BONUS_LOW",
                        "ƒêi·ªÉm th∆∞·ªüng phong ƒë·ªô ·ªïn",
                        "ƒêi·ªÉm c·ªông cho phong ƒë·ªô ·ªïn (v√≠ d·ª•: 1.0).",
                    ),
                ],
            ),
        ]

        # --- T·∫°o c√°c √¥ nh·∫≠p li·ªáu ---
        current_row = 0
        current_settings = SETTINGS.get_all_settings()

        for group_name, settings in self.setting_definitions:
            # Ti√™u ƒë·ªÅ nh√≥m
            group_label = ttk.Label(
                main_frame, text=group_name, font=("TkDefaultFont", 11, "bold")
            )
            group_label.grid(
                row=current_row,
                column=0,
                columnspan=3,
                sticky="w",
                padx=5,
                pady=(10, 2),
            )
            current_row += 1

            for key, label, tooltip in settings:
                ttk.Label(main_frame, text=label + ":").grid(
                    row=current_row, column=0, sticky="w", padx=5, pady=3
                )

                # L·∫•y gi√° tr·ªã hi·ªán t·∫°i
                val = current_settings.get(key, "")
                entry_var = tk.StringVar(value=str(val))

                entry_widget = ttk.Entry(main_frame, textvariable=entry_var)
                entry_widget.grid(
                    row=current_row, column=1, sticky="ew", padx=5, pady=3
                )

                ttk.Label(
                    main_frame, text=f"({tooltip})", style="TLabel", foreground="gray"
                ).grid(row=current_row, column=2, sticky="w", padx=5, pady=3)

                self.entries[key] = entry_var  # L∆∞u bi·∫øn, kh√¥ng ph·∫£i widget
                current_row += 1

        # --- 4. C·∫•u H√¨nh Hi·ªáu NƒÉng (M·ªöI) ---
        grp_perf = ttk.LabelFrame(main_frame, text="4. C·∫•u H√¨nh Hi·ªáu NƒÉng (Data Slicing)", padding="10")
        grp_perf.grid(row=current_row, column=0, columnspan=3, sticky="ew", padx=5, pady=5)
        grp_perf.columnconfigure(1, weight=1)
        current_row += 1

        # Gi·ªõi h·∫°n d·ªØ li·ªáu Dashboard
        ttk.Label(grp_perf, text="Gi·ªõi h·∫°n d·ªØ li·ªáu Dashboard (0 = Full):").grid(
            row=0, column=0, sticky="w", padx=5, pady=3
        )
        val_dashboard = current_settings.get("DATA_LIMIT_DASHBOARD", "0")
        entry_dashboard_var = tk.StringVar(value=str(val_dashboard))
        entry_dashboard = ttk.Entry(grp_perf, textvariable=entry_dashboard_var)
        entry_dashboard.grid(
            row=0, column=1, sticky="ew", padx=5, pady=3
        )
        self.entries["DATA_LIMIT_DASHBOARD"] = entry_dashboard_var

        # Gi·ªõi h·∫°n d·ªØ li·ªáu T·ªëi ∆Øu H√≥a
        ttk.Label(grp_perf, text="Gi·ªõi h·∫°n d·ªØ li·ªáu T·ªëi ∆Øu H√≥a (0 = Full):").grid(
            row=1, column=0, sticky="w", padx=5, pady=3
        )
        val_research = current_settings.get("DATA_LIMIT_RESEARCH", "0")
        entry_research_var = tk.StringVar(value=str(val_research))
        entry_research = ttk.Entry(grp_perf, textvariable=entry_research_var)
        entry_research.grid(
            row=1, column=1, sticky="ew", padx=5, pady=3
        )
        self.entries["DATA_LIMIT_RESEARCH"] = entry_research_var

        # Gi·ªõi h·∫°n d·ªØ li·ªáu Qu√©t C·∫ßu
        ttk.Label(grp_perf, text="Gi·ªõi h·∫°n d·ªØ li·ªáu Qu√©t C·∫ßu (0 = Full):").grid(
            row=2, column=0, sticky="w", padx=5, pady=3
        )
        val_scanner = current_settings.get("DATA_LIMIT_SCANNER", "2")
        entry_scanner_var = tk.StringVar(value=str(val_scanner))
        entry_scanner = ttk.Entry(grp_perf, textvariable=entry_scanner_var)
        entry_scanner.grid(
            row=2, column=1, sticky="ew", padx=5, pady=3
        )
        self.entries["DATA_LIMIT_SCANNER"] = entry_scanner_var

        # Label gi·∫£i th√≠ch chung
        ttk.Label(
            grp_perf, 
            text="* Gi·∫£m s·ªë l∆∞·ª£ng k·ª≥ gi√∫p tƒÉng t·ªëc ƒë·ªô x·ª≠ l√Ω.", 
            font=("Arial", 8, "italic"), 
            foreground="gray"
        ).grid(row=3, column=1, sticky="w", padx=5, pady=(0, 5))

        # --- N√∫t L∆∞u ---
        save_button = ttk.Button(
            main_frame, text="L∆∞u C√†i ƒë·∫∑t", command=self.save_all_settings
        )
        save_button.grid(
            row=current_row, column=0, columnspan=3, sticky="ew", padx=5, pady=(15, 5)
        )

        current_row += 1

        # --- N√∫t N·∫°p 756 C·∫ßu B·∫°c Nh·ªõ ---
        load_memory_button = ttk.Button(
            main_frame, text="N·∫°p 756 C·∫ßu B·∫°c Nh·ªõ", command=self.load_756_memory_bridges
        )
        load_memory_button.grid(
            row=current_row, column=0, columnspan=3, sticky="ew", padx=5, pady=(5, 5)
        )

    def save_all_settings(self):
        """L·∫∑p qua t·∫•t c·∫£ c√°c √¥ Entry v√† l∆∞u c√†i ƒë·∫∑t."""
        self.app.logger.log("ƒêang l∆∞u c√†i ƒë·∫∑t...")
        try:
            any_errors = False
            for key, entry_var in self.entries.items():
                new_value = entry_var.get()

                # G·ªçi h√†m update c·ªßa config_manager
                success, message = SETTINGS.update_setting(key, new_value)

                if not success:
                    any_errors = True
                    self.app.logger.log(f"L·ªñI: {message}")

            if any_errors:
                messagebox.showerror(
                    "L·ªói L∆∞u",
                    "M·ªôt s·ªë c√†i ƒë·∫∑t c√≥ l·ªói. Vui l√≤ng ki·ªÉm tra log.",
                    parent=self.window,
                )
            else:
                self.app.logger.log("ƒê√£ l∆∞u t·∫•t c·∫£ c√†i ƒë·∫∑t v√†o config.json.")
                messagebox.showinfo(
                    "Th√†nh c√¥ng",
                    "ƒê√£ l∆∞u t·∫•t c·∫£ c√†i ƒë·∫∑t th√†nh c√¥ng!",
                    parent=self.window,
                )
                self.window.destroy()  # ƒê√≥ng c·ª≠a s·ªï sau khi l∆∞u

        except Exception as e:
            messagebox.showerror(
                "L·ªói Nghi√™m Tr·ªçng", f"Kh√¥ng th·ªÉ l∆∞u c√†i ƒë·∫∑t: {e}", parent=self.window
            )
            self.app.logger.log(traceback.format_exc())

    def load_756_memory_bridges(self):
        """N·∫°p 756 c·∫ßu B·∫°c Nh·ªõ v√†o database v·ªõi progress bar."""
        # Create a custom dialog with options
        dialog = tk.Toplevel(self.window)
        dialog.title("N·∫°p 756 C·∫ßu B·∫°c Nh·ªõ")
        dialog.geometry("500x250")
        dialog.transient(self.window)
        dialog.grab_set()

        # Dialog content
        ttk.Label(
            dialog,
            text="B·∫°n c√≥ ch·∫Øc mu·ªën th√™m 756 c·∫ßu B·∫°c Nh·ªõ v√†o database?",
            font=("TkDefaultFont", 10, "bold")
        ).pack(pady=(20, 10))

        ttk.Label(
            dialog,
            text="L∆∞u √Ω: C·∫ßu tr√πng s·∫Ω ƒë∆∞·ª£c b·ªè qua",
            font=("TkDefaultFont", 9)
        ).pack(pady=5)

        # Option for enabling all bridges
        enable_var = tk.BooleanVar(value=False)
        enable_check = ttk.Checkbutton(
            dialog,
            text="B·∫¨T t·∫•t c·∫£ c·∫ßu ƒë·ªÉ ph√¢n t√≠ch ngay (khuy·∫øn ngh·ªã)",
            variable=enable_var
        )
        enable_check.pack(pady=10)

        ttk.Label(
            dialog,
            text="üí° N·∫øu b·∫≠t: T·∫•t c·∫£ 756 c·∫ßu s·∫Ω ƒë∆∞·ª£c B·∫¨T ƒë·ªÉ backtest t√≠nh t·ª∑ l·ªá ƒÉn.\n"
                 "Sau ƒë√≥ d√πng 'L·ªçc C·∫ßu Y·∫øu' ƒë·ªÉ t·ª± ƒë·ªông T·∫ÆT c·∫ßu c√≥ t·ª∑ l·ªá th·∫•p.",
            font=("TkDefaultFont", 8),
            foreground="blue",
            wraplength=450,
            justify="left"
        ).pack(pady=5)

        ttk.Label(
            dialog,
            text="N·∫øu kh√¥ng b·∫≠t: C·∫ßu s·∫Ω T·∫ÆT, b·∫°n ph·∫£i B·∫¨T th·ªß c√¥ng t·ª´ng c·∫ßu.",
            font=("TkDefaultFont", 8),
            foreground="gray",
            wraplength=450,
            justify="left"
        ).pack(pady=5)

        # Store result
        result = {"confirmed": False, "enable_all": False}

        def on_ok():
            result["confirmed"] = True
            result["enable_all"] = enable_var.get()
            dialog.destroy()

        def on_cancel():
            dialog.destroy()

        # Buttons
        button_frame = ttk.Frame(dialog)
        button_frame.pack(pady=20)

        ttk.Button(button_frame, text="OK", command=on_ok, width=10).pack(side=tk.LEFT, padx=5)
        ttk.Button(button_frame, text="H·ªßy", command=on_cancel, width=10).pack(side=tk.LEFT, padx=5)

        # Wait for dialog to close
        self.window.wait_window(dialog)

        if not result["confirmed"]:
            return

        enable_all = result["enable_all"]

        # T·∫°o progress window
        progress_window = tk.Toplevel(self.window)
        progress_window.title("ƒêang n·∫°p c·∫ßu...")
        progress_window.geometry("400x150")
        progress_window.transient(self.window)
        progress_window.grab_set()

        # Progress label
        progress_label = ttk.Label(
            progress_window,
            text="ƒêang chu·∫©n b·ªã...",
            font=("TkDefaultFont", 10)
        )
        progress_label.pack(pady=(20, 10))

        # Progress bar
        progress_bar = ttk.Progressbar(
            progress_window,
            mode="determinate",
            length=350
        )
        progress_bar.pack(pady=10, padx=25)

        # Status label
        status_label = ttk.Label(
            progress_window,
            text="0/756",
            font=("TkDefaultFont", 9)
        )
        status_label.pack(pady=5)

        # Import the function
        try:
            from logic.bridges.bridge_manager_core import init_all_756_memory_bridges_to_db
        except ImportError as e:
            messagebox.showerror(
                "L·ªói Import",
                f"Kh√¥ng th·ªÉ import h√†m n·∫°p c·∫ßu: {e}",
                parent=self.window
            )
            progress_window.destroy()
            return

        # Progress callback
        def update_progress(current, total, message):
            progress_bar["maximum"] = total
            progress_bar["value"] = current
            progress_label["text"] = message
            status_label["text"] = f"{current}/{total}"
            progress_window.update()

        # Run the import in a separate thread to keep UI responsive

        result_container = {}

        def do_import():
            try:
                success, message, added, skipped = init_all_756_memory_bridges_to_db(
                    progress_callback=update_progress,
                    enable_all=enable_all
                )
                result_container["success"] = success
                result_container["message"] = message
                result_container["added"] = added
                result_container["skipped"] = skipped
                result_container["enable_all"] = enable_all
            except Exception as e:
                result_container["success"] = False
                result_container["message"] = f"L·ªói: {e}"
                result_container["error"] = str(e)

        # Start import thread
        import_thread = threading.Thread(target=do_import)
        import_thread.start()

        # Wait for thread to complete
        while import_thread.is_alive():
            progress_window.update()
            import_thread.join(timeout=0.1)

        # Close progress window
        progress_window.destroy()

        # Show result
        if result_container.get("success"):
            self.app.logger.log(result_container["message"])

            # Build success message with next steps
            success_msg = result_container["message"]
            if result_container.get("enable_all"):
                success_msg += "\n\n‚úÖ T·∫•t c·∫£ c·∫ßu ƒë√£ ƒë∆∞·ª£c B·∫¨T.\n\n"
                success_msg += "üîÑ B∆∞·ªõc ti·∫øp theo:\n"
                success_msg += "1. Ch·∫°y 'C·∫≠p Nh·∫≠t Cache K2N' ƒë·ªÉ t√≠nh t·ª∑ l·ªá ƒÉn\n"
                success_msg += "2. D√πng 'L·ªçc C·∫ßu Y·∫øu' ƒë·ªÉ T·∫ÆT c·∫ßu c√≥ t·ª∑ l·ªá th·∫•p\n"
                success_msg += "3. Ch·∫°y Backtest v·ªõi c√°c c·∫ßu c√≤n l·∫°i"
            else:
                success_msg += "\n\n‚ö†Ô∏è C·∫ßu ƒëang ·ªü tr·∫°ng th√°i T·∫ÆT.\n\n"
                success_msg += "B·∫°n c·∫ßn B·∫¨T c·∫ßu th·ªß c√¥ng trong 'Qu·∫£n L√Ω C·∫ßu' tr∆∞·ªõc khi backtest."

            messagebox.showinfo(
                "Th√†nh c√¥ng",
                success_msg,
                parent=self.window
            )
        else:
            error_msg = result_container.get("message", "L·ªói kh√¥ng x√°c ƒë·ªãnh")
            self.app.logger.log(f"L·ªñI: {error_msg}")
            messagebox.showerror(
                "L·ªói",
                error_msg,
                parent=self.window
            )


--------------------------------------------------

=== FILE: ui\ui_tuner.py ===
# T√™n file: git1/ui/ui_tuner.py
#
# (PHI√äN B·∫¢N V7.9 - FIXED ATTRIBUTE ERROR UPDATE_OUTPUT)
#
import tkinter as tk
import traceback
from tkinter import messagebox, ttk

# (M·ªöI Gƒê 9) Import SETTINGS ƒë·ªÉ l·∫•y gi√° tr·ªã hi·ªán t·∫°i
try:
    from logic.config_manager import SETTINGS
except ImportError:
    print("L·ªñI: ui_tuner.py kh√¥ng th·ªÉ import logic.config_manager.")
    SETTINGS = None


class TunerWindow:
    """
    (M·ªöI Gƒê 9) C·ª≠a s·ªï "Tr·ª£ l√Ω Tinh ch·ªânh Tham s·ªë".
    Gi√∫p ng∆∞·ªùi d√πng backtest c√°c tham s·ªë trong config.json.
    """

    def __init__(self, app):
        self.app = app
        self.root = app.root

        if (
            hasattr(self.app, "tuner_window")
            and self.app.tuner_window
            and self.app.tuner_window.window.winfo_exists()
        ):
            self.app.tuner_window.window.lift()
            return

        # [FIX] S·ª≠ d·ª•ng logger.log thay v√¨ update_output (h√†m c≈© kh√¥ng t·ªìn t·∫°i)
        if hasattr(self.app, 'logger'):
            self.app.logger.log("ƒêang m·ªü Tr·ª£ l√Ω Tinh ch·ªânh Tham s·ªë...")

        self.window = tk.Toplevel(self.root)
        self.app.tuner_window = self  # G√°n l·∫°i v√†o app ch√≠nh
        self.window.title("Tr·ª£ l√Ω Tinh ch·ªânh Tham s·ªë")
        self.window.geometry("700x500")

        main_frame = ttk.Frame(self.window, padding="10")
        main_frame.pack(expand=True, fill=tk.BOTH)
        main_frame.rowconfigure(2, weight=1)  # Khung log s·∫Ω co gi√£n
        main_frame.columnconfigure(0, weight=1)

        # --- Khung C√†i ƒë·∫∑t ---
        settings_frame = ttk.Labelframe(
            main_frame, text="1. Ch·ªçn Tham s·ªë ƒë·ªÉ Ki·ªÉm th·ª≠", padding="10"
        )
        settings_frame.grid(row=0, column=0, sticky="ew")
        settings_frame.columnconfigure(1, weight=1)

        # Danh s√°ch c√°c tham s·ªë c√≥ th·ªÉ ki·ªÉm th·ª≠
        # (Key trong SETTINGS, T√™n hi·ªÉn th·ªã)
        self.tunable_parameters = {
            "GAN_DAYS": "S·ªë ng√†y t√≠nh L√¥ Gan",
            "HIGH_WIN_THRESHOLD": "Ng∆∞·ª°ng C·∫ßu T·ª∑ L·ªá Cao (%)",
            "AUTO_ADD_MIN_RATE": "Ng∆∞·ª°ng Th√™m C·∫ßu M·ªõi (%)",
            "AUTO_PRUNE_MIN_RATE": "Ng∆∞·ª°ng L·ªçc C·∫ßu Y·∫øu (%)",
            "K2N_RISK_START_THRESHOLD": "Ng∆∞·ª°ng ph·∫°t K2N (khung thua)",
            "K2N_RISK_PENALTY_PER_FRAME": "ƒêi·ªÉm ph·∫°t K2N / khung",
            "RECENT_FORM_PERIODS": "S·ªë k·ª≥ x√©t phong ƒë·ªô",
            "RECENT_FORM_MIN_HIGH": "Ng∆∞·ª°ng phong ƒë·ªô r·∫•t cao",
            "RECENT_FORM_BONUS_HIGH": "ƒêi·ªÉm th∆∞·ªüng phong ƒë·ªô r·∫•t cao",
            "RECENT_FORM_MIN_MED": "Ng∆∞·ª°ng phong ƒë·ªô t·ªët",
            "RECENT_FORM_BONUS_MED": "ƒêi·ªÉm th∆∞·ªüng phong ƒë·ªô t·ªët",
            "RECENT_FORM_MIN_LOW": "Ng∆∞·ª°ng phong ƒë·ªô ·ªïn",
            "RECENT_FORM_BONUS_LOW": "ƒêi·ªÉm th∆∞·ªüng phong ƒë·ªô ·ªïn",
        }

        ttk.Label(settings_frame, text="Ch·ªçn tham s·ªë:").grid(
            row=0, column=0, sticky="w", padx=5, pady=5
        )
        self.param_var = tk.StringVar()
        param_dropdown = ttk.Combobox(
            settings_frame,
            textvariable=self.param_var,
            values=list(self.tunable_parameters.values()),
            state="readonly",
            width=30,
        )
        param_dropdown.grid(row=0, column=1, columnspan=3, sticky="ew", padx=5, pady=5)
        param_dropdown.bind("<<ComboboxSelected>>", self.on_param_select)

        # --- Khung Gi√° tr·ªã ---
        range_frame = ttk.Frame(settings_frame)
        range_frame.grid(row=1, column=0, columnspan=4, sticky="ew", pady=5)
        range_frame.columnconfigure(1, weight=1)
        range_frame.columnconfigure(3, weight=1)
        range_frame.columnconfigure(5, weight=1)

        ttk.Label(range_frame, text="T·ª´:").grid(row=0, column=0, sticky="w", padx=5)
        self.from_var = tk.StringVar()
        self.from_entry = ttk.Entry(range_frame, textvariable=self.from_var, width=10)
        self.from_entry.grid(row=0, column=1, sticky="ew", padx=(0, 10))

        ttk.Label(range_frame, text="ƒê·∫øn:").grid(row=0, column=2, sticky="w", padx=5)
        self.to_var = tk.StringVar()
        self.to_entry = ttk.Entry(range_frame, textvariable=self.to_var, width=10)
        self.to_entry.grid(row=0, column=3, sticky="ew", padx=(0, 10))

        ttk.Label(range_frame, text="B∆∞·ªõc nh·∫£y:").grid(
            row=0, column=4, sticky="w", padx=5
        )
        self.step_var = tk.StringVar(value="1")  # M·∫∑c ƒë·ªãnh b∆∞·ªõc nh·∫£y l√† 1
        self.step_entry = ttk.Entry(range_frame, textvariable=self.step_var, width=10)
        self.step_entry.grid(row=0, column=5, sticky="ew")

        # --- N√∫t Ch·∫°y ---
        self.run_button = ttk.Button(
            main_frame, text="Ch·∫°y Ph√¢n t√≠ch Tinh ch·ªânh", command=self.run_tuning
        )
        self.run_button.grid(row=1, column=0, sticky="ew", padx=10, pady=10)

        # --- Khung Log K·∫øt qu·∫£ ---
        log_frame = ttk.Labelframe(
            main_frame, text="2. K·∫øt qu·∫£ Ph√¢n t√≠ch", padding="10"
        )
        log_frame.grid(row=2, column=0, sticky="nsew", padx=10)
        log_frame.rowconfigure(0, weight=1)
        log_frame.columnconfigure(0, weight=1)

        log_scrollbar = ttk.Scrollbar(log_frame, orient=tk.VERTICAL)
        log_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)

        self.log_text = tk.Text(
            log_frame,
            height=15,
            width=80,
            font=("Courier New", 10),
            yscrollcommand=log_scrollbar.set,
        )
        self.log_text.pack(expand=True, fill=tk.BOTH)
        log_scrollbar.config(command=self.log_text.yview)
        self.log_text.config(state=tk.DISABLED)

    def on_param_select(self, event):
        """Khi ng∆∞·ªùi d√πng ch·ªçn m·ªôt tham s·ªë, t·ª± ƒë·ªông ƒëi·ªÅn gi√° tr·ªã hi·ªán t·∫°i."""
        if not SETTINGS:
            return

        selected_name = self.param_var.get()
        # T√¨m key t·ª´ value
        selected_key = next(
            (
                key
                for key, value in self.tunable_parameters.items()
                if value == selected_name
            ),
            None,
        )

        if selected_key:
            current_value = SETTINGS.get_all_settings().get(selected_key)
            if current_value is not None:
                self.from_var.set(str(current_value))
                self.to_var.set(str(current_value))
                # G·ª£i √Ω b∆∞·ªõc nh·∫£y
                if isinstance(current_value, float):
                    self.step_var.set("0.1")
                else:
                    self.step_var.set("1")

    def log(self, message):
        """Ghi log an to√†n v√†o Text box."""
        self.log_text.config(state=tk.NORMAL)
        self.log_text.insert(tk.END, message + "\n")
        self.log_text.see(tk.END)
        self.log_text.config(state=tk.DISABLED)
        self.window.update_idletasks()  # C·∫≠p nh·∫≠t UI ngay

    def clear_log(self):
        self.log_text.config(state=tk.NORMAL)
        self.log_text.delete("1.0", tk.END)
        self.log_text.config(state=tk.DISABLED)

    def run_tuning(self):
        """L·∫•y gi√° tr·ªã v√† g·ªçi h√†m logic trong app ch√≠nh."""
        try:
            # 1. L·∫•y tham s·ªë
            selected_name = self.param_var.get()
            param_key = next(
                (
                    key
                    for key, value in self.tunable_parameters.items()
                    if value == selected_name
                ),
                None,
            )
            if not param_key:
                messagebox.showerror(
                    "L·ªói", "Vui l√≤ng ch·ªçn m·ªôt tham s·ªë.", parent=self.window
                )
                return

            # 2. L·∫•y gi√° tr·ªã (v√† ki·ªÉm tra)
            val_from = float(self.from_var.get())
            val_to = float(self.to_var.get())
            val_step = float(self.step_var.get())

            if val_step <= 0:
                messagebox.showerror(
                    "L·ªói", "B∆∞·ªõc nh·∫£y ph·∫£i l·ªõn h∆°n 0.", parent=self.window
                )
                return
            if val_from > val_to:
                messagebox.showerror(
                    "L·ªói",
                    "Gi√° tr·ªã 'T·ª´' kh√¥ng th·ªÉ l·ªõn h∆°n gi√° tr·ªã 'ƒê·∫øn'.",
                    parent=self.window,
                )
                return

            # 3. X√≥a log c≈© v√† chu·∫©n b·ªã
            self.clear_log()
            # S·ª≠a F541: X√≥a ti·ªÅn t·ªë 'f' kh√¥ng c·∫ßn thi·∫øt
            self.log("--- B·∫ÆT ƒê·∫¶U KI·ªÇM TH·ª¨ THAM S·ªê ---")
            self.log(f"Tham s·ªë: {selected_name} ({param_key})")
            self.log(
                f"Kho·∫£ng ki·ªÉm th·ª≠: T·ª´ {val_from} ƒë·∫øn {val_to}, b∆∞·ªõc nh·∫£y {val_step}"
            )
            self.log("Vui l√≤ng ch·ªù...")

            # 4. T·∫Øt n√∫t
            self.run_button.config(state=tk.DISABLED)

            # 5. G·ªçi h√†m logic trong app ch√≠nh (s·∫Ω ƒë∆∞·ª£c t·∫°o ·ªü B∆∞·ªõc 2)
            # H√†m n√†y s·∫Ω t·ª± ch·∫°y ƒëa lu·ªìng
            self.app.run_parameter_tuning(param_key, val_from, val_to, val_step, self)

        except ValueError:
            messagebox.showerror(
                "L·ªói Gi√° tr·ªã",
                "Gi√° tr·ªã 'T·ª´', 'ƒê·∫øn', 'B∆∞·ªõc nh·∫£y' ph·∫£i l√† s·ªë.",
                parent=self.window,
            )
        except Exception as e:
            messagebox.showerror("L·ªói", f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}", parent=self.window)
            self.log(traceback.format_exc())

--------------------------------------------------

=== FILE: ui\ui_vote_statistics.py ===
# ui/ui_vote_statistics.py
# B·∫£ng th·ªëng k√™ Vote - Hi·ªÉn th·ªã c·∫∑p s·ªë ƒë∆∞·ª£c d·ª± ƒëo√°n b·ªüi bao nhi√™u c·∫ßu

import tkinter as tk
from tkinter import ttk, messagebox

try:
    from lottery_service import get_prediction_consensus
except ImportError:
    print("L·ªñI: ui_vote_statistics.py kh√¥ng th·ªÉ import lottery_service.")

    def get_prediction_consensus():
        return []


class VoteStatisticsWindow:
    """C·ª≠a s·ªï hi·ªÉn th·ªã th·ªëng k√™ vote cho c√°c c·∫∑p s·ªë d·ª± ƒëo√°n."""

    def __init__(self, app):
        self.app = app
        self.root = app.root

        # NgƒÉn m·ªü nhi·ªÅu c·ª≠a s·ªï
        if (
            hasattr(self.app, "vote_stats_window")
            and self.app.vote_stats_window
            and self.app.vote_stats_window.winfo_exists()
        ):
            self.app.vote_stats_window.lift()
            return

        self.app.logger.log("ƒêang m·ªü c·ª≠a s·ªï Th·ªëng K√™ Vote...")

        self.window = tk.Toplevel(self.root)
        self.window.title("üìä Th·ªëng K√™ Vote - C·∫∑p S·ªë D·ª± ƒêo√°n")
        self.app.vote_stats_window = self.window
        self.window.geometry("700x500")

        self.window.transient(self.root)
        self.window.grab_set()

        # Main frame
        main_frame = ttk.Frame(self.window, padding=10)
        main_frame.pack(fill=tk.BOTH, expand=True)

        # Title v√† description
        title_label = ttk.Label(
            main_frame,
            text="üìä Th·ªëng K√™ Vote Theo C·∫∑p S·ªë",
            font=("TkDefaultFont", 12, "bold"),
        )
        title_label.pack(pady=(0, 5))

        desc_label = ttk.Label(
            main_frame,
            text="Hi·ªÉn th·ªã c·∫∑p s·ªë ƒë∆∞·ª£c d·ª± ƒëo√°n b·ªüi bao nhi√™u c·∫ßu.\n"
            "Vote c√†ng cao = c√†ng nhi·ªÅu c·∫ßu ƒë·ªìng thu·∫≠n d·ª± ƒëo√°n c·∫∑p s·ªë ƒë√≥.",
            font=("TkDefaultFont", 9),
            foreground="gray",
        )
        desc_label.pack(pady=(0, 10))

        # Treeview frame v·ªõi scrollbar
        tree_frame = ttk.Frame(main_frame)
        tree_frame.pack(fill=tk.BOTH, expand=True)

        # Scrollbars
        tree_scroll = ttk.Scrollbar(tree_frame, orient="vertical")
        tree_scroll.pack(side=tk.RIGHT, fill=tk.Y)

        tree_scroll_h = ttk.Scrollbar(tree_frame, orient="horizontal")
        tree_scroll_h.pack(side=tk.BOTTOM, fill=tk.X)

        # Treeview
        self.tree = ttk.Treeview(
            tree_frame,
            columns=("Pair", "VoteCount", "Bridges"),
            show="headings",
            yscrollcommand=tree_scroll.set,
            xscrollcommand=tree_scroll_h.set,
        )

        tree_scroll.config(command=self.tree.yview)
        tree_scroll_h.config(command=self.tree.xview)

        # Column headers
        self.tree.heading("Pair", text="C·∫∑p S·ªë")
        self.tree.heading("VoteCount", text="S·ªë Vote")
        self.tree.heading("Bridges", text="C√°c C·∫ßu D·ª± ƒêo√°n")

        # Column widths
        self.tree.column("Pair", width=100, stretch=False, anchor="center")
        self.tree.column("VoteCount", width=80, stretch=False, anchor="center")
        self.tree.column("Bridges", width=450, stretch=True, anchor="w")

        self.tree.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)

        # Buttons frame
        button_frame = ttk.Frame(main_frame)
        button_frame.pack(fill=tk.X, pady=(10, 0))

        refresh_button = ttk.Button(
            button_frame, text="üîÑ L√†m M·ªõi", command=self.load_vote_statistics
        )
        refresh_button.pack(side=tk.LEFT, padx=5)

        close_button = ttk.Button(
            button_frame, text="ƒê√≥ng", command=self.window.destroy
        )
        close_button.pack(side=tk.RIGHT, padx=5)

        # Status label
        self.status_label = ttk.Label(
            main_frame, text="", font=("TkDefaultFont", 9), foreground="blue"
        )
        self.status_label.pack(pady=(5, 0))

        # Load data
        self.load_vote_statistics()

    def load_vote_statistics(self):
        """T·∫£i v√† hi·ªÉn th·ªã th·ªëng k√™ vote."""
        # Clear existing data
        for item in self.tree.get_children():
            self.tree.delete(item)

        self.status_label["text"] = "ƒêang t·∫£i..."
        self.window.update()

        try:
            # Get consensus data
            consensus_list = get_prediction_consensus()

            if not consensus_list:
                self.status_label["text"] = "Kh√¥ng c√≥ d·ªØ li·ªáu d·ª± ƒëo√°n."
                self.status_label["foreground"] = "red"
                messagebox.showinfo(
                    "Kh√¥ng c√≥ d·ªØ li·ªáu",
                    "Kh√¥ng t√¨m th·∫•y d·ª± ƒëo√°n t·ª´ c√°c c·∫ßu ƒë√£ b·∫≠t.\n\n"
                    "H√£y ƒë·∫£m b·∫£o:\n"
                    "1. ƒê√£ B·∫¨T c√°c c·∫ßu trong 'Qu·∫£n L√Ω C·∫ßu'\n"
                    "2. ƒê√£ ch·∫°y 'C·∫≠p Nh·∫≠t Cache K2N'",
                    parent=self.window,
                )
                return

            # Populate tree
            for pair_key, vote_count, bridges_str in consensus_list:
                # Add color coding based on vote count
                tag = ""
                if vote_count >= 10:
                    tag = "high_vote"
                elif vote_count >= 5:
                    tag = "medium_vote"
                else:
                    tag = "low_vote"

                self.tree.insert(
                    "",
                    "end",
                    values=(pair_key, f"x{vote_count}", bridges_str),
                    tags=(tag,),
                )

            # Configure tags for color coding
            self.tree.tag_configure("high_vote", background="#90EE90")  # Light green
            self.tree.tag_configure("medium_vote", background="#FFE4B5")  # Moccasin
            self.tree.tag_configure("low_vote", background="white")

            # Update status
            total_pairs = len(consensus_list)
            max_vote = max([v[1] for v in consensus_list]) if consensus_list else 0
            self.status_label["text"] = (
                f"‚úÖ T√¨m th·∫•y {total_pairs} c·∫∑p s·ªë. Vote cao nh·∫•t: x{max_vote}"
            )
            self.status_label["foreground"] = "green"

            self.app.logger.log(
                f"ƒê√£ t·∫£i th·ªëng k√™ vote: {total_pairs} c·∫∑p s·ªë, vote cao nh·∫•t: x{max_vote}"
            )

        except Exception as e:
            self.status_label["text"] = f"L·ªói: {e}"
            self.status_label["foreground"] = "red"
            self.app.logger.log(f"L·ªói khi t·∫£i th·ªëng k√™ vote: {e}")
            messagebox.showerror(
                "L·ªói", f"Kh√¥ng th·ªÉ t·∫£i th·ªëng k√™ vote:\n{e}", parent=self.window
            )


--------------------------------------------------

=== FILE: ui\__init__.py ===


--------------------------------------------------

=== FILE: ui\popups\ui_backtest_popup.py ===
# T√™n file: ui/popups/ui_backtest_popup.py
# Popup hi·ªÉn th·ªã k·∫øt qu·∫£ backtest 30 ng√†y (D√πng chung cho L√¥ v√† ƒê·ªÅ)

import tkinter as tk
from tkinter import ttk


class BacktestPopup(tk.Toplevel):
    """
    Popup hi·ªÉn th·ªã k·∫øt qu·∫£ backtest 30 ng√†y.
    D√πng chung cho c·∫£ L√¥ v√† ƒê·ªÅ.
    """
    
    def __init__(self, parent, bridge_name, backtest_data):
        """
        Args:
            parent: Parent window
            bridge_name: T√™n c·∫ßu
            backtest_data: List c√°c dict v·ªõi format:
                [{'date': 'DD/MM/YYYY', 'pred': 'xx-yy', 'result': 'zz', 'is_win': True/False, 'status': 'ƒÇn/G√£y'}]
        """
        super().__init__(parent)
        
        self.bridge_name = bridge_name
        self.backtest_data = backtest_data or []
        
        self.title(f"Backtest 30 Ng√†y - {bridge_name}")
        self.geometry("700x500")
        self.transient(parent)
        self.grab_set()
        
        # T√≠nh th·ªëng k√™
        total_days = len(self.backtest_data)
        win_count = sum(1 for item in self.backtest_data if item.get('is_win', False))
        win_rate = (win_count / total_days * 100) if total_days > 0 else 0
        
        # Header v·ªõi th·ªëng k√™
        header_frame = ttk.Frame(self, padding=10)
        header_frame.pack(fill=tk.X)
        
        title_label = ttk.Label(
            header_frame,
            text=f"C·∫ßu: {bridge_name}",
            font=("Arial", 12, "bold")
        )
        title_label.pack(anchor=tk.W)
        
        stats_label = ttk.Label(
            header_frame,
            text=f"Th·∫Øng {win_count}/{total_days} ng√†y ({win_rate:.1f}%)",
            font=("Arial", 10)
        )
        stats_label.pack(anchor=tk.W, pady=(5, 0))
        
        # Treeview
        tree_frame = ttk.Frame(self, padding=10)
        tree_frame.pack(fill=tk.BOTH, expand=True)
        
        columns = ("date", "pred", "result", "status")
        self.tree = ttk.Treeview(
            tree_frame,
            columns=columns,
            show="headings",
            height=15
        )
        
        # C·∫•u h√¨nh c·ªôt
        self.tree.heading("date", text="Ng√†y")
        self.tree.heading("pred", text="D·ª± ƒêo√°n")
        self.tree.heading("result", text="K·∫øt Qu·∫£")
        self.tree.heading("status", text="Tr·∫°ng Th√°i")
        
        self.tree.column("date", width=120, anchor=tk.CENTER)
        self.tree.column("pred", width=100, anchor=tk.CENTER)
        self.tree.column("result", width=300, anchor=tk.W)
        self.tree.column("status", width=100, anchor=tk.CENTER)
        
        # Scrollbar
        scrollbar = ttk.Scrollbar(tree_frame, orient=tk.VERTICAL, command=self.tree.yview)
        self.tree.configure(yscrollcommand=scrollbar.set)
        
        self.tree.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        
        # Tags cho m√†u s·∫Øc
        self.tree.tag_configure("win", background="#D5E8D4")  # Xanh nh·∫°t
        self.tree.tag_configure("lose", background="#F8CECC")  # ƒê·ªè nh·∫°t
        
        # N·∫°p d·ªØ li·ªáu
        self._populate_data()
        
        # N√∫t ƒë√≥ng
        button_frame = ttk.Frame(self, padding=10)
        button_frame.pack(fill=tk.X)
        
        close_button = ttk.Button(button_frame, text="ƒê√≥ng", command=self.destroy)
        close_button.pack(side=tk.RIGHT)
        
        # Focus v√†o window
        self.focus_set()
    
    def _populate_data(self):
        """N·∫°p d·ªØ li·ªáu v√†o treeview"""
        for item in self.backtest_data:
            date = item.get('date', '')
            pred = item.get('pred', '')
            result = item.get('result', '')
            status = item.get('status', '')
            is_win = item.get('is_win', False)
            
            # Ch·ªçn tag d·ª±a tr√™n k·∫øt qu·∫£
            tag = "win" if is_win else "lose"
            
            self.tree.insert(
                "",
                tk.END,
                values=(date, pred, result, status),
                tags=(tag,)
            )



--------------------------------------------------

=== FILE: ui\popups\__init__.py ===
# Popups module
from .ui_backtest_popup import BacktestPopup

__all__ = ['BacktestPopup']



--------------------------------------------------

